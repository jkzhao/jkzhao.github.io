<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>jkzhao&#39;s blog</title>
  <subtitle>学习 总结 思考</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2016-08-05T07:52:49.302Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Zhao Jiankai</name>
    <email>jk.zhaocoder@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>安装部署Apache Hadoop (完全分布式模式并且实现NameNode HA和ResourceManager HA)</title>
    <link href="http://yoursite.com/2016/08/07/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Apache%20Hadoop%20(%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%BC%8F%E5%B9%B6%E4%B8%94%E5%AE%9E%E7%8E%B0NameNode%20HA%E5%92%8CResourceManager%20HA)/"/>
    <id>http://yoursite.com/2016/08/07/安装部署Apache Hadoop (完全分布式模式并且实现NameNode HA和ResourceManager HA)/</id>
    <published>2016-08-07T08:51:08.000Z</published>
    <updated>2016-08-05T07:52:49.302Z</updated>
    
    <content type="html">&lt;p&gt;关于Apache Hadoop的介绍以本地模式、伪分布式安装部署请参见上篇博文，本篇博文主要记录完全分布式部署，并实现NameNode高可用和ResourceManager高可用。&lt;/p&gt;
&lt;h1 id=&quot;环境规划&quot;&gt;&lt;a href=&quot;#环境规划&quot; class=&quot;headerlink&quot; title=&quot;环境规划&quot;&gt;&lt;/a&gt;环境规划&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;th&gt;运行的进程&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;hadoop16&lt;/td&gt;
&lt;td&gt;172.16.206.16&lt;/td&gt;
&lt;td&gt;CentOS 7.2&lt;/td&gt;
&lt;td&gt;JDK1.7、hadoop-2.7.2&lt;/td&gt;
&lt;td&gt;NameNode、DFSZKFailoverController(zkfc)、ResourceManager&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hadoop26&lt;/td&gt;
&lt;td&gt;172.16.206.26&lt;/td&gt;
&lt;td&gt;CentOS 6.5&lt;/td&gt;
&lt;td&gt;JDK1.7、hadoop-2.7.2&lt;/td&gt;
&lt;td&gt;NameNode、DFSZKFailoverController(zkfc)、ResourceManager&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hadoop27&lt;/td&gt;
&lt;td&gt;172.16.206.27&lt;/td&gt;
&lt;td&gt;CentOS 6.5&lt;/td&gt;
&lt;td&gt;JDK1.7、hadoop-2.7.2、Zookeeper&lt;/td&gt;
&lt;td&gt;DataNode、NodeManager、JournalNode、QuorumPeerMain&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hadoop28&lt;/td&gt;
&lt;td&gt;172.16.206.28&lt;/td&gt;
&lt;td&gt;CentOS 6.5&lt;/td&gt;
&lt;td&gt;JDK1.7、hadoop-2.7.2、Zookeeper&lt;/td&gt;
&lt;td&gt;DataNode、NodeManager、JournalNode、QuorumPeerMain&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hadoop29&lt;/td&gt;
&lt;td&gt;172.16.206.29&lt;/td&gt;
&lt;td&gt;CentOS 6.5&lt;/td&gt;
&lt;td&gt;JDK1.7、hadoop-2.7.2、Zookeeper&lt;/td&gt;
&lt;td&gt;DataNode、NodeManager、JournalNode、QuorumPeerMain&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;这里由于机器紧张，将NameNode和ResourceManager安装在一台机器上。在hadoop16主机上安装NameNode和ResourceManager使其处于active状态，在hadoop26上安装NameNode和ResourceManager使其处于standby状态。&lt;/p&gt;
&lt;p&gt;环境拓扑：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/32.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意：&lt;/strong&gt;这里由于实验环境，所以将NameNode和ResourceManager放在了一起，生产环境下应该将NameNode和ResourceManager放在单独的机器上。&lt;br&gt;&lt;br&gt;Hadoop2.0官方提供了两种HDFS HA的解决方案，一种是NFS，另一种是QJM。这两种共享数据的方案，NFS是操作系统层面的，JournalNode是hadoop层面的，这里我们使用简单的QJM集群进行数据共享。在该方案中，主备NameNode之间通过一组JournalNode同步元数据信息，一条数据只要成功写入多数JournalNode即认为写入成功。通常配置奇数个JournalNode。&lt;br&gt;&lt;br&gt;这里还配置了一个zookeeper集群(27,28,29主机)，用于ZKFC（DFSZKFailoverController）故障转移，当Active NameNode挂掉了，会自动切换Standby NameNode和ResourceManager为standby状态。同时27,28,29主机作为DataNode节点。&lt;/p&gt;
&lt;h1 id=&quot;配置集群各节点hosts文件&quot;&gt;&lt;a href=&quot;#配置集群各节点hosts文件&quot; class=&quot;headerlink&quot; title=&quot;配置集群各节点hosts文件&quot;&gt;&lt;/a&gt;配置集群各节点hosts文件&lt;/h1&gt;&lt;p&gt;在各节点，编辑hosts文件，配置好各节点主机名和ip地址的对应关系：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# vim /etc/hosts&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.16.206.16 hadoop16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.16.206.26 hadoop26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.16.206.27 hadoop27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.16.206.28 hadoop28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.16.206.29 hadoop29&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;安装JDK1-7&quot;&gt;&lt;a href=&quot;#安装JDK1-7&quot; class=&quot;headerlink&quot; title=&quot;安装JDK1.7&quot;&gt;&lt;/a&gt;安装JDK1.7&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Hadoop Java Versions&lt;/strong&gt; &lt;br&gt;&lt;br&gt;Version 2.7 and later of Apache Hadoop requires Java 7. It is built and tested on both OpenJDK and Oracle (HotSpot)’s JDK/JRE. &lt;br&gt;&lt;br&gt;Earlier versions (2.6 and earlier) support Java 6.&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# mkdir /usr/java&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# tar zxf /usr/local/jdk-7u80-linux-x64.gz -C /usr/java/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# vim /etc/profile&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export JAVA_HOME=/usr/java/jdk1.7.0_80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export PATH=$JAVA_HOME/bin:$PATH&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# source /etc/profile&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;安装依赖包ssh和rsync&quot;&gt;&lt;a href=&quot;#安装依赖包ssh和rsync&quot; class=&quot;headerlink&quot; title=&quot;安装依赖包ssh和rsync&quot;&gt;&lt;/a&gt;安装依赖包ssh和rsync&lt;/h1&gt;&lt;p&gt;对于Redhat/CentOS系列的，安装系统时一般都会默认安装openssh软件，里面包含了ssh客户端和ssh服务端，所以先检查下这个软件包是否安装了：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# yum list all openssh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果没有安装，安装：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# yum install -y openssh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在检查rsync软件包是否安装：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# yum list all rsync&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;各节点时间同步&quot;&gt;&lt;a href=&quot;#各节点时间同步&quot; class=&quot;headerlink&quot; title=&quot;各节点时间同步&quot;&gt;&lt;/a&gt;各节点时间同步&lt;/h1&gt;&lt;p&gt;采用NTP(Network Time Protocol)方式来实现, 选择一台机器, 作为集群的时间同步服务器, 然后分别配置服务端和集群其他机器。我这里以hadoop16机器时间为准，其他机器同这台机器时间做同步。&lt;/p&gt;
&lt;h2 id=&quot;NTP服务端&quot;&gt;&lt;a href=&quot;#NTP服务端&quot; class=&quot;headerlink&quot; title=&quot;NTP服务端&quot;&gt;&lt;/a&gt;NTP服务端&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装ntp服务&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# yum install ntp -y&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;配置/etc/ntp.conf，这边采用本地机器作为时间的原点&lt;br&gt;注释server列表：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;server 0.centos.pool.ntp.org iburst&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server 1.centos.pool.ntp.org iburst&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server 2.centos.pool.ntp.org iburst&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server 3.centos.pool.ntp.org iburst&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;添加如下内容：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;server 127.127.1.0 prefer&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;fudge 127.127.1.0 stratum 8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;logfile /var/log/ntp.log&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;启动ntpd服务&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# systemctl start ntpd&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查看ntp服务状态&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# systemctl status ntpd&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;加入开机启动&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# systemctl enable ntpd&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;NTP客户端&quot;&gt;&lt;a href=&quot;#NTP客户端&quot; class=&quot;headerlink&quot; title=&quot;NTP客户端&quot;&gt;&lt;/a&gt;NTP客户端&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装ntp&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# yum install ntpdate&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;配置crontab任务主动同步&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# crontab -e&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;*/10 * * * * /usr/sbin/ntpdate 172.16.206.16;hwclock -w&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;安装Zookeeper集群&quot;&gt;&lt;a href=&quot;#安装Zookeeper集群&quot; class=&quot;headerlink&quot; title=&quot;安装Zookeeper集群&quot;&gt;&lt;/a&gt;安装Zookeeper集群&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;对于Zookeeper集群的话，官方推荐的最小节点数为3个。&lt;/p&gt;
&lt;h2 id=&quot;安装配置zk&quot;&gt;&lt;a href=&quot;#安装配置zk&quot; class=&quot;headerlink&quot; title=&quot;安装配置zk&quot;&gt;&lt;/a&gt;安装配置zk&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;配置zk节点的hosts文件&lt;br&gt;配置zk节点的hosts文件：配置3台机器的ip地址和主机名的对应关系。上面已经做过了。这里选择3台安装zk：hadoop27，hadoop28，hadoop29。&lt;/li&gt;
&lt;li&gt;解压安装配置第一台zk&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# cd /usr/local/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# tar zxf zookeeper-3.4.6.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# cd zookeeper-3.4.6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;创建快照日志存放目录：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# mkdir dataDir&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;创建事务日志存放目录：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# mkdir dataLogDir&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;如果不配置dataLogDir，那么事务日志也会写在dataDir目录中。这样会严重影响zk的性能。因为在zk吞吐量很高的时候，产生的事务日志和快照日志太多。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# cd conf&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# mv zoo_sample.cfg zoo.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# vim zoo.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 存放数据文件&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;dataDir=/usr/local/zookeeper-3.4.6/dataDir&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 存放日志文件&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;dataLogDir=/usr/local/zookeeper-3.4.6/dataLogDir&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# zookeeper cluster，2888为选举端口，3888为心跳端口&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server.1=hadoop27:2888:3888&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server.2=hadoop28:2888:3888&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;server.3=hadoop29:2888:3888&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/33.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在我们配置的dataDir指定的目录下面，创建一个myid文件，里面内容为一个数字，用来标识当前主机，conf/zoo.cfg文件中配置的server.X中X为什么数字，则myid文件中就输入这个数字： &lt;br&gt;&lt;br&gt;hadoop27主机：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# echo &amp;quot;1&amp;quot; &amp;gt; /usr/local/zookeeper-3.4.6/dataDir/myid&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;远程复制第一台的zk到另外两台上，并修改myid文件为2和3&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# cd /usr/local/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# scp -rp zookeeper-3.4.6 root@172.16.206.28:/usr/local/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# echo &amp;quot;2&amp;quot; &amp;gt; /usr/local/zookeeper-3.4.6/dataDir/myid&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# scp -rp zookeeper-3.4.6 root@172.16.206.29:/usr/local/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# echo &amp;quot;3&amp;quot; &amp;gt; /usr/local/zookeeper-3.4.6/dataDir/myid&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;启动和关闭zk&quot;&gt;&lt;a href=&quot;#启动和关闭zk&quot; class=&quot;headerlink&quot; title=&quot;启动和关闭zk&quot;&gt;&lt;/a&gt;启动和关闭zk&lt;/h2&gt;&lt;p&gt;在ZooKeeper集群的每个结点上，执行启动ZooKeeper服务的脚本，如下所示：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop27 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh start&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop28 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh start&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop29 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh start&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;查看启动的进程：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/34.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;停止zk命令：&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# /usr/local/zookeeper-3.4.6/bin/zkServer.sh stop&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;测试zk集群&quot;&gt;&lt;a href=&quot;#测试zk集群&quot; class=&quot;headerlink&quot; title=&quot;测试zk集群&quot;&gt;&lt;/a&gt;测试zk集群&lt;/h2&gt;&lt;p&gt;可以通过ZooKeeper的脚本来查看启动状态，包括集群中各个结点的角色（或是Leader，或是Follower）：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop27 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh status&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;JMX enabled by default&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Mode: follower&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop28 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh status&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;JMX enabled by default&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Mode: leader&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop29 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh status&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;JMX enabled by default&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Mode: follower&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过上面状态查询结果可见，hadoop28是集群的Leader，其余的两个结点是Follower。&lt;br&gt;&lt;br&gt;另外，可以通过客户端脚本，连接到ZooKeeper集群上。对于客户端来说，ZooKeeper是一个整体，连接到ZooKeeper集群实际上感觉在独享整个集群的服务，所以，你可以在任何一个结点上建立到服务集群的连接。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop29 ~]# /usr/local/zookeeper-3.4.6/bin/zkCli.sh -server hadoop27:2181&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Connecting to localhost:2181&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,647 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,650 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=hadoop29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,650 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.7.0_80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,652 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,652 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/usr/java/jdk1.7.0_80/jre&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,652 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/usr/local/zookeeper-3.4.6/bin/../build/classes:/usr/local/zookeeper-3.4.6/bin/../build/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/usr/local/zookeeper-3.4.6/bin/../lib/log4j-1.2.16.jar:/usr/local/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/usr/local/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/usr/local/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../conf:.:/usr/java/jdk1.7.0_80/lib/dt.jar:/usr/java/jdk1.7.0_80/lib/tools.jar&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,652 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/tmp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&amp;lt;NA&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Linux&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=amd64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=2.6.32-431.el6.x86_64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=root&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/root&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/root&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:26:57,654 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@279ac931&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop29 ~]# /usr/local/zookeeper-3.4.6/bin/zkCli.sh -server hadoop27:2181&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Connecting to hadoop27:2181&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,216 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,219 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=hadoop29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,219 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.7.0_80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/usr/java/jdk1.7.0_80/jre&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/usr/local/zookeeper-3.4.6/bin/../build/classes:/usr/local/zookeeper-3.4.6/bin/../build/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/usr/local/zookeeper-3.4.6/bin/../lib/log4j-1.2.16.jar:/usr/local/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/usr/local/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/usr/local/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../conf:.:/usr/java/jdk1.7.0_80/lib/dt.jar:/usr/java/jdk1.7.0_80/lib/tools.jar&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/tmp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&amp;lt;NA&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Linux&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=amd64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,222 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=2.6.32-431.el6.x86_64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,222 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=root&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,222 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/root&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,222 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/root&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,223 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=hadoop27:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@194d62f1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Welcome to ZooKeeper!&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,245 [myid:] - INFO  [main-SendThread(hadoop27:2181):ClientCnxn$SendThread@975] - Opening socket connection to server hadoop27/172.16.206.27:2181. Will not attempt to authenticate using SASL (unknown error)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2016-07-18 21:29:48,249 [myid:] - INFO  [main-SendThread(hadoop27:2181):ClientCnxn$SendThread@852] - Socket connection established to hadoop27/172.16.206.27:2181, initiating session&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;JLine support is enabled&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[zk: hadoop27:2181(CONNECTING) 0] 2016-07-18 21:29:48,356 [myid:] - INFO  [main-SendThread(hadoop27:2181):ClientCnxn$SendThread@1235] - Session establishment complete on server hadoop27/172.16.206.27:2181, sessionid = 0x155fc2e082e0000, negotiated timeout = 30000&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;WATCHER::&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;WatchedEvent state:SyncConnected type:None path:null&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[zk: hadoop27:2181(CONNECTED) 0]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输入quit，可以退出。&lt;/p&gt;
&lt;h2 id=&quot;脚本定期清理zk快照和日志文件&quot;&gt;&lt;a href=&quot;#脚本定期清理zk快照和日志文件&quot; class=&quot;headerlink&quot; title=&quot;脚本定期清理zk快照和日志文件&quot;&gt;&lt;/a&gt;脚本定期清理zk快照和日志文件&lt;/h2&gt;&lt;p&gt;正常运行过程中，ZK会不断地把快照数据和事务日志输出到dataDir和dataLogDir这两个目录，并且如果没有人为操作的话，ZK自己是不会清理这些文件的。&lt;br&gt;&lt;br&gt;我这里采用脚本切割。将脚本上传到/usr/local/zookeeper-3.4.6/目录下。脚本内容如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;#!/bin/bash&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;###Description:This script is used to clear zookeeper snapshot file and transaction logs.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;###Written by: jkzhao - jkzhao@wisedu.com&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;###History: 2016-04-08 First release.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Snapshot file dir.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;dataDir=/usr/local/zookeeper-3.4.6/dataDir/version-2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Transaction logs dir.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;dataLogDir=/usr/local/zookeeper-3.4.6/dataLogDir/version-2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Reserved 5 files.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;COUNT=5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ls -t $dataDir/snapshot.* | tail -n +$[$COUNT+1] | xargs rm -f&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ls -t $dataLogDir/log.* | tail -n +$[$COUNT+1] | xargs rm -f&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;赋予脚本执行权限：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# chmod +x clean_zklog.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;配置周期性任务，每个星期日的0点0分执行：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# crontab -e&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0 0 * * 0 /usr/local/zookeeper-3.4.6/clean_zklog.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;所有zk节点都得配置脚本和周期性任务。&lt;/p&gt;
&lt;h1 id=&quot;添加Hadoop运行用户&quot;&gt;&lt;a href=&quot;#添加Hadoop运行用户&quot; class=&quot;headerlink&quot; title=&quot;添加Hadoop运行用户&quot;&gt;&lt;/a&gt;添加Hadoop运行用户&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# groupadd hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# useradd -g hadoop hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# echo &amp;quot;wisedu&amp;quot; | passwd --stdin hadoop &amp;amp;&amp;gt; /dev/null&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;所有节点都得添加hadoop用户。&lt;/p&gt;
&lt;h1 id=&quot;配置主节点登录自己和其他节点不需要输入密码&quot;&gt;&lt;a href=&quot;#配置主节点登录自己和其他节点不需要输入密码&quot; class=&quot;headerlink&quot; title=&quot;配置主节点登录自己和其他节点不需要输入密码&quot;&gt;&lt;/a&gt;配置主节点登录自己和其他节点不需要输入密码&lt;/h1&gt;&lt;p&gt;这里的主节点指的是NameNode，ResourceManager。配置hadoop16主机(Active)登录hadoop16，hadoop26，hadoop27，hadoop28，hadoop29主机免密码。还要配置hadoop26主机(Standby)登录hadoop16，hadoop26,hadoop27，hadoop28，hadoop29主机免密码。 (也可以不配置，每个节点一个一个启动服务，最好不要这样做）。&lt;br&gt;hadoop用户登录shell：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;配置hadoop16主机(Active)登录hadoop16，hadoop26，hadoop27，hadoop28，hadoop29主机免密码&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-keygen -t rsa -P &amp;apos;&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop29&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;配置hadoop26主机(Standby)登录hadoop16，hadoop26，hadoop27，hadoop28，hadoop29主机免密码&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-keygen -t rsa -P &amp;apos;&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop29&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;安装hadoop&quot;&gt;&lt;a href=&quot;#安装hadoop&quot; class=&quot;headerlink&quot; title=&quot;安装hadoop&quot;&gt;&lt;/a&gt;安装hadoop&lt;/h1&gt;&lt;h2 id=&quot;安装配置master节点-hadoop16主机&quot;&gt;&lt;a href=&quot;#安装配置master节点-hadoop16主机&quot; class=&quot;headerlink&quot; title=&quot;安装配置master节点(hadoop16主机)&quot;&gt;&lt;/a&gt;安装配置master节点(hadoop16主机)&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;将安装包上传至//usr/local目录下并解压&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop16 ~]# cd /usr/local/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop16 local]# tar zxf hadoop-2.7.2.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop16 local]# ln -sv hadoop-2.7.2 hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop16 local]# cd hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop16 hadoop]# mkdir logs&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop16 hadoop]# chmod g+w logs&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop16 hadoop]# chown -R hadoop:hadoop ./*&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop16 hadoop]# chown -R hadoop:hadoop /usr/local/hadoop-2.7.2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;配置hadoop环境变量&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@hadoop16 hadoop]# vim /etc/profile&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# HADOOP&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export HADOOP_HOME=/usr/local/hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export PATH=$PATH:$&amp;#123;HADOOP_HOME&amp;#125;/bin:$&amp;#123;HADOOP_HOME&amp;#125;/sbin&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;修改文件hadoop-env.sh和yarn-env.sh&lt;br&gt;Hadoop的各守护进程依赖于JAVA_HOME环境变量，可在这两个文件中配置特定的JAVA环境。此处仅需要修改hadoop-env.sh文件。此外，Hadoop大多数守护进程默认使用的堆大小为1GB，但现实应用中，可能需要对其各类进程的堆内存大小做出调整，这只需要编辑这两个文件中的相关环境变量值即可，例如HADOOP_HEAPSIZE、HADOOP_JOB_HISTORY_HEAPSIZE、JAVA_HEAP_SIZE和YARN_HEAP_SIZE等。&lt;br&gt;&lt;br&gt;hadoop用户登录shell，或者root用户登录，su - hadoop。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/35.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;修改配置文件&lt;br&gt;hadoop用户登录shell，或者root用户登录，su - hadoop。&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ cd /usr/local/hadoop/etc/hadoop/&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;修改core-site.xml，&lt;/strong&gt;该文件包含了NameNode主机地址以及其监听RPC端口等信息，对于伪分布式模式的安装来说，其主机地址是localhost；对于完全分布式中master节点的主机名称或者ip地址；如果配置NameNode是HA，指定HDFS的nameservice为一个自定义名称，然后在hdfs-site.xml配置NameNode节点的主机信息。NameNode默认的RPC端口是8020。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- 指定hdfs的nameservice为ns1 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hdfs://ns1&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- 指定hadoop临时目录 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;/usr/local/hadoop/tmp&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- 指定zookeeper地址 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;ha.zookeeper.quorum&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hadoop27:2181,hadoop28:2181,hadoop29:2181&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修改hdfs-site.xml，&lt;/strong&gt;该文件主要用于配置HDFS相关的属性，例如复制因子（即数据块的副本数）、NN和DN用于存储数据的目录等。数据块的副本数对于伪分布式的Hadoop应该为1，完全分布式模式下默认数据副本是3份。在这个配置文件中还可以配置NN和DN用于存储的数据的目录。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;70&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.nameservices&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;ns1&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.ha.namenodes.ns1&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;nn1,nn2&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- nn1的RPC通信地址 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.namenode.rpc-address.ns1.nn1&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hadoop16:9000&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- nn1的http通信地址 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.namenode.http-address.ns1.nn1&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hadoop16:50070&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- nn2的RPC通信地址 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.namenode.rpc-address.ns1.nn2&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hadoop26:9000&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- nn2的http通信地址 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.namenode.http-address.ns1.nn2&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hadoop26:50070&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.namenode.shared.edits.dir&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;qjournal://hadoop27:8485;hadoop28:8485;hadoop29:8485/ns1&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.journalnode.edits.dir&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;/usr/local/hadoop/journaldata&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- 开启NameNode失败自动切换 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.ha.automatic-failover.enabled&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- 配置失败自动切换实现方式 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.client.failover.proxy.provider.ns1&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.ha.fencing.methods&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                        sshfence&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                        shell(/bin/true)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.ha.fencing.ssh.private-key-files&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;/home/hadoop/.ssh/id_rsa&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;!-- 配置sshfence隔离机制超时时间 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.ha.fencing.ssh.connect-timeout&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;30000&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;如果需要其它用户对hdfs有写入权限，还需要在hdfs-site.xml添加一项属性定义。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &amp;lt;name&amp;gt;dfs.permissions&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修改mapred-site.xml，&lt;/strong&gt;该文件用于配置集群的MapReduce framework，此处应该指定yarn，另外的可用值还有local和classic。mapred-site.xml默认是不存在，但有模块文件mapred-site.xml.template，只需要将其复制mapred-site.xml即可。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 hadoop]$ cp mapred-site.xml.template mapred-site.xml&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 hadoop]$ vim mapred-site.xml&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;!-- 指定mr框架为yarn方式 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;修改yarn-site.xml，&lt;/strong&gt;该文件用于配置YARN进程及YARN的相关属性。首先需要指定ResourceManager守护进程的主机和监听的端口，对于伪分布式模型来来讲，其主机为localhost，默认的端口是8032；其次需要指定ResourceManager使用的scheduler，以及NodeManager的辅助服务。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;!-- 开启RM高可用 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.ha.enabled&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;!-- 指定RM的cluster id --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.cluster-id&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;yrc&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;!-- 指定RM的名字 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.ha.rm-ids&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;rm1,rm2&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;!-- 分别指定RM的地址 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.hostname.rm1&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;hadoop16&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.hostname.rm2&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;hadoop26&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;!-- 指定zk集群地址 --&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.zk-address&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;hadoop27:2181,hadoop28:2181,hadoop29:2181&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修改slaves，&lt;/strong&gt;该文件存储了当前集群的所有slave节点的列表，对于伪分布式模型，其文件内容仅应该是你localhost，这也的确是这个文件的默认值。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 hadoop]$ vim slaves&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hadoop27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hadoop28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hadoop29&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装配置其他节点&quot;&gt;&lt;a href=&quot;#安装配置其他节点&quot; class=&quot;headerlink&quot; title=&quot;安装配置其他节点&quot;&gt;&lt;/a&gt;安装配置其他节点&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;这里由于节点数目少，没有使用ansible等自动化工具。 &lt;br&gt;&lt;br&gt;&lt;strong&gt;重复操作解压、配置环境变量，参照前面。&lt;/strong&gt; &lt;br&gt;&lt;br&gt;Hadoop集群的各节点配置文件都是一样的，我们可以将master节点上的配置文件scp到其他节点上：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ scp -p /usr/local/hadoop/etc/hadoop/* hadoop@hadoop26:/usr/local/hadoop/etc/hadoop/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ scp -p /usr/local/hadoop/etc/hadoop/* hadoop@hadoop27:/usr/local/hadoop/etc/hadoop/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ scp -p /usr/local/hadoop/etc/hadoop/* hadoop@hadoop28:/usr/local/hadoop/etc/hadoop/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ scp -p /usr/local/hadoop/etc/hadoop/* hadoop@hadoop29:/usr/local/hadoop/etc/hadoop/&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;启动hadoop&quot;&gt;&lt;a href=&quot;#启动hadoop&quot; class=&quot;headerlink&quot; title=&quot;启动hadoop&quot;&gt;&lt;/a&gt;启动hadoop&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;请严格按照下面的步骤启动。&lt;/p&gt;
&lt;h2 id=&quot;启动Zookeeper集群&quot;&gt;&lt;a href=&quot;#启动Zookeeper集群&quot; class=&quot;headerlink&quot; title=&quot;启动Zookeeper集群&quot;&gt;&lt;/a&gt;启动Zookeeper集群&lt;/h2&gt;&lt;p&gt;分别在hadoop27、hadoop28、hadoop29上启动zk，前面已经启动好了，不再重复。&lt;/p&gt;
&lt;h2 id=&quot;启动journalnode&quot;&gt;&lt;a href=&quot;#启动journalnode&quot; class=&quot;headerlink&quot; title=&quot;启动journalnode&quot;&gt;&lt;/a&gt;启动journalnode&lt;/h2&gt;&lt;p&gt;hadoop用户登录shell，分别在在hadoop27、hadoop28、hadoop29上执行：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop27 ~]$ /usr/local/hadoop/sbin/hadoop-daemon.sh start journalnode&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;运行jps命令检验，hadoop27、hadoop28、hadoop29上多了JournalNode进程。&lt;/p&gt;
&lt;h2 id=&quot;格式化HDFS&quot;&gt;&lt;a href=&quot;#格式化HDFS&quot; class=&quot;headerlink&quot; title=&quot;格式化HDFS&quot;&gt;&lt;/a&gt;格式化HDFS&lt;/h2&gt;&lt;p&gt;在HDFS的NN启动之前需要先初始化其用于存储数据的目录，可以在hdfs-site.xml配置文件中使用dfs.namenode.name.dir属性定义HDFS元数据持久存储路径，默认为${hadoop.tmp.dir}/dfs/name，这里是存放在JournalNode中；dfs.datanode.data.dir属性定义DataNode用于存储数据块的目录路径，默认为${hadoop.tmp.dir}/dfs/data。如果指定的目录不存在，格式化命令会自动创建之；如果事先存在，请确保其权限设置正确，此时格式化操作会清除其内部的所有数据并重新建立一个新的文件系统。 &lt;br&gt;&lt;br&gt;在hadoop16(Active)上执行命令:&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ hdfs namenode -format&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/36.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/usr/local/hadoop/tmp。&lt;br&gt;&lt;br&gt;启动hadoop16主机上的NameNode：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ hadoop-daemon.sh start namenode&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后在hadoop26(Standby)主机上执行如下命令，同步hadoop16主机上的NameNode元数据信息：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ hdfs namenode –bootstrapStandby&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;同步完成后，停止hadoop16主机上的NameNode：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ hadoop-daemon.sh stop namenode&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这里如果不启动Active的NameNode，就在Standby主机上同步，会报如下的错误：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/37.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这是因为没有启动active namenode，因为standby namenode是通过active namenode的9000端口通讯的。若active namenode没有启动，则9000没有程序监听提供服务。 &lt;br&gt;&lt;br&gt;当然也可以不启动Active NameNode就进行同步元数据信息，就是直接用命令拷贝Active主机上的元数据信息目录到Standby主机上，但是不建议这么做：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 hadoop]$ scp -r tmp/ hadoop@hadoop26:/usr/local/hadoop&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;格式化ZKFC-仅在hadoop16上执行即可&quot;&gt;&lt;a href=&quot;#格式化ZKFC-仅在hadoop16上执行即可&quot; class=&quot;headerlink&quot; title=&quot;格式化ZKFC(仅在hadoop16上执行即可)&quot;&gt;&lt;/a&gt;格式化ZKFC(仅在hadoop16上执行即可)&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ hdfs zkfc -formatZK&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/38.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;启动HDFS-在hadoop16上执行&quot;&gt;&lt;a href=&quot;#启动HDFS-在hadoop16上执行&quot; class=&quot;headerlink&quot; title=&quot;启动HDFS(在hadoop16上执行)&quot;&gt;&lt;/a&gt;启动HDFS(在hadoop16上执行)&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ /usr/local/hadoop/sbin/start-dfs.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/39.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可以在各主机执行jps，查看启动的进程：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/40.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/41.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/42.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;启动YARN&quot;&gt;&lt;a href=&quot;#启动YARN&quot; class=&quot;headerlink&quot; title=&quot;启动YARN&quot;&gt;&lt;/a&gt;启动YARN&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;还是在hadoop16上执行start-yarn.sh，这是因为没有把namenode和resourcemanager分开，生产环境需要把他们分开，他们分开了就要分别在不同的机器上启动。&lt;br&gt;&lt;br&gt;&lt;strong&gt;启动yarn(在hadoop16上)：&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ /usr/local/hadoop/sbin/start-yarn.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/43.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;启动yarn standby(在hadoop26上)：&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$  /usr/local/hadoop/sbin/yarn-daemon.sh start resourcemanager&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;可以在各节点执行jps，查看启动的进程：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/44.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/45.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/46.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;停止hadoop&quot;&gt;&lt;a href=&quot;#停止hadoop&quot; class=&quot;headerlink&quot; title=&quot;停止hadoop&quot;&gt;&lt;/a&gt;停止hadoop&lt;/h1&gt;&lt;p&gt;停止HDFS集群：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ stop-dfs.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;停止YARN集群：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ stop-yarn.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;停止ResourceManager(Standby)：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ yarn-daemon.sh stop resourcemanager&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;关于Apache Hadoop的介绍以本地模式、伪分布式安装部署请参见上篇博文，本篇博文主要记录完全分布式部署，并实现NameNode高可用和ResourceManager高可用。&lt;/p&gt;
&lt;h1 id=&quot;环境规划&quot;&gt;&lt;a href=&quot;#环境规划&quot; class=&quot;heade
    
    </summary>
    
    
      <category term="大数据，Hadoop" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%EF%BC%8CHadoop/"/>
    
  </entry>
  
  <entry>
    <title>安装部署Apache Hadoop (本地模式和伪分布式)</title>
    <link href="http://yoursite.com/2016/08/04/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Apache%20Hadoop%20(%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F%E5%92%8C%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F)/"/>
    <id>http://yoursite.com/2016/08/04/安装部署Apache Hadoop (本地模式和伪分布式)/</id>
    <published>2016-08-04T00:48:36.000Z</published>
    <updated>2016-08-04T08:44:33.091Z</updated>
    
    <content type="html">&lt;h1 id=&quot;Hadoop版本&quot;&gt;&lt;a href=&quot;#Hadoop版本&quot; class=&quot;headerlink&quot; title=&quot;Hadoop版本&quot;&gt;&lt;/a&gt;Hadoop版本&lt;/h1&gt;&lt;h2 id=&quot;Hadoop版本种类&quot;&gt;&lt;a href=&quot;#Hadoop版本种类&quot; class=&quot;headerlink&quot; title=&quot;Hadoop版本种类&quot;&gt;&lt;/a&gt;Hadoop版本种类&lt;/h2&gt;&lt;p&gt;目前Hadoop发行版非常多，有华为发行版、Intel发行版、Cloudera发行版（CDH）等，所有这些发行版均是基于Apache Hadoop衍生出来的，之所以有这么多的版本，完全是由&lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Apache Hadoop的开源协议&lt;/a&gt;决定的：任何人可以对其进行修改，并作为开源或商业产品发布/销售。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;国内绝大多数公司发行版是收费的，比如Intel发行版、华为发行版等，尽管这些发行版增加了很多开源版本没有的新feature，但绝大多数公司选择Hadoop版本时会将把是否收费作为重要指标，不收费的Hadoop版本主要有三个（均是国外厂商），分别是：Cloudera版本(Cloudera’s Distribution Including Apache Hadoop，简称“CDH”)、Apache基金会hadoop、Hortonworks版本(Hortonworks Data Platform，简称“HDP”)。按顺序代表了，在国内的使用率，CDH和HDP虽然是收费版本，但是他们是开源的，只是收取服务费用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Apache社区版本：&lt;/strong&gt;&lt;br&gt;完全开源，免费，非商业。apache社区的hadoop版本分枝较多，而且部分hadoop存在bug。在选择hadoop，hbase，hive等时，需要考虑兼容性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cloudera版本：&lt;/strong&gt;&lt;br&gt;开源，免费，有商业和非商业版本。是在apache社区版本的hadoop基础上，选择相对稳定版本的hadoop，并在此基础上，进行bug修改和维护。使用者不必考虑hadoop，hbase，hive等在使用过程中，版本兼容性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hortonworks版本：&lt;/strong&gt;&lt;br&gt;开源，免费，有商业和非商业版本。是在Apache基础上修改，具有apache的特色。&lt;/p&gt;
&lt;h2 id=&quot;Apache-Hadoop版本衍化&quot;&gt;&lt;a href=&quot;#Apache-Hadoop版本衍化&quot; class=&quot;headerlink&quot; title=&quot;Apache Hadoop版本衍化&quot;&gt;&lt;/a&gt;Apache Hadoop版本衍化&lt;/h2&gt;&lt;p&gt;Apache Hadoop版本分为两代，我们将第一代Hadoop称为Hadoop 1.0，第二代Hadoop称为Hadoop 2.0。第一代Hadoop包含三个大版本，分别是0.20.x，0.21.x和0.22.x，其中，0.20.x最后演化成1.0.x，变成了稳定版，而0.21.x和0.22.x则NameNode HA等新的重大特性。第二代Hadoop包含两个版本，分别是0.23.x和2.x，它们完全不同于Hadoop 1.0，是一套全新的架构，均包含HDFS Federation和YARN两个系统，相比于0.23.x，2.x增加了NameNode HA和Wire-compatibility两个重大特性。经过上面的大体解释，大家可能明白了Hadoop以重大特性区分各个版本的，总结起来，用于区分Hadoop版本的特性有以下几个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Append 支持文件追加功能，如果想使用HBase，需要这个特性。&lt;/li&gt;
&lt;li&gt;RAID 在保证数据可靠的前提下，通过引入校验码较少数据块数目.&lt;/li&gt;
&lt;li&gt;Symlink支持HDFS文件链接&lt;/li&gt;
&lt;li&gt;Security Hadoop安全。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;需要注意的是，Hadoop 2.0主要由Yahoo独立出来的hortonworks公司主持开发。&lt;/p&gt;
&lt;p&gt;2013年10月，Hadoop 2.0发布。关键特性包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;YARN&lt;br&gt;YARN是“Yet Another Resource Negotiator”的简称，它是Hadoop 2.0引入的一个全新的通用资源管理系统，可在其之上运行各种应用程序和框架，比如MapReduce、Tez、Storm等，它的引入使得各种应用运行在一个集群中成为可能。YARN是在MRv1基础上衍化而来的，是MapReduce发展到一定程度的必然产物，它的出现使得Hadoop计算类应用进入平台化时代，博客中包含大量介绍YARN的文章，有兴趣的读者可阅读：&lt;a href=&quot;http://dongxicheng.org/category/mapreduce-nextgen/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://dongxicheng.org/category/mapreduce-nextgen/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;HDFS单点故障得以解决&lt;br&gt;Hadoop 2.2.0同时解决了NameNode单点故障问题和内存受限问题，其中，单点故障是通过主备NameNode切换实现的，这是一种古老的解决服务单点故障的方案，主备NameNode之间通过一个共享存储同步元数据信息，因此共享存储系统的选择称为关键，而Hadoop则提供了NFS、QJM和Bookeeper三种可选的共享存储系统，具体可阅读我的这篇文章：Hadoop 2.0单点故障问题方案总结。&lt;/li&gt;
&lt;li&gt;HDFS Federation&lt;br&gt;前面提到HDFS 的NameNode存在内存受限问题，该问题也在2.2.0版本中得到了解决。这是通过HDFS Federation实现的，它允许一个HDFS集群中存在多个NameNode，每个NameNode分管一部分目录，而不同NameNode之间彼此独立，共享所有DataNode的存储资源，注意，NameNode Federation中的每个NameNode仍存在单点问题，需为每个NameNode提供一个backup以解决单点故障问题。&lt;/li&gt;
&lt;li&gt;HDFS快照&lt;br&gt;HDFS快照是指HDFS文件系统（或者子系统）在某一时刻的只读镜像，它的出现使得管理员可定时为重要文件或目录做快照，以防止数据误删、丢失等。具体可阅读：Snapshots for HDFS（使用说明），Support for RW/RO snapshots in HDFS。&lt;br&gt;通过NFSv3访问HDFS&lt;br&gt;NFS允许用户像访问本地文件系统一样访问远程文件系统，而将NFS引入HDFS后，用户可像读写本地文件一样读写HDFS上的文件，大大简化了HDFS使用，这是通过引入一个NFS gateway服务实现的，该服务能将NFS协议转换为HDFS访问协议，具体如下图所示。有兴趣的读者可阅读：Support NFSv3 interface to HDFS，以及相关设计文档：HDFS NFS Gateway。&lt;/li&gt;
&lt;li&gt;支持Windows操作系统&lt;br&gt;在2.2.0版本之前，Hadoop仅支持Linux操作系统，而Windows仅作为实验平台使用。从2.2.0开始，Hadoop开始支持Windows操作系统，具体可阅读我之前写的一篇文章：Hadoop For Windows。&lt;/li&gt;
&lt;li&gt;兼容1.x上运行的MapReduce应用程序与Hadoop生态系统其他系统进行了充分的集成测试&lt;br&gt;除了HDFS、MapReduce和YARN这三个核心系统外，Hadoop生态系统还包括Hbase、Hive、Pig等系统，这些系统底层依赖于Hadoop内核，而相比于Hadoop 1.0，Hadoop 2.0的最大变化出现在内核（HDFS、MapReduce和YARN），但与生态系统中其他系统进行集成测试是必需的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;除了以上特性外，Apache官方还给出了两个特殊说明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;HDFS变化：HDFS的symlinks（类似于Linux中的软连接）被将移到了2.3.0版本中&lt;/li&gt;
&lt;li&gt;YARN/MapReduce注意事项：管理员在NodeManager上设置ShuffleHandler service时，要采用“mapreduce_shuffle”，而非之前的“mapreduce.shuffle”作为属性值。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;新版本不仅增强了核心平台的大量功能，同时还修复了大量bug。新版本对HDFS做了两个非常重要的增强：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;支持异构的存储层次；&lt;/li&gt;
&lt;li&gt;通过数据节点为存储在HDFS中的数据提供了内存缓存功能。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;借助于HDFS对异构存储层次的支持，我们将能够在同一个Hadoop集群上使用不同的存储类型。此外我们还可以使用不同的存储媒介——例如商业磁盘、企业级磁盘、SSD或者内存等——更好地权衡成本和收益。如果你想更详细地了解与该增强相关的信息，那么可以访问这里。类似地，在新版本中我们还能使用Hadoop集群中的可用内存集中地缓存并管理数据节点内存中的数据集。MapReduce、Hive、Pig等类似的应用程序将能够申请内存进行缓存，然后直接从数据节点的地址空间中读取内容，通过完全避免磁盘操作极大地提高扫描效率。Hive现在正在为ORC文件实现一个非常有效的零复制读取路径，该功能就使用了这项新技术。&lt;br&gt;在YARN方面，令我们非常兴奋的事情是资源管理器自动故障转移功能已经进入尾声，虽然在2.3.0这个版本中该功能还没有被发布，但是极有可能会包含在Hadoop-2.4中。此外，2.3.0版本还对YARN做了一些关键的运维方面的增强，例如更好的日志、错误处理和诊断等。&lt;br&gt;MapReduce的一个关键增强MAPREDUCE-4421。借助于该功能我们已经不再需要在每一台机器上安装MapReduce二进制程序，仅仅需要通过YARN分布式缓存将一个MapReduce包复制到HDFS中就可以了。当然，新版本还包含大量的bug修复以及其他方面的增强。例如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;YarnClientImpl类中的异步轮询操作引入了超时；&lt;/li&gt;
&lt;li&gt;修复了RMFatalEventDispatcher没有记录事件原因的问题；&lt;/li&gt;
&lt;li&gt;HA配置不会影响节点管理器的RPC地址；&lt;/li&gt;
&lt;li&gt;RM Web UI和REST API统一使用YarnApplicationState；&lt;/li&gt;
&lt;li&gt;在RpcResponseHeader中包含RPC错误信息，而不是将其分开发送；&lt;/li&gt;
&lt;li&gt;向jetty/httpserver中添加了请求日志；&lt;/li&gt;
&lt;li&gt;修复了将dfs.checksum.type定义为NULL之后写文件和hflush会抛出java.lang.ArrayIndexOutOfBoundsException的问题。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2014年4月，Hadoop 2.4.0发布。关键特性包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;HDFS支持访问控制列表（ACLs,Access Control Lists）；&lt;/li&gt;
&lt;li&gt;原生支持HDFS滚动升级；&lt;/li&gt;
&lt;li&gt;HDFS FSImage用到了 protocol-buffers，从而可以平滑地升级；&lt;/li&gt;
&lt;li&gt;HDFS完全支持HTTPS；&lt;/li&gt;
&lt;li&gt;YARN ResourceManager支持自动故障转移，解决了YARN ResourceManager的单点故障；&lt;/li&gt;
&lt;li&gt;对YARN的Application History Server和 pplication Timeline Server上的新应用加强了支持；&lt;/li&gt;
&lt;li&gt;通过抢占使得YARN Capacity Scheduler支持强SLAs协议；&lt;br&gt;安全对于Hadoop来说至关重要，所以在Hadoop 2.4.0版本中对HDFS的所有访问（包括WebHDFS, HsFTP甚至是web-interfaces）都支持了HTTPS。在Hadoop 2.4.0解决了ResourceManager的单点故障。这样会在集群中存在两个ResourceManager，其中一个处于Active；另一个处于　　standby。当Active的出现故障，这样Hadoop可以自动平滑地切换到另外一个ResourceManager，这个新的ResourceManager将会自动的重启那些提交的applications。在下一阶段，Hadoop将会增加一个热standby（add a hot standby），这个standby可以继续从故障点运行的应用程序，以保存任何已经完成的工作。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2014年8月，Hadoop 2.5.0发布。关键特性包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Common&lt;ul&gt;
&lt;li&gt;使用HTTP代理服务器时认证改进。当通过代理服务器使用WebHDFS时这是非常有用的。&lt;/li&gt;
&lt;li&gt;增加了一个新的Hadoop指标监控sink，允许直接写到Graphite。&lt;/li&gt;
&lt;li&gt;Hadoop文件系统兼容相关的规范工作。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;HDFS&lt;ul&gt;
&lt;li&gt;支持 POSIX风格的扩展文件系统。更多细节查看Extended Attributes in HDFS文档。&lt;/li&gt;
&lt;li&gt;支持离线image浏览，客户端现在可以通过WebHDFS的API浏览一个fsimage。&lt;/li&gt;
&lt;li&gt;NFS网关得到大量可支持性的改进和bug修复。Hadoop portmapper不在需要运行网关，网关现在可以拒绝没有权限的端口的连接。&lt;/li&gt;
&lt;li&gt;SecondaryNameNode, JournalNode, and DataNode 的web UI已经使用HTML5和JS美化。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;YARN&lt;ul&gt;
&lt;li&gt;YARN的REST API现在支持写/修改操作。用户可以用REST API提交和杀死应用程序。&lt;/li&gt;
&lt;li&gt;时间线存储到YARN，用来存储一个应用通用的和特殊的信息，支持Kerberos认证。&lt;/li&gt;
&lt;li&gt;公平调度器支持动态分层用户队列，运行时，用户队列在任一指定的父队列中被动态的创建。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2014年11月，Hadoop 2.6.0发布。关键特性包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Common&lt;br&gt;Hadoop Key Management Server（KMS）是一个基于HadoopKeyProvider API编写的密钥管理服务器。他提供了一个client和一个server组件，client和server之间基于HTTP协议使用REST API通信。Client是一个KeyProvider的实现，使用KMS HTTP REST API与KMS交互。KMS和它的client有内置的安全机制，支持HTTP SPNEGO Kerberos认证和HTTPS安全传输。KMS是一个Java Web应用程序，运行在与Hadoop发行版绑定在一起的预先配置好的Tomcat服务器上。&lt;/li&gt;
&lt;li&gt;Tracing&lt;br&gt;HDFS-5274增加了追踪通过HDFS的请求的功能，此功能使用了开源的库，HTrace。大家可以看一下HTrace，功能很强大，Cloudera开源出来的。&lt;/li&gt;
&lt;li&gt;HDFS&lt;ul&gt;
&lt;li&gt;Transparent Encryption，HDFS实现了一个透明的，端到端的加密方式。一旦配置了加密，从HDFS读出数据解密和写入数据加密的过程对用户应用程序代码带来说都是透明的。加密过程是端到端的，这意味着数据只能在客户端被加密解密。HDFS从来不存储，也不访问未加密的数据和数据加密密钥。这样满足了加密过程的两个典型的需求：at-rest encryption（静态加密，也就是说，数据持久化在像硬盘这样的媒介上），in-transit encryption（在途加密，例如，当数据在网络中传输的时候）。&lt;/li&gt;
&lt;li&gt;Storage SSD &amp;amp;&amp;amp; Memory。ArchivalStorage（档案存储器）是将计算能力与不断增长的存储能力分离。拥有高密度低成本的存储但是计算能力较低的节点将变得可用，可以在集群中做冷存储。增加更多的节点作为冷存储可以提高集群的存储能力，跟集群的计算能力无关。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MapReduce&lt;br&gt;这一部分主要是一些bug的修复和改进。增加了两个新的新特，在2.5.2里已经有所描述了。这里在简单看一下。&lt;ul&gt;
&lt;li&gt;ResourceManger Restart&lt;/li&gt;
&lt;li&gt;允许AM发送历史事件信息到timeline server。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;YARN&lt;ul&gt;
&lt;li&gt;NodeManager Restart：这个特性可以使NodeManager在不丢失运行在节点中的活动的container的情况下重新启动。&lt;/li&gt;
&lt;li&gt;Docker Container Executor：DockerContainer Executor（DCE）允许YARN NodeManager在Docker container中启动YARN container。用户可以指定他们想用来运行YARN container的Docker的镜像。这些container提供了一个可以自定义的软件环境，用户的代码可以运行在其中，与NodeManager运行的环境隔离。这些运行用户代码的container可以包含应用程序需要的特定的库，它们可以拥有与NodeManager不同版本的Perl，Python甚至是Java。事实上，这些container可以运行与NodeManager所在的OS不同版本的Linux。尽管YARN container必须定义运行Job所需的所有的环境和库，但是NodeManager中的所有的东西都不会共享。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Docer为YARN提供了一致和隔离两种模式，一致模式下，所有的YARN container将拥有相同的软件环境，在隔离模式下，不管物理机器安装了什么都不干扰。&lt;/p&gt;
&lt;p&gt;2015年7月，Hadoop 2.7.0发布。关键特性包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Common&lt;br&gt;支持Windows Azure Storage，BLOB作为Hadoop中的文件系统。&lt;br&gt;Hadoop HDFS&lt;ul&gt;
&lt;li&gt;支持文件截断（file truncate）；&lt;/li&gt;
&lt;li&gt;支持每个存储类型配额(Support for quotas per storage type);&lt;/li&gt;
&lt;li&gt;支持可变长度的块文件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;YARN —— YARN安全模块可插拔&lt;ul&gt;
&lt;li&gt;YARN的本地化资源可以自动共享，全局缓存（测试版）&lt;br&gt;Hadoop MapReduce&lt;/li&gt;
&lt;li&gt;能够限制运行的Map/Reduce作业的任务&lt;/li&gt;
&lt;li&gt;为非常的大Job（有许多输出文件）加快了FileOutputCommitter。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;HDFS&lt;ul&gt;
&lt;li&gt;支持文件截断（file truncate）；&lt;/li&gt;
&lt;li&gt;支持每个存储类型配额(Support for quotas per storage type);&lt;/li&gt;
&lt;li&gt;支持可变长度的块文件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MAPREDUCE&lt;ul&gt;
&lt;li&gt;能够限制运行的Map/Reduce作业的任务&lt;/li&gt;
&lt;li&gt;为非常的大Job（有许多输出文件）加快了FileOutputCommitter。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2015年7月，Hadoop 2.7.1发布。关键特性包括：&lt;br&gt;本版本属于稳定版本，是自Hadoop 2.6.0以来又一个稳定版，同时也是Hadoop 2.7.x版本线的第一个稳定版本，也是 2.7版本线的维护版本，变化不大，主要是修复了一些比较严重的Bug（其中修复了131个Bugs和patches）&lt;/p&gt;
&lt;h1 id=&quot;安装部署Hadoop&quot;&gt;&lt;a href=&quot;#安装部署Hadoop&quot; class=&quot;headerlink&quot; title=&quot;安装部署Hadoop&quot;&gt;&lt;/a&gt;安装部署Hadoop&lt;/h1&gt;&lt;p&gt;Hadoop 有两个主要版本，Hadoop 1.x.y 和 Hadoop 2.x.y 系列，比较老的教材上用的可能是 0.20 这样的版本。Hadoop 2.x 版本在不断更新。&lt;br&gt;&lt;br&gt;Hadoop安装部署模式有3种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Local (Standalone) Mode  本地模式&lt;/li&gt;
&lt;li&gt;Pseudo-Distributed Mode  伪分布式模式&lt;/li&gt;
&lt;li&gt;Fully-Distributed Mode  完全分布式模式(即为多节点安装Hadoop)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;安装部署本地模式Hadoop&quot;&gt;&lt;a href=&quot;#安装部署本地模式Hadoop&quot; class=&quot;headerlink&quot; title=&quot;安装部署本地模式Hadoop&quot;&gt;&lt;/a&gt;安装部署本地模式Hadoop&lt;/h2&gt;&lt;p&gt;本次实验使用的版本是hadoop-2.7.2，实验环境如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;node3&lt;/td&gt;
&lt;td&gt;172.16.7.153&lt;/td&gt;
&lt;td&gt;CentOS 7.1&lt;/td&gt;
&lt;td&gt;hadoop-2.7.2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;安装JDK1-7&quot;&gt;&lt;a href=&quot;#安装JDK1-7&quot; class=&quot;headerlink&quot; title=&quot;安装JDK1.7&quot;&gt;&lt;/a&gt;安装JDK1.7&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Hadoop Java Versions&lt;/strong&gt; &lt;br&gt;&lt;br&gt;Version 2.7 and later of Apache Hadoop requires Java 7. It is built and tested on both OpenJDK and Oracle (HotSpot)’s JDK/JRE. &lt;br&gt;&lt;br&gt;Earlier versions (2.6 and earlier) support Java 6.&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@node3 ~]# mkdir /usr/java&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@node3 ~]# tar zxf /usr/local/jdk-7u80-linux-x64.gz -C /usr/java/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@node3 ~]# vim /etc/profile&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export JAVA_HOME=/usr/java/jdk1.7.0_80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export PATH=$JAVA_HOME/bin:$PATH&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@node3 ~]# source /etc/profile&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装依赖包ssh和rsync&quot;&gt;&lt;a href=&quot;#安装依赖包ssh和rsync&quot; class=&quot;headerlink&quot; title=&quot;安装依赖包ssh和rsync&quot;&gt;&lt;/a&gt;安装依赖包ssh和rsync&lt;/h3&gt;&lt;p&gt;对于Redhat/CentOS系列的，安装系统时一般都会默认安装openssh软件，里面包含了ssh客户端和ssh服务端，所以先检查下这个软件包是否安装了：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# yum list all openssh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果没有安装，安装：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# yum install -y openssh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在检查rsync软件包是否安装：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# yum list all rsync&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;添加Hadoop运行用户&quot;&gt;&lt;a href=&quot;#添加Hadoop运行用户&quot; class=&quot;headerlink&quot; title=&quot;添加Hadoop运行用户&quot;&gt;&lt;/a&gt;添加Hadoop运行用户&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# groupadd -g 1000 hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# useradd -g 1000 -u 1000 hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# echo &amp;quot;wisedu&amp;quot; | passwd --stdin hadoop &amp;amp;&amp;gt; /dev/null&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;配置主节点登录自己和其他节点不需要输入密码&quot;&gt;&lt;a href=&quot;#配置主节点登录自己和其他节点不需要输入密码&quot; class=&quot;headerlink&quot; title=&quot;配置主节点登录自己和其他节点不需要输入密码&quot;&gt;&lt;/a&gt;配置主节点登录自己和其他节点不需要输入密码&lt;/h3&gt;&lt;p&gt;hadoop用户登录主机，配置其ssh连接localhost不需要输入密码：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ ssh-keygen -t rsa -P &amp;apos;&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@localhost&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;此时再用 ssh localhost，无需输入密码就可以直接登陆了，如下图所示：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ ssh localhost&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;解压hadoop&quot;&gt;&lt;a href=&quot;#解压hadoop&quot; class=&quot;headerlink&quot; title=&quot;解压hadoop&quot;&gt;&lt;/a&gt;解压hadoop&lt;/h3&gt;&lt;p&gt;root用户登录shell：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@node3 ~]# cd /usr/local/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@node3 local]# tar zxf hadoop-2.7.2.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@node3 local]# ln -sv hadoop-2.7.2 hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;‘hadoop’ -&amp;gt; ‘hadoop-2.7.2’&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;配置hadoop环境变量&quot;&gt;&lt;a href=&quot;#配置hadoop环境变量&quot; class=&quot;headerlink&quot; title=&quot;配置hadoop环境变量&quot;&gt;&lt;/a&gt;配置hadoop环境变量&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@node3 ~]# vim /etc/profile&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;HADOOP_HOME=/usr/local/hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;PATH=$HADOOP_HOME/bin:$PATH&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export HADOOP_HOME PATH&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@node3 ~]# source /etc/profile&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@node3 ~]# hadoop version&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;修改/usr/local/hadoop的属主和属组为hadoop：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@node3 local]# chown -R hadoop.hadoop /usr/local/hadoop/&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;配置本地模式并测试&quot;&gt;&lt;a href=&quot;#配置本地模式并测试&quot; class=&quot;headerlink&quot; title=&quot;配置本地模式并测试&quot;&gt;&lt;/a&gt;配置本地模式并测试&lt;/h3&gt;&lt;p&gt;Hadoop 默认模式为非分布式模式，无需进行其他配置即可运行。非分布式即单 Java 进程，方便进行调试。不使用集群文件系统的，只是个调试查看模式，不会启动什么DataNode这类的进程。&lt;br&gt;&lt;br&gt;可以执行例子来感受下 Hadoop 的运行。Hadoop 附带了丰富的例子（运行 ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar 可以看到所有例子），包括 wordcount、terasort、join、grep 等。&lt;br&gt;&lt;br&gt;在此选择运行 grep 例子，我们将 input 文件夹中的所有文件作为输入，筛选当中符合正则表达式 dfs[a-z.]+ 的单词并统计出现的次数，最后输出结果到 output 文件夹中。&lt;/p&gt;
&lt;p&gt;hadoop用户登录shell：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 ~]$ cd /usr/local/hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ mkdir input&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ cp etc/hadoop/*.xml input     # 将配置文件作为输入文件&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ cat output/*    # 查看运行结果&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;执行成功后如下所示，输出了作业的相关信息，输出的结果是符合正则的单词 dfsadmin 出现了1次：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意:&lt;/strong&gt;Hadoop 默认不会覆盖结果文件，因此再次运行上面实例会提示出错，需要先将 ./output 删除。&lt;/p&gt;
&lt;h2 id=&quot;安装部署伪分布式Hadoop&quot;&gt;&lt;a href=&quot;#安装部署伪分布式Hadoop&quot; class=&quot;headerlink&quot; title=&quot;安装部署伪分布式Hadoop&quot;&gt;&lt;/a&gt;安装部署伪分布式Hadoop&lt;/h2&gt;&lt;p&gt;Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 Java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。&lt;/p&gt;
&lt;h3 id=&quot;Hadoop配置文件说明&quot;&gt;&lt;a href=&quot;#Hadoop配置文件说明&quot; class=&quot;headerlink&quot; title=&quot;Hadoop配置文件说明&quot;&gt;&lt;/a&gt;Hadoop配置文件说明&lt;/h3&gt;&lt;p&gt;Hadoop 的配置文件位于 /usr/local/hadoop/etc/hadoop/ 中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml 。Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。&lt;br&gt;&lt;br&gt;Hadoop 的运行方式是由配置文件决定的（运行 Hadoop 时会读取配置文件），因此如果需要从伪分布式模式切换回非分布式模式，需要删除 core-site.xml 中的配置项。&lt;br&gt;&lt;br&gt;此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（官方教程如此），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。&lt;/p&gt;
&lt;h3 id=&quot;修改配置文件-core-site-xml，配置Hadoop的核心属性&quot;&gt;&lt;a href=&quot;#修改配置文件-core-site-xml，配置Hadoop的核心属性&quot; class=&quot;headerlink&quot; title=&quot;修改配置文件 core-site.xml，配置Hadoop的核心属性&quot;&gt;&lt;/a&gt;修改配置文件 core-site.xml，配置Hadoop的核心属性&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ vim etc/hadoop/core-site.xml&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;value&amp;gt;file:/usr/local/hadoop/tmp&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;description&amp;gt;Abase for other temporary directories.&amp;lt;/description&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h3 id=&quot;修改配置文件-hdfs-site-xml，定义hdfs的属性&quot;&gt;&lt;a href=&quot;#修改配置文件-hdfs-site-xml，定义hdfs的属性&quot; class=&quot;headerlink&quot; title=&quot;修改配置文件 hdfs-site.xml，定义hdfs的属性&quot;&gt;&lt;/a&gt;修改配置文件 hdfs-site.xml，定义hdfs的属性&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ vim etc/hadoop/hdfs-site.xml&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;name&amp;gt;dfs.namenode.name.dir&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;value&amp;gt;file:/usr/local/hadoop/tmp/dfs/name&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;name&amp;gt;dfs.datanode.data.dir&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;value&amp;gt;file:/usr/local/hadoop/tmp/dfs/data&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;注意:&lt;/strong&gt;如果需要其它用户对hdfs有写入权限，还需要在hdfs-site.xml添加一项属性定义。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &amp;lt;name&amp;gt;dfs.permissions&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;HDFS进程有许多属性可以定义其工作路径，如dfs.namenode.name.dir属性定义的HDFS元数据持久存储路径，默认为${hadoop.tmp.dir}/dfs/name。&lt;br&gt;&lt;br&gt;dfs.datanode.data.dir属性定义DataNode用于存储数据块的目录路径，默认为${hadoop.tmp.dir}/dfs/data。&lt;br&gt;&lt;br&gt;fs.checkpoint.dir属性定义的SecondaryNameNode用于存储检查点文件的目录，默认为${hadoop.tmp.dir}/dfs/namesecondary。&lt;br&gt;&lt;br&gt;为了数据可用性及冗余的目的，HDFS会在多个节点上保存同一个数据块的多个副本，其默认为3个。而只有一个节点的伪分布式环境中其仅用保存一个副本，这可以通过dfs.replication属性进行定义。&lt;/p&gt;
&lt;h3 id=&quot;配置完成后，执行-NameNode-的格式化&quot;&gt;&lt;a href=&quot;#配置完成后，执行-NameNode-的格式化&quot; class=&quot;headerlink&quot; title=&quot;配置完成后，执行 NameNode 的格式化&quot;&gt;&lt;/a&gt;配置完成后，执行 NameNode 的格式化&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ bin/hdfs namenode -format&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;成功的话，会看到 “successfully formatted” 和 “Exitting with status 0” 的提示，若为 “Exitting with status 1” 则是出错。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;开启-NameNode-和-DataNode-守护进程&quot;&gt;&lt;a href=&quot;#开启-NameNode-和-DataNode-守护进程&quot; class=&quot;headerlink&quot; title=&quot;开启 NameNode 和 DataNode 守护进程&quot;&gt;&lt;/a&gt;开启 NameNode 和 DataNode 守护进程&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ sbin/start-dfs.sh&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Error: JAVA_HOME is not set and could not be found.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/10.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;解决：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ vim etc/hadoop/hadoop-env.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/11.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/12.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;再次启动：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ sbin/start-dfs.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/13.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程: “NameNode”、”DataNode” 和 “SecondaryNameNode”（如果 SecondaryNameNode 没有启动，请运行 sbin/stop-dfs.sh 关闭进程，然后再次尝试启动尝试）。如果没有 NameNode 或 DataNode ，那就是配置不成功，请仔细检查之前步骤，或通过查看启动日志排查原因。The hadoop daemon log output is written to the $HADOOP_LOG_DIR directory (defaults to $HADOOP_HOME/logs)。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/14.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;查看NameNode-信息&quot;&gt;&lt;a href=&quot;#查看NameNode-信息&quot; class=&quot;headerlink&quot; title=&quot;查看NameNode 信息&quot;&gt;&lt;/a&gt;查看NameNode 信息&lt;/h3&gt;&lt;p&gt;成功启动后，可以访问 Web 界面 &lt;a href=&quot;http://172.16.7.153:50070&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.7.153:50070&lt;/a&gt; 查看 NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/15.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;测试hadoop&quot;&gt;&lt;a href=&quot;#测试hadoop&quot; class=&quot;headerlink&quot; title=&quot;测试hadoop&quot;&gt;&lt;/a&gt;测试hadoop&lt;/h3&gt;&lt;p&gt;上面本地模式的例子，grep读取的是本地文件系统上的数据，本地模式是不使用集群文件系统HDFS的。&lt;br&gt;&lt;br&gt;伪分布式读取的则是 HDFS 上的数据。要使用 HDFS，首先需要在 HDFS 中创建用户目录。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在HDFS中创建目录&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 ~]$ cd /usr/local/hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ bin/hdfs dfs -mkdir -p /user/hadoop&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;接着将 ./etc/hadoop 中的 xml 文件作为输入文件复制到分布式文件系统中，即将 /usr/local/hadoop/etc/hadoop 复制到分布式文件系统中的 /user/root/input 中。我们使用的是hadoop用户，并且已创建相应的用户目录 /user/hadoop ，因此在命令中就可以使用相对路径如 input，其对应的绝对路径就是 /user/hadoop/input:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ bin/hdfs dfs -mkdir input&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ bin/hdfs dfs -put ./etc/hadoop/*.xml input&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;复制完成后，可以通过如下命令查看文件列表：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ bin/hdfs dfs -ls input&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/16.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;伪分布式运行 MapReduce 作业的方式跟单机模式相同，区别在于伪分布式读取的是HDFS中的文件（可以将单机步骤中创建的本地 input 文件夹，输出结果 output 文件夹都删掉来验证这一点）。&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output &amp;apos;dfs[a-z.]+&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/17.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;查看运行结果的命令（查看的是位于 HDFS 中的输出结果）：&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ bin/hdfs dfs -cat output/*&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;结果如下，注意到刚才我们已经更改了配置文件，所以运行结果不同。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/18.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/19.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;我们也可以将运行结果取回到本地&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ rm -r ./output    # 先删除本地的 output 文件夹（如果存在）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ bin/hdfs dfs -get output ./output    # 将HDFS 上的 output 文件夹拷贝到本机&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/20.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ cat ./output/*&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/21.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hadoop 运行程序时，输出目录不能存在，否则会提示错误 “org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/user/hadoop/output already exists” ，因此若要再次执行，需要执行如下命令删除 output 文件夹：&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ bin/hdfs dfs -rm -r output&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16/06/27 23:37:30 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Deleted output&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;注意:&lt;/strong&gt;运行 Hadoop 程序时，为了防止覆盖结果，程序指定的输出目录（如 output）不能存在，否则会提示错误，因此运行前需要先删除输出目录。在实际开发应用程序时，可考虑在程序中加上如下代码，能在每次运行时自动删除输出目录，避免繁琐的命令行操作：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Configuration conf = new Configuration();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Job job = new Job(conf);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Path outputPath = new Path(args[1]);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;outputPath.getFileSystem(conf).delete(outputPath, true);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;若要关闭 Hadoop，则运行&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ sbin/stop-dfs.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;下次启动 hadoop 时，无需进行 NameNode 的初始化，只需要运行 sbin/start-dfs.sh 就可以了。&lt;/p&gt;
&lt;h3 id=&quot;启动YARN&quot;&gt;&lt;a href=&quot;#启动YARN&quot; class=&quot;headerlink&quot; title=&quot;启动YARN&quot;&gt;&lt;/a&gt;启动YARN&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;伪分布式不启动 YARN 也可以，一般不会影响程序执行。&lt;br&gt;&lt;br&gt;玩过Hadoop V1版本的可能会疑惑，启动 Hadoop 后，见不到所说的 JobTracker 和 TaskTracker进程，这是因为新版的 Hadoop 使用了新的 MapReduce 框架（MapReduce V2，也称为 YARN，Yet Another Resource Negotiator）。&lt;br&gt;&lt;br&gt;YARN 是从 MapReduce 中分离出来的，负责资源管理与任务调度。YARN 运行于 MapReduce 之上，提供了高可用性、高扩展性。&lt;br&gt;&lt;br&gt;上述通过 sbin/start-dfs.sh 启动 Hadoop，仅仅是启动了 MapReduce 环境，我们可以启动 YARN ，让 YARN 来负责资源管理与任务调度。&lt;br&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;首先修改配置文件 mapred-site.xml&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 ~]$ cd /usr/local/hadoop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ mv ./etc/hadoop/mapred-site.xml.template ./etc/hadoop/mapred-site.xml&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ vim mapred-site.xml&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;修改配置文件 yarn-site.xml&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ vim yarn-site.xml&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;             &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &amp;lt;/property&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;启动 YARN 了（需要先执行过 ./sbin/start-dfs.sh）&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ sbin/start-yarn.sh                       # 启动YARN&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/24.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/25.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ sbin/mr-jobhistory-daemon.sh start historyserver  # 开启历史服务器，才能在Web中查看任务运行情况&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/26.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/27.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;启动 YARN 之后，运行实例的方法还是一样的，仅仅是资源管理方式、任务调度不同。观察日志信息可以发现，不启用 YARN 时，是 “mapred.LocalJobRunner” 在跑任务，启用 YARN 之后，是 “mapred.YARNRunner” 在跑任务。启动 YARN 有个好处是可以通过 Web 界面查看任务的运行情况：&lt;a href=&quot;http://localhost:8088/cluster，如下图所示。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://localhost:8088/cluster，如下图所示。&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/28.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在执行下上面的任务：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output &amp;apos;dfs[a-z.]+&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/29.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/30.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;但 YARN 主要是为集群提供更好的资源管理与任务调度，然而这在单机上体现不出价值，反而会使程序跑得稍慢些。因此在单机上是否开启 YARN 就看实际情况了。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;关闭 YARN 的脚本如下&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ sbin/stop-yarn.sh&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[hadoop@node3 hadoop]$ sbin/mr-jobhistory-daemon.sh stop historyserver&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;不启动 YARN 需重命名 mapred-site.xml。如果不想启动 YARN，务必把配置文件 mapred-site.xml 重命名，改成 mapred-site.xml.template，需要用时改回来就行。否则在该配置文件存在，而未开启 YARN 的情况下，运行程序会提示 “Retrying connect to server: 0.0.0.0/0.0.0.0:8032” 的错误，这也是为何该配置文件初始文件名为 mapred-site.xml.template。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Hadoop版本&quot;&gt;&lt;a href=&quot;#Hadoop版本&quot; class=&quot;headerlink&quot; title=&quot;Hadoop版本&quot;&gt;&lt;/a&gt;Hadoop版本&lt;/h1&gt;&lt;h2 id=&quot;Hadoop版本种类&quot;&gt;&lt;a href=&quot;#Hadoop版本种类&quot; class=&quot;headerlink&quot; title=&quot;Hadoop版本种类&quot;&gt;&lt;/a&gt;Hadoop版本种类&lt;/h2&gt;&lt;p&gt;目前Hadoop发行版非常多，有华为发行版、Intel发行版、Cloudera发行版（CDH）等，所有这些发行版均是基于Apache Hadoop衍生出来的，之所以有这么多的版本，完全是由&lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot;&gt;Apache Hadoop的开源协议&lt;/a&gt;决定的：任何人可以对其进行修改，并作为开源或商业产品发布/销售。&lt;br&gt;
    
    </summary>
    
    
      <category term="大数据，Hadoop" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%EF%BC%8CHadoop/"/>
    
  </entry>
  
  <entry>
    <title>使用Github Pages与Hexo搭建博客</title>
    <link href="http://yoursite.com/2016/06/08/%E4%BD%BF%E7%94%A8Github-Pages%E4%B8%8EHexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
    <id>http://yoursite.com/2016/06/08/使用Github-Pages与Hexo搭建博客/</id>
    <published>2016-06-08T09:58:10.000Z</published>
    <updated>2016-06-12T06:58:55.408Z</updated>
    
    <content type="html">&lt;h1 id=&quot;什么是Git-Github-Github-Pages&quot;&gt;&lt;a href=&quot;#什么是Git-Github-Github-Pages&quot; class=&quot;headerlink&quot; title=&quot;什么是Git, Github, Github Pages?&quot;&gt;&lt;/a&gt;什么是Git, Github, Github Pages?&lt;/h1&gt;&lt;p&gt;1.Git是一个开源的分布式版本控制系统，用以有效、高速的处理从很小到非常大的项目版本管理。&lt;br&gt;2.GitHub是一个具有版本管理功能的代码仓库，每个项目都有一个主页，列出项目的源文件。许多重要的项目都托管在上面。&lt;br&gt;3.GitHub Pages免费的静态站点，三个特点：免费托管、自带主题、支持自制页面和Jekyll。Github Pages 是面向用户、组织和项目开放的公共静态页面搭建托管服务，站点可以被免费托管在 Github 上，你可以选择使用 Github Pages 默认提供的域名 github.io 或者自定义域名来发布站点。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;更详尽的概念介绍见：&lt;a href=&quot;http://jmcglone.com/guides/github-pages/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;在Github上搭建和管理个人网站&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;什么是Hexo？&quot;&gt;&lt;a href=&quot;#什么是Hexo？&quot; class=&quot;headerlink&quot; title=&quot;什么是Hexo？&quot;&gt;&lt;/a&gt;什么是Hexo？&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/hexojs/hexo&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;是一个简单、快速、强大的静态博客框架,出自台湾大学生tommy351之手。相比于使用Jekyll、Octopress搭建个人博客，使用Hexo更轻便更快捷，下面是&lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo官网&lt;/a&gt;强调Hexo的四大特点：&lt;br&gt;1.极速生成静态页面&lt;br&gt;2.支持Markdown&lt;br&gt;3.一键部署博客&lt;br&gt;4.丰富的插件支持&lt;/p&gt;
&lt;h1 id=&quot;安装Git工具&quot;&gt;&lt;a href=&quot;#安装Git工具&quot; class=&quot;headerlink&quot; title=&quot;安装Git工具&quot;&gt;&lt;/a&gt;安装Git工具&lt;/h1&gt;&lt;p&gt;依次下载安装。&lt;br&gt;1.&lt;a href=&quot;https://nodejs.org/en/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Node.js&lt;/a&gt;&lt;br&gt;2.&lt;a href=&quot;https://git-scm.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Git&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;如何打开Git？&quot;&gt;&lt;a href=&quot;#如何打开Git？&quot; class=&quot;headerlink&quot; title=&quot;如何打开Git？&quot;&gt;&lt;/a&gt;如何打开Git？&lt;/h2&gt;&lt;p&gt;1.开始菜单找到Git Bash&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/QWTgytB.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;2.鼠标右键打开Git Bash&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/wmVehZb.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;注册Github&quot;&gt;&lt;a href=&quot;#注册Github&quot; class=&quot;headerlink&quot; title=&quot;注册Github&quot;&gt;&lt;/a&gt;注册Github&lt;/h1&gt;&lt;p&gt;访问&lt;a href=&quot;https://github.com&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Github&lt;/a&gt;，填写注册信息，申请成功后，在GitHub官网上登录，并验证邮箱即可。 &lt;br&gt;&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/gNuzom3.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;h1 id=&quot;配置SSH-Key&quot;&gt;&lt;a href=&quot;#配置SSH-Key&quot; class=&quot;headerlink&quot; title=&quot;配置SSH Key&quot;&gt;&lt;/a&gt;配置SSH Key&lt;/h1&gt;&lt;p&gt;我们如何让本地git项目与远程的GitHub建立联系呢？用SSH key。&lt;/p&gt;
&lt;h2 id=&quot;检查SSH-keys的设置&quot;&gt;&lt;a href=&quot;#检查SSH-keys的设置&quot; class=&quot;headerlink&quot; title=&quot;检查SSH keys的设置&quot;&gt;&lt;/a&gt;检查SSH keys的设置&lt;/h2&gt;&lt;p&gt;首先我们需要检查你电脑上现有的ssh key，打开Git Bash，输入：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ cd ~/.ssh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果提示：No such file or directory 说明你是第一次使用git。&lt;/p&gt;
&lt;h2 id=&quot;生成新的SSH-Key&quot;&gt;&lt;a href=&quot;#生成新的SSH-Key&quot; class=&quot;headerlink&quot; title=&quot;生成新的SSH Key&quot;&gt;&lt;/a&gt;生成新的SSH Key&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ ssh-keygen -t rsa -C &amp;quot;邮件地址@youremail.com&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Generating public/private rsa key pair.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa):&amp;lt;这里回车就好&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;注意1:&lt;/strong&gt; 此处的邮箱地址，你可以输入自己的邮箱地址；&lt;strong&gt;注意2:&lt;/strong&gt; 此处的「-C」的是大写的「C」&lt;br&gt;然后系统会要你输入密码。在回车中会提示你输入一个密码，这个密码会在你提交项目时使用，如果为空的话提交项目时则不用输入。这个设置是防止别人往你的项目里提交内容。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Enter passphrase (empty for no passphrase):&amp;lt;输入密码&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Enter same passphrase again:&amp;lt;再次输入密码&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;最后看到这样的界面，就成功设置ssh key了： &lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/MRyuTxy.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;h2 id=&quot;添加SSH-Key到GitHub&quot;&gt;&lt;a href=&quot;#添加SSH-Key到GitHub&quot; class=&quot;headerlink&quot; title=&quot;添加SSH Key到GitHub&quot;&gt;&lt;/a&gt;添加SSH Key到GitHub&lt;/h2&gt;&lt;p&gt;在本机设置SSH Key之后，需要添加到GitHub上，以完成SSH连接的设置。&lt;br&gt;1.登录&lt;a href=&quot;https://github.com&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Github&lt;/a&gt;，点击右上角的”Settings”，在点击左侧列表中的”SSH and GPG keys”，点击”New SSH Key”，见下图。 &lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/39O4jsC.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/BEL2upr.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;2.把你本地生成的密钥(类似C:\Users\dell.ssh这个路径下有个id_rsa.pub文件，用文本编辑器打开这个文件)，把该文件中的全部内容复制到下面的文本框中，点击Add key。&lt;br&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/VBojDNs.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;h2 id=&quot;测试设置是否成功&quot;&gt;&lt;a href=&quot;#测试设置是否成功&quot; class=&quot;headerlink&quot; title=&quot;测试设置是否成功&quot;&gt;&lt;/a&gt;测试设置是否成功&lt;/h2&gt;&lt;p&gt;可以输入下面的命令，看看设置是否成功，git@github.com的部分不要修改：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ ssh -T git@github.com&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果是下面的反馈：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;The authenticity of host &amp;apos;github.com (207.97.227.239)&amp;apos; can&amp;apos;t be established.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Are you sure you want to continue connecting (yes/no)?&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输入yes就好，然后会看到：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Hi cnfeat! You&amp;apos;ve successfully authenticated, but GitHub does not provide shell access.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;设置用户信息&quot;&gt;&lt;a href=&quot;#设置用户信息&quot; class=&quot;headerlink&quot; title=&quot;设置用户信息&quot;&gt;&lt;/a&gt;设置用户信息&lt;/h2&gt;&lt;p&gt;现在你已经可以通过SSH连接到GitHub了，还有一些个人信息需要完善的。&lt;br&gt;Git会根据用户的名字和邮箱来记录提交。GitHub也是用这些信息来做权限的处理，输入下面的代码进行个人信息的设置，把名称和邮箱替换成你自己的。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ git config --global user.name &amp;quot;jkzhao&amp;quot;//用户名&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ git config --global user.email  &amp;quot;jk.zhaocoder@gmail.com&amp;quot;//填写自己的邮箱&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;#使用GitHub Pages建立博客&lt;br&gt;与 GitHub 建立好连接之后，就可以方便的使用它提供的 Pages 服务，GitHub Pages 分两种，一种是用你的GitHub用户名建立的username.github.io这样的用户&amp;amp;组织站点，另一种是依附项目的Pages。&lt;/p&gt;
&lt;p&gt;想建立个人博客是用的第一种，形如username.github.io这样的可访问的站点，每个用户名下面只能建立一个。&lt;/p&gt;
&lt;h2 id=&quot;在GitHub上建立仓库&quot;&gt;&lt;a href=&quot;#在GitHub上建立仓库&quot; class=&quot;headerlink&quot; title=&quot;在GitHub上建立仓库&quot;&gt;&lt;/a&gt;在GitHub上建立仓库&lt;/h2&gt;&lt;p&gt;访问&lt;a href=&quot;https://github.com&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Github&lt;/a&gt;，点击页面右上角「New Repository」: &lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/RnRWWMa.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;填写项目信息：&lt;strong&gt;注意：&lt;/strong&gt;Github Pages的Repository名字是特定的，比如我Github账号是jkzhao，那么我Github Pages Repository名字就是jkzhao.github.io。&lt;br&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/3zQNxdx.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;h1 id=&quot;使用Hexo创建博客框架&quot;&gt;&lt;a href=&quot;#使用Hexo创建博客框架&quot; class=&quot;headerlink&quot; title=&quot;使用Hexo创建博客框架&quot;&gt;&lt;/a&gt;使用Hexo创建博客框架&lt;/h1&gt;&lt;h2 id=&quot;Hexo安装&quot;&gt;&lt;a href=&quot;#Hexo安装&quot; class=&quot;headerlink&quot; title=&quot;Hexo安装&quot;&gt;&lt;/a&gt;Hexo安装&lt;/h2&gt;&lt;p&gt;鼠标右键打开Git Bash，输入以下命令：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ npm install -g hexo&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;Hexo部署&quot;&gt;&lt;a href=&quot;#Hexo部署&quot; class=&quot;headerlink&quot; title=&quot;Hexo部署&quot;&gt;&lt;/a&gt;Hexo部署&lt;/h2&gt;&lt;p&gt;在我的电脑找个盘，建立一个名字叫「Hexo」的文件夹，然后在此文件夹中右键打开Git Bash。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ hexo init&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Hexo随后会自动在目标文件夹建立网站所需要的所有文件。现在我们已经搭建起本地的hexo博客了，执行以下命令，然后到浏览器输入localhost:4000看看。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ hexo g&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ hexo s&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;此时打开浏览器，在浏览器地址栏输入 &lt;a href=&quot;http://localhost:4000/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://localhost:4000/&lt;/a&gt; （默认端口为4000）, 便可以看到最原始的博客了。以后发表博文想先预览，也可以通过 hexo server 在本地先跑起来，看看效果。&lt;br&gt;效果如下图所示： &lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/iSsQF7B.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;此时个人博客的雏形已经有了。在 Git Bash 中按 Ctrl + C 可以停止该服务。&lt;br&gt;&lt;br&gt;## 将本地文件部署到 GitHub&lt;br&gt;### 修改 Hexo 中的 _config.yml 文件&lt;br&gt;在 Hexo 文件夹下找到 _config.yml 文件,如下图所示：&lt;br&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/HBDKyJv.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;打开这个文件，找到其中的 deploy 标签，改成下图所示形式(认真比对repository那一行的地址，最后的.git不要漏掉)，并保存。注意：冒号后面要加上一个空格，否则会报错。&lt;br&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/cAlEOWu.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;h3 id=&quot;将其-deploy-到仓库中&quot;&gt;&lt;a href=&quot;#将其-deploy-到仓库中&quot; class=&quot;headerlink&quot; title=&quot;将其 deploy 到仓库中&quot;&gt;&lt;/a&gt;将其 deploy 到仓库中&lt;/h3&gt;&lt;p&gt;鼠标右击「Hexo」文件夹，点击Git Bash，依次输入下面的命令：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hexo clean&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hexo generate&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hexo deploy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;到这一步，个人博客就已经部署到 GitHub 上了，你可以到你的GitHub仓库查看是否已经更新。此时，通过 your_user_name.github.io（即你那个仓库的名称，形如：”你的 GitHub 用户名”.github.io）,就可以看到你的个人博客了。&lt;/p&gt;
&lt;h1 id=&quot;安装NexT主题&quot;&gt;&lt;a href=&quot;#安装NexT主题&quot; class=&quot;headerlink&quot; title=&quot;安装NexT主题&quot;&gt;&lt;/a&gt;安装NexT主题&lt;/h1&gt;&lt;p&gt;使用Hexo生成的博客使用的是Hexo的默认主题：Landscape。后来选择了这个主题：&lt;a href=&quot;http://notes.iissnan.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;NexT&lt;/a&gt;。&lt;br&gt;1.简洁大方，比较符合我的品位；&lt;br&gt;2.作者iissnan很勤快，持续更新主题，作者博客的样式就是他正在开发而未上线的NexT主题新样式。&lt;/p&gt;
&lt;h2 id=&quot;下载-NexT-主题&quot;&gt;&lt;a href=&quot;#下载-NexT-主题&quot; class=&quot;headerlink&quot; title=&quot;下载 NexT 主题&quot;&gt;&lt;/a&gt;下载 NexT 主题&lt;/h2&gt;&lt;p&gt;Hexo 有两份主要的配置文件（_config.yml），一份位于站点根目录下，另一份位于主题目录下。为了描述方便，在以下说明中，将前者称为&lt;strong&gt;站点配置文件&lt;/strong&gt;，后者称为&lt;strong&gt;主题配置文件&lt;/strong&gt;。&lt;br&gt;鼠标右击「Hexo」文件夹，点击Git Bash，依次输入下面的命令：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;git clone https://github.com/iissnan/hexo-theme-next themes/next&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;启用NexT主题&quot;&gt;&lt;a href=&quot;#启用NexT主题&quot; class=&quot;headerlink&quot; title=&quot;启用NexT主题&quot;&gt;&lt;/a&gt;启用NexT主题&lt;/h2&gt;&lt;p&gt;下载完成后，打开 站点配置文件，找到 theme 字段，并将其值更改为 next。&lt;/p&gt;
&lt;h2 id=&quot;验证主题是否启用&quot;&gt;&lt;a href=&quot;#验证主题是否启用&quot; class=&quot;headerlink&quot; title=&quot;验证主题是否启用&quot;&gt;&lt;/a&gt;验证主题是否启用&lt;/h2&gt;&lt;p&gt;鼠标右击「Hexo」文件夹，点击Git Bash，依次输入下面的命令：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hexo clean&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hexo generate&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hexo deploy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后浏览器访问你的个人博客，就能看到你设置的主题是否启用。&lt;/p&gt;
&lt;h2 id=&quot;设置NexT主题和第三方服务&quot;&gt;&lt;a href=&quot;#设置NexT主题和第三方服务&quot; class=&quot;headerlink&quot; title=&quot;设置NexT主题和第三方服务&quot;&gt;&lt;/a&gt;设置NexT主题和第三方服务&lt;/h2&gt;&lt;h3 id=&quot;选择样式&quot;&gt;&lt;a href=&quot;#选择样式&quot; class=&quot;headerlink&quot; title=&quot;选择样式&quot;&gt;&lt;/a&gt;选择样式&lt;/h3&gt;&lt;p&gt;NexT默认的样式其实也比较丑，还有其他两种样式:Mist和Pisces。我这里用的是Pisces，启用 Pisces 很简单，仅需在 主题配置文件 中找到Scheme，添加一行scheme: Pisces。我这里的主题配置文件在路径：D:\Hexo\themes\next。&lt;/p&gt;
&lt;h3 id=&quot;菜单设置&quot;&gt;&lt;a href=&quot;#菜单设置&quot; class=&quot;headerlink&quot; title=&quot;菜单设置&quot;&gt;&lt;/a&gt;菜单设置&lt;/h3&gt;&lt;p&gt;菜单配置在 主题配置文件 的menu，下面是菜单配置示例：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;menu:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  #home: /&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  archives: /archives&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  about: /about&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  categories: /categories&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  tags: /tags&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  #commonweal: /404.html&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果需要添加菜单，需要先命令行生成页面，在配置这个menu。这里菜单可以先不配置，先做下面的一些设置。&lt;/p&gt;
&lt;h3 id=&quot;头像设置&quot;&gt;&lt;a href=&quot;#头像设置&quot; class=&quot;headerlink&quot; title=&quot;头像设置&quot;&gt;&lt;/a&gt;头像设置&lt;/h3&gt;&lt;p&gt;这里的头像是博客首页的一个头像，类似如下： &lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/VzfVlWh.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;1.设置或者上网找一个头像，大小要在580X580像素左右。然后放入站点的类似如下的路径下：D:\Hexo\themes\next\source\images。&lt;br&gt;2.编辑 站点配置文件，找到Avatar，值设置成/images/avatar.jpg。&lt;br&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/rniNQoa.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;h3 id=&quot;设置favicon图标&quot;&gt;&lt;a href=&quot;#设置favicon图标&quot; class=&quot;headerlink&quot; title=&quot;设置favicon图标&quot;&gt;&lt;/a&gt;设置favicon图标&lt;/h3&gt;&lt;p&gt;所谓的favicon图标是指网站logo，如下图： &lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/HSx1YO1.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;1.首先要有一个常见格式名(如.jpg, .png等)的图片作为备选favicon，选择一个favicon制作网站完成制作，例如比特虫是一个免费的在线制作ico图标网站。或者自己上网下载一个大小适合的。logo最好设置32*32。&lt;br&gt;2.将favicon.ico文件放在next主题目录下的相应路径即可，类似路径为：D:\Hexo\themes\next\source\images。然后修改 主题配置文件，找到”favicon”,添加一行内容：favicon: images/favicon.ico &lt;br&gt;&lt;br&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/36nQihk.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;h3 id=&quot;修改网站标题、副标题、作者信息、网站使用语言&quot;&gt;&lt;a href=&quot;#修改网站标题、副标题、作者信息、网站使用语言&quot; class=&quot;headerlink&quot; title=&quot;修改网站标题、副标题、作者信息、网站使用语言&quot;&gt;&lt;/a&gt;修改网站标题、副标题、作者信息、网站使用语言&lt;/h3&gt;&lt;p&gt;打开站点配置文件_config.yml，类似路径如下：D:\Hexo。找到Site段：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# Site &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;title: jkzhao&amp;apos;s blog   #网站标题 &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;subtitle: 学习 总结 思考  #网站副标题 &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;description: &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;author: Zhao Jiankai  #你的名字 &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;language: zh-Hans #网站使用的语言 &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;timezone: #网站时区。Hexo默认使用你电脑的时区 &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;email: jk.zhaocoder@gmail.com #你的邮箱地址&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;添加社交链接&quot;&gt;&lt;a href=&quot;#添加社交链接&quot; class=&quot;headerlink&quot; title=&quot;添加社交链接&quot;&gt;&lt;/a&gt;添加社交链接&lt;/h3&gt;&lt;p&gt;1.以添加Github、微博和知乎为例，编辑 站点配置文件，找到Social Links，添加如下内容：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/zpDQFBC.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;2.编辑 站点配置文件，找到Social Links Icons，添加如下内容：&lt;br&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/LYHTwIg.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;h3 id=&quot;添加友情链接&quot;&gt;&lt;a href=&quot;#添加友情链接&quot; class=&quot;headerlink&quot; title=&quot;添加友情链接&quot;&gt;&lt;/a&gt;添加友情链接&lt;/h3&gt;&lt;p&gt;编辑 站点配置文件，找到”links_title: 友情链接”，添加类似如下内容：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/qQOwbNm.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;h3 id=&quot;添加评论区&quot;&gt;&lt;a href=&quot;#添加评论区&quot; class=&quot;headerlink&quot; title=&quot;添加评论区&quot;&gt;&lt;/a&gt;添加评论区&lt;/h3&gt;&lt;p&gt;支持Disqus和多说两种评论样式。建议中文网站选择多说，英文网站选择Disqus。下面以多说为例说明。&lt;br&gt;1.注册&lt;a href=&quot;http://duoshuo.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;多说&lt;/a&gt;。&lt;br&gt;2.使用多说钱，我们需要先在多说创建一个站点。登录&lt;a href=&quot;http://duoshuo.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;多说&lt;/a&gt;，在首页点击”我要安装”。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/4hK6eAD.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;3.创建站点，填写站点相关信息。注意，&lt;em&gt;多说域名&lt;/em&gt;这一栏填写的即是你的duoshuo_shortname(这个等下要写到配置文件中，先记着)。类似如下：&lt;br&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/4ThHAmA.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;4.编辑站点的_config.yml，注意，添加 duoshuo_shortname 字段，设置如下：duoshuo_shortname: your-duoshuo-shortname。比如：&lt;br&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/W7DvGfr.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;strong&gt;注意：&lt;/strong&gt;duoshuo short name: 你的多说二级域名去掉 .duoshuo.com 部分。&lt;br&gt;&lt;br&gt;### 添加留言菜单&lt;br&gt;1.鼠标右击「Hexo」文件夹，点击Git Bash，输入下面的命令：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hexo new page &amp;quot;guestbook&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br&gt;&lt;br&gt;命令执行完后，就会发现在在 Hexo\source 目录中多了一个文件夹guestbook，里面还有一个index.md,这就代表我们新建了一个页面。 &lt;br&gt;&lt;br&gt;2.打开guestbook文件夹里的index.md，将下面的代码加到index.md底部就行。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;div class=&amp;quot;ds-recent-visitors&amp;quot; data-num-items=&amp;quot;28&amp;quot; data-avatar-size=&amp;quot;42&amp;quot; id=&amp;quot;ds-recent-visitors&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br&gt;&lt;br&gt;3.然后要登录自己多说的站点(我这里就是上面设置的站点jkzhao blog)，进入设置-&amp;gt;自定义CSS，添加如下代码：&lt;br&gt;&lt;pre class=&quot;prettyprint&quot;&gt;&lt;br&gt;#ds-reset .ds-avatar img,&lt;br&gt;#ds-recent-visitors .ds-avatar img {&lt;br&gt;    width: 54px;&lt;br&gt;    height: 54px;     /&lt;em&gt;設置图像的长和宽，这里要根据自己的评论框情況更改&lt;/em&gt;/&lt;br&gt;    border-radius: 27px;     /&lt;em&gt;设置图像圆角效果,在这里我直接设置了超过width/2的像素，即为圆形了&lt;/em&gt;/&lt;br&gt;    -webkit-border-radius: 27px;     /&lt;em&gt;圆角效果：兼容webkit浏览器&lt;/em&gt;/&lt;br&gt;    -moz-border-radius: 27px;&lt;br&gt;    box-shadow: inset 0 -1px 0 #3333sf;     /&lt;em&gt;设置图像阴影效果&lt;/em&gt;/&lt;br&gt;    -webkit-box-shadow: inset 0 -1px 0 #3333sf;&lt;br&gt;}&lt;br&gt;&lt;br&gt;#ds-recent-visitors .ds-avatar {&lt;br&gt;    float: left&lt;br&gt;}&lt;br&gt;/&lt;em&gt;隐藏多說底部版权&lt;/em&gt;/&lt;br&gt;#ds-thread #ds-reset .ds-powered-by {&lt;br&gt;    display: none;&lt;br&gt;}&lt;br&gt;&lt;/pre&gt;&lt;br&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/GyU4Le4.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;p&gt;4.菜单设置中添加留言菜单。找到NexT主题设置的_config.yml文件里面的menu项，加入如下内容：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/toJKP6L.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;h3 id=&quot;设置每篇文章在博客首页显示的预览内容&quot;&gt;&lt;a href=&quot;#设置每篇文章在博客首页显示的预览内容&quot; class=&quot;headerlink&quot; title=&quot;设置每篇文章在博客首页显示的预览内容&quot;&gt;&lt;/a&gt;设置每篇文章在博客首页显示的预览内容&lt;/h3&gt;&lt;p&gt;在写博文时，在希望展示在预览的部分下面写入：&lt;!-- more --&gt;，比如：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/lLl6w9m.png&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;h1 id=&quot;发表博文&quot;&gt;&lt;a href=&quot;#发表博文&quot; class=&quot;headerlink&quot; title=&quot;发表博文&quot;&gt;&lt;/a&gt;发表博文&lt;/h1&gt;&lt;h2 id=&quot;新建博文&quot;&gt;&lt;a href=&quot;#新建博文&quot; class=&quot;headerlink&quot; title=&quot;新建博文&quot;&gt;&lt;/a&gt;新建博文&lt;/h2&gt;&lt;p&gt;鼠标右击「Hexo」文件夹，点击Git Bash，依次输入下面的命令：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hexo new &amp;quot;文章题目&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;命令执行完后，就会发现在 Hexo\source_posts 目录中多了一个文件博文名.md，这就是我们刚才新建的博文。或者直接进入 Hexo\source_posts 目录中，右键新建一个文本文档，将名字改为博文名.md,这样也新建了一篇博文。建议使用命令去创建博文。&lt;/p&gt;
&lt;h2 id=&quot;新建页面&quot;&gt;&lt;a href=&quot;#新建页面&quot; class=&quot;headerlink&quot; title=&quot;新建页面&quot;&gt;&lt;/a&gt;新建页面&lt;/h2&gt;&lt;p&gt;上面新建的博文是显示在单个文章界面，这里新建的页面是作为单个页面显示的，比如下图的分类、标签、归档和关于我，你点击后都是显示为单个页面。 &lt;/p&gt;
&lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/vmIRWP7.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;你只需要记住新建博文是用上面的方法，新建页面是用这里的方法就行了，这里也采用命令新建页面：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hexo new page &amp;quot;页面名称&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;命令执行完后，就会发现在在 Hexo\source 目录中多了一个文件夹，里面还有一个index.md,这就代表我们新建了一个页面。&lt;/p&gt;
&lt;h2 id=&quot;写博文&quot;&gt;&lt;a href=&quot;#写博文&quot; class=&quot;headerlink&quot; title=&quot;写博文&quot;&gt;&lt;/a&gt;写博文&lt;/h2&gt;&lt;p&gt;用文本编辑器打开上面新建的博文，如下图所示。 &lt;/p&gt;
&lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://i.imgur.com/52V2yDF.png&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;新建的页面略有不同，没有categories标签，自己可以加上去，也可以不加。tags也没有内容，自己也可以加一些内容。&lt;br&gt;三个”-“后面就是博文的正文内容，接下来就是撰写博文了。可以下载对应操作系统上的Markdown编辑器，使用Markdown语法写博文。具体Markdown语法请看这里的Markdown教程：&lt;a href=&quot;http://www.markdown.cn/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Markdown中文网&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;发博文&quot;&gt;&lt;a href=&quot;#发博文&quot; class=&quot;headerlink&quot; title=&quot;发博文&quot;&gt;&lt;/a&gt;发博文&lt;/h2&gt;&lt;p&gt;鼠标右击「Hexo」文件夹，点击Git Bash，执行下面几条命令，将博客发表到Github上：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hexo clean&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hexo generate&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hexo deploy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;购买并绑定域名&quot;&gt;&lt;a href=&quot;#购买并绑定域名&quot; class=&quot;headerlink&quot; title=&quot;购买并绑定域名&quot;&gt;&lt;/a&gt;购买并绑定域名&lt;/h1&gt;&lt;p&gt;GitHub 提供的二级域名[username.github.io]，平常自己写写博客也够用了。当然愿意花钱购买个性化的域名，也可以绑定到个人博客上。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是Git-Github-Github-Pages&quot;&gt;&lt;a href=&quot;#什么是Git-Github-Github-Pages&quot; class=&quot;headerlink&quot; title=&quot;什么是Git, Github, Github Pages?&quot;&gt;&lt;/a&gt;什么是Git, Github, Github Pages?&lt;/h1&gt;&lt;p&gt;1.Git是一个开源的分布式版本控制系统，用以有效、高速的处理从很小到非常大的项目版本管理。&lt;br&gt;2.GitHub是一个具有版本管理功能的代码仓库，每个项目都有一个主页，列出项目的源文件。许多重要的项目都托管在上面。&lt;br&gt;3.GitHub Pages免费的静态站点，三个特点：免费托管、自带主题、支持自制页面和Jekyll。Github Pages 是面向用户、组织和项目开放的公共静态页面搭建托管服务，站点可以被免费托管在 Github 上，你可以选择使用 Github Pages 默认提供的域名 github.io 或者自定义域名来发布站点。&lt;br&gt;
    
    </summary>
    
      <category term="搭建博客" scheme="http://yoursite.com/categories/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="Build a blog" scheme="http://yoursite.com/tags/Build-a-blog/"/>
    
  </entry>
  
  <entry>
    <title>Nginx、Nignx Plus减轻DDoS攻击(译)</title>
    <link href="http://yoursite.com/2016/05/25/Nginx%E3%80%81Nignx-Plus%E5%87%8F%E8%BD%BBDDoS%E6%94%BB%E5%87%BB-%E8%AF%91/"/>
    <id>http://yoursite.com/2016/05/25/Nginx、Nignx-Plus减轻DDoS攻击-译/</id>
    <published>2016-05-25T01:39:34.000Z</published>
    <updated>2016-05-30T05:55:29.745Z</updated>
    
    <content type="html">&lt;p&gt;DDoS攻击是一种对服务的攻击，一般是对网站的攻击，通过使用多台机器连续的流量轰炸目标服务器，以使得提供服务的主机因为资源用尽而不再能够提供有效地提供服务。&lt;/p&gt;
&lt;p&gt;典型的，攻击者尝试通过大量的连接和请求使系统饱和，以使得目标主机无法再接收新的流量，或者响应变慢地不可用。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;应用层DDoS攻击特征&quot;&gt;&lt;a href=&quot;#应用层DDoS攻击特征&quot; class=&quot;headerlink&quot; title=&quot;应用层DDoS攻击特征&quot;&gt;&lt;/a&gt;应用层DDoS攻击特征&lt;/h1&gt;&lt;hr&gt;
&lt;p&gt;应用层(Layer 7/HTTP) DDoS攻击是通过利用特定系统的脆弱点而特制的软件程序来完成。例如，对于不处理大量并发连接请求的系统，仅仅打开大量的连接，并且周期性地发送少量的流量来使得连接存活就会耗尽系统的性能以至于无法响应新连接。其他的攻击可采取发送大量的请求或非常大的请求的形式。因为这些攻击是通过肉鸡完成的，而不是通过真实的用户，攻击者可以轻松地、很快地打开大量数据的连接和发送大量的请求。&lt;br&gt;DDoS的攻击特征可以被用来帮助抵御它们，包括下面(这并不意味着以下列出来的是详尽无遗的)：&lt;br&gt;&amp;emsp;&amp;emsp;1.流量正常是来自一个特定的IP地址的集合，属于那么完成攻击的机器。所以，每一个ip地址负责发起许多连接，而不是你想象的它们来自一个真实用户。&lt;br&gt;&amp;emsp;&amp;emsp;&lt;strong&gt;注意：&lt;/strong&gt;不要认为这些流量情况总是代表一次DDoS攻击。代理服务器转发也会造成这种情况，因为代理服务器的ip地址被作为了所有真实客户端的ip地址。不管怎么样，来自于一个代理服务器转发的连接请求数要比真正DDoS攻击的请求数量少很多。&lt;br&gt;&amp;emsp;&amp;emsp;2.因为流量是由于肉鸡产生的，而且是为了压垮目标服务器，流量的速率比一个真实用户能产生的要大的多。&lt;br&gt;&amp;emsp;&amp;emsp;3.头部中的User-Agent有时候被设置为一个非标准值。&lt;br&gt;&amp;emsp;&amp;emsp;4.头部中的Referer有时候被设置为某个值，使你能联想到这是攻击。&lt;/p&gt;
&lt;h1 id=&quot;用Nginx和Nginx-Plus抵御DDoS攻击&quot;&gt;&lt;a href=&quot;#用Nginx和Nginx-Plus抵御DDoS攻击&quot; class=&quot;headerlink&quot; title=&quot;用Nginx和Nginx Plus抵御DDoS攻击&quot;&gt;&lt;/a&gt;用Nginx和Nginx Plus抵御DDoS攻击&lt;/h1&gt;&lt;hr&gt;
&lt;p&gt;Nginx和Nginx Plus有许多特性——和上面提到的DDoS攻击的特性相结合——可以成为有效地防御DDoS攻击的一部分。因为它们是代理后端服务器，这些特性通过调节流量的进入和控制流量来防御DDoS攻击。&lt;/p&gt;
&lt;h2 id=&quot;限制请求速率&quot;&gt;&lt;a href=&quot;#限制请求速率&quot; class=&quot;headerlink&quot; title=&quot;限制请求速率&quot;&gt;&lt;/a&gt;限制请求速率&lt;/h2&gt;&lt;p&gt;你可以限制Nginx和Nginx Plus接收用户的请求速率为一个典型的真实用户请求的速率值。例如，你可以决定一个真正的用户每2秒只能访问登录页面一次。你可以配置Nginx和Nginx Plus允许一个ip地址每2秒可以尝试登录一次(相当于一分钟可以发起30次请求):&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
    &lt;code&gt;
    limit_req_zone $binary_remote_addr zone=one:10m rate=30r/m;

    server {
        ...
        location /login.html {
            limit_req zone=one;
        ...
        }
    }
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_limit_req_module.html?&amp;amp;_ga=1.17821497.1466916160.1455516425#limit_req_zone&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;limit_req_zone&lt;/a&gt;指令配置一个名字为one的共享区域，用来存储指定的key的请求状态，这种情况下客户端ip地址用变量($binary_remote_addr)来表示。在location /login.html模块中的&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_limit_req_module.html?&amp;amp;_ga=1.256286731.1466916160.1455516425#limit_req&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;limit_req&lt;/a&gt;指令指定了用到的共享存储区域。&lt;/p&gt;
&lt;h2 id=&quot;限制连接数&quot;&gt;&lt;a href=&quot;#限制连接数&quot; class=&quot;headerlink&quot; title=&quot;限制连接数&quot;&gt;&lt;/a&gt;限制连接数&lt;/h2&gt;&lt;p&gt;你可以限制一个客户端ip地址可以建立的连接数，指定为一个合适的值。例如，对于你网站的/store资源，你可以允许每个一个客户端ip地址打开不多于10个连接:&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
    &lt;code&gt;
    limit_conn_zone $binary_remote_addr zone=addr:10m;

    server {
        ...
        location /store/ {
           limit_conn addr 10;
        ...
        }
    }
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html?&amp;amp;_ga=1.256286731.1466916160.1455516425#limit_conn_zone&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;limit_conn_zone&lt;/a&gt;指令配置了一个名为&lt;strong&gt;addr&lt;/strong&gt;的共享区域，用来存储指定的key的请求状态，这种情况下客户端ip用变量$binary_remote_addr来表示。在location /store模块中的&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html?&amp;amp;_ga=1.256286731.1466916160.1455516425#limit_conn&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;limit_conn&lt;/a&gt;指令指定了共享存储区域和设置一个客户端ip的最大连接数为10。&lt;/p&gt;
&lt;h2 id=&quot;关闭慢连接&quot;&gt;&lt;a href=&quot;#关闭慢连接&quot; class=&quot;headerlink&quot; title=&quot;关闭慢连接&quot;&gt;&lt;/a&gt;关闭慢连接&lt;/h2&gt;&lt;p&gt;你可以把写数据非常少的连接关闭掉，这些连接尝试着保持连接尽可能长时间(那样会降低服务器接收新连接的能力)。Slowloris就是一个攻击的例子。&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_core_module.html?&amp;amp;_ga=1.247309060.1466916160.1455516425#client_body_timeout&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;client_body_timeout&lt;/a&gt;指令控制Nginx等待客户端的发送请求体的时间间隔，&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_core_module.html?&amp;amp;_ga=1.247309060.1466916160.1455516425#client_header_timeout&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;client_header_timeout&lt;/a&gt;指令控制Nginx等待客户端发送请求头的时间间隔。默认这两个指令设置的时间是60秒。下面的例子配置Nginx等待请求头和请求体的时间不超过5秒。&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
    &lt;code&gt;
    server {
        client_body_timeout 5s;
        client_header_timeout 5s;
        ...
    }
    &lt;/code&gt;
&lt;/pre&gt;

&lt;h2 id=&quot;把IP地址列入黑名单&quot;&gt;&lt;a href=&quot;#把IP地址列入黑名单&quot; class=&quot;headerlink&quot; title=&quot;把IP地址列入黑名单&quot;&gt;&lt;/a&gt;把IP地址列入黑名单&lt;/h2&gt;&lt;p&gt;如果你能够确认某个客户端ip地址是用来攻击的，你可以使用deny指令让Nginx和Nginx Plus不接受来自他们的连接或请求。例如，如果你确定攻击来自ip地址范围是123.123.123.1~123.123.123.16:&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
    &lt;code&gt;
    location / {
        deny 123.123.123.0/28;
        ...
    }
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;或者如果你确定攻击来自于客户端ip地址123.123.123.3,123.123.123.5和123.123.123.7:&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
    &lt;code&gt;
    location / {
       deny 123.123.123.3;
       deny 123.123.123.5;
       deny 123.123.123.7;
       ...
    }
    &lt;/code&gt;
&lt;/pre&gt;

&lt;h2 id=&quot;把IP地址列入白名单&quot;&gt;&lt;a href=&quot;#把IP地址列入白名单&quot; class=&quot;headerlink&quot; title=&quot;把IP地址列入白名单&quot;&gt;&lt;/a&gt;把IP地址列入白名单&lt;/h2&gt;&lt;p&gt;如果仅允许来自某个或某些特定集合范围的客户端ip地址访问你的网站，你可以一起使用allow和deny指令只允许那些ip地址访问你的网站和应用。例如，你可以限定一个指定网络中的ip地址可以访问网站或应用：&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
    &lt;code&gt;
    location / {
       allow 192.168.1.0/24;
       deny all;
       ...
    }
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;这里，deny指令阻止了所有的客户端ip地址的访问，除了allow指令指定的ip地址范围。&lt;/p&gt;
&lt;h2 id=&quot;使用缓存来缓和流量峰值&quot;&gt;&lt;a href=&quot;#使用缓存来缓和流量峰值&quot; class=&quot;headerlink&quot; title=&quot;使用缓存来缓和流量峰值&quot;&gt;&lt;/a&gt;使用缓存来缓和流量峰值&lt;/h2&gt;&lt;p&gt;你可以配置Nginx和Nginx Plus开启缓存和设置指定的缓存参数来吸收一次攻击中的流量峰值，为后端减轻请求压力。一些有帮助的设置有： &lt;br&gt;&lt;br&gt;&amp;emsp;&amp;emsp;1.&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_use_stale&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;proxy_cache_use_stale&lt;/a&gt;指令的updating参数告诉Nginx当它需要获取一个陈旧的缓存对象的更新时，它应该只用一个线程去更新缓存对象，并且在线程接收到后端服务器已更新通知的时间段内，所有线程仍然提供陈旧的对象给请求它们的客户端。当一次攻击中有重复请求同一个文件的，这将大大减少对后端服务器的请求数量。 &lt;br&gt;&lt;br&gt;&amp;emsp;&amp;emsp;2.&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_proxy_module.html?&amp;amp;_ga=1.88409883.1466916160.1455516425#proxy_cache_key&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;proxy_cache_key&lt;/a&gt;指令定义的key通常由嵌入的变量(默认的key有3个，$scheme$proxy_host$request_uri)。如果值中包含变量&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_core_module.html?&amp;amp;_ga=1.17821497.1466916160.1455516425#var_query_string&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;$query_string&lt;/a&gt;，那么一次攻击发送随机的查询字符串会导致过多的缓存。我们推荐不要在key中使用变量$query_string，除非你有特殊的理由。&lt;/p&gt;
&lt;h2 id=&quot;阻塞请求&quot;&gt;&lt;a href=&quot;#阻塞请求&quot; class=&quot;headerlink&quot; title=&quot;阻塞请求&quot;&gt;&lt;/a&gt;阻塞请求&lt;/h2&gt;&lt;p&gt;你可以配置Nginx和Nginx Plus去阻塞几种请求： &lt;br&gt;&lt;br&gt;&amp;emsp;&amp;emsp;1.请求一个似乎是目标的中指定URL&lt;br&gt;&amp;emsp;&amp;emsp;2.请求中的User-Agent头部的值与正常客户端请求的值符合&lt;br&gt;&amp;emsp;&amp;emsp;3.请求中的Referer头部的值被设置为了一个与攻击有关系的值&lt;br&gt;&amp;emsp;&amp;emsp;4.请求中的其他头部有与攻击相关的值。 &lt;br&gt;&lt;br&gt;例如：如果你确定DDoS攻击是攻击目标URL &lt;strong&gt;/foo.php&lt;/strong&gt;，你可以阻止对这个页面的所有请求： &lt;br&gt;&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
    &lt;code&gt;
    location /foo.php {
       deny all;
    }
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;或者如果你发现DDoS攻击请求中的User-Agent头部的值是foo或bar，你可以拒绝这些请求。 &lt;br&gt;&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
    &lt;code&gt;
    location / {
       if ($http_user_agent ~* foo|bar) {
           return 403;
       }
       ...
    }
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;变量http_&lt;em&gt;name&lt;/em&gt;引用一个请求头，在上面的例子中就是User-Agent头部。类似的方法可以用在其他的那些可能被用来标识一次攻击的头部上。&lt;/p&gt;
&lt;h2 id=&quot;限制连入后端服务器的连接数&quot;&gt;&lt;a href=&quot;#限制连入后端服务器的连接数&quot; class=&quot;headerlink&quot; title=&quot;限制连入后端服务器的连接数&quot;&gt;&lt;/a&gt;限制连入后端服务器的连接数&lt;/h2&gt;&lt;p&gt;一个Nginx和Nginx Plus实例通常可以对付的并发数比它正在负载均衡的后端服务器要多。使用Nginx Plus，你可以限制每个后端服务器所接受的请求数。例如，如果你想通过Nginx Plus限制名字叫做&lt;strong&gt;website&lt;/strong&gt;后端服务器组里的两个服务器中每个服务器接受不超过200个连接：&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
    &lt;code&gt;
    upstream website {
       server 192.168.100.1:80 max_conns=200;
       server 192.168.100.2:80 max_conns=200;
       queue 10 timeout=30s;
    }
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_upstream_module.html?&amp;amp;_ga=1.83879958.1466916160.1455516425#max_conns&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;max_conns&lt;/a&gt;参数为每一个后端服务器指定Nginx Plus为它们打开的最大连接数。&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_upstream_module.html?&amp;amp;_ga=1.83799446.1466916160.1455516425#queue&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;queue&lt;/a&gt;指令用于当在后端服务器组里的所有服务器都达到了它们的最大连接限制时，限制排队的请求数目。timeout参数指定了一个请求在队列中保留多久。&lt;/p&gt;
&lt;h2 id=&quot;对付基于范围的攻击&quot;&gt;&lt;a href=&quot;#对付基于范围的攻击&quot; class=&quot;headerlink&quot; title=&quot;对付基于范围的攻击&quot;&gt;&lt;/a&gt;对付基于范围的攻击&lt;/h2&gt;&lt;p&gt;攻击的一个方法就是发送一个具有非常大的值的范围头部，这可能会导致缓冲区溢出。关于如何使用NGINX和NGINX Plus以一种简单的方式减缓这种类型的攻击，见&lt;a href=&quot;https://www.nginx.com/blog/nginx-protect-cve-2015-1635/?_ga=1.246867972.1466916160.1455516425&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Using NGINX and NGINX Plus to Protect Against CVE-2015-1635&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;对付高负载&quot;&gt;&lt;a href=&quot;#对付高负载&quot; class=&quot;headerlink&quot; title=&quot;对付高负载&quot;&gt;&lt;/a&gt;对付高负载&lt;/h2&gt;&lt;p&gt;DDoS攻击通常会导致很高流量负载。关于调整NGINX或者NGINX Plus以及操作系统让系统能够处理更高的负载，见&lt;a href=&quot;https://www.nginx.com/blog/tuning-nginx/?_ga=1.11987124.1466916160.1455516425&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Tuning NGINX for Performance&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h1 id=&quot;标识DDoS攻击&quot;&gt;&lt;a href=&quot;#标识DDoS攻击&quot; class=&quot;headerlink&quot; title=&quot;标识DDoS攻击&quot;&gt;&lt;/a&gt;标识DDoS攻击&lt;/h1&gt;&lt;hr&gt;
&lt;p&gt;到目前为主，我们主要关注可以利用NGINX和NGINX Plus减轻DDoS攻击的影响。但是NGINX或者NGINX是如何帮助你发现DDoS攻击？NGINX Plus状态模块提供了对被负载的后端服务器流量的详细度量，你可以使用这些指标发现不正常流量模式。NGINX Plus有一个web页面显示状态信息，生动地描绘了NGINX Plus系统当前的状态(示例见&lt;a href=&quot;http://demo.nginx.com/status.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;demo.nginx.com&lt;/a&gt;)。通过API的方式可以获得同样的指标度量，你可以将这些指标注入自定义或者第三方的监控系统，你可以做历史趋势分析去发现异常模式和启用报警。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h1 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h1&gt;&lt;hr&gt;
&lt;p&gt;NGINX和NGINX Plus可以作为一个减轻DDoS攻击的重要组成部分，而且NGINX Plus提供额外的特性去抵御DDoS攻击，并且在它们发生时，帮助发现它们。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;em&gt;原文&lt;/em&gt;：&lt;a href=&quot;https://www.nginx.com/blog/mitigating-ddos-attacks-with-nginx-and-nginx-plus/?mkt_tok=eyJpIjoiT1dVNE56QXlabVk1WmpBMSIsInQiOiIwSkc5NzZhdDllWlIrUkZZSTZqTFwvTFZXVTVXRlhlUlFSTlErV1VtMENKVUNrRnlRTHowUVBINFRcL2Znd00zbjA1WGVTTXRTcExPSDEzRFwvVks2eVRXcFdcLzdCaHYwazJmVDlQN28xUWY5Ymc9In0%3D&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Mitigating DDoS Attacks&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;DDoS攻击是一种对服务的攻击，一般是对网站的攻击，通过使用多台机器连续的流量轰炸目标服务器，以使得提供服务的主机因为资源用尽而不再能够提供有效地提供服务。&lt;/p&gt;
&lt;p&gt;典型的，攻击者尝试通过大量的连接和请求使系统饱和，以使得目标主机无法再接收新的流量，或者响应变慢地不可用。&lt;br&gt;
    
    </summary>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>个人这一年半以来的运维总结</title>
    <link href="http://yoursite.com/2016/05/23/%E4%B8%AA%E4%BA%BA%E8%BF%99%E4%B8%80%E5%B9%B4%E5%8D%8A%E4%BB%A5%E6%9D%A5%E7%9A%84%E8%BF%90%E7%BB%B4%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2016/05/23/个人这一年半以来的运维总结/</id>
    <published>2016-05-23T05:29:35.000Z</published>
    <updated>2016-06-08T09:40:34.321Z</updated>
    
    <content type="html">&lt;hr&gt;
&lt;p&gt;从事了一年半的运维工作，更多的是做业务运维，或者说是应用运维。对于机房内的一些基础设施，比如交换机、路由器并不清楚怎么去配置。&lt;br&gt;&lt;br&gt;对于一个大公司来说，如果有成型的运维体系，运维按照工作内容来看，可分为基础运维、业务运维、监控运维和产品运维。而我的工作内容就是一些开源组件和商用中间件集群的部署和调优，并写一些脚本做一些简单的自动化部署。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;最近调到其他产品组开始搞大数据运维，同时也开始着手docker的调研。一个人去做这些事情有好处也有坏处，好处是培养自己解决问题的能力，因为处于研发部，研发人员对运维的工作懂得少之又少，所以遇到问题也只能自己想办法去学习相关的知识或者去google解决；而坏处就是去调研一个东西花的时间较长，而且很多东西只能有自己这一个思维去想，不少问题考虑的不够全面。解决问题花的时间也比较长，我记得最长的一次是花了4天。&lt;br&gt;&lt;br&gt;这一年多以来，加了无数的班，基本没什么事情都是在公司学习。学习Linux基础，学习各种服务的原理和部署，学习各种自动化工具，无论说这些东西公司用到用不到。当然，公司产品组用到的一些，也提供了我场景，让我去应用。但是毕竟不是互联网公司，用到的东西不多，而且业务量不大，所以用的也不深。至于加班不加班这种事情，就看自己怎么想了，你觉得你是为公司加班的，而公司又不给加班费，那么你可能会觉得很不爽。如果你觉得你是为自己提升技术能力加班的，那么可能就不会有这方面的怨言了。当然，我们公司也是没有加班费的。&lt;br&gt;&lt;br&gt;干了一年多，也学了不少东西。但是由于身边也没什么做运维工作的人，所以对自己现在所处的水平也是比较疑惑。于是陆续也查看了各大招聘网站上对于Linux运维工程师的要求，也投出了不少，面试了几家。其中包括杭州的几家互联网公司(基本都是6000上以上的)、南京的一些大小公司。杭州的互联网公司面试时相对比较专业，一般都有好几轮，一面会针对简历上的技术点进行询问，二面就是针对整体架构、设计上的一些询问，平时思考问题的方式等。&lt;br&gt;&lt;br&gt;之前一直对自己的能力也不是很清楚，但是经过这几家的面试，发现即便是杭州的互联网公司，自己还是能够定岗到中级运维工程师，也算是对我这一年多的肯定吧。但是与一些运维资深人员交流下来发现两个问题，第一是对一些开源的东西理解的还不够深入；第二是不懂代码，真的很多事情做不了。就如自己一直想要去做运维开发这块，想要去做运维自动化平台，去解决公司环境部署、版本迭代这些重复劳动的工作。但是由于coding能力不足，人手短缺，这块也只是用jenkins+shell做了简单的持续集成和自动发布。还有就是不懂代码，对一些开源的项目理解不够深入，仅仅会使用是完全不够的。要想想它是怎么实现的，如何实现的，以及为什么要这么来实现。在学习的时候，不能浮于表面，要多思考。&lt;br&gt;&lt;br&gt;纵观大多数大型公司的招聘Linux运维工程师的要求，大多都有一条熟悉shell/python/ruby中的一门或两门语言，遇到大数据这种职位，还会要求你精通java。我也打算从java入手，在学校里也是学过java的，只是没做过什么大项目。正好我这个组也就是在做大数据产品，接下来又要经过一段艰难的时光了。当然运维这块工作还是要由我来做，只是把工作的重心转移到开发上来。&lt;br&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;从事了一年半的运维工作，更多的是做业务运维，或者说是应用运维。对于机房内的一些基础设施，比如交换机、路由器并不清楚怎么去配置。&lt;br /&gt;&lt;br&gt;对于一个大公司来说，如果有成型的运维体系，运维按照工作内容来看，可分为基础运维、业务运维、监控运维和产品运维。而我的工作内容就是一些开源组件和商用中间件集群的部署和调优，并写一些脚本做一些简单的自动化部署。&lt;br&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
</feed>
