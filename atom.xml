<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>jkzhao&#39;s blog</title>
  <subtitle>学习 总结 思考</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-07-28T08:51:02.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Zhao Jiankai</name>
    <email>jk.zhaocoder@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Ansible实战：部署分布式日志系统</title>
    <link href="http://yoursite.com/2017/07/27/Ansible%E5%AE%9E%E6%88%98%EF%BC%9A%E9%83%A8%E7%BD%B2%E5%88%86%E5%B8%83%E5%BC%8F%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"/>
    <id>http://yoursite.com/2017/07/27/Ansible实战：部署分布式日志系统/</id>
    <published>2017-07-27T12:30:05.000Z</published>
    <updated>2017-07-28T08:51:02.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;产品组在开发一个分布式日志系统，用的组件较多，单独手工部署一各个个软件比较繁琐，花的时间比较长，于是就想到了使用ansible playbook + roles进行部署，效率大大提高。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;分布式日志系统架构图&quot;&gt;&lt;a href=&quot;#分布式日志系统架构图&quot; class=&quot;headerlink&quot; title=&quot;分布式日志系统架构图&quot;&gt;&lt;/a&gt;分布式日志系统架构图&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/48.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;创建roles&quot;&gt;&lt;a href=&quot;#创建roles&quot; class=&quot;headerlink&quot; title=&quot;创建roles&quot;&gt;&lt;/a&gt;创建roles&lt;/h2&gt;&lt;p&gt;每一个软件或集群都创建一个单独的角色。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# mkdir -pv ansible_playbooks/roles/{db_server,web_server,redis_server,zk_server,kafka_server,es_server,tomcat_server,flume_agent,hadoop,spark,hbase,hive}/{tasks,files,templates,meta,handlers,vars} 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/49.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;JDK7-role&quot;&gt;&lt;a href=&quot;#JDK7-role&quot; class=&quot;headerlink&quot; title=&quot;JDK7 role&quot;&gt;&lt;/a&gt;JDK7 role&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@node1 jdk7]# pwd
/root/ansible_playbooks/roles/jdk7
[root@node1 jdk7]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;上传安装包&quot;&gt;&lt;a href=&quot;#上传安装包&quot; class=&quot;headerlink&quot; title=&quot;上传安装包&quot;&gt;&lt;/a&gt;上传安装包&lt;/h4&gt;&lt;p&gt;将jdk-7u80-linux-x64.gz上传到files目录下。&lt;/p&gt;
&lt;h4 id=&quot;编写tasks&quot;&gt;&lt;a href=&quot;#编写tasks&quot; class=&quot;headerlink&quot; title=&quot;编写tasks&quot;&gt;&lt;/a&gt;编写tasks&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 jdk7]# vim tasks/main.yml 
- name: mkdir necessary catalog                                                                                                               
  file: path=/usr/java state=directory mode=0755
- name: copy and unzip jdk 
  unarchive: src={{jdk_package_name}} dest=/usr/java/
- name: set env 
  lineinfile: dest={{env_file}} insertafter=&amp;quot;{{item.position}}&amp;quot; line=&amp;quot;{{item.value}}&amp;quot; state=present
  with_items:
  - {position: EOF, value: &amp;quot;\n&amp;quot;}
  - {position: EOF, value: &amp;quot;export JAVA_HOME=/usr/java/{{jdk_version}}&amp;quot;}
  - {position: EOF, value: &amp;quot;export PATH=$JAVA_HOME/bin:$PATH&amp;quot;}
  - {position: EOF, value: &amp;quot;export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar&amp;quot;}
- name: enforce env 
  shell: source {{env_file}}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;编写vars&quot;&gt;&lt;a href=&quot;#编写vars&quot; class=&quot;headerlink&quot; title=&quot;编写vars&quot;&gt;&lt;/a&gt;编写vars&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 jdk7]# vim vars/main.yml 
jdk_package_name: jdk-7u80-linux-x64.gz                                                                                                       
env_file: /etc/profile
jdk_version: jdk1.7.0_80
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;使用角色&quot;&gt;&lt;a href=&quot;#使用角色&quot; class=&quot;headerlink&quot; title=&quot;使用角色&quot;&gt;&lt;/a&gt;使用角色&lt;/h4&gt;&lt;p&gt;在roles同级目录，创建一个jdk.yml文件，里面定义好你的playbook。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim jdk.yml 
- hosts: jdk
  remote_user: root
  roles:
  - jdk7
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook安装JDK7：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# ansible-playbook jdk.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;使用jdk7 role可以需要根据实际环境修改vars/main.yml里的变量以及/etc/ansible/hosts文件里定义的主机。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;JDK8-role&quot;&gt;&lt;a href=&quot;#JDK8-role&quot; class=&quot;headerlink&quot; title=&quot;JDK8 role&quot;&gt;&lt;/a&gt;JDK8 role&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@node1 jdk8]# pwd
/root/ansible_playbooks/roles/jdk8
[root@node1 jdk8]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;上传安装包-1&quot;&gt;&lt;a href=&quot;#上传安装包-1&quot; class=&quot;headerlink&quot; title=&quot;上传安装包&quot;&gt;&lt;/a&gt;上传安装包&lt;/h4&gt;&lt;p&gt;将jdk-8u73-linux-x64.gz上传到files目录下。&lt;/p&gt;
&lt;h4 id=&quot;编写tasks-1&quot;&gt;&lt;a href=&quot;#编写tasks-1&quot; class=&quot;headerlink&quot; title=&quot;编写tasks&quot;&gt;&lt;/a&gt;编写tasks&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 jdk8]# vim tasks/main.yml 
- name: mkdir necessary catalog                                                                                                               
  file: path=/usr/java state=directory mode=0755
- name: copy and unzip jdk 
  unarchive: src={{jdk_package_name}} dest=/usr/java/
- name: set env 
  lineinfile: dest={{env_file}} insertafter=&amp;quot;{{item.position}}&amp;quot; line=&amp;quot;{{item.value}}&amp;quot; state=present
  with_items:
  - {position: EOF, value: &amp;quot;\n&amp;quot;}
  - {position: EOF, value: &amp;quot;export JAVA_HOME=/usr/java/{{jdk_version}}&amp;quot;}
  - {position: EOF, value: &amp;quot;export PATH=$JAVA_HOME/bin:$PATH&amp;quot;}
  - {position: EOF, value: &amp;quot;export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar&amp;quot;}
- name: enforce env 
  shell: source {{env_file}}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;编写vars-1&quot;&gt;&lt;a href=&quot;#编写vars-1&quot; class=&quot;headerlink&quot; title=&quot;编写vars&quot;&gt;&lt;/a&gt;编写vars&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 jdk8]# vim vars/main.yml 
jdk_package_name: jdk-8u73-linux-x64.gz                                                                                                       
env_file: /etc/profile
jdk_version: jdk1.8.0_73
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;使用角色-1&quot;&gt;&lt;a href=&quot;#使用角色-1&quot; class=&quot;headerlink&quot; title=&quot;使用角色&quot;&gt;&lt;/a&gt;使用角色&lt;/h4&gt;&lt;p&gt;在roles同级目录，创建一个jdk.yml文件，里面定义好你的playbook。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim jdk.yml 
- hosts: jdk
  remote_user: root
  roles:
  - jdk8
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook安装JDK8：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# ansible-playbook jdk.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;使用jdk8 role可以需要根据实际环境修改vars/main.yml里的变量以及/etc/ansible/hosts文件里定义的主机。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;Zookeeper-role&quot;&gt;&lt;a href=&quot;#Zookeeper-role&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper role&quot;&gt;&lt;/a&gt;Zookeeper role&lt;/h3&gt;&lt;p&gt;Zookeeper集群节点配置好/etc/hosts文件，配置集群各节点主机名和ip地址的对应关系。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 zk_server]# pwd
/root/ansible_playbooks/roles/zk_server
[root@node1 zk_server]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;上传安装包-2&quot;&gt;&lt;a href=&quot;#上传安装包-2&quot; class=&quot;headerlink&quot; title=&quot;上传安装包&quot;&gt;&lt;/a&gt;上传安装包&lt;/h4&gt;&lt;p&gt;将zookeeper-3.4.6.tar.gz和clean_zklog.sh上传到files目录。clean_zklog.sh是清理Zookeeper日志的脚本。&lt;/p&gt;
&lt;h4 id=&quot;编写tasks-2&quot;&gt;&lt;a href=&quot;#编写tasks-2&quot; class=&quot;headerlink&quot; title=&quot;编写tasks&quot;&gt;&lt;/a&gt;编写tasks&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 zk_server]# vim tasks/main.yml 
- name: install zookeeper                                                                                                                     
  unarchive: src=zookeeper-3.4.6.tar.gz dest=/usr/local/
- name: install configuration file for zookeeper
  template: src=zoo.cfg.j2 dest=/usr/local/zookeeper-3.4.6/conf/zoo.cfg
- name: add myid file
  shell: echo {{ myid }} &amp;gt; /usr/local/zookeeper-3.4.6/dataDir/myid
- name: copy script to clear zookeeper logs.
  copy: src=clean_zklog.sh dest=/usr/local/zookeeper-3.4.6/clean_zklog.sh mode=755
- name: crontab task
  cron: name=&amp;quot;clear zk logs&amp;quot; weekday=&amp;quot;0&amp;quot; hour=&amp;quot;0&amp;quot; minute=&amp;quot;0&amp;quot; job=&amp;quot;/usr/local/zookeeper-3.4.6/clean_zklog.sh&amp;quot;
- name: start zookeeper
  shell: /usr/local/zookeeper-3.4.6/bin/zkServer.sh start
  tags:
  - start
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;编写templates&quot;&gt;&lt;a href=&quot;#编写templates&quot; class=&quot;headerlink&quot; title=&quot;编写templates&quot;&gt;&lt;/a&gt;编写templates&lt;/h4&gt;&lt;p&gt;将zookeeper-3.4.6.tar.gz包中的默认配置文件重命名为zoo.cfg.j2，并修改其中的内容。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim roles/zk_server/templates/zoo.cfg.j2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置文件内容过多，具体见github。配置文件内容也不在解释，在前面博客中的文章中都已写明。&lt;/p&gt;
&lt;h4 id=&quot;编写vars-2&quot;&gt;&lt;a href=&quot;#编写vars-2&quot; class=&quot;headerlink&quot; title=&quot;编写vars&quot;&gt;&lt;/a&gt;编写vars&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 zk_server]# vim vars/main.yml 
server1_hostname: hadoop27                                                                                                                    
server2_hostname: hadoop28
server3_hostname: hadoop29
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;另外在tasks中还使用了个变量，该变量每台主机的值是不一样的，所以定义在了/etc/ansible/hosts文件中:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[zk_servers]
172.16.206.27 myid=1
172.16.206.28 myid=2
172.16.206.29 myid=3
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;设置主机组&quot;&gt;&lt;a href=&quot;#设置主机组&quot; class=&quot;headerlink&quot; title=&quot;设置主机组&quot;&gt;&lt;/a&gt;设置主机组&lt;/h4&gt;&lt;p&gt;/etc/ansible/hosts文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[zk_servers]
172.16.206.27 myid=1
172.16.206.28 myid=2
172.16.206.29 myid=3
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;使用角色-2&quot;&gt;&lt;a href=&quot;#使用角色-2&quot; class=&quot;headerlink&quot; title=&quot;使用角色&quot;&gt;&lt;/a&gt;使用角色&lt;/h4&gt;&lt;p&gt;在roles同级目录，创建一个zk.yml文件，里面定义好你的playbook。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim zk.yml 
- hosts: zk_servers
  remote_user: root
  roles:
  - zk_server
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook安装Zookeeper集群：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# ansible-playbook zk.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;使用zk_server role需要根据实际环境修改vars/main.yml里的变量以及/etc/ansible/hosts文件里定义的主机。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;Kafka-role&quot;&gt;&lt;a href=&quot;#Kafka-role&quot; class=&quot;headerlink&quot; title=&quot;Kafka role&quot;&gt;&lt;/a&gt;Kafka role&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@node1 kafka_server]# pwd
/root/ansible_playbooks/roles/kafka_server
[root@node1 kafka_server]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;上传安装包-3&quot;&gt;&lt;a href=&quot;#上传安装包-3&quot; class=&quot;headerlink&quot; title=&quot;上传安装包&quot;&gt;&lt;/a&gt;上传安装包&lt;/h4&gt;&lt;p&gt;将kafka_2.11-0.9.0.1.tar.gz、kafka-manager-1.3.0.6.zip和clean_kafkalog.sh上传到files目录。clean_kafkalog.sh是清理kafka日志的脚本。&lt;/p&gt;
&lt;h4 id=&quot;编写tasks-3&quot;&gt;&lt;a href=&quot;#编写tasks-3&quot; class=&quot;headerlink&quot; title=&quot;编写tasks&quot;&gt;&lt;/a&gt;编写tasks&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 kafka_server]# vim tasks/main.yml 
- name: copy and unzip kafka
  unarchive: src=kafka_2.11-0.9.0.1.tgz dest=/usr/local/
- name: install configuration file for kafka
  template: src=server.properties.j2 dest=/usr/local/kafka_2.11-0.9.0.1/config/server.properties
- name: copy script to clear kafka logs.
  copy: src=clean_kafkalog.sh dest=/usr/local/kafka_2.11-0.9.0.1/clean_kafkalog.sh mode=755                                                   
- name: crontab task                                                         
  cron: name=&amp;quot;clear kafka logs&amp;quot; weekday=&amp;quot;0&amp;quot; hour=&amp;quot;0&amp;quot; minute=&amp;quot;0&amp;quot; job=&amp;quot;/usr/local/kafka_2.11-0.9.0.1/clean_kafkalog.sh&amp;quot;
- name: start kafka                            
  shell: JMX_PORT=9997 /usr/local/kafka_2.11-0.9.0.1/bin/kafka-server-start.sh -daemon /usr/local/kafka_2.11-0.9.0.1/config/server.properties &amp;amp;                                              
  tags:                                        
  - start                                      
- name: copy and unizp kafka-manager           
  unarchive: src=kafka-manager-1.3.0.6.zip dest=/usr/local/
  when: ansible_default_ipv4[&amp;apos;address&amp;apos;] == &amp;quot;{{kafka_manager_ip}}&amp;quot;
- name: install configuration file for kafka-manager
  template: src=application.conf.j2 dest=/usr/local/kafka-manager-1.3.0.6/conf/application.conf
  when: ansible_default_ipv4[&amp;apos;address&amp;apos;] == &amp;quot;{{kafka_manager_ip}}&amp;quot;
- name: start kafka-manager                    
  shell: nohup /usr/local/kafka-manager-1.3.0.6/bin/kafka-manager &amp;amp;
  when: ansible_default_ipv4[&amp;apos;address&amp;apos;] == &amp;quot;{{kafka_manager_ip}}&amp;quot;
  tags:                                        
  - kafkaManagerStart
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;编写templates-1&quot;&gt;&lt;a href=&quot;#编写templates-1&quot; class=&quot;headerlink&quot; title=&quot;编写templates&quot;&gt;&lt;/a&gt;编写templates&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 kafka_server]# vim templates/server.properties.j2 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置文件内容过多，具体见github。配置文件内容也不再解释，在前面博客中的文章中都已写明。&lt;/p&gt;
&lt;h4 id=&quot;编写vars-3&quot;&gt;&lt;a href=&quot;#编写vars-3&quot; class=&quot;headerlink&quot; title=&quot;编写vars&quot;&gt;&lt;/a&gt;编写vars&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 kafka_server]# vim vars/main.yml
zk_cluster: 172.16.7.151:2181,172.16.7.152:2181,172.16.7.153:2181
kafka_manager_ip: 172.16.7.151 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;另外在template的文件中还使用了个变量，该变量每台主机的值是不一样的，所以定义在了/etc/ansible/hosts文件中:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[kafka_servers]
172.16.206.17 broker_id=0
172.16.206.31 broker_id=1
172.16.206.32 broker_id=2
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;设置主机组-1&quot;&gt;&lt;a href=&quot;#设置主机组-1&quot; class=&quot;headerlink&quot; title=&quot;设置主机组&quot;&gt;&lt;/a&gt;设置主机组&lt;/h4&gt;&lt;p&gt;/etc/ansible/hosts文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[kafka_servers]
172.16.206.17 broker_id=0
172.16.206.31 broker_id=1
172.16.206.32 broker_id=2
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;使用角色-3&quot;&gt;&lt;a href=&quot;#使用角色-3&quot; class=&quot;headerlink&quot; title=&quot;使用角色&quot;&gt;&lt;/a&gt;使用角色&lt;/h4&gt;&lt;p&gt;在roles同级目录，创建一个kafka.yml文件，里面定义好你的playbook。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim kafka.yml 
- hosts: kafka_servers
  remote_user: root
  roles:
  - kafka_server
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook安装kafka集群：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# ansible-playbook kafka.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;使用kafka_server role需要根据实际环境修改vars/main.yml里的变量以及/etc/ansible/hosts文件里定义的主机。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;Elasticsearch-role&quot;&gt;&lt;a href=&quot;#Elasticsearch-role&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch role&quot;&gt;&lt;/a&gt;Elasticsearch role&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@node1 es_server]# pwd
/root/ansible_playbooks/roles/es_server
[root@node1 es_server]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;上传安装包-4&quot;&gt;&lt;a href=&quot;#上传安装包-4&quot; class=&quot;headerlink&quot; title=&quot;上传安装包&quot;&gt;&lt;/a&gt;上传安装包&lt;/h4&gt;&lt;p&gt;将elasticsearch-2.3.3.tar.gz  elasticsearch-analysis-ik-1.9.3.zip上传到files目录。&lt;/p&gt;
&lt;h4 id=&quot;编写tasks-4&quot;&gt;&lt;a href=&quot;#编写tasks-4&quot; class=&quot;headerlink&quot; title=&quot;编写tasks&quot;&gt;&lt;/a&gt;编写tasks&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 es_server]# vim tasks/main.yml
- name: create es user
  user: name=es password={{password}}
  vars:
    # created with:
    # python -c &amp;apos;import crypt; print crypt.crypt(&amp;quot;This is my Password&amp;quot;, &amp;quot;$1$SomeSalt$&amp;quot;)&amp;apos;
    # &amp;gt;&amp;gt;&amp;gt; import crypt
    # &amp;gt;&amp;gt;&amp;gt; crypt.crypt(&amp;apos;wisedu123&amp;apos;, &amp;apos;$1$bigrandomsalt$&amp;apos;)
    # &amp;apos;$1$bigrando$wzfZ2ifoHJPvaMuAelsBq0&amp;apos;
    password: $1$bigrando$wzfZ2ifoHJPvaMuAelsBq0
- name: mkdir directory for elasticsearch data
  file: dest=/esdata mode=0755 state=directory owner=es group=es
- name: copy and unzip es
  #unarchive module owner and group only effect on directory.
  unarchive: src=elasticsearch-2.3.3.tar.gz dest=/usr/local/
- name: install memory configuration file for es
  template: src=elasticsearch.in.sh.j2 dest=/usr/local/elasticsearch-2.3.3/bin/elasticsearch.in.sh owner=es group=es
- name: install configuration file for es
  template: src=elasticsearch.yml.j2 dest=/usr/local/elasticsearch-2.3.3/config/elasticsearch.yml owner=es group=es
- name: mkdir directory for elasticsearch-analysis-ik plugin
  file: dest=/usr/local/elasticsearch-2.3.3/plugins/ik mode=0755 state=directory owner=es group=es
- name: copy and unizp elasticsearch-analysis-ik plugin
  unarchive: src=elasticsearch-analysis-ik-1.9.3.zip dest=/usr/local/elasticsearch-2.3.3/plugins/ik
- name: change owner and group
  #recurse=yes make all files in a directory changed.
  file: path=/usr/local/elasticsearch-2.3.3 owner=es group=es recurse=yes
- name: start es
  shell: su - es -c &amp;apos;/usr/local/elasticsearch-2.3.3/bin/elasticsearch -d&amp;apos;
  #command: /usr/local/elasticsearch-2.3.3/bin/elasticsearch -d
  #become: true
  #become_method: su
  #become_user: es
  tags:
  - start
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;编写templates-2&quot;&gt;&lt;a href=&quot;#编写templates-2&quot; class=&quot;headerlink&quot; title=&quot;编写templates&quot;&gt;&lt;/a&gt;编写templates&lt;/h4&gt;&lt;p&gt;将模板elasticsearch.in.sh.j2和elasticsearch.yml.j2放入templates目录下&lt;br&gt;&lt;strong&gt;注意模板里的变量名中间不能用。比如：这样的变量名是不合法的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;配置文件内容过多，具体见github。配置文件内容也不再解释，在前面博客中的文章中都已写明。&lt;/p&gt;
&lt;h4 id=&quot;编写vars-4&quot;&gt;&lt;a href=&quot;#编写vars-4&quot; class=&quot;headerlink&quot; title=&quot;编写vars&quot;&gt;&lt;/a&gt;编写vars&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 es_server]# vim vars/main.yml
ES_MEM: 2g
cluster_name: wisedu
master_ip: 172.16.7.151 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;另外在template的文件中还使用了个变量，该变量每台主机的值是不一样的，所以定义在了/etc/ansible/hosts文件中:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es_servers]
172.16.7.151 node_master=true
172.16.7.152 node_master=false
172.16.7.153 node_master=false 
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;设置主机组-2&quot;&gt;&lt;a href=&quot;#设置主机组-2&quot; class=&quot;headerlink&quot; title=&quot;设置主机组&quot;&gt;&lt;/a&gt;设置主机组&lt;/h4&gt;&lt;p&gt;/etc/ansible/hosts文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es_servers]
172.16.7.151 node_master=true
172.16.7.152 node_master=false
172.16.7.153 node_master=false 
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;使用角色-4&quot;&gt;&lt;a href=&quot;#使用角色-4&quot; class=&quot;headerlink&quot; title=&quot;使用角色&quot;&gt;&lt;/a&gt;使用角色&lt;/h4&gt;&lt;p&gt;在roles同级目录，创建一个es.yml文件，里面定义好你的playbook。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim es.yml 
- hosts: es_servers
  remote_user: root
  roles:
  - es_server
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook安装Elasticsearch集群：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# ansible-playbook es.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;使用es_server role需要根据实际环境修改vars/main.yml里的变量以及/etc/ansible/hosts文件里定义的主机。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;MySQL-role&quot;&gt;&lt;a href=&quot;#MySQL-role&quot; class=&quot;headerlink&quot; title=&quot;MySQL role&quot;&gt;&lt;/a&gt;MySQL role&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@node1 db_server]# pwd
/root/ansible_playbooks/roles/db_server
[root@node1 db_server]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;上传安装包-5&quot;&gt;&lt;a href=&quot;#上传安装包-5&quot; class=&quot;headerlink&quot; title=&quot;上传安装包&quot;&gt;&lt;/a&gt;上传安装包&lt;/h4&gt;&lt;p&gt;将制作好的rpm包mysql-5.6.27-1.x86_64.rpm放到/root/ansible_playbooks/roles/db_server/files/目录下。&lt;br&gt;&lt;strong&gt;【注意】:这个rpm包是自己打包制作的，打包成rpm会使得部署的效率提高。关于如何打包成rpm见之前的博客《速成RPM包制作》。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;编写tasks-5&quot;&gt;&lt;a href=&quot;#编写tasks-5&quot; class=&quot;headerlink&quot; title=&quot;编写tasks&quot;&gt;&lt;/a&gt;编写tasks&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 db_server]# vim tasks/main.yml
- name: install dependency package
  yum: name={{ item }} state=present
  with_items:
  - libaio
  - libaio-devel
- name: copy mysql rpm
  copy: src=mysql-5.6.27-1.x86_64.rpm dest=/tmp/
- name: install mysql
  yum: name=/tmp/mysql-5.6.27-1.x86_64.rpm state=present
- name: start mysql
  shell: /etc/init.d/mysqld start
  tags:
  - start
- name: set up root password
  shell: /usr/local/mysql/bin/mysql -uroot -e &amp;quot;UPDATE mysql.user SET Password=PASSWORD(&amp;apos;wisedu123&amp;apos;) where USER=&amp;apos;root&amp;apos;&amp;quot; &amp;amp;&amp;gt;/dev/null
- name: delete anonymous account1
  shell: /usr/local/mysql/bin/mysql -uroot -Dmysql -pwisedu123 -e &amp;quot;DROP USER &amp;apos;&amp;apos;@localhost&amp;quot; &amp;amp;&amp;gt;/dev/null
- name: delete anonymous account2
  shell: /usr/local/mysql/bin/mysql -uroot -Dmysql -pwisedu123 -e &amp;quot;grant all on *.* to root@&amp;apos;%.%.%.%&amp;apos; identified by &amp;apos;wisedu123&amp;apos;&amp;quot; &amp;amp;&amp;gt;/dev/null
- name: flush privileges
  shell: /usr/local/mysql/bin/mysql -uroot -Dmysql -pwisedu123 -e &amp;quot;flush privileges&amp;quot; &amp;amp;&amp;gt;/dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;设置主机组-3&quot;&gt;&lt;a href=&quot;#设置主机组-3&quot; class=&quot;headerlink&quot; title=&quot;设置主机组&quot;&gt;&lt;/a&gt;设置主机组&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;# vim /etc/ansible/hosts 
[db_servers]
172.16.7.152 
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;使用角色-5&quot;&gt;&lt;a href=&quot;#使用角色-5&quot; class=&quot;headerlink&quot; title=&quot;使用角色&quot;&gt;&lt;/a&gt;使用角色&lt;/h4&gt;&lt;p&gt;在roles同级目录，创建一个db.yml文件，里面定义好你的playbook。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim db.yml 
- hosts: mysql_server
  remote_user: root
  roles:
  - db_server
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook安装MySQL：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# ansible-playbook db.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;使用db_server role需要根据实际环境修改/etc/ansible/hosts文件里定义的主机。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;Nginx-role&quot;&gt;&lt;a href=&quot;#Nginx-role&quot; class=&quot;headerlink&quot; title=&quot;Nginx role&quot;&gt;&lt;/a&gt;Nginx role&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@node1 web_server]# pwd
/root/ansible_playbooks/roles/web_server
[root@node1 web_server]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;上传安装包-6&quot;&gt;&lt;a href=&quot;#上传安装包-6&quot; class=&quot;headerlink&quot; title=&quot;上传安装包&quot;&gt;&lt;/a&gt;上传安装包&lt;/h4&gt;&lt;p&gt;将制作好的rpm包openresty-for-godseye-1.9.7.3-1.x86_64.rpm放到/root/ansible_playbooks/roles/web_server/files/目录下。&lt;br&gt;&lt;strong&gt;【注意】:做成rpm包，在安装时省去了编译nginx的过程，提升了部署效率。这个包里面打包了很多与我们系统相关的文件。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;编写tasks-6&quot;&gt;&lt;a href=&quot;#编写tasks-6&quot; class=&quot;headerlink&quot; title=&quot;编写tasks&quot;&gt;&lt;/a&gt;编写tasks&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 web_server]# vim tasks/main.yml 
- name: install dependency package
  yum: name={{ item }} state=present
  with_items:
  - openssl-devel
  - readline-devel
  - pcre-devel
  - gcc
- name: copy nginx
  copy: src=openresty-for-godseye-1.9.7.3-1.x86_64.rpm dest=/tmp/
- name: install nginx
  yum: name=/tmp/openresty-for-godseye-1.9.7.3-1.x86_64.rpm state=present
- name: install configuration file for nginx
  template: src=nginx.conf.j2 dest=/usr/local/openresty/nginx/conf/nginx.conf
- name: crontab task
  cron: name=&amp;quot;clear nginx logs&amp;quot; weekday=&amp;quot;0&amp;quot; hour=&amp;quot;0&amp;quot; minute=&amp;quot;0&amp;quot; job=&amp;quot;/usr/local/openresty/clrnginxlog.sh&amp;quot;
- name: start nginx
  shell: systemctl start nginx.service
  tags:
  - start
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;编写templates-3&quot;&gt;&lt;a href=&quot;#编写templates-3&quot; class=&quot;headerlink&quot; title=&quot;编写templates&quot;&gt;&lt;/a&gt;编写templates&lt;/h4&gt;&lt;p&gt;将模板nginx.conf.j2放入templates目录下&lt;/p&gt;
&lt;p&gt;配置文件内容过多，具体见github。配置文件内容也不再解释，在前面博客中的文章中都已写明。&lt;/p&gt;
&lt;h4 id=&quot;编写vars-5&quot;&gt;&lt;a href=&quot;#编写vars-5&quot; class=&quot;headerlink&quot; title=&quot;编写vars&quot;&gt;&lt;/a&gt;编写vars&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 web_server]# vim vars/main.yml 
elasticsearch_cluster: server 172.16.7.151:9200;server 172.16.7.152:9200;server 172.16.7.153:9200;
kafka_server1: 172.16.7.151
kafka_server2: 172.16.7.152
kafka_server3: 172.16.7.153   
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;经过测试，变量里面不能有逗号。 &lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;设置主机组-4&quot;&gt;&lt;a href=&quot;#设置主机组-4&quot; class=&quot;headerlink&quot; title=&quot;设置主机组&quot;&gt;&lt;/a&gt;设置主机组&lt;/h4&gt;&lt;p&gt;/etc/ansible/hosts文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/ansible/hosts 
[nginx_servers]
172.16.7.153 
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;使用角色-6&quot;&gt;&lt;a href=&quot;#使用角色-6&quot; class=&quot;headerlink&quot; title=&quot;使用角色&quot;&gt;&lt;/a&gt;使用角色&lt;/h4&gt;&lt;p&gt;在roles同级目录，创建一个nginx.yml文件，里面定义好你的playbook。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim nginx.yml 
- hosts: nginx_servers
  remote_user: root
  roles:
  - web_server  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook安装Nginx：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# ansible-playbook nginx.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;使用web_server role需要根据实际环境修改vars/main.yml里的变量以及/etc/ansible/hosts文件里定义的主机。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;Redis-role&quot;&gt;&lt;a href=&quot;#Redis-role&quot; class=&quot;headerlink&quot; title=&quot;Redis role&quot;&gt;&lt;/a&gt;Redis role&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@node1 redis_server]# pwd
/root/ansible_playbooks/roles/redis_server
[root@node1 redis_server]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;上传安装包-7&quot;&gt;&lt;a href=&quot;#上传安装包-7&quot; class=&quot;headerlink&quot; title=&quot;上传安装包&quot;&gt;&lt;/a&gt;上传安装包&lt;/h4&gt;&lt;p&gt;将制作好的rpm包redis-3.2.2-1.x86_64.rpm放到/root/ansible_playbooks/roles/redis_server/files/目录下。&lt;/p&gt;
&lt;h4 id=&quot;编写tasks-7&quot;&gt;&lt;a href=&quot;#编写tasks-7&quot; class=&quot;headerlink&quot; title=&quot;编写tasks&quot;&gt;&lt;/a&gt;编写tasks&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 redis_server]# vim tasks/main.yml
- name: install dependency package
  yum: name={{ item }} state=present
  with_items:
  - openssl-devel
  - readline-devel
  - pcre-devel
- name: copy redis
  copy: src=redis-3.2.2-1.x86_64.rpm dest=/tmp/
- name: install redis
  yum: name=/tmp/redis-3.2.2-1.x86_64.rpm state=present
- name: start redis
  shell: /usr/local/bin/redis-server /etc/redis.conf
  tags:
  - start
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;设置主机组-5&quot;&gt;&lt;a href=&quot;#设置主机组-5&quot; class=&quot;headerlink&quot; title=&quot;设置主机组&quot;&gt;&lt;/a&gt;设置主机组&lt;/h4&gt;&lt;p&gt;/etc/ansible/hosts文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/ansible/hosts 
[redis_servers]
172.16.7.152 
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;使用角色-7&quot;&gt;&lt;a href=&quot;#使用角色-7&quot; class=&quot;headerlink&quot; title=&quot;使用角色&quot;&gt;&lt;/a&gt;使用角色&lt;/h4&gt;&lt;p&gt;在roles同级目录，创建一个redis.yml文件，里面定义好你的playbook。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim redis.yml 
- hosts: redis_servers
  remote_user: root
  roles:
  - redis_server 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook安装redis：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# ansible-playbook redis.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;使用redis_server role需要根据实际环境修改vars/main.yml里的变量以及/etc/ansible/hosts文件里定义的主机。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;Hadoop-role&quot;&gt;&lt;a href=&quot;#Hadoop-role&quot; class=&quot;headerlink&quot; title=&quot;Hadoop role&quot;&gt;&lt;/a&gt;Hadoop role&lt;/h3&gt;&lt;p&gt;完全分布式集群部署，NameNode和ResourceManager高可用。&lt;br&gt;提前配置集群节点的/etc/hosts文件、节点时间同步、某些集群主节点登录其他节点不需要输入密码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 hadoop]# pwd
/root/ansible_playbooks/roles/hadoop
[root@node1 hadoop]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;上传安装包-8&quot;&gt;&lt;a href=&quot;#上传安装包-8&quot; class=&quot;headerlink&quot; title=&quot;上传安装包&quot;&gt;&lt;/a&gt;上传安装包&lt;/h4&gt;&lt;p&gt;将hadoop-2.7.2.tar.gz放到/root/ansible_playbooks/roles/hadoop/files/目录下。&lt;/p&gt;
&lt;h4 id=&quot;编写tasks-8&quot;&gt;&lt;a href=&quot;#编写tasks-8&quot; class=&quot;headerlink&quot; title=&quot;编写tasks&quot;&gt;&lt;/a&gt;编写tasks&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 hadoop]# cat tasks/main.yml 
- name: install dependency package
  yum: name={{ item }} state=present
  with_items:
  - openssh
  - rsync
- name: create hadoop user
  user: name=hadoop password={{password}}
  vars:
    # created with:
    # python -c &amp;apos;import crypt; print crypt.crypt(&amp;quot;This is my Password&amp;quot;, &amp;quot;$1$SomeSalt$&amp;quot;)&amp;apos;
    # &amp;gt;&amp;gt;&amp;gt; import crypt
    # &amp;gt;&amp;gt;&amp;gt; crypt.crypt(&amp;apos;wisedu123&amp;apos;, &amp;apos;$1$bigrandomsalt$&amp;apos;)
    # &amp;apos;$1$bigrando$wzfZ2ifoHJPvaMuAelsBq0&amp;apos;
    password: $1$bigrando$wzfZ2ifoHJPvaMuAelsBq0
- name: copy and unzip hadoop
  #unarchive module owner and group only effect on directory.
  unarchive: src=hadoop-2.7.2.tar.gz dest=/usr/local/
- name: create hadoop soft link
  file: src=/usr/local/hadoop-2.7.2 dest=/usr/local/hadoop state=link
- name: create hadoop logs directory
  file: dest=/usr/local/hadoop/logs mode=0775 state=directory
- name: change hadoop soft link owner and group
  #recurse=yes make all files in a directory changed.
  file: path=/usr/local/hadoop owner=hadoop group=hadoop recurse=yes
- name: change hadoop-2.7.2 directory owner and group
  #recurse=yes make all files in a directory changed.
  file: path=/usr/local/hadoop-2.7.2 owner=hadoop group=hadoop recurse=yes
- name: set hadoop env
  lineinfile: dest={{env_file}} insertafter=&amp;quot;{{item.position}}&amp;quot; line=&amp;quot;{{item.value}}&amp;quot; state=present
  with_items:
  - {position: EOF, value: &amp;quot;\n&amp;quot;}
  - {position: EOF, value: &amp;quot;# Hadoop environment&amp;quot;}
  - {position: EOF, value: &amp;quot;export HADOOP_HOME=/usr/local/hadoop&amp;quot;}
  - {position: EOF, value: &amp;quot;export PATH=$PATH:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin&amp;quot;}
- name: enforce env
  shell: source {{env_file}}
- name: install configuration file hadoop-env.sh.j2 for hadoop
  template: src=hadoop-env.sh.j2 dest=/usr/local/hadoop/etc/hadoop/hadoop-env.sh owner=hadoop group=hadoop
- name: install configuration file core-site.xml.j2 for hadoop
  template: src=core-site.xml.j2 dest=/usr/local/hadoop/etc/hadoop/core-site.xml owner=hadoop group=hadoop
- name: install configuration file hdfs-site.xml.j2 for hadoop
  template: src=hdfs-site.xml.j2 dest=/usr/local/hadoop/etc/hadoop/hdfs-site.xml owner=hadoop group=hadoop
- name: install configuration file mapred-site.xml.j2 for hadoop
  template: src=mapred-site.xml.j2 dest=/usr/local/hadoop/etc/hadoop/mapred-site.xml owner=hadoop group=hadoop
- name: install configuration file yarn-site.xml.j2 for hadoop
  template: src=yarn-site.xml.j2 dest=/usr/local/hadoop/etc/hadoop/yarn-site.xml owner=hadoop group=hadoop
- name: install configuration file slaves.j2 for hadoop
  template: src=slaves.j2 dest=/usr/local/hadoop/etc/hadoop/slaves owner=hadoop group=hadoop
- name: install configuration file hadoop-daemon.sh.j2 for hadoop
  template: src=hadoop-daemon.sh.j2 dest=/usr/local/hadoop/sbin/hadoop-daemon.sh owner=hadoop group=hadoop
- name: install configuration file yarn-daemon.sh.j2 for hadoop
  template: src=yarn-daemon.sh.j2 dest=/usr/local/hadoop/sbin/yarn-daemon.sh owner=hadoop group=hadoop
# make sure zookeeper started, and then start hadoop.
# start journalnode
- name: start journalnode
  shell: /usr/local/hadoop/sbin/hadoop-daemon.sh start journalnode
  become: true
  become_method: su
  become_user: hadoop
  when: datanode == &amp;quot;true&amp;quot;
# format namenode
- name: format active namenode hdfs
  shell: /usr/local/hadoop/bin/hdfs namenode -format
  become: true
  become_method: su
  become_user: hadoop
  when: namenode_active == &amp;quot;true&amp;quot;
- name: start active namenode hdfs
  shell: /usr/local/hadoop/sbin/hadoop-daemon.sh start namenode
  become: true
  become_method: su
  become_user: hadoop
  when: namenode_active == &amp;quot;true&amp;quot;
- name: format standby namenode hdfs
  shell: /usr/local/hadoop/bin/hdfs namenode -bootstrapStandby
  become: true
  become_method: su
  become_user: hadoop
  when: namenode_standby == &amp;quot;true&amp;quot;
- name: stop active namenode hdfs
  shell: /usr/local/hadoop/sbin/hadoop-daemon.sh stop namenode
  become: true
  become_method: su
  become_user: hadoop
  when: namenode_active == &amp;quot;true&amp;quot;
# format ZKFC
- name: format ZKFC
  shell: /usr/local/hadoop/bin/hdfs zkfc -formatZK
  become: true
  become_method: su
  become_user: hadoop
  when: namenode_active == &amp;quot;true&amp;quot;
# start hadoop cluster
- name: start namenode
  shell: /usr/local/hadoop/sbin/start-dfs.sh
  become: true
  become_method: su
  become_user: hadoop
  when: namenode_active == &amp;quot;true&amp;quot;
- name: start yarn
  shell: /usr/local/hadoop/sbin/start-yarn.sh
  become: true
  become_method: su
  become_user: hadoop
  when: namenode_active == &amp;quot;true&amp;quot;
- name: start standby rm
  shell: /usr/local/hadoop/sbin/yarn-daemon.sh start resourcemanager
  become: true
  become_method: su
  become_user: hadoop
  when: namenode_standby == &amp;quot;true&amp;quot; 
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;编写templates-4&quot;&gt;&lt;a href=&quot;#编写templates-4&quot; class=&quot;headerlink&quot; title=&quot;编写templates&quot;&gt;&lt;/a&gt;编写templates&lt;/h4&gt;&lt;p&gt;将模板core-site.xml.j2、hadoop-daemon.sh.j2、hadoop-env.sh.j2、hdfs-site.xml.j2、mapred-site.xml.j2、slaves.j2、yarn-daemon.sh.j2、yarn-site.xml.j2放入templates目录下。&lt;/p&gt;
&lt;p&gt;配置文件内容过多，具体见github。配置文件内容也不再解释，在前面博客中的文章中都已写明。&lt;/p&gt;
&lt;h4 id=&quot;编写vars-6&quot;&gt;&lt;a href=&quot;#编写vars-6&quot; class=&quot;headerlink&quot; title=&quot;编写vars&quot;&gt;&lt;/a&gt;编写vars&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 hadoop]# vim vars/main.yml 
env_file: /etc/profile
# hadoop-env.sh.j2 file variables.
JAVA_HOME: /usr/java/jdk1.8.0_73
# core-site.xml.j2 file variables.
ZK_NODE1: node1:2181
ZK_NODE2: node2:2181
ZK_NODE3: node3:2181
# hdfs-site.xml.j2 file variables.
NAMENODE1_HOSTNAME: node1
NAMENODE2_HOSTNAME: node2
DATANODE1_HOSTNAME: node3
DATANODE2_HOSTNAME: node4
DATANODE3_HOSTNAME: node5
# mapred-site.xml.j2 file variables.
MR_MODE: yarn
# yarn-site.xml.j2 file variables.
RM1_HOSTNAME: node1
RM2_HOSTNAME: node2
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;设置主机组-6&quot;&gt;&lt;a href=&quot;#设置主机组-6&quot; class=&quot;headerlink&quot; title=&quot;设置主机组&quot;&gt;&lt;/a&gt;设置主机组&lt;/h4&gt;&lt;p&gt;/etc/ansible/hosts文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/ansible/hosts 
[hadoop]
172.16.7.151 namenode_active=true namenode_standby=false datanode=false
172.16.7.152 namenode_active=false namenode_standby=true datanode=false
172.16.7.153 namenode_active=false namenode_standby=false datanode=true
172.16.7.154 namenode_active=false namenode_standby=false datanode=true
172.16.7.155 namenode_active=false namenode_standby=false datanode=true
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;使用角色-8&quot;&gt;&lt;a href=&quot;#使用角色-8&quot; class=&quot;headerlink&quot; title=&quot;使用角色&quot;&gt;&lt;/a&gt;使用角色&lt;/h4&gt;&lt;p&gt;在roles同级目录，创建一个hadoop.yml文件，里面定义好你的playbook。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim hadoop.yml 
- hosts: hadoop
  remote_user: root
  roles:
  - jdk8
  - hadoop  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook安装hadoop集群：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# ansible-playbook hadoop.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;使用hadoop role需要根据实际环境修改vars/main.yml里的变量以及/etc/ansible/hosts文件里定义的主机。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;Spark-role&quot;&gt;&lt;a href=&quot;#Spark-role&quot; class=&quot;headerlink&quot; title=&quot;Spark role&quot;&gt;&lt;/a&gt;Spark role&lt;/h3&gt;&lt;p&gt;Standalone模式部署spark (无HA)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 spark]# pwd
/root/ansible_playbooks/roles/spark
[root@node1 spark]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;上传安装包-9&quot;&gt;&lt;a href=&quot;#上传安装包-9&quot; class=&quot;headerlink&quot; title=&quot;上传安装包&quot;&gt;&lt;/a&gt;上传安装包&lt;/h4&gt;&lt;p&gt;将scala-2.10.6.tgz和spark-1.6.1-bin-hadoop2.6.tgz放到/root/ansible_playbooks/roles/hadoop/files/目录下。&lt;/p&gt;
&lt;h4 id=&quot;编写tasks-9&quot;&gt;&lt;a href=&quot;#编写tasks-9&quot; class=&quot;headerlink&quot; title=&quot;编写tasks&quot;&gt;&lt;/a&gt;编写tasks&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 spark]# cat tasks/main.yml 
- name: copy and unzip scala
  unarchive: src=scala-2.10.6.tgz dest=/usr/local/
- name: set scala env
  lineinfile: dest={{env_file}} insertafter=&amp;quot;{{item.position}}&amp;quot; line=&amp;quot;{{item.value}}&amp;quot; state=present
  with_items:
  - {position: EOF, value: &amp;quot;\n&amp;quot;}
  - {position: EOF, value: &amp;quot;# Scala environment&amp;quot;}
  - {position: EOF, value: &amp;quot;export SCALA_HOME=/usr/local/scala-2.10.6&amp;quot;}
  - {position: EOF, value: &amp;quot;export PATH=$SCALA_HOME/bin:$PATH&amp;quot;}
- name: copy and unzip spark
  unarchive: src=spark-1.6.1-bin-hadoop2.6.tgz dest=/usr/local/
- name: rename spark directory
  command: mv /usr/local/spark-1.6.1-bin-hadoop2.6 /usr/local/spark-1.6.1
- name: set spark env
  lineinfile: dest={{env_file}} insertafter=&amp;quot;{{item.position}}&amp;quot; line=&amp;quot;{{item.value}}&amp;quot; state=present
  with_items:
  - {position: EOF, value: &amp;quot;\n&amp;quot;}
  - {position: EOF, value: &amp;quot;# Spark environment&amp;quot;}
  - {position: EOF, value: &amp;quot;export SPARK_HOME=/usr/local/spark-1.6.1&amp;quot;}
  - {position: EOF, value: &amp;quot;export PATH=$SPARK_HOME/bin:$PATH&amp;quot;}
- name: enforce env
  shell: source {{env_file}}
- name: install configuration file for spark
  template: src=slaves.j2 dest=/usr/local/spark-1.6.1/conf/slaves
- name: install configuration file for spark
  template: src=spark-env.sh.j2 dest=/usr/local/spark-1.6.1/conf/spark-env.sh
- name: start spark cluster
  shell: /usr/local/spark-1.6.1/sbin/start-all.sh
  tags:
  - start
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;编写templates-5&quot;&gt;&lt;a href=&quot;#编写templates-5&quot; class=&quot;headerlink&quot; title=&quot;编写templates&quot;&gt;&lt;/a&gt;编写templates&lt;/h4&gt;&lt;p&gt;将模板slaves.j2和spark-env.sh.j2放到/root/ansible_playbooks/roles/spark/templates/目录下。&lt;/p&gt;
&lt;p&gt;配置文件内容过多，具体见github。配置文件内容也不再解释，在前面博客中的文章中都已写明。&lt;/p&gt;
&lt;h4 id=&quot;编写vars-7&quot;&gt;&lt;a href=&quot;#编写vars-7&quot; class=&quot;headerlink&quot; title=&quot;编写vars&quot;&gt;&lt;/a&gt;编写vars&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 spark]# vim vars/main.yml
env_file: /etc/profile
# spark-env.sh.j2 file variables
JAVA_HOME: /usr/java/jdk1.8.0_73
SCALA_HOME: /usr/local/scala-2.10.6
SPARK_MASTER_HOSTNAME: node1
SPARK_HOME: /usr/local/spark-1.6.1
SPARK_WORKER_MEMORY: 256M
HIVE_HOME: /usr/local/apache-hive-2.1.0-bin
HADOOP_CONF_DIR: /usr/local/hadoop/etc/hadoop/
# slave.j2 file variables
SLAVE1_HOSTNAME: node2
SLAVE2_HOSTNAME: node3
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;设置主机组-7&quot;&gt;&lt;a href=&quot;#设置主机组-7&quot; class=&quot;headerlink&quot; title=&quot;设置主机组&quot;&gt;&lt;/a&gt;设置主机组&lt;/h4&gt;&lt;p&gt;/etc/ansible/hosts文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/ansible/hosts 
[spark]
172.16.7.151
172.16.7.152
172.16.7.153 
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;使用角色-9&quot;&gt;&lt;a href=&quot;#使用角色-9&quot; class=&quot;headerlink&quot; title=&quot;使用角色&quot;&gt;&lt;/a&gt;使用角色&lt;/h4&gt;&lt;p&gt;在roles同级目录，创建一个spark.yml文件，里面定义好你的playbook。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim spark.yml 
- hosts: spark
  remote_user: root
  roles:
  - spark  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook安装spark集群：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# ansible-playbook spark.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;使用spark role需要根据实际环境修改vars/main.yml里的变量以及/etc/ansible/hosts文件里定义的主机。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所有的文件都在github上。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;产品组在开发一个分布式日志系统，用的组件较多，单独手工部署一各个个软件比较繁琐，花的时间比较长，于是就想到了使用ansible playbook + roles进行部署，效率大大提高。&lt;br&gt;
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Ansible之roles介绍</title>
    <link href="http://yoursite.com/2017/07/24/Ansible%E4%B9%8Broles%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2017/07/24/Ansible之roles介绍/</id>
    <published>2017-07-24T01:09:22.000Z</published>
    <updated>2017-07-24T02:52:44.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;什么场景下会用roles？&quot;&gt;&lt;a href=&quot;#什么场景下会用roles？&quot; class=&quot;headerlink&quot; title=&quot;什么场景下会用roles？&quot;&gt;&lt;/a&gt;什么场景下会用roles？&lt;/h2&gt;&lt;p&gt;假如我们现在有3个被管理主机，第一个要配置成httpd，第二个要配置成php服务器，第三个要配置成MySQL服务器。我们如何来定义playbook？&lt;br&gt;第一个play用到第一个主机上，用来构建httpd，第二个play用到第二个主机上，用来构建php，第三个play用到第三个主机上，用来构建MySQL。这些个play定义在playbook中比较麻烦，将来也不利于模块化调用，不利于多次调。比如说后来又加进来一个主机，这个第4个主机既是httpd服务器，又是php服务器，我们只能写第4个play，上面写上安装httpd和php。这样playbook中的代码就重复了。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;为了避免代码重复，roles能够实现代码重复被调用。定义一个角色叫websrvs，第二个角色叫phpappsrvs，第三个角色叫dbsrvs。那么调用时如下来调用：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hosts: host1
role:
- websrvs

hosts: host2
role:
- phpappsrvs

hosts: host3
role:
- dbsrvs

hosts: host4
role:
- websrvs
- phpappsrvs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样代码就可以重复利用了,每个角色可以被独立重复调用。下面举例说明使用方式。&lt;/p&gt;
&lt;h2 id=&quot;roles示例&quot;&gt;&lt;a href=&quot;#roles示例&quot; class=&quot;headerlink&quot; title=&quot;roles示例&quot;&gt;&lt;/a&gt;roles示例&lt;/h2&gt;&lt;p&gt;假设有3台主机，172.16.7.151主机上安装MySQL，172.16.7.152上安装httpd，172.16.7.153上安装MySQL和httpd。我们建立两个角色websrvs和dbsrvs，然后应用到这几个主机上。&lt;/p&gt;
&lt;h3 id=&quot;创建roles的必需目录&quot;&gt;&lt;a href=&quot;#创建roles的必需目录&quot; class=&quot;headerlink&quot; title=&quot;创建roles的必需目录&quot;&gt;&lt;/a&gt;创建roles的必需目录&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@node1 opt]# mkdir -pv ansible_playbooks/roles/{websrvs,dbsrvs}/{tasks,files,templates,meta,handlers,vars}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/44.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/45.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;每个role下面有个目录叫meta，在里面可以新建文件main.yml，在文件中可以设置该role和其它role之前的关联关系。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/46.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;配置角色&quot;&gt;&lt;a href=&quot;#配置角色&quot; class=&quot;headerlink&quot; title=&quot;配置角色&quot;&gt;&lt;/a&gt;配置角色&lt;/h3&gt;&lt;h4 id=&quot;配置角色websrvs&quot;&gt;&lt;a href=&quot;#配置角色websrvs&quot; class=&quot;headerlink&quot; title=&quot;配置角色websrvs&quot;&gt;&lt;/a&gt;配置角色websrvs&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 opt]# cd ansible_playbooks/roles/
[root@node1 roles]# cd websrvs/
[root@node1 websrvs]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;1.将httpd配置文件上传到files目录下，我这里假设httpd.conf每台主机都是一样的，实际上应该用模板，先用一样的配置文件举例&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 websrvs]# cp /etc/httpd/conf/httpd.conf files/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;直接复制的静态文件都放在files目录下。打算用模板文件的都放在templates目录下。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2.编写任务列表tasks&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 websrvs]# vim tasks/main.yml
- name: install httpd package
  yum: name=httpd
- name: install configuration file
  copy: src=httpd.conf dest=/etc/httpd/conf
  tags:
  - conf
  notify:
  - restart httpd
- name: start httpd
  service: name=httpd state=started
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/47.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;3.由于上面的tasks中定义了notify，所以要定义handlers&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 websrvs]# vim handlers/main.yml
- name: restart httpd
  service: name=httpd state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果需要定义变量，则在vars目录下创建main.yml文件，在文件中写入变量，以key:value的形式定义，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http_port: 8080
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;配置角色dbsrvs&quot;&gt;&lt;a href=&quot;#配置角色dbsrvs&quot; class=&quot;headerlink&quot; title=&quot;配置角色dbsrvs&quot;&gt;&lt;/a&gt;配置角色dbsrvs&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@node1 roles]# cd dbsrvs/
[root@node1 dbsrvs]# ls
files  handlers  meta  tasks  templates  vars
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;1.将MySQL配置文件上传到files目录下。&lt;br&gt;2.编写任务列表tasks&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 dbsrvs]# vim tasks/main.yml
- name: install mysql-server package
  yum: name=mysql-server state=latest
- name: install configuration file
  copy: src=my.cnf dest/etc/my.cnf
  tags:
  - conf
  notify:
  - restart mysqld
- name:
  service: name=mysqld enabled=true state=started
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.定义handlers&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 dbsrvs]# vim handlers/main.yml
- name: restart mysqld
  service: name=mysqld state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;定义playbook&quot;&gt;&lt;a href=&quot;#定义playbook&quot; class=&quot;headerlink&quot; title=&quot;定义playbook&quot;&gt;&lt;/a&gt;定义playbook&lt;/h4&gt;&lt;p&gt;【注意】：要在roles目录同级创建playbook。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# vim web.yml
- hosts: 172.16.7.152
  roles:
  - websrvs 

[root@node1 ansible_playbooks]# vim db.yml
- hosts: 172.16.7.151
  roles:
  - dbsrvs 

[root@node1 ansible_playbooks]# vim site.yml
- hosts: 172.16.7.153
  roles:
  - websrvs
  - dbsrvs 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ansible_playbooks]# ansible-playbook web.yml
[root@node1 ansible_playbooks]# ansible-playbook db.yml
[root@node1 ansible_playbooks]# ansible-playbook site.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当然也可以把这些内容写入同一个playbook中。playbook的名字可以自定义。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么场景下会用roles？&quot;&gt;&lt;a href=&quot;#什么场景下会用roles？&quot; class=&quot;headerlink&quot; title=&quot;什么场景下会用roles？&quot;&gt;&lt;/a&gt;什么场景下会用roles？&lt;/h2&gt;&lt;p&gt;假如我们现在有3个被管理主机，第一个要配置成httpd，第二个要配置成php服务器，第三个要配置成MySQL服务器。我们如何来定义playbook？&lt;br&gt;第一个play用到第一个主机上，用来构建httpd，第二个play用到第二个主机上，用来构建php，第三个play用到第三个主机上，用来构建MySQL。这些个play定义在playbook中比较麻烦，将来也不利于模块化调用，不利于多次调。比如说后来又加进来一个主机，这个第4个主机既是httpd服务器，又是php服务器，我们只能写第4个play，上面写上安装httpd和php。这样playbook中的代码就重复了。&lt;br&gt;
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Ansible之tags介绍</title>
    <link href="http://yoursite.com/2017/07/22/Ansible%E4%B9%8Btags%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2017/07/22/Ansible之tags介绍/</id>
    <published>2017-07-22T12:37:16.000Z</published>
    <updated>2017-07-24T01:01:28.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;tags介绍&quot;&gt;&lt;a href=&quot;#tags介绍&quot; class=&quot;headerlink&quot; title=&quot;tags介绍&quot;&gt;&lt;/a&gt;tags介绍&lt;/h2&gt;&lt;p&gt;我们每次改完配置文件，比如上一篇博客中的的apache.yml，没必要把整个playbook都运行一遍，只需要运行改变了的task。我们可以给task一个标签，运行playbook时明确只运行这个标签对应的task就可以了。多个任务可以使用同一个tags。&lt;br&gt;如果在某次运行中，我们多次运行同一个playbook，第一次运行时我们期望所有的tasks都运行，第二次运行时我们期望只运行某一个task，你可以给这个task定义一个tags，例如：&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim apache.yml 
- hosts: nginx
  remote_user: root
  vars:
  - package: apache
  tasks:
  - name: install httpd package
    yum: name={{ package }} state=latest
  - name: install configuration file for httpd
    template: src=/root/conf/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf
    tags:
    - conf                                                                    
    notify:
    - restart httpd
  - name: start httpd service 
    service: enabled=true name=httpd state=started
  handlers:
  - name: restart httpd
    service: name=httpd state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/43.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;运行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-playbook apache.yml --tags=&amp;quot;conf&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果一个playbook中有多个tags，但是有个tag你不想跑，可以使用–skip-tags。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;tags介绍&quot;&gt;&lt;a href=&quot;#tags介绍&quot; class=&quot;headerlink&quot; title=&quot;tags介绍&quot;&gt;&lt;/a&gt;tags介绍&lt;/h2&gt;&lt;p&gt;我们每次改完配置文件，比如上一篇博客中的的apache.yml，没必要把整个playbook都运行一遍，只需要运行改变了的task。我们可以给task一个标签，运行playbook时明确只运行这个标签对应的task就可以了。多个任务可以使用同一个tags。&lt;br&gt;如果在某次运行中，我们多次运行同一个playbook，第一次运行时我们期望所有的tasks都运行，第二次运行时我们期望只运行某一个task，你可以给这个task定义一个tags，例如：&lt;br&gt;
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Ansible之迭代、模板</title>
    <link href="http://yoursite.com/2017/07/20/Ansible%E4%B9%8B%E8%BF%AD%E4%BB%A3%E3%80%81%E6%A8%A1%E6%9D%BF/"/>
    <id>http://yoursite.com/2017/07/20/Ansible之迭代、模板/</id>
    <published>2017-07-20T07:05:29.000Z</published>
    <updated>2017-07-20T09:13:27.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;迭代&quot;&gt;&lt;a href=&quot;#迭代&quot; class=&quot;headerlink&quot; title=&quot;迭代&quot;&gt;&lt;/a&gt;迭代&lt;/h2&gt;&lt;p&gt;当有需要重复性执行的任务时，可以使用迭代机制。其使用格式为将需要迭代的内容定义为item变量引用，并通过with_items语句来指明迭代的元素列表即可。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- name: add several users
  user: name={{ item }} state=present groups=wheel
  with_items:
        - testuser1
        - testuser2
&lt;/code&gt;&lt;/pre&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;上面语句的功能等同于下面的语句：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- name: add user testuser1
  user: name=testuser1 state=present groups=wheel
- name: add user testuser2
  user: name=testuser2 state=present groups=wheel
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;另外，with_items中使用的元素还可以是hashes，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- name: add several users
  user: name={{ item.name }} state=present groups={{ item.groups }}
  with_items:
        - { name: &amp;apos;testuser1&amp;apos;, groups: &amp;apos;wheel&amp;apos;}
        - { name: &amp;apos;testuser2&amp;apos;, groups: &amp;apos;root&amp;apos;}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;【注意】：item是固定变量名。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;模板-JInjia2相关&quot;&gt;&lt;a href=&quot;#模板-JInjia2相关&quot; class=&quot;headerlink&quot; title=&quot;模板(JInjia2相关)&quot;&gt;&lt;/a&gt;模板(JInjia2相关)&lt;/h2&gt;&lt;p&gt;假如为两台webserver安装httpd，而他们的配置文件，172.16.7.152上的httpd需要监听80端口，172.16.7.153需要监听8080端口，ServerName也是不一样的，所以我们就需要两个配置文件，这管理起来极为不便。&lt;br&gt;在这种情况下，我们可以考虑在配置文件中使用变量来定义。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# mkdir templates
[root@node1 ~]# cp conf/httpd.conf templates/
[root@node1 ~]# mv templates/httpd.conf templates/httpd.conf.j2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;后缀为j2表明是Jinja2模板。编辑这个模板：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim templates/httpd.conf.j2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/39.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/40.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;这个模板复制到每台主机上时都应该将这文件里的变量换成对应的值。这个模板就是Jinjia2模板。&lt;/strong&gt;&lt;br&gt;设置每台主机使用的变量值：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim /etc/ansible/hosts
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/41.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;当然这http_port和maxClients也可以在playbook中定义。但是那样我们没法区别每台主机使用不同的值了。因此我们要想让每个主机变量名相同但值不同时只能使用主机变量来定义。下面定义playbook：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim apache.yml 
- hosts: nginx
  remote_user: root
  vars:
  - package: apache
  tasks:
  - name: install httpd package
    yum: name={{ package }} state=latest
  - name: install configuration file for httpd
    template: src=/root/conf/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf                                                                    
    notify:
    - restart httpd
  - name: start httpd service 
    service: enabled=true name=httpd state=started
  handlers:
  - name: restart httpd
    service: name=httpd state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/42.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-playbook apache.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;执行完成后，去查看两个节点的配置文件，发生变量都被替换了。&lt;/p&gt;
&lt;h2 id=&quot;Jinja2相关&quot;&gt;&lt;a href=&quot;#Jinja2相关&quot; class=&quot;headerlink&quot; title=&quot;Jinja2相关&quot;&gt;&lt;/a&gt;Jinja2相关&lt;/h2&gt;&lt;h3 id=&quot;字面量&quot;&gt;&lt;a href=&quot;#字面量&quot; class=&quot;headerlink&quot; title=&quot;字面量&quot;&gt;&lt;/a&gt;字面量&lt;/h3&gt;&lt;p&gt;表达式最简单的形式就是字面量。字面量表示诸如字符串和数值的Python对象。下面的字面量是可用的：&lt;br&gt;1.字符串：“Hello World”&lt;br&gt;双引号或单引号中间的一切都是字符串，无论何时你需要在模板中使用一个字符串（比如函数引用、过滤器或只是包含或继承一个模板的参数），它们都是有用的。&lt;/p&gt;
&lt;p&gt;2.整数和浮点数：42 / 42.23&lt;br&gt;直接写下数值就可以创建整数和浮点数。如果有小数点，则为浮点数，否则为整数。在Python里，42和42.0是不一样的。&lt;/p&gt;
&lt;p&gt;3.列表：[‘list’, ‘of’, ‘object’]&lt;br&gt;一对中括号括起来的东西是一个列表。列表用于存储和迭代序列化的数据。例如你可以容易地在for循环中用列表和元组创建一个链接的列表：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;ul&amp;gt;
{% for href, caption in [(&#39;index.html&#39;, &#39;Index&#39;), (&#39;about.html&#39;, &#39;About&#39;), (&#39;download.html&#39;, &#39;Downloads&#39;)] %}
            &lt;li&gt;&lt;a href=&quot;{{ href }}&quot;&gt;{{ caption }}&lt;/a&gt;&lt;/li&gt;
        {% end for %}
/ul&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.元组：(‘tuple’, ‘of’, ‘values’)&lt;br&gt;元组和列表类似，只是不能修改里面的元素。如果元组中只有一项，你需要使用逗号结尾它。元组通常用于表示两个或更多元素的项。&lt;/p&gt;
&lt;p&gt;5.字典：{‘dict’: ‘of’, ‘key’: ‘and’, ‘value’: ‘pairs’}&lt;br&gt;Python中的字典是一种关联键和值的结构。键必须是唯一的，并且键必须只有一个值。&lt;/p&gt;
&lt;p&gt;6.Boolen：true / false&lt;/p&gt;
&lt;h3 id=&quot;算术运算&quot;&gt;&lt;a href=&quot;#算术运算&quot; class=&quot;headerlink&quot; title=&quot;算术运算&quot;&gt;&lt;/a&gt;算术运算&lt;/h3&gt;&lt;p&gt;Jinja2允许你用计算值。这在模板中很少使用，但为了完整性允许其存在，支持下面的运算符：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+ 把两个对象加到一起，通常对象是整数或浮点数，但是如果两者是字符串或列表，你可以用这种方式来连接它们。无论如何这不是首选的连接字符串的方式。{{ 1 + 1 }}等于2。

- 用第一个数减去第二个数，{{ 3 - 2 }}等于1.

/ 对两个数做除法，返回值会是一个浮点数。{{ 1 / 2 }}等于{{ 0.5 }}。

// 对两个手做除法，返回整数商，{{ 20 / 7 }}等于2。

% 计算整数除法的余数。{{  11 % 7 }}等于4。

* 用右边的数乘左边的操作数。{{ 2 * 2 }}会返回4，也可以用于重复一个字符串多次，{{ &#39;=&#39; * 80 }}会打印80个等号的横条。

** 取左操作数的右操作数次幂，{{ 2**3 }}会返回8。
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;比较操作符&quot;&gt;&lt;a href=&quot;#比较操作符&quot; class=&quot;headerlink&quot; title=&quot;比较操作符&quot;&gt;&lt;/a&gt;比较操作符&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;== 比较两个对象是否相等。
!= 比较两个对象是否不等。
&amp;gt; 如果左边大于右边，返回true。
&amp;lt; 如果左边小于右边，返回true。
&amp;gt;= 如果左边大于等于右边，返回true。
&amp;lt;= 如果左边小于等于右边，返回true。
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;迭代&quot;&gt;&lt;a href=&quot;#迭代&quot; class=&quot;headerlink&quot; title=&quot;迭代&quot;&gt;&lt;/a&gt;迭代&lt;/h2&gt;&lt;p&gt;当有需要重复性执行的任务时，可以使用迭代机制。其使用格式为将需要迭代的内容定义为item变量引用，并通过with_items语句来指明迭代的元素列表即可。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- name: add several users
  user: name={{ item }} state=present groups=wheel
  with_items:
        - testuser1
        - testuser2
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Ansible条件测试</title>
    <link href="http://yoursite.com/2017/07/17/Ansible%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95/"/>
    <id>http://yoursite.com/2017/07/17/Ansible条件测试/</id>
    <published>2017-07-17T05:39:32.000Z</published>
    <updated>2017-07-17T06:10:14.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Ansible条件测试&quot;&gt;&lt;a href=&quot;#Ansible条件测试&quot; class=&quot;headerlink&quot; title=&quot;Ansible条件测试&quot;&gt;&lt;/a&gt;Ansible条件测试&lt;/h2&gt;&lt;p&gt;在ansible中还可以进行条件测试。如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试。&lt;/p&gt;
&lt;h3 id=&quot;when语句&quot;&gt;&lt;a href=&quot;#when语句&quot; class=&quot;headerlink&quot; title=&quot;when语句&quot;&gt;&lt;/a&gt;when语句&lt;/h3&gt;&lt;p&gt;在task后添加when子句即可使用条件测试：when语句支持Jinja2表达式语法。例如：&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- name: &amp;quot;shutdown Debian flavored systems&amp;quot;
  command: /sbin/shutdown -h now
  when: ansible_os_family == &amp;quot;Debian&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;when语句还可以使用Jinja2的大多“filter”，例如要忽略此前某语句额错误并基于其结果（failed或success）运行后面指定的语句，可使用类似如下形式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- command: /bin/false
  register: result
  ignore_errors: True
- command: /bin/sonmething
  when: result|failed
- command: /bin/something_else
  when: result|success
- command: /bin/still/something_else
  when: result|skipped
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此外，when语句还可以使用facts或playbook中定义的变量。facts就是主机报告上来的变量。比如：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/37.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Ansible条件测试&quot;&gt;&lt;a href=&quot;#Ansible条件测试&quot; class=&quot;headerlink&quot; title=&quot;Ansible条件测试&quot;&gt;&lt;/a&gt;Ansible条件测试&lt;/h2&gt;&lt;p&gt;在ansible中还可以进行条件测试。如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试。&lt;/p&gt;
&lt;h3 id=&quot;when语句&quot;&gt;&lt;a href=&quot;#when语句&quot; class=&quot;headerlink&quot; title=&quot;when语句&quot;&gt;&lt;/a&gt;when语句&lt;/h3&gt;&lt;p&gt;在task后添加when子句即可使用条件测试：when语句支持Jinja2表达式语法。例如：&lt;br&gt;
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>ansible playbook基础组件介绍</title>
    <link href="http://yoursite.com/2017/07/15/ansible-playbook%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2017/07/15/ansible-playbook基础组件介绍/</id>
    <published>2017-07-15T07:24:31.000Z</published>
    <updated>2017-07-20T08:18:24.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;ansible-playbook介绍&quot;&gt;&lt;a href=&quot;#ansible-playbook介绍&quot; class=&quot;headerlink&quot; title=&quot;ansible playbook介绍&quot;&gt;&lt;/a&gt;ansible playbook介绍&lt;/h2&gt;&lt;p&gt;playbook是由一个或多个“play”组成的列表(剧本是由多出戏组成的)。play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色。从根本上来讲，所谓task无非是调用ansible的一个module。将多个play组织在一个playbook中，即可以让它们联同起来按事先编排的机制同唱一台大戏。下面是一个简单示例。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- hosts: webnodes
  vars:
  http_port: 80
  max_clients: 256
remote_user: root
tasks:          
- name: ensure apache is at the latest version
  yum: name=httpd state=latest
- name: ensure apache is running
  service: name=httpd state=started
handlers:
- name: restart apache
  service: name=httpd state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，tasks是一个一个任务。&lt;/p&gt;
&lt;h2 id=&quot;ansible-playbook基础组件&quot;&gt;&lt;a href=&quot;#ansible-playbook基础组件&quot; class=&quot;headerlink&quot; title=&quot;ansible playbook基础组件&quot;&gt;&lt;/a&gt;ansible playbook基础组件&lt;/h2&gt;&lt;p&gt;Playbooks结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tasks：任务，即调用模块完成的某操作。&lt;/li&gt;
&lt;li&gt;Variables：变量&lt;/li&gt;
&lt;li&gt;Templates：模板&lt;/li&gt;
&lt;li&gt;Handlers：处理器，指的是在某条件满足时能够触发完成的功能，或者说是由某事件触发执行的操作&lt;/li&gt;
&lt;li&gt;Roles：角色。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Hosts和Users&quot;&gt;&lt;a href=&quot;#Hosts和Users&quot; class=&quot;headerlink&quot; title=&quot;Hosts和Users&quot;&gt;&lt;/a&gt;Hosts和Users&lt;/h3&gt;&lt;p&gt;playbook中的每一个play的目的都是为了让某个或某些主机以某个指定的用户身份执行任务。hosts用于指定要执行指定任务的主机，其可以是一个或多个由冒号分隔主机组；remote_user则用于指定远程主机上的执行任务的用户。如上面示例中的&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-hosts: webnodes
 remote_user: root
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;不过，remote_user也可用于各task中。也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- hosts: webnodes
 remote_user: mageedu
 tasks:
   - name: test connection
     ping:
     remote_user: mageedu
     sudo: yes
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;比如写一个最简单的playbook，里面写了两个play，一个play是在nginx组的主机上都创建一个nginx组，nginx用户，另一个play是复制一个文件到mysql组的主机上：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim nginx.yml
- hosts: nginx                                                                                                                                
  remote_user: root
  tasks:
  - name: create nginx group
    group: name=nginx system=yes gid=208
  - name: create nginx user
    user: name=nginx uid=208 group=nginx system=yes
- hosts: mysql
  remote_user: root
  tasks:
  - name: copy file to mysql hosts
    copy: src=/etc/inittab dest=/tmp/inittab.ans
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看ansible-playbook的使用方法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# man ansible-playbook
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-playbook nginx.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/31.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;任务列表-Tasks-和action&quot;&gt;&lt;a href=&quot;#任务列表-Tasks-和action&quot; class=&quot;headerlink&quot; title=&quot;任务列表(Tasks)和action&quot;&gt;&lt;/a&gt;任务列表(Tasks)和action&lt;/h3&gt;&lt;p&gt;play的主体部分是task list。task list中的各任务按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个任务后再开始第二个。在运行自下而下某playbook时，如果中途发生错误，所有已执行任务都可能回滚，因此，在更正playbook后重新执行一次即可。(因为具有幂等性)&lt;br&gt;task的目的是使用指定的参数执行模块，而在模块参数中可以使用变量。模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致。&lt;br&gt;每个task都应该有其name，用于playbook的执行结果输出，建议其内容尽可能清晰地描述任务执行步骤。如果未提供name，则action的结果将用于输出。&lt;br&gt;定义task的可以使用“action: module options”(这个在较新版本上才能执行)或“module: options”的格式，推荐使用后者以实现向后兼容。如果action一行的内容过多，也可以使用在行首使用几个空白字符进行换行。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- name: make sure apache is running
  service: name=httpd state=running
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在众多模块中，只有command和shell模块仅需要给定一个列表而无需使用“key=value”格式，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- name: disable selinux
  command: /sbin/setenforce 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果命令或脚本的退出码不为零，可能会阻止playbook继续往下执行可以使用如下方式替代：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- name: run this command and ignore the result
  shell: /usr/bin/somecommand || /bin/true
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;也就是说这个命令失败也是要继续往下走的，就是失败了但不要影响下面的操作。或者使用ignore_errors来忽略错误信息：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- name: run this command and ignore the result
  shell: /usr/bin/somecommand
  ignore_errors: True        
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;handlers&quot;&gt;&lt;a href=&quot;#handlers&quot; class=&quot;headerlink&quot; title=&quot;handlers&quot;&gt;&lt;/a&gt;handlers&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;用于当关注的资源发生变化时采取一定的操作。&lt;/strong&gt;&lt;br&gt;“notify”这个action可用于在每个play的最后被触发，这样可以避免多次有改变发生时每次都执行指定的操作，取而代之，仅在所有的变化发生完成后一次性地执行指定操作。在notify中列出的操作称为handler，也即notify中调用handler中定义的操作。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- name: template configuration file
  template: src=template.j2 dest=/etc/foo.conf
  notify:
  - restart memcached
  - restart apache    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;handler是task列表，这些task与前述的task并没有本质上的不同。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;handlers:
- name: restart memcached
  service:  name=memcached state=restarted
- name: restart apache
  service: name=apache state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【举例】：比如有个配置nginx的playbook，然后利用这个来说明handlers。&lt;br&gt;1.先创建一个apache.yml，里面定义play安装启动apache&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim apache.yml
- hosts: mysql
  remote_user: root
  tasks:
  - name: install httpd package
    yum: name=httpd state=latest
  - name: install configuration file for httpd
    copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf 
  - name: start httpd service 
    service: enabled=true name=httpd state=started
[root@node1 ~]# ansible-playbook apache.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.假如说某个时刻httpd.conf发生改变了，比如说不再监听在80，而是监听在8080端口，其他没变。修改/root/conf/httpd.conf，把端口改成8080，再执行这个playbook：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-playbook apache.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;到mysql组所在的主机172.16.7.153上查看端口，发现监听端口仍然是80：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node3 ~]# ss -tnlp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/32.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;3.一个程序的配置文件发生了改变，那么程序应该重读配置文件才对。然而默认情况下，你多次唱同一个剧本，如果那个task此前执行过，为了保证幂等性，它是不会再被执行。handlers就是为了解决这种问题而生的。Handlers也是任务，但它不是上来就执行的，只有某个条件满足时才会执行。所以我们去修改apache.yml：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- hosts: mysql
  remote_user: root
  tasks:
  - name: install httpd package
    yum: name=httpd state=latest
  - name: install configuration file for httpd
    copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf 
    notify:
    - restart httpd
  - name: start httpd service 
    service: enabled=true name=httpd state=started
  handlers:
  - name: restart httpd
    service: name=httpd state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/33.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;修改/root/conf/httpd.conf，把端口改成8090，再执行这个playbook：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-playbook apache.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/34.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;到mysql组所在的主机172.16.7.153上查看端口，发现监听端口改变了，变成了8090：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/35.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;playbook中使用变量&quot;&gt;&lt;a href=&quot;#playbook中使用变量&quot; class=&quot;headerlink&quot; title=&quot;playbook中使用变量&quot;&gt;&lt;/a&gt;playbook中使用变量&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;- hosts: mysql
  remote_user: root
  vars:
  - package: httpd
  tasks:
  - name: install httpd package
    yum: name={{ package }} state=latest                                                                                                      
  - name: install configuration file for httpd
    copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf 
    notify:
    - restart httpd
  - name: start httpd service 
    service: enabled=true name=httpd state=started
  handlers:
  - name: restart httpd
    service: name=httpd state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/36.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;【注意】：playbook中能使用的变量不仅仅是这里定义的变量，而是可以使用ansible中定义的所有变量。例如：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible 172.16.7.152 -m setup
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/37.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;另外，在inventory中定义的变量也可以在playbook中调用。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim /etc/ansible/hosts
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/38.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;ansible-playbook介绍&quot;&gt;&lt;a href=&quot;#ansible-playbook介绍&quot; class=&quot;headerlink&quot; title=&quot;ansible playbook介绍&quot;&gt;&lt;/a&gt;ansible playbook介绍&lt;/h2&gt;&lt;p&gt;playbook是由一个或多个“play”组成的列表(剧本是由多出戏组成的)。play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色。从根本上来讲，所谓task无非是调用ansible的一个module。将多个play组织在一个playbook中，即可以让它们联同起来按事先编排的机制同唱一台大戏。下面是一个简单示例。&lt;br&gt;
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Ansible的基础元素和YAML介绍</title>
    <link href="http://yoursite.com/2017/07/11/Ansible%E7%9A%84%E5%9F%BA%E7%A1%80%E5%85%83%E7%B4%A0%E5%92%8CYAML%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2017/07/11/Ansible的基础元素和YAML介绍/</id>
    <published>2017-07-11T10:37:28.000Z</published>
    <updated>2017-07-14T08:03:58.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;YAML&quot;&gt;&lt;a href=&quot;#YAML&quot; class=&quot;headerlink&quot; title=&quot;YAML&quot;&gt;&lt;/a&gt;YAML&lt;/h2&gt;&lt;h3 id=&quot;YAML介绍&quot;&gt;&lt;a href=&quot;#YAML介绍&quot; class=&quot;headerlink&quot; title=&quot;YAML介绍&quot;&gt;&lt;/a&gt;YAML介绍&lt;/h3&gt;&lt;p&gt;YAML是一个可读性高的用来表达资料序列的格式。YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822等。Clark Evans在2001年在首次发表了这种语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者。&lt;br&gt;YAML Ain’t Markup Language，即YAML不是XML。不过，在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）。其特性：&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;YAML的可读性好&lt;/li&gt;
&lt;li&gt;YAML和脚本语言的交互性好&lt;/li&gt;
&lt;li&gt;YAML使用实现语言的数据类型&lt;/li&gt;
&lt;li&gt;YAML有一个一致的信息模型&lt;/li&gt;
&lt;li&gt;YAML易于实现&lt;/li&gt;
&lt;li&gt;YAML可以基于流来处理&lt;/li&gt;
&lt;li&gt;YAML表达能力强，扩展性好&lt;br&gt;更多的内容及规范参见&lt;a href=&quot;http://www.yaml.org。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.yaml.org。&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;YAML语法&quot;&gt;&lt;a href=&quot;#YAML语法&quot; class=&quot;headerlink&quot; title=&quot;YAML语法&quot;&gt;&lt;/a&gt;YAML语法&lt;/h3&gt;&lt;p&gt;YAML的语法和其他高阶语言类似，并且可以简单表达清单、散列表、标量等数据结构。其结构（Structure）通过空格来展示，序列（Sequence）里的项用”-“来代表，Map里的键值对用”:”分隔。下面是一个示例。YAML是用键值对和缩进来表示的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name: John Smith
age: 41
gender: Male
spouse:                         
    name: Jane Smith
    age: 37
    gender: Female
children:                     
    - name: Jimmy Smith
      age: 17
      gender: Male
    - name: Jenny Smith
      age 13
      gender: Female
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;YAML文件扩展名通常为.yaml，如example.yaml。&lt;/p&gt;
&lt;h3 id=&quot;Ansible常用的数据类型&quot;&gt;&lt;a href=&quot;#Ansible常用的数据类型&quot; class=&quot;headerlink&quot; title=&quot;Ansible常用的数据类型&quot;&gt;&lt;/a&gt;Ansible常用的数据类型&lt;/h3&gt;&lt;p&gt;在ansible中常用的数据类型有序列(list)，也叫列表，还有字典，这些都很类似Python语言。&lt;/p&gt;
&lt;h4 id=&quot;list&quot;&gt;&lt;a href=&quot;#list&quot; class=&quot;headerlink&quot; title=&quot;list&quot;&gt;&lt;/a&gt;list&lt;/h4&gt;&lt;p&gt;列表中的所有元素都使用“-”打头，例如：A list of tasty fruits&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apple&lt;/li&gt;
&lt;li&gt;Orange&lt;/li&gt;
&lt;li&gt;Strawberry&lt;/li&gt;
&lt;li&gt;Mango&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;dictionary&quot;&gt;&lt;a href=&quot;#dictionary&quot; class=&quot;headerlink&quot; title=&quot;dictionary&quot;&gt;&lt;/a&gt;dictionary&lt;/h4&gt;&lt;h2 id=&quot;字典通过key与value进行标识，例如：&quot;&gt;&lt;a href=&quot;#字典通过key与value进行标识，例如：&quot; class=&quot;headerlink&quot; title=&quot;字典通过key与value进行标识，例如：&quot;&gt;&lt;/a&gt;字典通过key与value进行标识，例如：&lt;/h2&gt;&lt;p&gt;An employee record：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name: Example Developer
job: Developer
skill: Elite
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;也可以将key-value放置于-中进行表示，例如：&quot;&gt;&lt;a href=&quot;#也可以将key-value放置于-中进行表示，例如：&quot; class=&quot;headerlink&quot; title=&quot;也可以将key:value放置于{}中进行表示，例如：&quot;&gt;&lt;/a&gt;也可以将key:value放置于{}中进行表示，例如：&lt;/h2&gt;&lt;p&gt;An employ record：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{name: Example Developer, job: Developer, skill: Elite}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Ansible基础元素&quot;&gt;&lt;a href=&quot;#Ansible基础元素&quot; class=&quot;headerlink&quot; title=&quot;Ansible基础元素&quot;&gt;&lt;/a&gt;Ansible基础元素&lt;/h2&gt;&lt;h3 id=&quot;变量&quot;&gt;&lt;a href=&quot;#变量&quot; class=&quot;headerlink&quot; title=&quot;变量&quot;&gt;&lt;/a&gt;变量&lt;/h3&gt;&lt;h4 id=&quot;变量命名&quot;&gt;&lt;a href=&quot;#变量命名&quot; class=&quot;headerlink&quot; title=&quot;变量命名&quot;&gt;&lt;/a&gt;变量命名&lt;/h4&gt;&lt;p&gt;变量名仅能由字母、数字和下划线组成，而且只能以字母开头。&lt;/p&gt;
&lt;h4 id=&quot;facts&quot;&gt;&lt;a href=&quot;#facts&quot; class=&quot;headerlink&quot; title=&quot;facts&quot;&gt;&lt;/a&gt;facts&lt;/h4&gt;&lt;p&gt;facts是由正在通信的远程目标主机发回的信息，这些信息被保存在ansible变量中。要获取指定的远程主机所支持的所有facts，可使用如下命令进行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ansible hostname -m setup
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;register&quot;&gt;&lt;a href=&quot;#register&quot; class=&quot;headerlink&quot; title=&quot;register&quot;&gt;&lt;/a&gt;register&lt;/h4&gt;&lt;p&gt;把任务的输出定义为变量，然后用于其他任务，示例如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
  - shell: /usr/bin/foo
    register: foo_result
    ignore_errors: True
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;通过命令行传递变量&quot;&gt;&lt;a href=&quot;#通过命令行传递变量&quot; class=&quot;headerlink&quot; title=&quot;通过命令行传递变量&quot;&gt;&lt;/a&gt;通过命令行传递变量&lt;/h4&gt;&lt;p&gt;在运行playbook的时候也可以传递一些变量供playbook使用，示例如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ansible-playbook test.yml --extra-vars &amp;quot;hosts=www user=magedu&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;就是说hosts和user这两个变量可以在test.yml文件中直接调用&lt;/p&gt;
&lt;h4 id=&quot;通过roles传递变量&quot;&gt;&lt;a href=&quot;#通过roles传递变量&quot; class=&quot;headerlink&quot; title=&quot;通过roles传递变量&quot;&gt;&lt;/a&gt;通过roles传递变量&lt;/h4&gt;&lt;p&gt;当给一个主机应用角色的时候可以传递变量，然后在角色内使用这些变量，示例如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- hosts: webservers
  roles: 
      - common
      - { role: foo_app_instance, dir: &amp;apos;/web/htdocs/a.com&amp;apos;, port: 8080 }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意:role、dir、port是变量名，冒号后面的是变量值。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;Inventory&quot;&gt;&lt;a href=&quot;#Inventory&quot; class=&quot;headerlink&quot; title=&quot;Inventory&quot;&gt;&lt;/a&gt;Inventory&lt;/h3&gt;&lt;p&gt;ansible的主要功能在于批量主机操作，为了便捷地使用其中的部分主机，可以在inventory file中将其分组命名。默认的inventory file为/etc/ansible/hosts。&lt;br&gt;inventory file可以有多个，且也可以通过Dynamic Inventory来动态生成。&lt;/p&gt;
&lt;h4 id=&quot;inventory文件格式&quot;&gt;&lt;a href=&quot;#inventory文件格式&quot; class=&quot;headerlink&quot; title=&quot;inventory文件格式&quot;&gt;&lt;/a&gt;inventory文件格式&lt;/h4&gt;&lt;p&gt;inventory文件遵循INI文件风格，中括号中的字符为组名。可以将同一个主机同时归并到多个不同的组中；此外，当如若目标主机使用了非默认的SSH端口，还可以在主机名称之后使用冒号加端口号标明。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[webservers]
www1.wisedu.com:8888
www2.wisedu.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果主机名称遵循相似的命名模式，还可以使用列表的方式标识各主机，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[webservers]
www[01:50].example.com

[databases]
db-[a:f].example.com
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;主机变量&quot;&gt;&lt;a href=&quot;#主机变量&quot; class=&quot;headerlink&quot; title=&quot;主机变量&quot;&gt;&lt;/a&gt;主机变量&lt;/h4&gt;&lt;p&gt;可以在inventory中定义主机时为其添加主机变量以便于在playbook中使用，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[webservers]
www1.wisedu.com http_port=80 maxRequestsPerChild=808
www2.wisedu.com http_port=8080 maxRequestsPerChild=909
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;组变量&quot;&gt;&lt;a href=&quot;#组变量&quot; class=&quot;headerlink&quot; title=&quot;组变量&quot;&gt;&lt;/a&gt;组变量&lt;/h4&gt;&lt;p&gt;组变量是指赋予给指定组内所有主机上的在playbook中可用的变量。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; [webservers]
 www1.wisedu.com
 www2.wisedu.com

[webservers:vars]   # 表示向webservers这组主机定义变量如下，回头这两台主机上都可以调用变量ntp_server和nfs_server
ntp_server=ntp.wisedu.com
nfs_server=ntp.wisedu.com
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;组嵌套&quot;&gt;&lt;a href=&quot;#组嵌套&quot; class=&quot;headerlink&quot; title=&quot;组嵌套&quot;&gt;&lt;/a&gt;组嵌套&lt;/h4&gt;&lt;p&gt;inventory中，组还可以包含其它的组，并且也可以向组中的主机指定变量。不过，这些变量只能在ansible-playbook中使用，而ansible不支持。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[apache]
httpd1.wisedu.com
httpd2.wisedu.com

[nginx]
ngx1.wisedu.com
ngx2.wisedu.com

[webservers:children]     # 注意:children是固定格式
apache
nginx

[webservers:vars]
ntp_server=ntp.wisedu.com
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;inventory参数&quot;&gt;&lt;a href=&quot;#inventory参数&quot; class=&quot;headerlink&quot; title=&quot;inventory参数&quot;&gt;&lt;/a&gt;inventory参数&lt;/h4&gt;&lt;p&gt;ansible基于ssh连接inventory中指定的远程主机时，还可以通过参数指定其交互方式，这些参数如下所示：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/29.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/30.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;YAML&quot;&gt;&lt;a href=&quot;#YAML&quot; class=&quot;headerlink&quot; title=&quot;YAML&quot;&gt;&lt;/a&gt;YAML&lt;/h2&gt;&lt;h3 id=&quot;YAML介绍&quot;&gt;&lt;a href=&quot;#YAML介绍&quot; class=&quot;headerlink&quot; title=&quot;YAML介绍&quot;&gt;&lt;/a&gt;YAML介绍&lt;/h3&gt;&lt;p&gt;YAML是一个可读性高的用来表达资料序列的格式。YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822等。Clark Evans在2001年在首次发表了这种语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者。&lt;br&gt;YAML Ain’t Markup Language，即YAML不是XML。不过，在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）。其特性：&lt;br&gt;
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Ansible常见模块介绍</title>
    <link href="http://yoursite.com/2017/07/07/Ansible%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9D%97%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2017/07/07/Ansible常见模块介绍/</id>
    <published>2017-07-07T00:48:26.000Z</published>
    <updated>2017-07-07T03:06:49.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;ansible命令基础&quot;&gt;&lt;a href=&quot;#ansible命令基础&quot; class=&quot;headerlink&quot; title=&quot;ansible命令基础&quot;&gt;&lt;/a&gt;ansible命令基础&lt;/h2&gt;&lt;p&gt;语法：ansible &lt;host-pattern&gt; [-f forks] [-m module_name] [-a args] [options] &lt;/host-pattern&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;host-pattern：这次的命令对哪些主机生效；&lt;/li&gt;
&lt;li&gt;-f forks：启动的并发线程数，就是一次并行处理多少主机；&lt;/li&gt;
&lt;li&gt;-m module_name：要使用的模块；&lt;/li&gt;
&lt;li&gt;-a args：模块特有的参数。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常见的模块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;user&lt;/li&gt;
&lt;li&gt;yum&lt;/li&gt;
&lt;li&gt;copy&lt;/li&gt;
&lt;li&gt;cron&lt;/li&gt;
&lt;li&gt;command：这是默认的模块，表示在被管理主机上运行一个命令。对于command模块，-a不再是指定参数，而是命令本身。&lt;/li&gt;
&lt;li&gt;shell&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;常见模块举例&quot;&gt;&lt;a href=&quot;#常见模块举例&quot; class=&quot;headerlink&quot; title=&quot;常见模块举例&quot;&gt;&lt;/a&gt;常见模块举例&lt;/h2&gt;&lt;h3 id=&quot;etc-ansible-hosts配置文件内容&quot;&gt;&lt;a href=&quot;#etc-ansible-hosts配置文件内容&quot; class=&quot;headerlink&quot; title=&quot;/etc/ansible/hosts配置文件内容&quot;&gt;&lt;/a&gt;/etc/ansible/hosts配置文件内容&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;command模块&quot;&gt;&lt;a href=&quot;#command模块&quot; class=&quot;headerlink&quot; title=&quot;command模块&quot;&gt;&lt;/a&gt;command模块&lt;/h3&gt;&lt;p&gt;command模块是默认的模块，表示在被管理主机上运行一个命令。对于command模块，-a不再是指定参数，而是命令本身。所以这个模块有个缺陷，运行的命令中不能使用变量或者参数。&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible nginx -m command -a &amp;quot;date&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m command -a &amp;quot;tail -3 /etc/passwd&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;cron模块&quot;&gt;&lt;a href=&quot;#cron模块&quot; class=&quot;headerlink&quot; title=&quot;cron模块&quot;&gt;&lt;/a&gt;cron模块&lt;/h3&gt;&lt;p&gt;cron模块可以让每一个被管理节点能够自动生成一个定期任务计划。查看cron模块的用法：&lt;br&gt;[root@node1 ~]# ansible-doc -s cron&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/10.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;几个主要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;state：present表示安装crontab任务&lt;pre&gt;&lt;code&gt;absent表示移除crontab任务
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;job：指明运行的命令是什么&lt;/li&gt;
&lt;li&gt;&lt;p&gt;name：crontab任务的名字&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m cron -a &amp;apos;minute=&amp;quot;*/10&amp;quot; job=&amp;quot;/usr/bin/echo hello&amp;quot; name=&amp;quot;test cron job&amp;quot;&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/11.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;注意：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;所有的参数可以用””包含起来&lt;/li&gt;
&lt;li&gt;day之类的参数没有指定，默认都是*&lt;/li&gt;
&lt;li&gt;默认state参数的值为present&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/12.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;user模块&quot;&gt;&lt;a href=&quot;#user模块&quot; class=&quot;headerlink&quot; title=&quot;user模块&quot;&gt;&lt;/a&gt;user模块&lt;/h3&gt;&lt;p&gt;user模块实现用户账号管理。查看user模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s user
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;几个主要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;name=：用户名&lt;/li&gt;
&lt;li&gt;uid：用户的uid&lt;/li&gt;
&lt;li&gt;group：所属组，即私有组&lt;/li&gt;
&lt;li&gt;groups：附加组。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;state：状态。&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m user -a &amp;apos;name=&amp;quot;jack&amp;quot;&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/13.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m user -a &amp;apos;name=&amp;quot;jack&amp;quot; state=absent&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/14.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;group模块&quot;&gt;&lt;a href=&quot;#group模块&quot; class=&quot;headerlink&quot; title=&quot;group模块&quot;&gt;&lt;/a&gt;group模块&lt;/h3&gt;&lt;p&gt;group模块：组管理。查看group模块的用法：&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s group
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/15.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m group -a &amp;apos;name=mysql gid=306 system=yes&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/16.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;copy模块&quot;&gt;&lt;a href=&quot;#copy模块&quot; class=&quot;headerlink&quot; title=&quot;copy模块&quot;&gt;&lt;/a&gt;copy模块&lt;/h3&gt;&lt;p&gt;copy模块实现文件复制。查看copy模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s copy
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;几个主要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;src=：指明源文件本地路径。可以是绝对路径，也可以是相对路径。可以不使用src，使用content。就是说用content内容来生成文件。&lt;/li&gt;
&lt;li&gt;dest=：定义远程目标文件路径，只能使用绝对路径。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;content=：可以不使用src，使用content。就是说用content内容来生成文件。&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m copy -a &amp;apos;src=/etc/fstab dest=/tmp/fstab.ansible owner=root mode=640&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/17.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m copy -a &amp;apos;content=&amp;quot;Hello World\nGood boy&amp;quot; dest=/tmp/test.txt owner=root mode=640&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/18.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;file模块&quot;&gt;&lt;a href=&quot;#file模块&quot; class=&quot;headerlink&quot; title=&quot;file模块&quot;&gt;&lt;/a&gt;file模块&lt;/h3&gt;&lt;p&gt;file模块可以设定文件属性，还可以创建文件的符号链接。查看file模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s file
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;几个重要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;path=：指明对哪个文件做管理。也可以使用dest和name。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建文件的符号链接：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;src=：指明源文件&lt;/li&gt;
&lt;li&gt;&lt;p&gt;path=：指明符号链接文件路径&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;  [root@node1 ~]# ansible mysql -m file -a ‘owner=root group=mysql mode=644 path=/tmp/test.txt’&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/19.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;  [root@node1 ~]# ansible mysql -m file -a ‘path=/tmp/test.link src=/tmp/test.txt state=link’&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/20.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;ping模块&quot;&gt;&lt;a href=&quot;#ping模块&quot; class=&quot;headerlink&quot; title=&quot;ping模块&quot;&gt;&lt;/a&gt;ping模块&lt;/h3&gt;&lt;p&gt;ping模块测试指定主机是否能连接。查看ping模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s ping
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible nginx -m ping
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/21.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;service模块&quot;&gt;&lt;a href=&quot;#service模块&quot; class=&quot;headerlink&quot; title=&quot;service模块&quot;&gt;&lt;/a&gt;service模块&lt;/h3&gt;&lt;p&gt;service模块是管理服务的。查看service模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/22.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;几个重要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;enabled=：是否开机自动启动，取值为true或false；&lt;/li&gt;
&lt;li&gt;name=：服务名字；&lt;/li&gt;
&lt;li&gt;&lt;p&gt;state=：状态，取值有started，stoped    ，restarted。&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible 172.16.7.151 -m service -a &amp;apos;enabled=true name=httpd state=stopped&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/23.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;shell模块&quot;&gt;&lt;a href=&quot;#shell模块&quot; class=&quot;headerlink&quot; title=&quot;shell模块&quot;&gt;&lt;/a&gt;shell模块&lt;/h3&gt;&lt;p&gt;shell模块：和command模块类似，但是可以使用变量。用于执行一些复杂的命令。查看shell模块的使用方法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s shell
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m user -a &amp;apos;name=&amp;quot;test&amp;quot;&amp;apos;
[root@node1 ~]# ansible mysql -m command -a &amp;apos;echo wisedu | passwd --stdin test&amp;apos;
[root@node1 ~]# ansible mysql -m command -a &amp;apos;tail -1 /etc/passwd&amp;apos; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/24.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m shell -a &amp;apos;echo wisedu | passwd --stdin user1&amp;apos;
[root@node1 ~]# ansible mysql -m command -a &amp;apos;tail -1 /etc/shadow&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/25.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;所以一旦有管道、变量之类的，你最好使用shell模块，而不要用command模块。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;script模块&quot;&gt;&lt;a href=&quot;#script模块&quot; class=&quot;headerlink&quot; title=&quot;script模块&quot;&gt;&lt;/a&gt;script模块&lt;/h3&gt;&lt;p&gt;script模块将本地脚本复制到远程主机并运行之。查看script模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s script
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim test.sh
#/bin/bash                                                                                                                                    
echo &amp;quot;hello world&amp;quot; &amp;gt;/tmp/nba.txt
 [root@node1 ~]# chmod +x test.sh 
 [root@node1 ~]# ansible mysql -m script -a &amp;apos;/root/test.sh&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/26.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;yum模块&quot;&gt;&lt;a href=&quot;#yum模块&quot; class=&quot;headerlink&quot; title=&quot;yum模块&quot;&gt;&lt;/a&gt;yum模块&lt;/h3&gt;&lt;p&gt;yum模块管理程序包。查看yum模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s yum        
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;几个重要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;name=：指定要安装的程序包，可以带上版本号，否则安装最新版本；&lt;/li&gt;
&lt;li&gt;&lt;p&gt;state=：present表示安装，absent表示卸载。&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m yum -a &amp;apos;name=ksh&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/27.png&quot; alt=&quot;&quot;&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;setup模块&quot;&gt;&lt;a href=&quot;#setup模块&quot; class=&quot;headerlink&quot; title=&quot;setup模块&quot;&gt;&lt;/a&gt;setup模块&lt;/h3&gt;&lt;p&gt;setup模块：收集远程主机的facts。ansbile在管理每一个主机时，这些主机在被运行管理命令之前，会首先向ansible节点报告自己主机当前的各种可能被ansible主机用到的状态信息，如操作系统版本、ip地址等信息，这些信息都是以变量的形式，ansible主机可以在jinjia2中调用，为不同的服务器生成不同的配置文件。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m setup
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/28.png&quot; alt=&quot;&quot;&gt;  &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;ansible命令基础&quot;&gt;&lt;a href=&quot;#ansible命令基础&quot; class=&quot;headerlink&quot; title=&quot;ansible命令基础&quot;&gt;&lt;/a&gt;ansible命令基础&lt;/h2&gt;&lt;p&gt;语法：ansible &lt;host-pattern&gt; [-f forks] [-m module_name] [-a args] [options] &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;host-pattern：这次的命令对哪些主机生效；&lt;/li&gt;
&lt;li&gt;-f forks：启动的并发线程数，就是一次并行处理多少主机；&lt;/li&gt;
&lt;li&gt;-m module_name：要使用的模块；&lt;/li&gt;
&lt;li&gt;-a args：模块特有的参数。
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Ansible介绍及安装部署</title>
    <link href="http://yoursite.com/2017/07/05/Ansible%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/07/05/Ansible介绍及安装部署/</id>
    <published>2017-07-05T07:33:54.000Z</published>
    <updated>2017-07-07T01:17:11.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;运维工具&quot;&gt;&lt;a href=&quot;#运维工具&quot; class=&quot;headerlink&quot; title=&quot;运维工具&quot;&gt;&lt;/a&gt;运维工具&lt;/h2&gt;&lt;p&gt;作为一个Linux运维人员，需要了解大量的运维工具，并熟知这些工具的差异，能够熟练运用这些工具去解决一些手动重复的劳动，一方面是避免人工操作失误，另一方面也可以提高工作效率。同时还能将自己从这些重复的工作中解放出来，以便研究更新和更深的技术。&lt;br&gt;运维工具大体上可以分为3类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OS Provisioning：提供操作系统安装的。PXE，Cobbler(repository,distritution,profile)。&lt;/li&gt;
&lt;li&gt;OS Config：cfengine、puppet、saltstack、chef、func、Task Excute工具(fabric、func、saltstack)&lt;/li&gt;
&lt;li&gt;Deployment：capistranoc、fabric&lt;br&gt;而Ansible是一款较新的工具，可以实现OS Config、Task Excute和Deployment。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
运维工具实现远程管理的两种方式：&lt;br&gt;1.有agent：puppet、saltstack、func&lt;br&gt;2.agentless：ansible、fabric&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Ansible特性&quot;&gt;&lt;a href=&quot;#Ansible特性&quot; class=&quot;headerlink&quot; title=&quot;Ansible特性&quot;&gt;&lt;/a&gt;Ansible特性&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;学习曲线平缓；&lt;/li&gt;
&lt;li&gt;不需要agent；&lt;/li&gt;
&lt;li&gt;没有有线状态图，没有次序，我们自己定义动作间的依赖关系就行，任何一个任务出错会很快出错，你可以立即进行修改；&lt;/li&gt;
&lt;li&gt;没有代理；&lt;/li&gt;
&lt;li&gt;没有服务端；&lt;/li&gt;
&lt;li&gt;依赖ssh来工作，无需ssl，也就无需证书等功能；&lt;/li&gt;
&lt;li&gt;模块可以使用任何编程语言来编写，包括shell脚本；&lt;/li&gt;
&lt;li&gt;默认使用ssh工作；&lt;/li&gt;
&lt;li&gt;支持多级的解决方案。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Ansible架构图和核心组件&quot;&gt;&lt;a href=&quot;#Ansible架构图和核心组件&quot; class=&quot;headerlink&quot; title=&quot;Ansible架构图和核心组件&quot;&gt;&lt;/a&gt;Ansible架构图和核心组件&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;架构图：&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;ansible是Python编写的，Python有一个模块叫paramiko，paramiko组件能够实现并行地基于ssh协议远程连接至各主机的库。ansible就是用了paramiko。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核心组件：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ansible core：ansible核心。&lt;/li&gt;
&lt;li&gt;host inventory：主机池，或叫主机列表，主机归档文件。&lt;/li&gt;
&lt;li&gt;core modules：ansible核心模块。&lt;/li&gt;
&lt;li&gt;custom modules：用户可以自定义模块&lt;/li&gt;
&lt;li&gt;playbook：将多个任务写在一个yaml格式的配置文件中。支持使用Python的jinjia2来定义模板。同一个playbook应用带同一台主机上，无论你应用多少次，他们的结果都是相等的，不会重复执行。这种特性我们称为幂等性。&lt;/li&gt;
&lt;li&gt;connect plugins：连接插件&lt;/li&gt;
&lt;li&gt;plugins：其他的一些插件，比如email、logging等等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;安装Ansible&quot;&gt;&lt;a href=&quot;#安装Ansible&quot; class=&quot;headerlink&quot; title=&quot;安装Ansible&quot;&gt;&lt;/a&gt;安装Ansible&lt;/h2&gt;&lt;p&gt;可以选择源码编译安装或者yum安装。ansible的rpm包在epel源中，事先安装好epel源。我这里实验环境是CentOS 7。&lt;br&gt;安装：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install ansible -y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看安装的rpm包里有哪些文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# rpm -ql ansible | more
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;ansible配置文件：/etc/ansible/ansible.cfg&lt;br&gt;inventory文件：/etc/ansible/hosts&lt;/p&gt;
&lt;h2 id=&quot;演示使用示例&quot;&gt;&lt;a href=&quot;#演示使用示例&quot; class=&quot;headerlink&quot; title=&quot;演示使用示例&quot;&gt;&lt;/a&gt;演示使用示例&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;node1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.7.151&lt;/td&gt;
&lt;td&gt;ansible-noarh-2.2.0.0-4.el7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.7.152&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node3&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.7.153&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;配置Ansible主机登录其他主机使用密钥登录&quot;&gt;&lt;a href=&quot;#配置Ansible主机登录其他主机使用密钥登录&quot; class=&quot;headerlink&quot; title=&quot;配置Ansible主机登录其他主机使用密钥登录&quot;&gt;&lt;/a&gt;配置Ansible主机登录其他主机使用密钥登录&lt;/h3&gt;&lt;p&gt;由于Ansible默认使用ssh管理主机，所以首先需要配置Ansible所在主机登录其他被管理主机不需要输入密码。在node1主机上执行如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ssh-keygen -t rsa -P &amp;apos;&amp;apos;
[root@node1 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@172.16.7.151
[root@node1 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@172.16.7.152
[root@node1 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@172.16.7.153
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;定义主机&quot;&gt;&lt;a href=&quot;#定义主机&quot; class=&quot;headerlink&quot; title=&quot;定义主机&quot;&gt;&lt;/a&gt;定义主机&lt;/h3&gt;&lt;p&gt;每一个主机可以使用主机名，也可以使用ip地址。也可以把多个主机定义到一个组里。比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim /etc/ansible/hosts
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;使用模块&quot;&gt;&lt;a href=&quot;#使用模块&quot; class=&quot;headerlink&quot; title=&quot;使用模块&quot;&gt;&lt;/a&gt;使用模块&lt;/h3&gt;&lt;p&gt;Ansible是依赖模块进行工作的，里面有大量的模块帮助我们去完成任务。比如使用command模块：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible 172.16.7.152 -m command -a &amp;quot;date&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;如上，在执行任务时，可以指定IP，也可以指定组名，ansible有个默认的组叫all，代表/etc/ansible/hosts文件里的所有主机。&lt;/p&gt;
&lt;p&gt;列出当前主机可以使用的ansible模块：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -l
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;常用的模块有：user、yum、copy、command等。如果想知道某个模块怎么使用的，比如想知道yum怎么用：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s yum
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;运维工具&quot;&gt;&lt;a href=&quot;#运维工具&quot; class=&quot;headerlink&quot; title=&quot;运维工具&quot;&gt;&lt;/a&gt;运维工具&lt;/h2&gt;&lt;p&gt;作为一个Linux运维人员，需要了解大量的运维工具，并熟知这些工具的差异，能够熟练运用这些工具去解决一些手动重复的劳动，一方面是避免人工操作失误，另一方面也可以提高工作效率。同时还能将自己从这些重复的工作中解放出来，以便研究更新和更深的技术。&lt;br&gt;运维工具大体上可以分为3类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OS Provisioning：提供操作系统安装的。PXE，Cobbler(repository,distritution,profile)。&lt;/li&gt;
&lt;li&gt;OS Config：cfengine、puppet、saltstack、chef、func、Task Excute工具(fabric、func、saltstack)&lt;/li&gt;
&lt;li&gt;Deployment：capistranoc、fabric&lt;br&gt;而Ansible是一款较新的工具，可以实现OS Config、Task Excute和Deployment。
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>FlumeNG介绍及安装部署</title>
    <link href="http://yoursite.com/2017/07/01/FlumeNG%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/07/01/FlumeNG介绍及安装部署/</id>
    <published>2017-07-01T12:53:40.000Z</published>
    <updated>2017-07-02T03:58:56.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Flume简介&quot;&gt;&lt;a href=&quot;#Flume简介&quot; class=&quot;headerlink&quot; title=&quot;Flume简介&quot;&gt;&lt;/a&gt;Flume简介&lt;/h2&gt;&lt;p&gt;Flume是一个分布式、可靠、高可用的海量日志聚合系统，支持在系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据的简单处理，并写到各种数据接收方的能力。&lt;br&gt;Flume在0.9.x和1.x之间有较大的架构调整，1.x版本之后的改称为Flume NG。0.9.x的称为Flume OG。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Flume OG体系架构如下，Flume OG已经不再进行版本更新：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Flume NG体系架构如下：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;最新的Flume NG是1.7.0，运行最新版本的Flume NG时，机器必须安装JDK7.0或以上的版本，并且，Flume目前在只有在Linux系统的启动脚本，没有Windows环境的启动脚本。&lt;/p&gt;
&lt;h2 id=&quot;Flume-NG核心组件&quot;&gt;&lt;a href=&quot;#Flume-NG核心组件&quot; class=&quot;headerlink&quot; title=&quot;Flume NG核心组件&quot;&gt;&lt;/a&gt;Flume NG核心组件&lt;/h2&gt;&lt;p&gt;Flume NG主要由3个重要的组件构成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source&lt;/li&gt;
&lt;li&gt;Sink&lt;/li&gt;
&lt;li&gt;Channel&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Source&quot;&gt;&lt;a href=&quot;#Source&quot; class=&quot;headerlink&quot; title=&quot;Source&quot;&gt;&lt;/a&gt;Source&lt;/h3&gt;&lt;p&gt;完成对日志数据的收集，分成transtion和event打入到channel中。&lt;br&gt;Flume提供了各种source的实现，包括Avro Source(监控端口)、Exce Source(对命令监控)、Spooling Directory Source(监控某个目录)、NetCat Source、Syslog Source、Syslog TCP Source、Syslog UDP Source、HTTP Source、HDFS Source等。&lt;br&gt;对现有程序改动最小的使用方式是使用直接读取程序原来记录的日志文件，基本可以实现无缝接入，不需要对现有程序进行任何改动。直接读取文件Source，有两种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exec Source&lt;br&gt;以运行Linux命令的方式，持续的输出最新的数据，如tail -f 文件名，在这种方式下，取的文件名必须是指定的。        &lt;/li&gt;
&lt;li&gt;Spool Source&lt;br&gt;是监测配置的目录下新增的文件，并将文件中的数据读取出来。使用Spool Source需要注意：&lt;br&gt;(1)拷贝到spool目录下的文件不可以再打开编辑。因为放进去的目录可能在一直被读，一般不可以再被打开了。&lt;br&gt;(2)spool目录下不可包含相应的子目录。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Spool Source如何使用？&lt;br&gt;在实际使用过程中，可以结合log4j使用，使用log4j的时候，将log4j的文件切割机制设为1分钟1次，将文件拷贝到spool的监控目录。log4j有一个TimeRolling的插件，可以把log4j分割的文件到spool目录。基本实现了实时的监控。Flume在传完文件之后，将会修改文件的后缀，变为.COMPLETED(后缀也可以在配置文件中灵活指定)。&lt;/p&gt;
&lt;p&gt;Exec Source和Spool Source比较？&lt;br&gt;Exec Source可以实现对日志的实时收集，但是存在Flume不运行或者指令执行出错时，将无法收集到日志数据，无法保证日志数据的完整性。&lt;br&gt;Spool Source虽然无法实现实时的收集数据，但是可以使用以分钟的方式切割文件，趋近于实时。&lt;br&gt;总结：如果应用无法实现以分钟切割文件的话，可以两种收集方式结合使用。&lt;/p&gt;
&lt;h3 id=&quot;Sink&quot;&gt;&lt;a href=&quot;#Sink&quot; class=&quot;headerlink&quot; title=&quot;Sink&quot;&gt;&lt;/a&gt;Sink&lt;/h3&gt;&lt;p&gt;Flume Sink取出Channel中的数据，进行相应的存储文件系统，数据库，或者提交到远程服务器。&lt;br&gt;Flume也提供了各种sink的实现，包括HDFS sink、Logger sink、Avro sink、File Roll sink、Null sink、HBase sink等。&lt;br&gt;Flume Sink在设置数据存储时，可以向文件系统中、数据库中、hadoop中储数据，在日志数据较少时，可以将数据存储在文件系统中，并且设定一定的时间间隔保存数据。在日志数据较多时，可以将相应的日志数据存储到Hadoop中，便于日后进行相应的数据分析。&lt;/p&gt;
&lt;h3 id=&quot;Channel&quot;&gt;&lt;a href=&quot;#Channel&quot; class=&quot;headerlink&quot; title=&quot;Channel&quot;&gt;&lt;/a&gt;Channel&lt;/h3&gt;&lt;p&gt;Flume Channel主要提供一个队列的功能，对Source提供中的数据进行简单的缓存。&lt;br&gt;Flume对于Channel，则提供了Memory Channel、JDBC Channel、File Channel等。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MemoryChannel&lt;br&gt;可以实现高速的吞吐，但是无法保证数据的完整性。&lt;/li&gt;
&lt;li&gt;MemoryRecoverChannel&lt;br&gt;官方文档建议使用FileChannel来替换。&lt;/li&gt;
&lt;li&gt;FileChannel&lt;br&gt;保证数据的完整性和一致性。在具体配置不现的FileChannel时，建议FileChannel设置的目录和程序日志文件保存的目录设成不同的磁盘，以便提高效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Flume部署种类&quot;&gt;&lt;a href=&quot;#Flume部署种类&quot; class=&quot;headerlink&quot; title=&quot;Flume部署种类&quot;&gt;&lt;/a&gt;Flume部署种类&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.单一代理流程&lt;/strong&gt;&lt;br&gt;就是只有一个agent在客户端采集。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.多代理流程&lt;/strong&gt;&lt;br&gt;就是一个agent通过中转的Avro传到下一个agent。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;3.流合并&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;4.多路复用流&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Flume单机安装&quot;&gt;&lt;a href=&quot;#Flume单机安装&quot; class=&quot;headerlink&quot; title=&quot;Flume单机安装&quot;&gt;&lt;/a&gt;Flume单机安装&lt;/h2&gt;&lt;h3 id=&quot;安装JDK1-6&quot;&gt;&lt;a href=&quot;#安装JDK1-6&quot; class=&quot;headerlink&quot; title=&quot;安装JDK1.6&quot;&gt;&lt;/a&gt;安装JDK1.6&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@log1 local]# mkdir /usr/java
[root@log1 local]# tar zxf jdk-7u80-linux-x64.gz -C /usr/java/
[root@log1 local]# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.7.0_80
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
[root@log1 local]# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装Flume-NG&quot;&gt;&lt;a href=&quot;#安装Flume-NG&quot; class=&quot;headerlink&quot; title=&quot;安装Flume NG&quot;&gt;&lt;/a&gt;安装Flume NG&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@db local]# tar zxf apache-flume-1.7.0-bin.tar.gz 
[root@db local]# cd apache-flume-1.7.0-bin
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;一个简单的例子&quot;&gt;&lt;a href=&quot;#一个简单的例子&quot; class=&quot;headerlink&quot; title=&quot;一个简单的例子&quot;&gt;&lt;/a&gt;一个简单的例子&lt;/h3&gt;&lt;p&gt;下面写一个单节点的配置文件。这个配置文件让flume接收事件，并输出到终端。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@db apache-flume-1.7.0-bin]# vim conf/example.conf
# example.conf: A single-node Flume configuration

# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444

# Describe the sink
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个配置文件定义了一个单agent名字叫a1。a1有一个source在端口44444监听数据，a1的channel是Memory channel，sink是直接输送到终端上，&lt;/p&gt;
&lt;p&gt;启动Flume NG：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@db apache-flume-1.7.0-bin]# bin/flume-ng agent --conf conf --conf-file conf/example.conf --name a1 -Dflume.root.logger=INFO,console
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;测试&quot;&gt;&lt;a href=&quot;#测试&quot; class=&quot;headerlink&quot; title=&quot;测试&quot;&gt;&lt;/a&gt;测试&lt;/h3&gt;&lt;p&gt;打开另外一个终端，telnet端口44444，然后发送一个事件：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;查看原来的终端，可以看到如下的内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2017-07-02 11:43:37,111 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: { headers:{} body: 48 65 6C 6C 6F 20 4D 61 6E 21 0D                Hello Man!. }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Flume简介&quot;&gt;&lt;a href=&quot;#Flume简介&quot; class=&quot;headerlink&quot; title=&quot;Flume简介&quot;&gt;&lt;/a&gt;Flume简介&lt;/h2&gt;&lt;p&gt;Flume是一个分布式、可靠、高可用的海量日志聚合系统，支持在系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据的简单处理，并写到各种数据接收方的能力。&lt;br&gt;Flume在0.9.x和1.x之间有较大的架构调整，1.x版本之后的改称为Flume NG。0.9.x的称为Flume OG。&lt;br&gt;
    
    </summary>
    
      <category term="数据采集" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"/>
    
    
      <category term="Flume 数据采集" scheme="http://yoursite.com/tags/Flume-%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch安全问题</title>
    <link href="http://yoursite.com/2017/06/29/Elasticsearch%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2017/06/29/Elasticsearch安全问题/</id>
    <published>2017-06-29T03:51:51.000Z</published>
    <updated>2017-07-25T06:09:52.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;Elasticsearch设计之初就定位在纯私网环境而不做权限和安全控制，虽然有个叫Security Manager的配置，但是显然是不够的。但是后来专门出了个收费的shield来保护Elasticsearch，可是毕竟是收费的。当然我们也有替代品：search-guard。下面介绍下 Elasticsearch 围绕安全方面的的几点使用事项：&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;修改默认的-Elasticsearch-集群名称&quot;&gt;&lt;a href=&quot;#修改默认的-Elasticsearch-集群名称&quot; class=&quot;headerlink&quot; title=&quot;修改默认的 Elasticsearch 集群名称&quot;&gt;&lt;/a&gt;修改默认的 Elasticsearch 集群名称&lt;/h2&gt;&lt;p&gt;Elasticsearch 默认的集群名称是 elasticsearch，请在生成环境上一定要修改成其他的名称，并且不同的环境和不同的集群要保证不相同，监控集群节点情况，如果有未知节点加入，一定要及时预警。&lt;/p&gt;
&lt;h2 id=&quot;不要暴露-Elasticsearch-在公网上&quot;&gt;&lt;a href=&quot;#不要暴露-Elasticsearch-在公网上&quot; class=&quot;headerlink&quot; title=&quot;不要暴露 Elasticsearch 在公网上&quot;&gt;&lt;/a&gt;不要暴露 Elasticsearch 在公网上&lt;/h2&gt;&lt;p&gt;Elasticsearch默认的http.port是9200，集群各节点间的通信端口transport.tcp.port是9300。建议修改这两个端口。&lt;/p&gt;
&lt;p&gt;所以强烈建议替换掉Elasticsearch的监控端口，就像是给你家金库做了个“暗门”，骇客想要进入金库至少先得找到门路才行。&lt;/p&gt;
&lt;h2 id=&quot;不要以-root-身份运行-Elasticsearch&quot;&gt;&lt;a href=&quot;#不要以-root-身份运行-Elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;不要以 root 身份运行 Elasticsearch&quot;&gt;&lt;/a&gt;不要以 root 身份运行 Elasticsearch&lt;/h2&gt;&lt;p&gt;一定不要以 root 身份来运行 Elasticsearch，另外，要不和其他的服务公用相同的用户，然后还要保证该用户的权限要最小化。&lt;/p&gt;
&lt;h2 id=&quot;定期对-Elasticsearch-进行备份&quot;&gt;&lt;a href=&quot;#定期对-Elasticsearch-进行备份&quot; class=&quot;headerlink&quot; title=&quot;定期对 Elasticsearch 进行备份&quot;&gt;&lt;/a&gt;定期对 Elasticsearch 进行备份&lt;/h2&gt;&lt;p&gt;使用 Elasticsearch 提供的备份还原机制，定期对 Elasticsearch 的数据进行快照备份，以备不时之需。官网的备份介绍：&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装Elasticsearch的权限系统插件-SearchGuard&quot;&gt;&lt;a href=&quot;#安装Elasticsearch的权限系统插件-SearchGuard&quot; class=&quot;headerlink&quot; title=&quot;安装Elasticsearch的权限系统插件-SearchGuard&quot;&gt;&lt;/a&gt;安装Elasticsearch的权限系统插件-SearchGuard&lt;/h2&gt;&lt;p&gt;search-guard是elastcisearch的一款插件，提供加密，身份验证和授权，基于search guard SSL，另外提供可插入的身份验证/授权模块，search-guard是shield的替代品，可免费提供所有的基本安全功能，其功能特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于用户和角色的权限控制&lt;/li&gt;
&lt;li&gt;支持SSL和TLS方式安全认证&lt;/li&gt;
&lt;li&gt;支持LDAP认证&lt;br&gt;项目地址：&lt;a href=&quot;https://github.com/floragunncom/search-guard&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/floragunncom/search-guard&lt;/a&gt;&lt;br&gt;依赖关系：&lt;a href=&quot;https://github.com/floragunncom/search-guard/wiki&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/floragunncom/search-guard/wiki&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;安装插件&quot;&gt;&lt;a href=&quot;#安装插件&quot; class=&quot;headerlink&quot; title=&quot;安装插件&quot;&gt;&lt;/a&gt;安装插件&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;注意：插件版本需要和你使用的Elasticsearch版本对应。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/plugin install -b com.floragunn/search-guard-2/2.3.3.10
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/16.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/plugin install -b com.floragunn/search-guard-ssl/2.3.3.19
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意:以上两步在集群每个节点都要执行。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;证书&quot;&gt;&lt;a href=&quot;#证书&quot; class=&quot;headerlink&quot; title=&quot;证书&quot;&gt;&lt;/a&gt;证书&lt;/h3&gt;&lt;p&gt;根据自身情况修改官方脚本生成admin证书、node证书、根证书，将 node 证书和根证书放在 elasticsearch 配置文件目录下，同时将admin证书和根证书放到search-guard 配置文件目录下。&lt;br&gt;1.集群中任意一台机器下载 searchguard-ssl 的包，里面包含自动创建证书的脚本：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ wget https://github.com/floragunncom/search-guard-ssl/archive/v2.3.3.19.zip  
[es@log1 elasticsearch]$ unzip -oq v2.3.3.19.zip
[es@log1 elasticsearch]$ cd search-guard-ssl-2.3.3.19/example-pki-scripts/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;有三个脚本：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gen_client_node_cert.sh 创建客户端证书&lt;/li&gt;
&lt;li&gt;gen_node_cert.sh        创建节点证书&lt;/li&gt;
&lt;li&gt;gen_root_ca.sh          创建根证书&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.生成证书&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#生成文件：
./example.sh
#管理员的证书：
./gen_client_node_cert.sh admin changeit capass
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;命令会生成一个admin-keystore.jks的文件，把truststore.jks、admin-keystore.jks拷贝到${ES_HOME}/plugins/search-guard-2/sgconfig目录下&lt;/p&gt;
&lt;p&gt;给plugins/search-guard-2/tools/sgadmin.sh执行权限：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ chmod +x plugins/search-guard-2/tools/sgadmin.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将example-pki-scripts下生成的truststore.jks文件复制到ES集群中各个节点的config目录下，且把生成的node-&lt;em&gt;-keystore.jks文件复制到各个节点的config目录下。&lt;em&gt;*注意: The keystore files are specific per node. Copy node-0-keystore.jks to the config directory of your first ES node, node-1-keystore.jks to the second and so forth.&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 example-pki-scripts]$ cp truststore.jks node-0-keystore.jks /usr/local/elasticsearch/config/
[es@log1 example-pki-scripts]$ scp -p truststore.jks node-1-keystore.jks es@log2:/usr/local/elasticsearch/config/
[es@log1 example-pki-scripts]$ scp -p truststore.jks node-2-keystore.jks es@log3:/usr/local/elasticsearch/config/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.在Elasticsearch中添加search-guard和search-guard-ssl的配置项&lt;br&gt;找到config/elasticsearch.yml文件，添加以下配置项：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##########################################################
# SEARCH GUARD SSL                                                                             
# Configuration
##########################################################
################## Transport layer SSL ###################                        
####节点下放的是node-*，这里就写哪个
searchguard.ssl.transport.enabled: true
searchguard.ssl.transport.keystore_filepath: node-0-keystore.jks
searchguard.ssl.transport.keystore_password: changeit
searchguard.ssl.transport.truststore_filepath: truststore.jks
searchguard.ssl.transport.truststore_password: changeit
searchguard.ssl.transport.enforce_hostname_verification: false
searchguard.ssl.transport.resolve_hostname: false
searchguard.ssl.transport.enabled_protocols:
 - &amp;quot;TLSv1&amp;quot;
 - &amp;quot;TLSv1.1&amp;quot;
 - &amp;quot;TLSv1.2&amp;quot;

################# HTTP/REST layer SSL ####################
searchguard.ssl.http.enabled: true
searchguard.ssl.http.keystore_filepath: node-0-keystore.jks
searchguard.ssl.http.truststore_filepath: truststore.jks
searchguard.ssl.http.truststore_password: changeit
searchguard.ssl.http.enabled_protocols:
 - &amp;quot;TLSv1&amp;quot;
 - &amp;quot;TLSv1.1&amp;quot;
 - &amp;quot;TLSv1.2&amp;quot;

##### 管理员账号配置
searchguard.authcz.admin_dn:
  - &amp;quot;CN=admin, OU=client, O=client, L=Test, C=DE&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意：配置文件的node-x-keystore.jks对应每台config目录下放置的文件。&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;4.重启集群中的各台Elasticsearch然后初始化search-guard的配置项&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/elasticsearch -d
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3台集群中的节点都要重启。重启后，elasticsearch 之间的连接已经是加密的了。&lt;/p&gt;
&lt;p&gt;在log1上初始化searchguard索引：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd /usr/local/elasticsearch
$ plugins/search-guard-2/tools/sgadmin.sh -cd plugins/search-guard-2/sgconfig -ts plugins/search-guard-2/sgconfig/truststore.jks -ks  plugins/search-guard-2/sgconfig/admin-keystore.jks -kspass changeit -tspass changeit  -icl -nhnv -h 114.55.253.15 
Will connect to 114.55.253.15:9300 ... done
Contacting elasticsearch cluster &amp;apos;elasticsearch&amp;apos; and wait for YELLOW clusterstate ...
Clustername: wisedu
Clusterstate: GREEN
Number of nodes: 3
Number of data nodes: 3
searchguard index does not exists, attempt to create it ... done (with 2 replicas, auto expand replicas is off)
Populate config from /usr/local/elasticsearch/plugins/search-guard-2/sgconfig
Will update &amp;apos;config&amp;apos; with plugins/search-guard-2/sgconfig/sg_config.yml
   SUCC: Configuration for &amp;apos;config&amp;apos; created or updated
Will update &amp;apos;roles&amp;apos; with plugins/search-guard-2/sgconfig/sg_roles.yml
   SUCC: Configuration for &amp;apos;roles&amp;apos; created or updated
Will update &amp;apos;rolesmapping&amp;apos; with plugins/search-guard-2/sgconfig/sg_roles_mapping.yml
   SUCC: Configuration for &amp;apos;rolesmapping&amp;apos; created or updated
Will update &amp;apos;internalusers&amp;apos; with plugins/search-guard-2/sgconfig/sg_internal_users.yml
   SUCC: Configuration for &amp;apos;internalusers&amp;apos; created or updated
Will update &amp;apos;actiongroups&amp;apos; with plugins/search-guard-2/sgconfig/sg_action_groups.yml
   SUCC: Configuration for &amp;apos;actiongroups&amp;apos; created or updated
Done with success 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里的-icl是忽略集群的名称，不加会报错。&lt;br&gt;&lt;strong&gt;注意1：如果修改了searchguard，则需要重新加载配置执行。&lt;br&gt;注意2：search-guard配置的相关改动不需要重启elasticsearch，相关的配置实际上存储在searchguard 的indice下了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;其中 sg_internal_users.yml 保存着默认的用户和密码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ cd plugins/search-guard-2/sgconfig/
[es@log1 sgconfig]$ head -n 5  sg_internal_users.yml
# This is the internal user database
# The hash value is a bcrypt hash and can be generated with plugin/tools/hash.sh
admin:
  hash: $2a$12$VcCDgh2NDk07JGN0rjGbM.Ad41qVR/YFJcgHp0UGns5JDymv..TOG
  #password is: admin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;浏览器输入&lt;a href=&quot;https://114.55.253.15:9200/，输入用户名和密码admin/admin&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://114.55.253.15:9200/，输入用户名和密码admin/admin&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/17.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/18.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;HTTP和Java-Api方式访问ElasticSearch&quot;&gt;&lt;a href=&quot;#HTTP和Java-Api方式访问ElasticSearch&quot; class=&quot;headerlink&quot; title=&quot;HTTP和Java Api方式访问ElasticSearch&quot;&gt;&lt;/a&gt;HTTP和Java Api方式访问ElasticSearch&lt;/h3&gt;&lt;h4 id=&quot;HTTP方式访问Elasticsearch&quot;&gt;&lt;a href=&quot;#HTTP方式访问Elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;HTTP方式访问Elasticsearch&quot;&gt;&lt;/a&gt;HTTP方式访问Elasticsearch&lt;/h4&gt;&lt;p&gt;1.在浏览器上访问Elasticsearch，会直接出弹窗，输入用户名密码即可。&lt;br&gt;2.在服务器上使用curl的话需要加上参数-u adminName，类似如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -u adminName:adminname -XGET &amp;quot;http://114.55.253.15:9200/blog/article/1?pretty&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;Java-API中使用search-guard&quot;&gt;&lt;a href=&quot;#Java-API中使用search-guard&quot; class=&quot;headerlink&quot; title=&quot;Java API中使用search-guard&quot;&gt;&lt;/a&gt;Java API中使用search-guard&lt;/h4&gt;&lt;p&gt;1.加入jar包&lt;br&gt;进到/usr/local/elasticsearch/plugins/search-guard-ssl目录下拷贝以下jar包加到CLASSPATH中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;search-guard-ssl-2.3.4.14.jar
netty-buffer-4.0.37.Final.jar
netty-codec-4.0.37.Final.jar
netty-common-4.0.37.Final.jar
netty-handler-4.0.37.Final.jar
netty-transport-4.0.37.Final.jar
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.修改setting&lt;br&gt;以下部分需要从ES节点的这个目录下复制出来放到工程中，并且修改为你实际的路径。&lt;br&gt;目录：/usr/local/elasticsearch/plugins/search-guard-2/sgconfig中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.net.InetAddress;
import java.net.InetSocketAddress;
import org.elasticsearch.action.admin.cluster.node.info.NodesInfoRequest;
import org.elasticsearch.common.transport.InetSocketTransportAddress;
import com.floragunn.searchguard.ssl.SearchGuardSSLPlugin;

Settings settings = Settings.settingsBuilder()
        .put(&amp;quot;path.home&amp;quot;, &amp;quot;.&amp;quot;)
        .put(&amp;quot;cluster.name&amp;quot;, &amp;quot;wisedu&amp;quot;)
        .put(&amp;quot;searchguard.ssl.transport.enabled&amp;quot;, true)
        .put(&amp;quot;searchguard.ssl.transport.keystore_filepath&amp;quot;, &amp;quot;I:/Work/WorkSpace/ultrasearch/plugins/search-guard-2/sgconfig/admin-keystore.jks&amp;quot;)
        .put(&amp;quot;searchguard.ssl.transport.truststore_filepath&amp;quot;, &amp;quot;I:/Work/WorkSpace/ultrasearch/plugins/search-guard-2/sgconfig/truststore.jks&amp;quot;)
        .put(&amp;quot;searchguard.ssl.transport.enforce_hostname_verification&amp;quot;, false)              
        .build();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.修改client&lt;br&gt;以下为你想要连接的ES节点的ip和port，请修改为你实际的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;TransportClient client = TransportClient.builder().settings(settings).addPlugin(SearchGuardSSLPlugin.class).build();
TransportClient addTransportAddress = client.addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress(&amp;quot;114.55.253.15&amp;quot;, 9300)));
//do something with tc
NodesInfoRequest nodesInfoRequest= new NodesInfoRequest();
nodesInfoRequest.putHeader(&amp;quot;sg.impersonate.as&amp;quot;, &amp;quot;worf&amp;quot;);
client.admin().cluster().nodesInfo(new NodesInfoRequest()).actionGet();
client.admin().cluster().nodesInfo(nodesInfoRequest).actionGet();
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;search-guard中的用户权限管理介绍&quot;&gt;&lt;a href=&quot;#search-guard中的用户权限管理介绍&quot; class=&quot;headerlink&quot; title=&quot;search-guard中的用户权限管理介绍&quot;&gt;&lt;/a&gt;search-guard中的用户权限管理介绍&lt;/h3&gt;&lt;p&gt;searchguard 主要有5个配置文件在/ultra/ES/elasticsearch-2.3.4/plugins/search-guard-2/sgconfig 下：&lt;br&gt;1.sg_config.yml：主配置文件不需要做改动。&lt;/p&gt;
&lt;p&gt;2.sg_internal_users.yml：本地用户文件，定义用户密码以及对应的权限。例如：对于 ELK 我们需要一个 kibana 登录用户和一个 logstash 用户，如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kibana4:
  hash: $2a$12$xZOcnwYPYQ3zIadnlQIJ0eNhX1ngwMkTN.oMwkKxoGvDVPn4/6XtO
  #password is: kirk
  roles:
    - kibana4
logstash:
  hash: $2a$12$xZOcnwYPYQ3zIadnlQIJ0eNhX1ngwMkTN.oMwkKxoGvDVPn4/6XtO
  roles:
    - logstash
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意：用户的密码可用plugins/search-guard-2/tools/hash.sh生成。比如修改admin用户的默认密码为wisedu123：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 tools]$ ./hash.sh -p wisedu123
$2a$12$AmrZnl1wYGLGNODLDMY5/O86wmYE9eBcXtVa6AQjfzsF1gcKhkXqe
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.sg_roles.yml：权限配置文件，以下为kibana4 和 logstash 的权限样例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#&amp;lt;sg_role_name&amp;gt;:
#  cluster:
#    - &amp;apos;&amp;lt;permission&amp;gt;&amp;apos;
#  indices:
#    &amp;apos;&amp;lt;indexname or alias&amp;gt;&amp;apos;:
#      &amp;apos;&amp;lt;type&amp;gt;&amp;apos;:  
#        - &amp;apos;&amp;lt;permission&amp;gt;&amp;apos;
#      _dls_: &amp;apos;&amp;lt;querydsl query&amp;gt;&amp;apos;
#      _fls_:
#        - &amp;apos;&amp;lt;field&amp;gt;&amp;apos;
#        - &amp;apos;&amp;lt;field&amp;gt;&amp;apos;
sg_kibana4:
  cluster:
      - cluster:monitor/nodes/info
      - cluster:monitor/health
  indices:
    &amp;apos;*&amp;apos;:
      &amp;apos;*&amp;apos;:
        - indices:admin/mappings/fields/get
        - indices:admin/validate/query
        - indices:data/read/search
        - indices:data/read/msearch
        - indices:admin/get
        - indices:data/read/field_stats
    &amp;apos;?kibana&amp;apos;:
      &amp;apos;*&amp;apos;:
        - indices:admin/exists
        - indices:admin/mapping/put
        - indices:admin/mappings/fields/get
        - indices:admin/refresh
        - indices:admin/validate/query
        - indices:data/read/get
sg_logstash:
  cluster:
    - indices:admin/template/get
    - indices:admin/template/put
  indices:
    &amp;apos;logstash-*&amp;apos;:
      &amp;apos;*&amp;apos;:
        - WRITE
        - indices:data/write/bulk
        - indices:data/write/delete
        - indices:data/write/update
        - indices:data/read/search
        - indices:data/read/scroll
        - CREATE_INDEX
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.sg_roles_mapping.yml:定义用户的映射关系，添加 kibana 及 logstash 用户对应的映射如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sg_logstash:
  users:
    - logstash
sg_kibana4:
  backendroles:
    - kibana
  users:
    - kibana4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;5.sg_action_groups.yml：定义权限。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;补充一点：Search Guard可以实现和Logstash、Kibana的完美结合，对于使用ELK的用户大可不必担心，修改集成很容易的。&lt;br&gt;并且，Elasticsearch在5.x之后，对Search Guard、Search Guard SSL （当然还有Logstash 、Kibana）等插件的版本号都做了统一，变得更加的简单直观了。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;利用操作系统防火墙设置规避9200端口开放问题&quot;&gt;&lt;a href=&quot;#利用操作系统防火墙设置规避9200端口开放问题&quot; class=&quot;headerlink&quot; title=&quot;利用操作系统防火墙设置规避9200端口开放问题&quot;&gt;&lt;/a&gt;利用操作系统防火墙设置规避9200端口开放问题&lt;/h2&gt;&lt;p&gt;对于search-guard插件配置繁琐，也可以使用操作系统防火墙对访问源IP进行隔离控制。&lt;br&gt;架设Nginx反向代理服务器，ES主机防火墙设置仅允许Nginx所在主机访问ES主机的9200端口。&lt;/p&gt;
&lt;h3 id=&quot;安装防火墙&quot;&gt;&lt;a href=&quot;#安装防火墙&quot; class=&quot;headerlink&quot; title=&quot;安装防火墙&quot;&gt;&lt;/a&gt;安装防火墙&lt;/h3&gt;&lt;p&gt;在centos7上停止firewalld，启用iptables。&lt;br&gt;停止firewalld：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl stop firewalld.service   #停止firewall
# systemctl disable firewalld.service    #禁止firewall开机启动
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;安装iptables防火墙：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install -y iptables-services
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;配置防火墙&quot;&gt;&lt;a href=&quot;#配置防火墙&quot; class=&quot;headerlink&quot; title=&quot;配置防火墙&quot;&gt;&lt;/a&gt;配置防火墙&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;# vim /etc/sysconfig/iptables     #修改默认的配置文件
*filter
:INPUT ACCEPT [1837:149118]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [1656:224717]
-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT
-A INPUT -s 114.55.248.157/32 -p tcp -m tcp --dport 9200 -j ACCEPT
-A INPUT -p tcp -m tcp --dport 9200 -j DROP
COMMIT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/19.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;其实也就是加了两条规则：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;iptables -A INPUT -s 114.55.248.157 -p TCP --dport 9200 -j ACCEPT
iptables -A INPUT -p TCP --dport 9200 -j DROP
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动防火墙和设置开机启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl start iptables.service      
# systemctl enable iptables.service    
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;配置Nginx&quot;&gt;&lt;a href=&quot;#配置Nginx&quot; class=&quot;headerlink&quot; title=&quot;配置Nginx&quot;&gt;&lt;/a&gt;配置Nginx&lt;/h3&gt;&lt;p&gt;Nginx主要配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;upstream elasticsearch_servers {
        server 114.55.253.15:9200;
        server 114.55.132.143:9200;
        server 114.55.252.185:9200;
}

server {
        listen  8080;
        access_log logs/es_access.log main;

        location = /* {
            deny all;
        }

        location / {
            proxy_pass http://elasticsearch_servers;
        }

}
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;Elasticsearch设计之初就定位在纯私网环境而不做权限和安全控制，虽然有个叫Security Manager的配置，但是显然是不够的。但是后来专门出了个收费的shield来保护Elasticsearch，可是毕竟是收费的。当然我们也有替代品：search-guard。下面介绍下 Elasticsearch 围绕安全方面的的几点使用事项：&lt;br&gt;
    
    </summary>
    
      <category term="搜索引擎" scheme="http://yoursite.com/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
      <category term="Elasticsearch 搜索引擎" scheme="http://yoursite.com/tags/Elasticsearch-%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch介绍及安装部署</title>
    <link href="http://yoursite.com/2017/06/20/Elasticsearch%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/06/20/Elasticsearch介绍及安装部署/</id>
    <published>2017-06-20T03:29:04.000Z</published>
    <updated>2017-07-23T04:31:52.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Elasticsearch介绍&quot;&gt;&lt;a href=&quot;#Elasticsearch介绍&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch介绍&quot;&gt;&lt;/a&gt;Elasticsearch介绍&lt;/h2&gt;&lt;p&gt;Elasticsearch是一个分布式搜索服务，提供Restful API，底层基于Lucene，采用多shard的方式保证数据安全，并且提供自动resharding的功能，加之github等大型的站点也采用 Elasticsearch作为其搜索服务。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Elasticsearch集群安装部署&quot;&gt;&lt;a href=&quot;#Elasticsearch集群安装部署&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch集群安装部署&quot;&gt;&lt;/a&gt;Elasticsearch集群安装部署&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;JDK1.7、elasticsearch-2.2.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;JDK1.7、elasticsearch-2.2.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log3&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.253.15&lt;/td&gt;
&lt;td&gt;JDK1.7、elasticsearch-2.2.3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;安装JDK1-8&quot;&gt;&lt;a href=&quot;#安装JDK1-8&quot; class=&quot;headerlink&quot; title=&quot;安装JDK1.8&quot;&gt;&lt;/a&gt;安装JDK1.8&lt;/h3&gt;&lt;p&gt;版本是Elasticsearch 2.2.3，官方建议jdk是1.8。&lt;br&gt;&lt;strong&gt;3台机器都需要安装jdk1.8，添加新用户es。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# mkdir /usr/java
[root@log1 local]# tar zxf jdk-8u73-linux-x64.gz -C /usr/java/
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;添加用户&quot;&gt;&lt;a href=&quot;#添加用户&quot; class=&quot;headerlink&quot; title=&quot;添加用户&quot;&gt;&lt;/a&gt;添加用户&lt;/h3&gt;&lt;p&gt;Elasticsearch不能使用root用户去启动。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# groupadd -g 510 es
[root@log1 local]# useradd -g 510 -u 510 es
[root@log1 local]# echo &amp;quot;wisedu123&amp;quot; | passwd --stdin es &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;用新创建的用户登录shell，配置PATH环境变量。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 ~]$ vim ~/.bashrc
export JAVA_HOME=/usr/java/jdk1.8.0_73
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
[es@log1 ~]$ source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建安装elasticsearch的目录。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mkdir /usr/local/elasticsearch
# chown -R es.es elasticsearch
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;下载安装elasticsearch&quot;&gt;&lt;a href=&quot;#下载安装elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;下载安装elasticsearch&quot;&gt;&lt;/a&gt;下载安装elasticsearch&lt;/h3&gt;&lt;p&gt;es用户登录shell，下载安装elasticsearch。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 ~]$ cd /usr/local/elasticsearch/
[es@log1 elasticsearch]$ wget https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.2.3/elasticsearch-2.2.3.tar.gz 
[es@log1 elasticsearch]$ tar zxf elasticsearch-2.2.3.tar.gz 
[es@log1 elasticsearch]$ mv elasticsearch-2.2.1/* ./
[es@log1 elasticsearch]$ rm -rf elasticsearch-2.2.1
[es@log1 elasticsearch]$ rm -f elasticsearch-2.2.1.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;配置elasticsearch&quot;&gt;&lt;a href=&quot;#配置elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;配置elasticsearch&quot;&gt;&lt;/a&gt;配置elasticsearch&lt;/h3&gt;&lt;p&gt;1.配置elasticsearch 堆内存，编辑bin/elasticsearch.in.sh&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ vim bin/elasticsearch.in.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将参数：ES_MIN_MEM、ES_MAX_MEM设置为当前物理机内存的一半（注意单位，并保证两个值相等）&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;2.配置Elasticsearch集群名称以及节点名称、是否为主节点、path data等信息&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ vim config/elasticsearch.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;3.配置保护Elasticsearch使用的内存防止其被swapped。&lt;br&gt;在memory section下，启用配置：bootstrap.mlockall: true&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4.配置network host&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;【注意】:另外，请在Network段在多加两个配置，内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;network.bind_host: 114.55.29.86
# Set the address other nodes will use to communicate with this node. If not 
# set, it is automatically derived. It must point to an actual IP address.
network.publish_host: 114.55.29.86
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;如果不加上如上的配置，程序在连接时会报错：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;^A[2016-03-28 16:18:08.791] [ERROR] [godseye] [godseye] [RMI TCP Connection(2)-127.0.0.1] [com.wisedu.godseye.search.util.SearchUtil] [buildIndex:70] NoNodeAvailableException[None of the configured nodes are available: [{#transport#-1}{114.55.29.86}{114.55.29.86:9300}]]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;5.配置Elasticsearch的自动发现机制&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;另外两台也是做如上的安装配置。只不过在配置中需要修改下面几处。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/8.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Elasticsearch优化&quot;&gt;&lt;a href=&quot;#Elasticsearch优化&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch优化&quot;&gt;&lt;/a&gt;Elasticsearch优化&lt;/h2&gt;&lt;p&gt;1.检验配置中的bootstrap.mlockall: true是否生效&lt;br&gt;启动Elasticsearch：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ bin/elasticsearch -d
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在shell终端执行命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl http://114.55.29.86:9200/_nodes/process?pretty
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;关注这个这个请求返回数据中的mlockall的值，如果为false，则说明锁定内存失败，这可能由于运行elasticsearch的用户不具备这样的权限。解决该问题的方法是：&lt;br&gt;在运行elasticsearch之前，以root身份执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ulimit -l unlimited
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后再次重启elasticsearch。并查看上面的请求中的mlockall的值是否为true。&lt;br&gt;&lt;strong&gt;【注意】：这时候需要在root执行ulimit -l unlimited的shell终端上su - es，然后重启elasticsearch。因为这是命令行设置的ulimit -l unlimited，只对当前会话生效。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# ulimit -l unlimited
[root@log1 ~]# su - es
[es@log1 ~]$ ps -ef|grep elasticsearch
[es@log1 ~]$ kill -9 27189
[es@log1 ~]$ /usr/local/elasticsearch/bin/elasticsearch -d
[es@log1 ~]$ curl http://114.55.29.86:9200/_nodes/process?pretty
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/10.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;如果仍然是false，可能是下面的原因：&lt;br&gt;Another possible reason why mlockall can fail is that the temporary directory (usually /tmp) is mounted with the noexec option. This can be solved by specifying a new temp directory, by starting Elasticsearch with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./bin/elasticsearch -Djna.tmpdir=/path/to/new/dir
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;要想永久修改锁定内存大小无限制，需修改/etc/security/limits.conf，添加下面的内容，改完不需要重启系统，但是需要重新打开一个shell建立会话。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;es - memlock -1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，es代表运行elasticsearch的用户，-表示同时设置了soft和hard，memlock代表设置的是”锁定内存”这个类型，-1(unlimited或者infinity)代表没限制。&lt;/p&gt;
&lt;p&gt;2.配置操作系统文件描述符数&lt;br&gt;查看elasticsearch能打开的最大文件描述符个数：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl http://114.55.29.86:9200/_nodes/stats/process?pretty
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看参数：max_file_descriptors&lt;br&gt;推荐设置到32K甚至64K。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/11.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;或者输入下面的命令进行查看：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ulimit -a
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/12.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;设置需要修改：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim /etc/security/limits.conf
es               -       nofile          65535
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.增大虚拟内存mmap count配置&lt;br&gt;备注：如果你以.deb或.rpm包安装，则默认不需要设置此项，因为已经被自动设置，查看方式为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sysctl vm.max_map_count
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果是手动安装，以root身份执行如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sysctl vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;并修改文件使设置永久生效：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# vim /etc/sysctl.conf    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加一行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vm.max_map_count = 262144
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使生效：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# sysctl -p
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;改完后，重启elasticsearch。&lt;br&gt;在浏览器输入&lt;a href=&quot;http://ip:9200/，查看页面信息，是否正常启动。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ip:9200/，查看页面信息，是否正常启动。&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/13.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;另外两台也需要做这些优化。&lt;/p&gt;
&lt;h2 id=&quot;安装插件：中文分词器ik&quot;&gt;&lt;a href=&quot;#安装插件：中文分词器ik&quot; class=&quot;headerlink&quot; title=&quot;安装插件：中文分词器ik&quot;&gt;&lt;/a&gt;安装插件：中文分词器ik&lt;/h2&gt;&lt;p&gt;elasticsearch-analysis-ik 是一款中文的分词插件，支持自定义词库。项目地址为：&lt;a href=&quot;https://github.com/medcl/elasticsearch-analysis-ik&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/medcl/elasticsearch-analysis-ik&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装Maven&quot;&gt;&lt;a href=&quot;#安装Maven&quot; class=&quot;headerlink&quot; title=&quot;安装Maven&quot;&gt;&lt;/a&gt;安装Maven&lt;/h3&gt;&lt;p&gt;由于该项目使用了Maven来管理，源代码放到github上。所以要先在服务器上面安装Maven，便可以直接在服务器上面生成项目jar包，部署起来更加方便了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# yum install -y maven
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装ik&quot;&gt;&lt;a href=&quot;#安装ik&quot; class=&quot;headerlink&quot; title=&quot;安装ik&quot;&gt;&lt;/a&gt;安装ik&lt;/h3&gt;&lt;p&gt;注意分词插件的版本，2.2.3对应的插件版本是1.9.3&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/14.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 ~]$ git clone https://github.com/medcl/elasticsearch-analysis-ik.git
[es@log1 ~]$ cd elasticsearch-analysis-ik/
[es@log1 elasticsearch-analysis-ik]$ mvn package
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;拷贝和解压&quot;&gt;&lt;a href=&quot;#拷贝和解压&quot; class=&quot;headerlink&quot; title=&quot;拷贝和解压&quot;&gt;&lt;/a&gt;拷贝和解压&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch-analysis-ik]$ mkdir -p /usr/local/elasticsearch/plugins/ik
[es@log1 elasticsearch-analysis-ik]$ cp target/releases/elasticsearch-analysis-ik-1.9.3.zip /usr/local/elasticsearch/plugins/ik
[es@log1 ~]$ cd /usr/local/elasticsearch/plugins/ik/
[es@log1 ik]$ unzip -oq elasticsearch-analysis-ik-1.9.3.zip
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;重启elasticsearch&quot;&gt;&lt;a href=&quot;#重启elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;重启elasticsearch&quot;&gt;&lt;/a&gt;重启elasticsearch&lt;/h3&gt;&lt;p&gt;直接重启就可以了，不需要在Elasticsearch中添加配置index.analysis.analyzer.ik.type : “ik”  。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 ik]$ cd /usr/local/elasticsearch/bin/
[es@log1 bin]$ jps
20221 Jps
14910 Elasticsearch
[es@log1 bin]$ kill -9 14910
[es@log1 elasticsearch]$ bin/elasticsearch -d
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;另外两台也需要解压这个插件进去，重新启动。&lt;/p&gt;
&lt;h3 id=&quot;分词测试&quot;&gt;&lt;a href=&quot;#分词测试&quot; class=&quot;headerlink&quot; title=&quot;分词测试&quot;&gt;&lt;/a&gt;分词测试&lt;/h3&gt;&lt;p&gt;①    创建一个索引，名为index&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ curl -XPUT http://114.55.29.86:9200/index
{&amp;quot;acknowledged&amp;quot;:true}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;②    index some docs&lt;br&gt;命令行输入以下内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -XPOST http://114.55.29.86:9200/index/fulltext/1 -d&amp;apos;
{&amp;quot;content&amp;quot;:&amp;quot;美国留给伊拉克的是个烂摊子吗&amp;quot;}
&amp;apos;

curl -XPOST http://114.55.29.86:9200/index/fulltext/2 -d&amp;apos;
{&amp;quot;content&amp;quot;:&amp;quot;公安部：各地校车将享最高路权&amp;quot;}
&amp;apos;

curl -XPOST http:// 114.55.29.86:9200/index/fulltext/3 -d&amp;apos;
{&amp;quot;content&amp;quot;:&amp;quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船&amp;quot;}
&amp;apos;

curl -XPOST http:// 114.55.29.86:9200/index/fulltext/4 -d&amp;apos;
{&amp;quot;content&amp;quot;:&amp;quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&amp;quot;}
&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;③    测试&lt;br&gt;命令行输入：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -XPOST http://114.55.29.86:9200/index/fulltext/_search  -d&amp;apos;
{
    &amp;quot;query&amp;quot; : { &amp;quot;term&amp;quot; : { &amp;quot;content&amp;quot; : &amp;quot;中国&amp;quot; }},
    &amp;quot;highlight&amp;quot; : {
        &amp;quot;pre_tags&amp;quot; : [&amp;quot;&amp;lt;tag1&amp;gt;&amp;quot;, &amp;quot;&amp;lt;tag2&amp;gt;&amp;quot;],
        &amp;quot;post_tags&amp;quot; : [&amp;quot;&amp;lt;/tag1&amp;gt;&amp;quot;, &amp;quot;&amp;lt;/tag2&amp;gt;&amp;quot;],
        &amp;quot;fields&amp;quot; : {
            &amp;quot;content&amp;quot; : {}
        }
    }
}
&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;took&amp;quot;:74,&amp;quot;timed_out&amp;quot;:false,&amp;quot;_shards&amp;quot;:{&amp;quot;total&amp;quot;:5,&amp;quot;successful&amp;quot;:5,&amp;quot;failed&amp;quot;:0},&amp;quot;hits&amp;quot;:{&amp;quot;total&amp;quot;:2,&amp;quot;max_score&amp;quot;:1.5,&amp;quot;hits&amp;quot;:[{&amp;quot;_index&amp;quot;:&amp;quot;index&amp;quot;,&amp;quot;_type&amp;quot;:&amp;quot;fulltext&amp;quot;,&amp;quot;_id&amp;quot;:&amp;quot;4&amp;quot;,&amp;quot;_score&amp;quot;:1.5,&amp;quot;_source&amp;quot;:
{&amp;quot;content&amp;quot;:&amp;quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&amp;quot;}
,&amp;quot;highlight&amp;quot;:{&amp;quot;content&amp;quot;:[&amp;quot;&amp;lt;tag1&amp;gt;中国&amp;lt;/tag1&amp;gt;驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&amp;quot;]}},{&amp;quot;_index&amp;quot;:&amp;quot;index&amp;quot;,&amp;quot;_type&amp;quot;:&amp;quot;fulltext&amp;quot;,&amp;quot;_id&amp;quot;:&amp;quot;3&amp;quot;,&amp;quot;_score&amp;quot;:0.53699243,&amp;quot;_source&amp;quot;:
{&amp;quot;content&amp;quot;:&amp;quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船&amp;quot;}
,&amp;quot;highlight&amp;quot;:{&amp;quot;content&amp;quot;:[&amp;quot;中韩渔警冲突调查：韩警平均每天扣1艘&amp;lt;tag1&amp;gt;中国&amp;lt;/tag1&amp;gt;渔船&amp;quot;]}}]}}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/15.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Elasticsearch介绍&quot;&gt;&lt;a href=&quot;#Elasticsearch介绍&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch介绍&quot;&gt;&lt;/a&gt;Elasticsearch介绍&lt;/h2&gt;&lt;p&gt;Elasticsearch是一个分布式搜索服务，提供Restful API，底层基于Lucene，采用多shard的方式保证数据安全，并且提供自动resharding的功能，加之github等大型的站点也采用 Elasticsearch作为其搜索服务。&lt;br&gt;
    
    </summary>
    
      <category term="搜索引擎" scheme="http://yoursite.com/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
      <category term="搜索 Elasticsearch" scheme="http://yoursite.com/tags/%E6%90%9C%E7%B4%A2-Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Storm介绍及安装部署</title>
    <link href="http://yoursite.com/2017/06/10/Storm%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/06/10/Storm介绍及安装部署/</id>
    <published>2017-06-10T02:39:13.000Z</published>
    <updated>2017-06-12T04:36:51.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Apache-Storm是什么&quot;&gt;&lt;a href=&quot;#Apache-Storm是什么&quot; class=&quot;headerlink&quot; title=&quot;Apache Storm是什么&quot;&gt;&lt;/a&gt;Apache Storm是什么&lt;/h2&gt;&lt;p&gt;Apache Storm是自由开源的分布式实时计算系统，擅长处理海量数据，适用于数据实时处理而非批处理。&lt;br&gt;批处理使用的大多是鼎鼎大名的hadoop或者hive，作为一个批处理系统，hadoop以其吞吐量大、自动容错等优点，在海量数据处理上得到了广泛的使用。但是，hadoop不擅长实时计算，因为它天然就是为批处理而生的，这也是业界一致的共识。否则最近几年也不会有s4,storm,puma这些实时计算系统如雨后春笋般冒出来啦。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;举个搜索场景中的例子，当一个卖家发布了一条宝贝信息时，他希望的当然是这个宝贝马上就可以被卖家搜索出来、点击、购买啦，相反，如果这个宝贝要等到第二天或者更久才可以被搜出来，估计就会有不少损失了。&lt;br&gt;再举一个推荐的例子，如果用户昨天在淘宝上买了一双袜子，今天想买一副泳镜去游泳，但是却发现系统在不遗余力地给他推荐袜子、鞋子，根本对他今天寻找泳镜的行为视而不见，这样商家的利益就有所损失。这是因为后台系统做的是每天一次的全量处理，而且大多是在夜深人静之时做的，那么客户今天白天做的事情要到明天才能反映出来。这也就是为什么需要实时处理的原因。&lt;/p&gt;
&lt;h2 id=&quot;Apache-Storm核心概念&quot;&gt;&lt;a href=&quot;#Apache-Storm核心概念&quot; class=&quot;headerlink&quot; title=&quot;Apache Storm核心概念&quot;&gt;&lt;/a&gt;Apache Storm核心概念&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Nimbus：Storm集群主节点，负责资源分配和任务调度。我们提交任务和截止任务都是在Nimbus上操作的。一个Storm集群只有一个Nimbus节点。&lt;/li&gt;
&lt;li&gt;Supervisor：Storm集群工作节点，接受Nimbus分配任务，管理所有Worker。&lt;/li&gt;
&lt;li&gt;Worker：工作进程，每个工作进程中都有多个Task。&lt;/li&gt;
&lt;li&gt;Task：任务，每个Spout和Bolt都是一个任务，每个任务都是一个线程。&lt;/li&gt;
&lt;li&gt;Topology：计算拓扑，包含了应用程序的逻辑。&lt;/li&gt;
&lt;li&gt;Stream：消息流，关键抽象，是没有边界的Tuple序列。&lt;/li&gt;
&lt;li&gt;Spout：消息流的源头，Topology的消息生产者。&lt;/li&gt;
&lt;li&gt;Bolt：消息处理单元，可以过滤、聚合、查询数据库。&lt;/li&gt;
&lt;li&gt;Stream grouping：消息分发策略，一共6种，定义每个Bolt接受何种输入。&lt;/li&gt;
&lt;li&gt;Reliability：可靠性，Storm保证每个Tuple都会被处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Storm原理架构&quot;&gt;&lt;a href=&quot;#Storm原理架构&quot; class=&quot;headerlink&quot; title=&quot;Storm原理架构&quot;&gt;&lt;/a&gt;Storm原理架构&lt;/h2&gt;&lt;h3 id=&quot;Storm集群架构图&quot;&gt;&lt;a href=&quot;#Storm集群架构图&quot; class=&quot;headerlink&quot; title=&quot;Storm集群架构图&quot;&gt;&lt;/a&gt;Storm集群架构图&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Zookeeper集群在Storm集群中的作用：&lt;br&gt;Zookeeper集群负责Nimbus节点和Supervior节点之间的通信，监控各个节点之间的状态。比如通常我们提交任务的时候是在Nimbus节点上执行的，Nimbus节点通过zk集群将任务分发下去，而Supervisor是真正执行任务的地方。Nimbus节点通过zk集群监控各个Supervisor节点的状态，当某个Supervisor节点出现故障的时候，Nimbus节点就会通过zk集群将那个Supervisor节点上的任务重新分发，在其他Supervisor节点上执行。这就意味着Storm集群也是高可用集群，如果Nimbus节点出现故障的时候，整个任务并不会停止，但是任务的管理会出现影响，通常这种情况下我们只需要将Nimbus节点恢复就可以了。Nimbus节点不支持高可用，这也是Storm目前面临的问题之一。不过一般情况下，Nimbus节点的压力不大，通常不会出现问题。&lt;br&gt;一般情况下，Zookeeper集群的压力并不大，一般只需要部署3台就够了。Zookeeper集群在Storm集群中逻辑上是独立的，但在实际部署的时候，一般会将zk节点部署在Nimbus节点或Supervisor节点上。&lt;/p&gt;
&lt;h3 id=&quot;数据处理流程图&quot;&gt;&lt;a href=&quot;#数据处理流程图&quot; class=&quot;headerlink&quot; title=&quot;数据处理流程图&quot;&gt;&lt;/a&gt;数据处理流程图&lt;/h3&gt;&lt;p&gt;storm处理数据的特点：数据源源不断，不断处理。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;拓扑图分析&quot;&gt;&lt;a href=&quot;#拓扑图分析&quot; class=&quot;headerlink&quot; title=&quot;拓扑图分析&quot;&gt;&lt;/a&gt;拓扑图分析&lt;/h3&gt;&lt;p&gt;storm中是没有数据存储结构的，我们需要自己设计数据落地接口，指明数据存储到哪一部分中。Storm本身是不存储数据的。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Storm集群安装部署&quot;&gt;&lt;a href=&quot;#Storm集群安装部署&quot; class=&quot;headerlink&quot; title=&quot;Storm集群安装部署&quot;&gt;&lt;/a&gt;Storm集群安装部署&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6、apache-storm-1.0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6、apache-storm-1.0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log3&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.253.15&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6、apache-storm-1.0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;安装Zookeeper集群&quot;&gt;&lt;a href=&quot;#安装Zookeeper集群&quot; class=&quot;headerlink&quot; title=&quot;安装Zookeeper集群&quot;&gt;&lt;/a&gt;安装Zookeeper集群&lt;/h3&gt;&lt;p&gt;见之前的文章《Zookeeper介绍及安装部署》。&lt;/p&gt;
&lt;h3 id=&quot;安装Storm集群&quot;&gt;&lt;a href=&quot;#安装Storm集群&quot; class=&quot;headerlink&quot; title=&quot;安装Storm集群&quot;&gt;&lt;/a&gt;安装Storm集群&lt;/h3&gt;&lt;p&gt;log1、log2和log3部署storm集群，log1作为Nimbus节点，log2和log3作为surpervisor节点。&lt;/p&gt;
&lt;p&gt;1.下载安装软件并解压&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# wget http://apache.fayea.com/storm/apache-storm-1.0.0/apache-storm-1.0.0.tar.gz
[root@log1 local]# tar zxf apache-storm-1.0.0.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.配置storm&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# cd /usr/local/apache-storm-1.0.0/
[root@log1 apache-storm-1.0.0]# vim conf/storm.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(1)配置Zookeeper地址&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意: 如果Zookeeper集群使用的不是默认端口，那么还需要配置storm.zookeeper.port。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(2)storm.local.dir: The Nimbus and Supervisor daemons require a directory on the local disk to store small amounts of state (like jars, confs, and things like that).&lt;br&gt;添加一行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;storm.local.dir: &amp;quot;/usr/local/apache-storm-1.0.0/status&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这个status目录在storm启动的时候会自动创建，当然也可以提前创建好。&lt;/p&gt;
&lt;p&gt;(3)配置nimbus.seeds：用于配置主控节点的地址，可以配置多个。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;(4)配置supervisor.slots.ports&lt;br&gt;supervisor.slots.ports:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- 6700
- 6701
- 6702
- 6703
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;配置工作节点上的进程端口。你配置一个端口，意味着工作节点上启动一个worker，在实际的生产环境中，我们需要根据实际的物理配置以及每个节点上的负载情况来配置这个端口的数量。在这里每个节点我象征性的配置4个端口。&lt;br&gt;&lt;strong&gt;注意:以上配置，凡是有冒号的地方，冒号后都要有个空格。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;log2和log3主机也是同样的配置。拷贝这台机器的storm包到log2和log2主机：&lt;br&gt;[root@log1 local]# scp -pr apache-storm-1.0.0 root@114.55.29.241:/usr/local/&lt;br&gt;[root@log1 local]# scp -pr apache-storm-1.0.0 root@114.55.253.15:/usr/local/&lt;br&gt;(5)对于两台supervisor node，我们额外开启JMX支持，在配置文件中加入如下配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;supervisor.childopts: -verbose:gc -XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=9998
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/8.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;9998就是用于通过JMX收集supervisior JVM指标的端口。&lt;/p&gt;
&lt;p&gt;3.配置storm环境变量&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 apache-storm-0.10.0]# vim /etc/profile
export STORM_HOME=/usr/local/apache-storm-0.10.0
export PATH=$STORM_HOME/bin:$PATH
[root@log1 apache-storm-0.10.0]# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;启动storm-ui、Nimbus和Supervisor&quot;&gt;&lt;a href=&quot;#启动storm-ui、Nimbus和Supervisor&quot; class=&quot;headerlink&quot; title=&quot;启动storm ui、Nimbus和Supervisor&quot;&gt;&lt;/a&gt;启动storm ui、Nimbus和Supervisor&lt;/h2&gt;&lt;p&gt;log1节点启动nimbus和storm ui：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# nohup storm ui &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
[root@log1 ~]# nohup storm nimbus &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;log2和log3主机启动Supervisor节点：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 ~]# nohup storm supervisor &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
[root@log3 ~]# nohup storm supervisor &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;访问ui页面：&lt;br&gt;&lt;a href=&quot;http://114.55.29.86:8080/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://114.55.29.86:8080/&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/9.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;界面介绍：&lt;br&gt;Used slots：使用的worker数。&lt;br&gt;Free slots：空闲的worker数。&lt;br&gt;Executors：每个worker的物理线程数。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Apache-Storm是什么&quot;&gt;&lt;a href=&quot;#Apache-Storm是什么&quot; class=&quot;headerlink&quot; title=&quot;Apache Storm是什么&quot;&gt;&lt;/a&gt;Apache Storm是什么&lt;/h2&gt;&lt;p&gt;Apache Storm是自由开源的分布式实时计算系统，擅长处理海量数据，适用于数据实时处理而非批处理。&lt;br&gt;批处理使用的大多是鼎鼎大名的hadoop或者hive，作为一个批处理系统，hadoop以其吞吐量大、自动容错等优点，在海量数据处理上得到了广泛的使用。但是，hadoop不擅长实时计算，因为它天然就是为批处理而生的，这也是业界一致的共识。否则最近几年也不会有s4,storm,puma这些实时计算系统如雨后春笋般冒出来啦。&lt;br&gt;
    
    </summary>
    
      <category term="实时处理" scheme="http://yoursite.com/categories/%E5%AE%9E%E6%97%B6%E5%A4%84%E7%90%86/"/>
    
    
      <category term="Storm 实时处理" scheme="http://yoursite.com/tags/Storm-%E5%AE%9E%E6%97%B6%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ介绍及安装部署</title>
    <link href="http://yoursite.com/2017/06/04/RabbitMQ%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/06/04/RabbitMQ介绍及安装部署/</id>
    <published>2017-06-04T12:45:36.000Z</published>
    <updated>2017-07-16T08:01:05.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;RabbitMQ介绍&quot;&gt;&lt;a href=&quot;#RabbitMQ介绍&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ介绍&quot;&gt;&lt;/a&gt;RabbitMQ介绍&lt;/h2&gt;&lt;p&gt;消息系统通过将消息的发送和接收分离来实现应用程序的异步和解偶。&lt;br&gt;或许你正在考虑进行数据投递，非阻塞操作或推送通知。或许你想要实现发布／订阅，异步处理，或者工作队列。所有这些都属于消息系统的模式。&lt;br&gt;RabbitMQ是一个消息代理，一个消息系统的媒介。它可以为你的应用提供一个通用的消息发送和接收平台，并且保证消息再传输过程中的安全。&lt;br&gt;RabbitMQ是一个在AMQP协议标准上完整的、可复用的企业消息系统。它遵循Mozilla Public License开源协议，采用Erlang语言实现的工业级的消息队列。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;RabbitMQ运行原理&quot;&gt;&lt;a href=&quot;#RabbitMQ运行原理&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ运行原理&quot;&gt;&lt;/a&gt;RabbitMQ运行原理&lt;/h2&gt;&lt;p&gt;RabbitMQ的两大核心组件是Exchange和Queue，以下是它的运行原理图：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;RabbitMQ重要术语&quot;&gt;&lt;a href=&quot;#RabbitMQ重要术语&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ重要术语&quot;&gt;&lt;/a&gt;RabbitMQ重要术语&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.Server(broker):&lt;/strong&gt; 接受客户端连接，实现AMQP消息队列和路由功能的进程。&lt;br&gt;&lt;strong&gt;2.Vitual Host:&lt;/strong&gt; 这是一个虚拟概念，类似于权限控制组，一个Vitual Host里面可以有若干个Exchange和Queue，但是权限控制的最小粒度是Vitual Host。&lt;br&gt;&lt;strong&gt;3.Exchange:&lt;/strong&gt; 接收生产者发送的消息，并根据Binding规则将消息路由给服务器中的队列。ExchangeType决定了Exchange路由消息的行为，例如，在RabbitMQ中，ExchangeType有direct、Fanout和Topic三种，不同类型的Exchange路由的行为是不一样的。&lt;br&gt;&lt;strong&gt;4.Message Queue:&lt;/strong&gt; 消息队列，用于存储还未被消费者消费的消息。&lt;br&gt;&lt;strong&gt;5.Message:&lt;/strong&gt; 由Header和Body组成，Header是由生产者添加的各种属性的集合，包括Message是否被持久化、由哪个Message Queue接受、优先级是多少等。而body是真正需要传输的APP数据。&lt;br&gt;&lt;strong&gt;6.BindingKey:&lt;/strong&gt; 所谓绑定就是将一个特定的一个Exchange和一个特定的Queue绑定起来，绑定关键字称为BindingKey。&lt;/p&gt;
&lt;h2 id=&quot;三种ExchangeType&quot;&gt;&lt;a href=&quot;#三种ExchangeType&quot; class=&quot;headerlink&quot; title=&quot;三种ExchangeType&quot;&gt;&lt;/a&gt;三种ExchangeType&lt;/h2&gt;&lt;p&gt;RabbitMQ消息模型的核心理念是：发布者（producer）不会直接发送任何消息给队列。事实上，发布者（producer）甚至不知道消息是否已经被投递到队列。&lt;br&gt;发布者（producer）只需要把消息发送给一个交换机（exchange）。交换机非常简单，它一边从发布者方接收消息，一边把消息推送到队列。交换机必须知道如何处理它接收到的消息，是应该推送到指定的队列还是是多个队列，或者是直接忽略消息。这些规则是通过交换机类型（exchange type）来定义的。&lt;/p&gt;
&lt;h3 id=&quot;直接式交换器类型-Direct&quot;&gt;&lt;a href=&quot;#直接式交换器类型-Direct&quot; class=&quot;headerlink&quot; title=&quot;直接式交换器类型(Direct)&quot;&gt;&lt;/a&gt;直接式交换器类型(Direct)&lt;/h3&gt;&lt;p&gt;Direct Exchange：直接交互式处理路由键。需要将一个队列绑定到交换机上，要求该消息与一个特定的路由键完全匹配，这是一个完整的匹配。路由键就是BindingKey。如果一个队列绑定到该交换机上要求路由键“dog”，则只有被标记为“dog”的消息才被转发，不会转发dog.puppy，也不会转发dog.guard，只会转发dog。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;广播式交换机类型-Fanout&quot;&gt;&lt;a href=&quot;#广播式交换机类型-Fanout&quot; class=&quot;headerlink&quot; title=&quot;广播式交换机类型(Fanout)&quot;&gt;&lt;/a&gt;广播式交换机类型(Fanout)&lt;/h3&gt;&lt;p&gt;Fanout Exchange：广播式路由键。你只需要简单的将队列绑定到交换机上。一个发送到交换机的消息都被转发到与该交换机绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。Fanout交换机转发消息是最快的。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;主题式交换金类型-Topic&quot;&gt;&lt;a href=&quot;#主题式交换金类型-Topic&quot; class=&quot;headerlink&quot; title=&quot;主题式交换金类型(Topic)&quot;&gt;&lt;/a&gt;主题式交换金类型(Topic)&lt;/h3&gt;&lt;p&gt;Topic Exchange：主题式交换器。通过消息的路由关键字和绑定关键字的模式匹配，将消息路由到被绑定的队列中。这种路由器类型可以被用来支持经典的发布/订阅消息传输类型——使用主题名字空间作为消息寻址模式，将消息传递给那些部分或者全部匹配主题模式的多个消费者。主题交换器类型的工作方式如下：绑定关键字用零个或多个标记构成，每一个标记之间用“.”字符分隔。绑定关键字必须用这种形式明确说明，并支持通配符：“&lt;em&gt;”匹配一个词组，“#”零个或多个词组。因此绑定关键字“&lt;/em&gt;.stock.#”匹配路由关键字“usd.stock”和“eur.stock.db”，但是不匹配“stock.nasdaq”。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;RabbitMQ集群种类&quot;&gt;&lt;a href=&quot;#RabbitMQ集群种类&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ集群种类&quot;&gt;&lt;/a&gt;RabbitMQ集群种类&lt;/h2&gt;&lt;p&gt;RabbitMQ是用erlang开发的，集群非常方便，因为erlang天生就是一门分布式语言,但其本身并不支持负载均衡。&lt;br&gt;Rabbit模式大概分为以下三种：单一模式、普通模式、镜像模式。&lt;br&gt;&lt;strong&gt;1.单一模式：&lt;/strong&gt;最简单的情况，非集群模式。&lt;br&gt;&lt;strong&gt;2.普通模式：&lt;/strong&gt;默认的集群模式。&lt;br&gt;对于Queue来说，消息实体只存在于其中一个节点，A、B两个节点仅有相同的元数据，即队列结构。&lt;br&gt;当消息进入A节点的Queue中后，consumer从B节点拉取时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。&lt;br&gt;所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连A或B，出口总在A，会产生瓶颈。&lt;br&gt;该模式存在一个问题就是当A节点故障后，B节点无法取到A节点中还未消费的消息实体。&lt;br&gt;如果做了消息持久化，那么得等A节点恢复，然后才可被消费；如果没有持久化的话，然后就没有然后了……&lt;br&gt;&lt;strong&gt;3.镜像模式：&lt;/strong&gt;把需要的队列做成镜像队列，存在于多个节点，属于RabbitMQ的HA方案。&lt;br&gt;该模式解决了上述问题，其实质和普通模式不同之处在于，消息实体会主动在镜像节点间同步，而不是在consumer取数据时临时拉取。&lt;br&gt;该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉。&lt;br&gt;所以在对可靠性要求较高的场合中适用。&lt;/p&gt;
&lt;h2 id=&quot;集群基本概念&quot;&gt;&lt;a href=&quot;#集群基本概念&quot; class=&quot;headerlink&quot; title=&quot;集群基本概念&quot;&gt;&lt;/a&gt;集群基本概念&lt;/h2&gt;&lt;p&gt;RabbitMQ的集群节点包括内存节点、磁盘节点。内存节点就是将所有数据放在内存，磁盘节点将数据放在磁盘。不过，如果在投递消息时，打开了消息的持久化，那么即使是内存节点，数据还是安全的放在磁盘。&lt;br&gt;一个rabbitmq集群中可以共享 user，vhost，queue，exchange等，所有的数据和状态都是必须在所有节点上复制的，一个例外是，那些当前只属于创建它的节点的消息队列，尽管它们可见且可被所有节点读取。rabbitmq节点可以动态的加入到集群中，一个节点它可以加入到集群中，也可以从集群环集群会进行一个基本的负载均衡。&lt;br&gt;集群中有两种节点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内存节点：只保存状态到内存（一个例外的情况是：持久的queue的持久内容将被保存到disk）&lt;/li&gt;
&lt;li&gt;磁盘节点：保存状态到内存和磁盘。&lt;br&gt;内存节点虽然不写入磁盘，但是它执行比磁盘节点要好。集群中，只需要一个磁盘节点来保存状态就足够了。&lt;br&gt;如果集群中只有内存节点，那么不能停止它们，否则所有的状态，消息等都会丢失。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;镜像模式部署集群&quot;&gt;&lt;a href=&quot;#镜像模式部署集群&quot; class=&quot;headerlink&quot; title=&quot;镜像模式部署集群&quot;&gt;&lt;/a&gt;镜像模式部署集群&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;console&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.248.157&lt;/td&gt;
&lt;td&gt;haproxy-1.5.14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;erlang、rabbitmq-server-3.5.0-1.noarch.rpm&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;erlang、rabbitmq-server-3.5.0-1.noarch.rpm&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;【环境说明】:集群中有3台机器，console主机作为反向代理，另外两台是rabbitmq server，一台使用磁盘模式，一台使用内存模式。&lt;br&gt;【注意】:请确保两台rabbitmq server主机的/etc/hosts里有ip地址和主机名的对应关系。如：&lt;br&gt;114.55.29.86 log1&lt;br&gt;114.55.29.241 log2&lt;/p&gt;
&lt;h3 id=&quot;集群每个节点安装rabbitmq-server&quot;&gt;&lt;a href=&quot;#集群每个节点安装rabbitmq-server&quot; class=&quot;headerlink&quot; title=&quot;集群每个节点安装rabbitmq server&quot;&gt;&lt;/a&gt;集群每个节点安装rabbitmq server&lt;/h3&gt;&lt;p&gt;log1和log2分别安装rabbitmq server。&lt;br&gt;1.配置好epel源&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rpm -Uvh http://download.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.安装依赖包&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# yum install erlang –y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.安装rabbitMq&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.5.0/rabbitmq-server-3.5.0-1.noarch.rpm
[root@log1 local]# yum localinstall rabbitmq-server-3.5.0-1.noarch.rpm -y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.添加开机启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# chkconfig rabbitmq-server on
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;5.启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# service rabbitmq-server start
Starting rabbitmq-server: SUCCESS
rabbitmq-server.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;6.开启web管理界面&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# rabbitmq-plugins enable rabbitmq_management
The following plugins have been enabled:
  mochiweb
  webmachine
  rabbitmq_web_dispatch
  amqp_client
  rabbitmq_management_agent
  rabbitmq_management

Applying plugin configuration to rabbit@log1... started 6 plugins.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;7.修改配置文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# cp /usr/share/doc/rabbitmq-server-3.5.0/rabbitmq.config.example /etc/rabbitmq/rabbitmq.config
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;修改用户配置 让其可以通过远程访问 不限于localhost。注意：rabbitmq从3.3.0开始禁止使用guest/guest权限通过除localhost外的访问。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# vim /etc/rabbitmq/rabbitmq.config
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;{loopback_users, []} 删除前面的注释%%，同时注意后面的逗号，只有一个配置项的时候，请删除后面的逗号。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;以上7步在log2主机上都要执行&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;8.因为默认用户为guest，要添加其他的管理账户。&lt;br&gt;&lt;strong&gt;注意:如果是集群的话，只要在一台主机设置即可，其它会自动同步。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# rabbitmqctl add_user zxadmin wisedu@2016
Creating user &amp;quot;zxadmin&amp;quot; ...
[root@log1 local]# rabbitmqctl set_user_tags zxadmin administrator
Setting tags for user &amp;quot;zxadmin&amp;quot; to [administrator] ...
[root@log1 local]# rabbitmqctl set_permissions -p / zxadmin &amp;quot;.*&amp;quot; &amp;quot;.*&amp;quot; &amp;quot;.*&amp;quot;
Setting permissions for user &amp;quot;zxadmin&amp;quot; in vhost &amp;quot;/&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;9.重启rabbitMQ&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# service rabbitmq-server restart
Restarting rabbitmq-server: SUCCESS
rabbitmq-server.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;10.访问管控台&lt;br&gt;浏览器输入URL：&lt;a href=&quot;http://ip/15672&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ip/15672&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;设置每个节点Cookie&quot;&gt;&lt;a href=&quot;#设置每个节点Cookie&quot; class=&quot;headerlink&quot; title=&quot;设置每个节点Cookie&quot;&gt;&lt;/a&gt;设置每个节点Cookie&lt;/h3&gt;&lt;p&gt;Rabbitmq的集群是依赖于erlang的集群来工作的，所以必须先构建起erlang的集群环境。Erlang的集群中各节点是通过一个magic cookie来实现的，这个cookie存放在  /var/lib/rabbitmq/.erlang.cookie 中，文件是400的权限。所以必须保证各节点cookie保持一致，否则节点之间就无法通信。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/8.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;将其中一台节点上的.erlang.cookie值复制下来保存到其他节点上。或者使用scp的方法也可，但是要注意文件的权限和属主属组。我这里将log1中的cookie 复制到log2中。&lt;br&gt;1.因为.erlang.cookie是只读的，先修改下log2中的.erlang.cookie权限&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 rabbitmq]# chmod 777 .erlang.cookie
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.copy log1主机上的.erlang.cookie到log2主机/var/lib/rabbitmq/目录下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 rabbitmq]# scp -p .erlang.cookie root@114.55.29.241:/var/lib/rabbitmq/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.停止所有节点RabbitMq服务，然后使用detached参数独立运行，这步很关键，尤其增加节点停止节点后再次启动遇到无法启动都可以参照这个顺序。&lt;br&gt;停止：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 rabbitmq]# service rabbitmq-server stop
[root@log2 rabbitmq]# service rabbitmq-server stop
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 rabbitmq]# rabbitmq-server -detached
Warning: PID file not written; -detached was passed.
[root@log2 rabbitmq]# rabbitmq-server -detached
Warning: PID file not written; -detached was passed.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.分别查看下每个节点&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 rabbitmq]# rabbitmqctl cluster_status
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 rabbitmq]# rabbitmqctl cluster_status
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/10.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;5.将log2作为内存节点与log1连接起来，在log2上执行如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 rabbitmq]# rabbitmqctl stop_app
[root@log2 rabbitmq]# rabbitmqctl join_cluster --ram rabbit@log1
[root@log2 rabbitmq]# rabbitmqctl start_app
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上述命令先停掉rabbitmq应用，然后调用cluster命令，将log2连接到log1，使两者成为一个集群，最后重启log2的rabbitmq应用。在这个cluster命令下，log2是内存节点，log1是磁盘节点（RabbitMQ启动后，默认是磁盘节点）。&lt;br&gt;log1如果要使log2在集群里也是磁盘节点，join_cluster 命令去掉–ram参数即可：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 rabbitmq]# rabbitmqctl join_cluster rabbit@log1 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;只要在节点列表里包含了自己，它就成为一个磁盘节点。在RabbitMQ集群里，必须至少有一个磁盘节点存在。&lt;/p&gt;
&lt;p&gt;6.再次查看各节点状态&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 rabbitmq]# rabbitmqctl cluster_status
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/11.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 rabbitmq]# rabbitmqctl cluster_status
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/12.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这样RabbitMQ集群就正常工作了。可以访问任意一个web管控台：&lt;a href=&quot;http://ip/15672&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ip/15672&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/13.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;添加镜像模式配置&quot;&gt;&lt;a href=&quot;#添加镜像模式配置&quot; class=&quot;headerlink&quot; title=&quot;添加镜像模式配置&quot;&gt;&lt;/a&gt;添加镜像模式配置&lt;/h3&gt;&lt;p&gt;上面配置RabbitMQ默认集群模式，但并不保证队列的高可用性，尽管交换机、绑定这些可以复制到集群里的任何一个节点，但是队列内容不会复制，虽然该模式解决一部分节点压力，但队列节点宕机直接导致该队列无法使用，只能等待重启，所以要想在队列节点宕机或故障也能正常使用，就要复制队列内容到集群里的每个节点，需要创建镜像队列。&lt;br&gt;1.安装haproxy&lt;br&gt;haproxy是在主机名为console上安装的。可以选择源代码编译安装或者yum安装，在这里我选择了yum安装。安装版本：haproxy-1.5.14-3.el7.x86_64 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# yum install -y haproxy
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.修改配置/etc/haproxy/haproxy.cfg&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# vim /etc/haproxy/haproxy.cfg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;删除 main frontend which proxys to the backends以下的所有内容，并添加&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;listen rabbitmq_cluster 0.0.0.0:5672
    mode tcp
    balance roundrobin
    server   rqslave1 114.55.29.241:5672 check inter 2000 rise 2 fall 3
    server   rqmaster 114.55.29.86:5672 check inter 2000 rise 2 fall 3
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果有3台或3台以上，可以把disc节点注释掉，原因就是让rabbitmq性能最佳化。这样负载均衡器会监听5672端口，轮询多个内存节点的5672端口，磁盘节点可以只做备份不提供给生产者、消费者使用，当然如果我们服务器资源充足情况也可以配置多个磁盘节点。此外，还需要修改defaults段配置：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/14.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;检查配置文件语法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# haproxy -c -f /etc/haproxy/haproxy.cfg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动haproxy：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# service haproxy start
Redirecting to /bin/systemctl start  haproxy.service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.配置策略：设置ha模式&lt;br&gt;使用Rabbit镜像功能，需要基于rabbitmq策略来实现，政策是用来控制和修改群集范围的某个vhost队列行为和Exchange行为。&lt;br&gt;其中ha-mode有三种模式:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;all: 同步至所有的；&lt;/li&gt;
&lt;li&gt;exactly: 同步最多N个机器. 当现有集群机器数小于N时,同步所有,大于等于N时则不进行同步. N需要额外通过ha-params来指定；&lt;/li&gt;
&lt;li&gt;&lt;p&gt;nodes: 只同步至符合指定名称的nodes. N需要额外通过ha-params来指定。&lt;br&gt;在cluster中任意节点启用策略，策略会自动同步到集群节点。我这里设置的是同步全部的queue, 可以按需自己选择指定的queue。语法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rabbitmqctl set_policy  [-p  vhostpath ] { name } { pattern } { definition } [ priority ]
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在log1主机上执行如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# rabbitmqctl set_policy ha-all &amp;quot;^&amp;quot; &amp;apos;{&amp;quot;ha-mode&amp;quot;:&amp;quot;all&amp;quot;}&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/15.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这行命令创建了一个策略，策略名称为ha-all,策略模式为 all ，即复制到所有节点，包含新增节点，策略正则表达式为 “^” 表示所有匹配所有队列名称。&lt;/p&gt;
&lt;h3 id=&quot;集群退出&quot;&gt;&lt;a href=&quot;#集群退出&quot; class=&quot;headerlink&quot; title=&quot;集群退出&quot;&gt;&lt;/a&gt;集群退出&lt;/h3&gt;&lt;p&gt;假设要把log2退出集群。&lt;br&gt;在log2上执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#rabbitmqctl stop_app
#rabbitmqctl reset
#rabbitmqctl start_app 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在集群主节点上执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# rabbitmqctl forget_cluster_node rabbit@log2
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;RabbitMQ介绍&quot;&gt;&lt;a href=&quot;#RabbitMQ介绍&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ介绍&quot;&gt;&lt;/a&gt;RabbitMQ介绍&lt;/h2&gt;&lt;p&gt;消息系统通过将消息的发送和接收分离来实现应用程序的异步和解偶。&lt;br&gt;或许你正在考虑进行数据投递，非阻塞操作或推送通知。或许你想要实现发布／订阅，异步处理，或者工作队列。所有这些都属于消息系统的模式。&lt;br&gt;RabbitMQ是一个消息代理，一个消息系统的媒介。它可以为你的应用提供一个通用的消息发送和接收平台，并且保证消息再传输过程中的安全。&lt;br&gt;RabbitMQ是一个在AMQP协议标准上完整的、可复用的企业消息系统。它遵循Mozilla Public License开源协议，采用Erlang语言实现的工业级的消息队列。&lt;br&gt;
    
    </summary>
    
      <category term="消息队列" scheme="http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="消息队列" scheme="http://yoursite.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Kafka介绍及安装部署</title>
    <link href="http://yoursite.com/2017/05/28/Kafka%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/05/28/Kafka介绍及安装部署/</id>
    <published>2017-05-28T11:46:22.000Z</published>
    <updated>2017-07-15T02:11:35.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;消息中间件&quot;&gt;&lt;a href=&quot;#消息中间件&quot; class=&quot;headerlink&quot; title=&quot;消息中间件&quot;&gt;&lt;/a&gt;消息中间件&lt;/h2&gt;&lt;p&gt;消息中间件是在消息的传输过程中保存消息的容器。消息中间件在将消息从消息生产者到消费者时充当中间人的作用。队列的主要目的是提供路由并保证消息的传送；如果发送消息时接收者不可用，消息对列会保留消息，直到可以成功地传递它为止，当然，消息队列保存消息也是有期限的。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;消息中间件特点&quot;&gt;&lt;a href=&quot;#消息中间件特点&quot; class=&quot;headerlink&quot; title=&quot;消息中间件特点&quot;&gt;&lt;/a&gt;消息中间件特点&lt;/h2&gt;&lt;p&gt;1.采用异步处理模式&lt;br&gt;消息发送者可以发送一个消息而无须等待响应。消息发送者将消息发送到一条虚拟的通道（主题或者队列）上，消息接收者则订阅或者监听该通道。一条消息可能最终转发给一个或多个消息接收者，这些接收者都无需对消息发送者做出同步回应。整个过程是异步的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比如用户信息注册。注册完成后过段时间发送邮件或者短信。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.应用程序和应用程序调用关系为松耦合关系&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;发送者和接收者不必要了解对方、只需要确认消息&lt;/li&gt;
&lt;li&gt;发送者和接收者不必同时在线&lt;br&gt;比如在线交易系统为了保证数据的最终一致，在支付系统处理完成后会把支付结果放到信息中间件里通知订单系统修改订单支付状态。两个系统通过消息中间件解耦。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;消息中间件的传递模型&quot;&gt;&lt;a href=&quot;#消息中间件的传递模型&quot; class=&quot;headerlink&quot; title=&quot;消息中间件的传递模型&quot;&gt;&lt;/a&gt;消息中间件的传递模型&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.点对点模型(PTP)&lt;/strong&gt;&lt;br&gt;点对点模型用于消息生产者和消息消费者之间点对点的通信。消息生产者将消息发送到由某个名字标识的特定消费者。这个名字实际上对应于消费服务中的一个队列(Queue)，在消息传递给消费者之前它被存储在这个队列中。队列消息可以放在内存中也可以是持久的，以保证在消息服务出现故障时仍然能够传递消息。&lt;br&gt;点对点模型特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消息只有一个消费者&lt;/li&gt;
&lt;li&gt;发送者和接受者没有时间依赖&lt;/li&gt;
&lt;li&gt;接受者确认消息接受和处理成功&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/1.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.发布—订阅模型(Pub/Sub)&lt;/strong&gt;&lt;br&gt;发布者/订阅者模型支持向一个特定的消息主题生产消息。0或多个订阅者可能对接收来自特定消息主题的消息感兴趣。在这种模型下，发布者和订阅者彼此不知道对方。这种模式好比是匿名公告板。这种模式被概括为：多个消费者可以获得消息。在发布者和订阅者之间存在时间依赖性。发布者需要建立一个订阅(subscription)，以便能够让消费者订阅。订阅者必须保持持续的活动状态以接收消息，除非订阅者建立了持久的订阅。在这种情况下，在订阅者未连接时发布的消息将在订阅者重新连接时重新发布。&lt;br&gt;其实消息中间件，像MySQL其实也可以作为消息中间件，只要你把消息中间件原理搞清楚，你会发现目前所有的存储，包括NoSQL，只要支持顺序性东西的，就可以作为一个消息中间件。就看你怎么去利用它了。就像redis里面那个队列list，就可以作为一个消息队列。&lt;br&gt;发布—订阅模型特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消息可以有多个订阅者&lt;/li&gt;
&lt;li&gt;客户端只有订阅后才能接收到消息&lt;/li&gt;
&lt;li&gt;持久订阅和非持久订阅&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(1)发布者和订阅者有时间依赖&lt;br&gt;接收者和发布者只有建立订阅关系才能收到消息。&lt;br&gt;(2)持久订阅&lt;br&gt;订阅关系建立后，消息就不会消失，不管订阅者是否在线。&lt;br&gt;(3)非持久订阅&lt;br&gt;订阅者为了接收消息，必须一直在线&lt;br&gt;当只有一个订阅者时约等于点对点模式。&lt;br&gt;&lt;strong&gt;大部分情况下会使用持久订阅。常用的消息队列有Kafka、RabbitMQ、ActiveMQ、metaq等&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Kafka介绍&quot;&gt;&lt;a href=&quot;#Kafka介绍&quot; class=&quot;headerlink&quot; title=&quot;Kafka介绍&quot;&gt;&lt;/a&gt;Kafka介绍&lt;/h2&gt;&lt;p&gt;Kafka是一种分布式消息系统，由LinkedIn使用Scala编写，用作LinkedIn的活动流(Activity Stream)和运营数据处理管道(Pipeline)的基础，具有高水平扩展和高吞吐量。&lt;br&gt;目前越来越多的开源分布式处理系统如Apache flume、Apache Storm、Spark、Elasticsearch都支持与Kafka集成。&lt;/p&gt;
&lt;h2 id=&quot;安装部署Kafka集群&quot;&gt;&lt;a href=&quot;#安装部署Kafka集群&quot; class=&quot;headerlink&quot; title=&quot;安装部署Kafka集群&quot;&gt;&lt;/a&gt;安装部署Kafka集群&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;JDK1.7、kafka_2.11-0.9.0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;JDK1.7、kafka_2.11-0.9.0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log3&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.253.15&lt;/td&gt;
&lt;td&gt;JDK1.7、kafka_2.11-0.9.0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;安装JDK1-7&quot;&gt;&lt;a href=&quot;#安装JDK1-7&quot; class=&quot;headerlink&quot; title=&quot;安装JDK1.7&quot;&gt;&lt;/a&gt;安装JDK1.7&lt;/h3&gt;&lt;p&gt;3台机器都需要安装JDK1.7。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# mkdir /usr/java
[root@log1 local]# tar zxf jdk-7u80-linux-x64.gz -C /usr/java/
[root@log1 local]# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.7.0_80
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
[root@log1 local]# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装集群&quot;&gt;&lt;a href=&quot;#安装集群&quot; class=&quot;headerlink&quot; title=&quot;安装集群&quot;&gt;&lt;/a&gt;安装集群&lt;/h3&gt;&lt;p&gt;需要先安装好Zookeeper集群，见之前的文章《Zookeeper介绍及安装部署》。&lt;br&gt;1.创建消息持久化目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# mkdir /kafkaLogs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.下载解压kafka，版本是kafka_2.11-0.9.0.1&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# wget http://mirrors.cnnic.cn/apache/kafka/0.9.0.1/kafka_2.11-0.9.0.1.tgz
[root@log1 local]# tar zxf kafka_2.11-0.9.0.1.tgz
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.修改配置&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# cd kafka_2.11-0.9.0.1/config/
[root@log1 config]# vim server.properties
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(1)修改broker.id&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(2)修改kafka监听地址&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意: advertised.host.name参数用来配置返回的host.name值，把这个参数配置为IP地址。这样客户端在使用java.net.InetAddress.getCanonicalHostName()获取时拿到的就是ip地址而不是主机名。&lt;/strong&gt;&lt;br&gt;(3)修改消息持久化目录&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(4)修改zk地址&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(5)添加启用删除topic配置&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(6)关闭自动创建topic&lt;br&gt;是否允许自动创建topic。如果设为true，那么produce，consume或者fetch metadata一个不存在的topic时，就会自动创建一个默认replication factor和partition number的topic。默认是true。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;auto.create.topics.enable=false
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4.把log1的配置好的kafka拷贝到log2和log3上&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# scp -rp kafka_2.11-0.9.0.1 root@114.55.29.241:/usr/local/
[root@log1 local]# scp -rp kafka_2.11-0.9.0.1 root@114.55.253.15:/usr/local/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;5.log2和log3主机上创建消息持久化目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 ~]# mkdir /kafkaLogs
[root@log3 ~]# mkdir /kafkaLogs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;6.修改log2配置文件中的broker.id为1，log3主机的为2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 config]# vim server.properties
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;启动集群&quot;&gt;&lt;a href=&quot;#启动集群&quot; class=&quot;headerlink&quot; title=&quot;启动集群&quot;&gt;&lt;/a&gt;启动集群&lt;/h3&gt;&lt;p&gt;log1主机启动kafka：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# cd /usr/local/kafka_2.11-0.9.0.1/
[root@log1 kafka_2.11-0.9.0.1]# JMX_PORT=9997 bin/kafka-server-start.sh -daemon config/server.properties &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/10.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;log2主机启动kafka：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 ~]# cd /usr/local/kafka_2.11-0.9.0.1/
[root@log2 kafka_2.11-0.9.0.1]# JMX_PORT=9997 bin/kafka-server-start.sh -daemon config/server.properties &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;log3主机启动kafka：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log3 ~]# cd /usr/local/kafka_2.11-0.9.0.1/
[root@log3 kafka_2.11-0.9.0.1]# JMX_PORT=9997 bin/kafka-server-start.sh -daemon config/server.properties &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;脚本定期清理logs下的日志文件&quot;&gt;&lt;a href=&quot;#脚本定期清理logs下的日志文件&quot; class=&quot;headerlink&quot; title=&quot;脚本定期清理logs下的日志文件&quot;&gt;&lt;/a&gt;脚本定期清理logs下的日志文件&lt;/h3&gt;&lt;p&gt;默认kafka是按天切割日志的，而且不删除：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/11.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这里写一个简单的脚本来清理这些日志，主要是清理server.log和controller.log。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# cd /usr/local/kafka_2.11-0.9.0.1/
[root@log1 kafka_2.11-0.9.0.1]# vim clean_kafkalog.sh
#!/bin/bash
###Description:This script is used to clear kafka logs, not message file.
###Written by: jkzhao - jkzhao@wisedu.com  
###History: 2016-04-18 First release.

# log file dir.
logDir=/usr/local/kafka_2.11-0.9.0.1/logs

# Reserved 7 files.
COUNT=7

ls -t $logDir/server.log* | tail -n +$[$COUNT+1] | xargs rm -f
ls -t $logDir/controller.log* | tail -n +$[$COUNT+1] | xargs rm -f
ls -t $logDir/state-change.log* | tail -n +$[$COUNT+1] | xargs rm -f
ls -t $logDir/log-cleaner.log* | tail -n +$[$COUNT+1] | xargs rm –f
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;赋予脚本执行权限：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 kafka_2.11-0.9.0.1]# chmod +x clean_kafkalog.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;周期性任务策略：每周日的0点0分去执行这个脚本。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 logs]# crontab -e
0 0 * * 0 /usr/local/kafka_2.11-0.9.0.1/clean_kafkalog.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/12.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;把清理日志的脚本拷贝到第二台和第三台主机：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 kafka_2.11-0.9.0.1]# scp -p clean_kafkalog.sh root@114.55.29.241:/usr/local/kafka_2.11-0.9.0.1
[root@log1 kafka_2.11-0.9.0.1]# scp -p clean_kafkalog.sh root@114.55.253.15:/usr/local/kafka_2.11-0.9.0.1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同样的需要配置周期性任务策略。&lt;/p&gt;
&lt;h3 id=&quot;停止kafka命令&quot;&gt;&lt;a href=&quot;#停止kafka命令&quot; class=&quot;headerlink&quot; title=&quot;停止kafka命令&quot;&gt;&lt;/a&gt;停止kafka命令&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@log1 ~]# /usr/local/kafka_2.11-0.9.0.1/bin/kafka-server-stop.sh
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;测试集群&quot;&gt;&lt;a href=&quot;#测试集群&quot; class=&quot;headerlink&quot; title=&quot;测试集群&quot;&gt;&lt;/a&gt;测试集群&lt;/h3&gt;&lt;p&gt;1.log1主机上创建一个名为test的topic&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 kafka_2.11-0.9.0.1]# bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.log2和log3主机上利用命令行工具创建一个consumer程序&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 kafka_2.11-0.9.0.1]# bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
[root@log2 kafka_2.11-0.9.0.1]# bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.log1主机上利用命令行工具创建一个producer程序&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 kafka_2.11-0.9.0.1]# bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;log1主机上终端输入message，然后到log2和log3主机的终端查看&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/13.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/14.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;创建生产环境topic&quot;&gt;&lt;a href=&quot;#创建生产环境topic&quot; class=&quot;headerlink&quot; title=&quot;创建生产环境topic&quot;&gt;&lt;/a&gt;创建生产环境topic&lt;/h3&gt;&lt;p&gt;如果kafka集群是3台，我们创建一个名为business的Topic，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 3 --topic business
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意:为Topic创建分区时，–partitions(分区数)最好是broker数量的整数倍，这样才能使一个Topic的分区均匀的分布在整个Kafka集群中。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;Kafka常用命令&quot;&gt;&lt;a href=&quot;#Kafka常用命令&quot; class=&quot;headerlink&quot; title=&quot;Kafka常用命令&quot;&gt;&lt;/a&gt;Kafka常用命令&lt;/h3&gt;&lt;p&gt;1.启动kafka&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nohup bin/kafka-server-start.sh config/server.properties &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.查看topic&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --list --zookeeper localhost:2181
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.控制台消费&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic middleware --from-beginning
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.删除topic&lt;br&gt;(1)删除kafka存储目录（server.properties文件log.dirs配置，默认为”/tmp/kafka-logs”）相关topic目录&lt;br&gt;(2)如果配置了delete.topic.enable=true直接通过命令删除，如果命令删除不掉，直接通过zookeeper-client 删除掉”/brokers/topics/“目录下相关topic节点。&lt;br&gt;&lt;strong&gt;注意: 如果你要删除一个topic并且重建，那么必须重新启动kafka，否则新建的topic在zookeeper的/brokers/topics/test-topic/目录下没有partitions这个目录，也就是没有分区信息。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装Yahoo-kafka-manager&quot;&gt;&lt;a href=&quot;#安装Yahoo-kafka-manager&quot; class=&quot;headerlink&quot; title=&quot;安装Yahoo kafka manager&quot;&gt;&lt;/a&gt;安装Yahoo kafka manager&lt;/h2&gt;&lt;h3 id=&quot;Yahoo-kafka-manager介绍&quot;&gt;&lt;a href=&quot;#Yahoo-kafka-manager介绍&quot; class=&quot;headerlink&quot; title=&quot;Yahoo kafka manager介绍&quot;&gt;&lt;/a&gt;Yahoo kafka manager介绍&lt;/h3&gt;&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/yahoo/kafka-manager&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/yahoo/kafka-manager&lt;/a&gt;&lt;br&gt;Requirements：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 0.8.1.1 or 0.8.2.*&lt;/li&gt;
&lt;li&gt;sbt 0.13.x&lt;/li&gt;
&lt;li&gt;Java 8+&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kafka Manager是一个管控台，这款工具主要支持以下几个功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;管理多个不同的集群；&lt;/li&gt;
&lt;li&gt;很容易地检查集群的状态(topics, brokers, 副本的分布, 分区的分布)；&lt;/li&gt;
&lt;li&gt;选择副本；&lt;/li&gt;
&lt;li&gt;产生分区分配(Generate partition assignments)基于集群的当前状态；&lt;/li&gt;
&lt;li&gt;重新分配分区。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;环境信息-1&quot;&gt;&lt;a href=&quot;#环境信息-1&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;console&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.246&lt;/td&gt;
&lt;td&gt;JDK1.8、kafka-manager-1.3.0.6.zip&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Kafka Manager可以装在任何一台机器上，我这里部署在一台单独的机器上。&lt;/p&gt;
&lt;h3 id=&quot;安装jdk1-8&quot;&gt;&lt;a href=&quot;#安装jdk1-8&quot; class=&quot;headerlink&quot; title=&quot;安装jdk1.8&quot;&gt;&lt;/a&gt;安装jdk1.8&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console local]# tar zxf jdk-8u73-linux-x64.gz -C /usr/java/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置PATH环境变量:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.8.0_73
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装sbt0-13-9&quot;&gt;&lt;a href=&quot;#安装sbt0-13-9&quot; class=&quot;headerlink&quot; title=&quot;安装sbt0.13.9&quot;&gt;&lt;/a&gt;安装sbt0.13.9&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console ~]# curl https://bintray.com/sbt/rpm/rpm | sudo tee /etc/yum.repos.d/bintray-sbt-rpm.repo
[root@console ~]# yum install -y sbt
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;构建kafka-manager包&quot;&gt;&lt;a href=&quot;#构建kafka-manager包&quot; class=&quot;headerlink&quot; title=&quot;构建kafka manager包&quot;&gt;&lt;/a&gt;构建kafka manager包&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console ~]# git clone https://github.com/yahoo/kafka-manager.git
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/15.png&quot; alt=&quot;&quot;&gt;    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# unzip -oq kafka-manager-upgrade-to-90.zip
[root@console ~]# mv kafka-manager-upgrade-to-90 kafka-manager
[root@console ~]# cd kafka-manager
[root@console kafka-manager]# sbt clean dist
The command below will create a zip file which can be used to deploy the application. 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用sbt编译打包的时候时间可能会比较长。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/16.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这个需要翻墙才能完成。配置代理：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# vim /usr/share/sbt-launcher-packaging/conf/sbtconfig.txt
-Dhttp.proxyHost=proxy
-Dhttp.proxyPort=8080
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;再次运行这个命令，依然需要等待较长的时间，有可能还会失败。如果失败就多次尝试打包：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console kafka-manager]# sbt clean dist
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/17.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/18.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;打包完成后会创建一个zip压缩包，而这个压缩包可以用来部署该应用。生成的包会在kafka-manager/target/universal 下面。生成的包只需要java环境就可以运行了，在以后部署到其他机器上不需要安装sbt进行打包构建了。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/19.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装kafka-manager&quot;&gt;&lt;a href=&quot;#安装kafka-manager&quot; class=&quot;headerlink&quot; title=&quot;安装kafka manager&quot;&gt;&lt;/a&gt;安装kafka manager&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console kafka-manager]# cp target/universal/kafka-manager-1.3.0.6.zip ~/
[root@console kafka-manager]# cd
[root@console ~]# unzip -oq kafka-manager-1.3.0.6.zip
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;配置kafka-manager&quot;&gt;&lt;a href=&quot;#配置kafka-manager&quot; class=&quot;headerlink&quot; title=&quot;配置kafka-manager&quot;&gt;&lt;/a&gt;配置kafka-manager&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console ~]# cd kafka-manager-1.3.0.6/
[root@console kafka-manager-1.3.0.6]# vim conf/application.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;设置zkhosts：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kafka-manager.zkhosts=&amp;quot;114.55.29.246:2181,114.55.29.86:2181,114.55.29.241:2181&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/20.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;启动kafka-manager&quot;&gt;&lt;a href=&quot;#启动kafka-manager&quot; class=&quot;headerlink&quot; title=&quot;启动kafka-manager&quot;&gt;&lt;/a&gt;启动kafka-manager&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console kafka-manager-1.3.0.6]# bin/kafka-manager
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/21.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;默认监听的端口是9000。你也可以在启动时指定配置文件和监听端口：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# bin/kafka-manager -Dconfig.file=/path/to/application.conf -Dhttp.port=8080
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动并置于后台运行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[kmanager@console kafka-manager-1.3.0.6]$ nohup bin/kafka-manager &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;kafka-manager添加kafka-cluster&quot;&gt;&lt;a href=&quot;#kafka-manager添加kafka-cluster&quot; class=&quot;headerlink&quot; title=&quot;kafka-manager添加kafka cluster&quot;&gt;&lt;/a&gt;kafka-manager添加kafka cluster&lt;/h2&gt;&lt;p&gt;浏览器输入地址访问：&lt;a href=&quot;http://114.55.29.246:9000/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://114.55.29.246:9000/&lt;/a&gt;&lt;br&gt;&lt;strong&gt;注意:安装完成后需要手动添加Cluster。添加Cluster是指添加一个已有的Kafka集群进入监控列表，而非通过Kafka Manager部署一个新的Kafka Cluster，这一点与Cloudera Manager不同。&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/22.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/23.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/24.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/25.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/26.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;消息中间件&quot;&gt;&lt;a href=&quot;#消息中间件&quot; class=&quot;headerlink&quot; title=&quot;消息中间件&quot;&gt;&lt;/a&gt;消息中间件&lt;/h2&gt;&lt;p&gt;消息中间件是在消息的传输过程中保存消息的容器。消息中间件在将消息从消息生产者到消费者时充当中间人的作用。队列的主要目的是提供路由并保证消息的传送；如果发送消息时接收者不可用，消息对列会保留消息，直到可以成功地传递它为止，当然，消息队列保存消息也是有期限的。&lt;br&gt;
    
    </summary>
    
      <category term="消息队列" scheme="http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="消息队列 Kafka 大数据" scheme="http://yoursite.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-Kafka-%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper介绍及安装部署</title>
    <link href="http://yoursite.com/2017/05/26/Zookeeper%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/05/26/Zookeeper介绍及安装部署/</id>
    <published>2017-05-26T01:20:04.000Z</published>
    <updated>2017-07-06T06:29:26.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Zookeeper介绍&quot;&gt;&lt;a href=&quot;#Zookeeper介绍&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper介绍&quot;&gt;&lt;/a&gt;Zookeeper介绍&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;是一个针对大型分布式系统的可靠协调系统；&lt;/li&gt;
&lt;li&gt;提供的功能包括：配置维护、名字服务、分布式同步、组服务等；&lt;/li&gt;
&lt;li&gt;目标就是封装好复杂易出错的关键职务，将简单易用的接口和性能高效、功能稳定的系统提供给用户；&lt;/li&gt;
&lt;li&gt;Zookeeper已经成为Hadoop生态系统中的基础组件。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Zookeeper特点&quot;&gt;&lt;a href=&quot;#Zookeeper特点&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper特点&quot;&gt;&lt;/a&gt;Zookeeper特点&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;最终一致性：为客户端展示同一视图，这是Zookeeper最重要的性能；&lt;/li&gt;
&lt;li&gt;可靠性：如果消息被一台服务器接受，那么它将被所有的服务器接受；&lt;/li&gt;
&lt;li&gt;原子性：更新只能成功或失败，没有中间状态；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Zookeeper应用场景&quot;&gt;&lt;a href=&quot;#Zookeeper应用场景&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper应用场景&quot;&gt;&lt;/a&gt;Zookeeper应用场景&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;一、统一命名服务&lt;/strong&gt;&lt;br&gt;1.分布式环境下，经常需要对应用/服务进行统一命名，便于识别不同的服务&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;类似于域名与ip之间对应关系，域名容易记住；&lt;/li&gt;
&lt;li&gt;通过名称来获取资源或服务的地址，提供者信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.按照层次结构组织服务/应用名称&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可将服务名称以及地址信息写在Zookeeper上，客户端通过Zookeeper获取可用服务列表。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;二、配置管理&lt;/strong&gt;&lt;br&gt;1.分布式环境下，配置文件管理和同步是一个常见问题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个集群中，所有节点的配置信息是一致的，比如Hadoop；&lt;/li&gt;
&lt;li&gt;对配置文件修改后，希望能够快速同步到各个节点上。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.配置管理可交由Zookeeper实现&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可将配置信息写入Zookeeper的一个znode上；&lt;/li&gt;
&lt;li&gt;各个节点监听这个znode&lt;/li&gt;
&lt;li&gt;一旦znode中的数据被修改，Zookeeper将会通知各个节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;三、集群管理&lt;/strong&gt;&lt;br&gt;1.分布式环境下，实时掌握每个节点的状态是必要的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可根据节点实时状态做出一些调整。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.可交由Zookeeper实现&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可将节点信息写入Zookeeper的一个znode上；&lt;/li&gt;
&lt;li&gt;监听这个znode可获得它的实时状态变化。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3.典型应用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HBase中Master状态的监控与选举。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;四、分布式通知/协调&lt;/strong&gt;&lt;br&gt;原理其实就是发布/订阅。&lt;br&gt;1.分布式环境下经常存在一个服务需要知道它所管理的子服务的状态&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NameNode需要知道各DataNode的状态&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.心跳检测机制可通过Zookeeper实现&lt;/p&gt;
&lt;p&gt;3.信息推送可由Zookeeper实现(发布/订阅模式)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;五、分布式锁&lt;/strong&gt;&lt;br&gt;1.Zookeeper是强一致性的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多个客户端同时在Zookeeper上创建相同znode，只有一个创建成功。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.实现锁的独占性&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多个客户端同时在Zookeeper上创建相同znode，创建成功的那个客户端得到锁，其他客户端等待。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3.控制锁的时序&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;各个客户端在某个znode下创建临时znode(类型为CreateMode.EPHEMERAL_SEQUENTIAL)，这样，该znode可掌握全局访问时序。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;用到了Zookeeper的一些系统&quot;&gt;&lt;a href=&quot;#用到了Zookeeper的一些系统&quot; class=&quot;headerlink&quot; title=&quot;用到了Zookeeper的一些系统&quot;&gt;&lt;/a&gt;用到了Zookeeper的一些系统&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;HDFS&lt;/li&gt;
&lt;li&gt;YARN&lt;/li&gt;
&lt;li&gt;Storm&lt;/li&gt;
&lt;li&gt;HBase&lt;/li&gt;
&lt;li&gt;Flume&lt;/li&gt;
&lt;li&gt;Dubbo&lt;/li&gt;
&lt;li&gt;metaq&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Zookeeper集群安装部署&quot;&gt;&lt;a href=&quot;#Zookeeper集群安装部署&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper集群安装部署&quot;&gt;&lt;/a&gt;Zookeeper集群安装部署&lt;/h2&gt;&lt;p&gt;下面开始介绍Zookeeper的安装部署。安装部署分三种模式：单机模式、伪分布式模式和分布式模式。&lt;br&gt;单机模式和为分布式比较简单，多用于本地测试调试，下面介绍分布式模式安装部署。&lt;br&gt;&lt;strong&gt;注意：3台机器都需要安装zk。对于Zookeeper集群的话，官方推荐的最小节点数为3个。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;console&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.246&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;安装jdk1-7&quot;&gt;&lt;a href=&quot;#安装jdk1-7&quot; class=&quot;headerlink&quot; title=&quot;安装jdk1.7&quot;&gt;&lt;/a&gt;安装jdk1.7&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;3台机器都需要安装jdk1.7&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# mkdir /usr/java
[root@log1 local]# tar zxf jdk-7u80-linux-x64.gz -C /usr/java/
[root@log1 local]# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.7.0_80
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
[root@log1 local]# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装配置zk&quot;&gt;&lt;a href=&quot;#安装配置zk&quot; class=&quot;headerlink&quot; title=&quot;安装配置zk&quot;&gt;&lt;/a&gt;安装配置zk&lt;/h3&gt;&lt;p&gt;1.配置zk节点的hosts文件：配置3台机器的ip地址和主机名的对应关系。以下以console主机为例，其hosts文件添加下面3行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;114.55.29.246 console
114.55.29.86 log1
114.55.29.241 log2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.解压安装配置第一台zk&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console local]# tar zxf zookeeper-3.4.6.tar.gz
[root@console local]# cd zookeeper-3.4.6
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建快照日志存放目录：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console zookeeper-3.4.6]# mkdir -p dataDir 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建事务日志存放目录：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console zookeeper-3.4.6]# mkdir dataLogDir
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【注意】:如果不配置dataLogDir，那么事务日志也会写在dataDir目录中。这样会严重影响zk的性能。因为在zk吞吐量很高的时候，产生的事务日志和快照日志太多。&lt;br&gt;修改配置文件，添加如下内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console zookeeper-3.4.6]# cd conf 
[root@console conf]# mv zoo_sample.cfg zoo.cfg 
[root@console conf]# vim zoo.cfg
# 存放数据文件
dataDir=/usr/local/zookeeper-3.4.6/dataDir
# 存放日志文件
dataLogDir=/usr/local/zookeeper-3.4.6/dataLogDir
# zookeeper cluster，2888为选举端口，3888为心跳端口
server.1=console:2888:3888
server.2=log1:2888:3888
server.3=log2:2888:3888
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在我们配置的dataDir指定的目录下面，创建一个myid文件，里面内容为一个数字，用来标识当前主机，conf/zoo.cfg文件中配置的server.X中X为什么数字，则myid文件中就输入这个数字：&lt;br&gt;console主机：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# echo &amp;quot;1&amp;quot; &amp;gt; /usr/local/zookeeper-3.4.6/dataDir/myid
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.远程复制第一台的zk到另外两台上，并修改myid文件为2和3&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console local]# scp -rp zookeeper-3.4.6 root@114.55.29.86:/usr/local/
[root@console local]# scp -rp zookeeper-3.4.6 root@114.55.29.241:/usr/local/
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;启动和关闭zk&quot;&gt;&lt;a href=&quot;#启动和关闭zk&quot; class=&quot;headerlink&quot; title=&quot;启动和关闭zk&quot;&gt;&lt;/a&gt;启动和关闭zk&lt;/h3&gt;&lt;p&gt;在ZooKeeper集群的每个结点上，执行启动ZooKeeper服务的脚本，如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console bin]# ./zkServer.sh start 
[root@log1 bin]# ./zkServer.sh start
[root@log2 bin]# ./zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;日志可查询：/usr/local/zookeeper-3.4.6/bin/zookeeper.out&lt;br&gt;可以通过命令jps查看Zookeeper进程：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Zookeeper/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;停止zk命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# /usr/local/zookeeper-3.4.6/bin/zkServer.sh stop
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;测试zk集群&quot;&gt;&lt;a href=&quot;#测试zk集群&quot; class=&quot;headerlink&quot; title=&quot;测试zk集群&quot;&gt;&lt;/a&gt;测试zk集群&lt;/h3&gt;&lt;p&gt;可以通过ZooKeeper的脚本来查看启动状态，包括集群中各个结点的角色（或是Leader，或是Follower）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console bin]# ./zkServer.sh status
JMX enabled by default
Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg
Mode: follower
[root@log1 bin]# ./zkServer.sh status
JMX enabled by default
Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg
Mode: leader
[root@log2 bin]# ./zkServer.sh status
JMX enabled by default
Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg
Mode: follower
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过上面状态查询结果可见，log1是集群的Leader，其余的两个结点是Follower。&lt;br&gt;另外，可以通过客户端脚本，连接到ZooKeeper集群上。对于客户端来说，ZooKeeper是一个整体，连接到ZooKeeper集群实际上感觉在独享整个集群的服务，所以，你可以在任何一个结点上建立到服务集群的连接。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 bin]# ./zkCli.sh -server log1:2181
Connecting to log1:2181
2016-03-08 14:21:31,502 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-03-08 14:21:31,505 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=log2
2016-03-08 14:21:31,505 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.7.0_80
2016-03-08 14:21:31,507 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation
2016-03-08 14:21:31,507 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/usr/java/jdk1.7.0_80/jre
2016-03-08 14:21:31,507 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/usr/local/zookeeper-3.4.6/bin/../build/classes:/usr/local/zookeeper-3.4.6/bin/../build/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/usr/local/zookeeper-3.4.6/bin/../lib/log4j-1.2.16.jar:/usr/local/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/usr/local/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/usr/local/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../conf:.:/usr/java/jdk1.7.0_80/lib/dt.jar:/usr/java/jdk1.7.0_80/lib/tools.jar
2016-03-08 14:21:31,507 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/tmp
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&amp;lt;NA&amp;gt;
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Linux
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=amd64
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=3.10.0-123.9.3.el7.x86_64
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=root
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/root
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/usr/local/zookeeper-3.4.6/bin
2016-03-08 14:21:31,510 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=log1:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@ee01430
Welcome to ZooKeeper!
2016-03-08 14:21:31,534 [myid:] - INFO  [main-SendThread(log1:2181):ClientCnxn$SendThread@975] - Opening socket connection to server log1/114.55.29.86:2181. Will not attempt to authenticate using SASL (unknown error)
2016-03-08 14:21:31,539 [myid:] - INFO  [main-SendThread(log1:2181):ClientCnxn$SendThread@852] - Socket connection established to log1/114.55.29.86:2181, initiating session
JLine support is enabled
[zk: log1:2181(CONNECTING) 0] 2016-03-08 14:21:31,572 [myid:] - INFO  [main-SendThread(log1:2181):ClientCnxn$SendThread@1235] - Session establishment complete on server log1/114.55.29.86:2181, sessionid = 0x25354db0d430000, negotiated timeout = 30000

WATCHER::

WatchedEvent state:SyncConnected type:None path:null

[zk: log1:2181(CONNECTED) 0]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;脚本定期清理zk快照和日志文件&quot;&gt;&lt;a href=&quot;#脚本定期清理zk快照和日志文件&quot; class=&quot;headerlink&quot; title=&quot;脚本定期清理zk快照和日志文件&quot;&gt;&lt;/a&gt;脚本定期清理zk快照和日志文件&lt;/h3&gt;&lt;p&gt;正常运行过程中，ZK会不断地把快照数据和事务日志输出到dataDir和dataLogDir这两个目录，并且如果没有人为操作的话，ZK自己是不会清理这些文件的。&lt;br&gt;我这里采用脚本切割。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# cd /usr/local/zookeeper-3.4.6/
[root@log1 zookeeper-3.4.6]# vim clean_zklog.sh
#!/bin/bash
###Description:This script is used to clear zookeeper snapshot file and transaction logs.
###Written by: jkzhao - jkzhao@wisedu.com  
###History: 2016-04-08 First release.

# Snapshot file dir.
dataDir=/usr/local/zookeeper-3.4.6/dataDir/version-2

# Transaction logs dir.
dataLogDir=/usr/local/zookeeper-3.4.6/dataLogDir/version-2

# Reserved 5 files.
COUNT=5

ls -t $dataDir/snapshot.* | tail -n +$[$COUNT+1] | xargs rm -f
ls -t $dataLogDir/log.* | tail -n +$[$COUNT+1] | xargs rm -f

[root@log1 zookeeper-3.4.6]# chmod +x clean_zklog.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;每个Zookeeper集群节点配置周期性任务，每个星期日的0点0分执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console zookeeper-3.4.6]# crontab -e
0 0 * * 0 /usr/local/zookeeper-3.4.6/clean_zklog.sh
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Zookeeper介绍&quot;&gt;&lt;a href=&quot;#Zookeeper介绍&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper介绍&quot;&gt;&lt;/a&gt;Zookeeper介绍&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;是一个针对大型分布式系统的可靠协调系统；&lt;/li&gt;
&lt;li&gt;提供的功能包括：配置维护、名字服务、分布式同步、组服务等；&lt;/li&gt;
&lt;li&gt;目标就是封装好复杂易出错的关键职务，将简单易用的接口和性能高效、功能稳定的系统提供给用户；&lt;/li&gt;
&lt;li&gt;Zookeeper已经成为Hadoop生态系统中的基础组件。
    
    </summary>
    
      <category term="分布式" scheme="http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="大数据 Zookeeper" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE-Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>zabbix的通知功能以及自定义脚本告警</title>
    <link href="http://yoursite.com/2017/05/24/zabbix%E7%9A%84%E9%80%9A%E7%9F%A5%E5%8A%9F%E8%83%BD%E4%BB%A5%E5%8F%8A%E8%87%AA%E5%AE%9A%E4%B9%89%E8%84%9A%E6%9C%AC%E5%91%8A%E8%AD%A6/"/>
    <id>http://yoursite.com/2017/05/24/zabbix的通知功能以及自定义脚本告警/</id>
    <published>2017-05-24T01:35:41.000Z</published>
    <updated>2017-06-12T07:56:05.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;zabbix的通知功能&quot;&gt;&lt;a href=&quot;#zabbix的通知功能&quot; class=&quot;headerlink&quot; title=&quot;zabbix的通知功能&quot;&gt;&lt;/a&gt;zabbix的通知功能&lt;/h2&gt;&lt;p&gt;在配置好监控项和触发器之后，一旦正常工作中的某触发器状态发生改变，一般意味着有异常情况发生，此时通常需要采取一定的动作(action)，如告警或者执行远程命令。&lt;br&gt;实现zabbix的通知功能，一般需要两个步骤：定义所需的“媒介”和配置一个”动作”。&lt;br&gt;媒介类型有：E-mail，SMS，Jabber和自定义的通知脚本。我这里就使用E-mail了。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;定义媒介&quot;&gt;&lt;a href=&quot;#定义媒介&quot; class=&quot;headerlink&quot; title=&quot;定义媒介&quot;&gt;&lt;/a&gt;定义媒介&lt;/h2&gt;&lt;p&gt;登录zabbix web管理控制台，点击Administration—&amp;gt; Media types，可以看到有3个定义好了的媒介，不用这3个，点击右上角的”Create media type”。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/90.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;填写信息：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/91.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;定义接收告警的用户&quot;&gt;&lt;a href=&quot;#定义接收告警的用户&quot; class=&quot;headerlink&quot; title=&quot;定义接收告警的用户&quot;&gt;&lt;/a&gt;定义接收告警的用户&lt;/h2&gt;&lt;h3 id=&quot;创建用户组&quot;&gt;&lt;a href=&quot;#创建用户组&quot; class=&quot;headerlink&quot; title=&quot;创建用户组&quot;&gt;&lt;/a&gt;创建用户组&lt;/h3&gt;&lt;p&gt;点击Administration—&amp;gt; User groups，点击右上角的Create user group。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/92.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入组名，点击Add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/93.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;创建用户&quot;&gt;&lt;a href=&quot;#创建用户&quot; class=&quot;headerlink&quot; title=&quot;创建用户&quot;&gt;&lt;/a&gt;创建用户&lt;/h3&gt;&lt;p&gt;点击Administration—&amp;gt; Users，点击右上角的Create user。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/94.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在User列填入个人信息：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/95.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击Media，点击Add，选择媒介和接收邮件的时间等信息：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/96.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/97.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击Permissions，根据这个新添的用户给予合适的权限&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/98.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;定义Action&quot;&gt;&lt;a href=&quot;#定义Action&quot; class=&quot;headerlink&quot; title=&quot;定义Action&quot;&gt;&lt;/a&gt;定义Action&lt;/h2&gt;&lt;p&gt;点击Configuration—&amp;gt; Actions，点击右上角的Create action：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/99.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Action配置：&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/100.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conditions配置：&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/101.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/102.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/103.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Operations配置：&lt;/strong&gt;&lt;br&gt;在一个action中，可以定义多个Operation。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/104.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/105.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;上面的Operation type有两种：Send message和Remote command。&lt;/p&gt;
&lt;h2 id=&quot;Zabbix自定义脚本发送报警邮件&quot;&gt;&lt;a href=&quot;#Zabbix自定义脚本发送报警邮件&quot; class=&quot;headerlink&quot; title=&quot;Zabbix自定义脚本发送报警邮件&quot;&gt;&lt;/a&gt;Zabbix自定义脚本发送报警邮件&lt;/h2&gt;&lt;p&gt;Zabbix发送报警邮件还可以采用自定义的脚本来发送。&lt;/p&gt;
&lt;h3 id=&quot;Python脚本发邮件&quot;&gt;&lt;a href=&quot;#Python脚本发邮件&quot; class=&quot;headerlink&quot; title=&quot;Python脚本发邮件&quot;&gt;&lt;/a&gt;Python脚本发邮件&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.定义Media types&lt;/strong&gt;&lt;br&gt;如下图，添加以下3个参数，分别对应sendEmail.sh脚本需要的3个参数：收件人地址、主题、详细内容&lt;br&gt;{ALERT.SENDTO}&lt;br&gt;{ALERT.SUBJECT}&lt;br&gt;{ALERT.MESSAGE}&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/106.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;【注意】: 很多人安装zabbix 3.0之后，写的脚本一直发信不成功,手动执行时可以的。那是因为zabbix3.0之后，可以自定义参数了。所以不写参数，它是不会传参数的。在2.x版本不存在这个问题，默认会传3个参数。脚本中可以使用$1, $2, $3来调用 action 中的 邮件的收件人, Default Subject, Default Message&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.定义Users的Media&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/107.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.python报警脚本&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr/local/zabbix-3.0.1/share/zabbix/alertscripts/
# vim zabbix_sendmail.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;脚本内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/python
# coding:utf-8 

import smtplib
from email.mime.text import MIMEText
import sys

# 邮箱服务器地址
mail_host = &amp;apos;smtp.exmail.qq.com&amp;apos;
# 邮箱用户名
mail_user = &amp;apos;01115009@wisedu.com&amp;apos;
# 邮箱密码
mail_pass = &amp;apos;123123123&amp;apos;
mail_postfix = &amp;apos;wisedu.com&amp;apos;

 def send_mail(to_list,subject,content):
     me = mail_user+&amp;quot;&amp;lt;&amp;quot;+mail_user+&amp;quot;@&amp;quot;+mail_postfix+&amp;quot;&amp;gt;&amp;quot;
     msg = MIMEText(content)
     msg[&amp;apos;Subject&amp;apos;] = subject
     msg[&amp;apos;From&amp;apos;] = me
     msg[&amp;apos;to&amp;apos;] = to_list

try:
    s = smtplib.SMTP()
    s.connect(mail_host)
    s.login(mail_user,mail_pass)
    s.sendmail(me,to_list,msg.as_string())
    s.close()
    return True
except Exception,e:
    print str(e)
    return False

if __name__ == &amp;quot;__main__&amp;quot;:
    send_mail(sys.argv[1], sys.argv[2], sys.argv[3])
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; 修改脚本权限：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# chmod +x zabbix_sendmail.py
# chown -R zabbix.zabbix zabbix_sendmail.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;4.修改zabbix_server配置&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /usr/local/zabbix-3.0.1/etc/zabbix_server.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加如下配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;### Option: AlertScriptsPath
AlertScriptsPath=/usr/local/zabbix-3.0.1/share/zabbix/alertscripts
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重启zabbix_server。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.配置Actions&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/108.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;【注意】:每触发一次Action，都会在Reports—&amp;gt;Action log看到记录：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/109.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;shell脚本发邮件&quot;&gt;&lt;a href=&quot;#shell脚本发邮件&quot; class=&quot;headerlink&quot; title=&quot;shell脚本发邮件&quot;&gt;&lt;/a&gt;shell脚本发邮件&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.先安装sendEmail&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@care local]# tar zxf sendEmail-v1.56.tar.gz
[root@care local]# cp sendEmail-v1.56/sendEmail /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将写好的脚本上传到/usr/local/zabbix-3.0.1/share/zabbix/alertscripts。这里为了业务需求，需要定制化发送邮件的内容，脚本内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
###Description:This script is used to alarm.
###Written by: jkzhao - jkzhao@wisedu.com  
###History: 2016-08-10 Second release.
###Modification: Please modify the variables host, user and passwd.

# 获取默认的邮件接收者，邮件主题，邮件正文
to=$1
subject=$2
bodyOrgin=$3

# 获取eventid
#eventid=grep &amp;quot;event ID&amp;quot; $bodyOrgin |awk &amp;apos;{print $4}&amp;apos;
eventid=$(echo $bodyOrgin | grep &amp;quot;event ID&amp;quot; |awk &amp;apos;{print $NF}&amp;apos;)
echo &amp;quot;eventid:$eventid&amp;quot; &amp;gt; /tmp/test.txt

# shell调用存储过程，获取主键viewid，传入参数：eventid，输出：viewid
host=172.16.9.112
user=root
passwd=zabbix
database=zabbix

viewid=$(mysql -u${user} -p${passwd} -h${host} -D${database} -e &amp;quot;call generateAlertView($eventid,@result)&amp;quot; 2&amp;gt;/dev/null | awk &amp;apos;NR&amp;gt;1&amp;apos;)
echo &amp;quot;viewid:$viewid&amp;quot; &amp;gt;&amp;gt; /tmp/test.txt
group=$(mysql -u${user} -p${passwd} -h${host} -D${database} -e &amp;quot;select alerts_view_group.group from alerts_view_group where viewid = $viewid&amp;quot; 2&amp;gt;/dev/null | awk &amp;apos;NR&amp;gt;1&amp;apos;)
echo &amp;quot;group:$group&amp;quot; &amp;gt;&amp;gt; /tmp/test.txt
body=$bodyOrgin&amp;quot;; 影响业务: &amp;quot;$group


# 因为需要格式化发送邮件的内容，将拼接好的body信息写入文件中再做处理
echo $body | awk -F&amp;apos;;&amp;apos; &amp;apos;{for(i=1;i&amp;lt;=NF;i++){print $i}}&amp;apos; &amp;gt; /tmp/messages.txt
# 将文件中出现的^M删除掉
sed -i &amp;apos;s/\x0D//g&amp;apos; /tmp/messages.txt
# 删除以空格开头的行前面的空格
sed -i &amp;apos;s/^\s*//g&amp;apos; /tmp/messages.txt

# 由于zabbix无论是故障还是恢复都是要发邮件的，但是对于故障和恢复的邮件内容需要定制为不同的内容，因此需要先获取到是故障还是恢复
state=$(echo $subject | awk -F: &amp;apos;{print $2}&amp;apos;)

# 按照安心守护要求修改邮件正文内容
if [ $state == &amp;quot;PROBLEM&amp;quot; ]; then
    sed -i &amp;apos;s/Trigger:/异常对象:/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Trigger severity:/{h;d};/Item values:/{G}&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;s/Trigger severity:/异常等级:/&amp;apos; /tmp/messages.txt 
    sed -i &amp;apos;s/Item values:/异常原因:/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Original event/d&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Trigger status:/d&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;$a发生时间: &amp;apos; /tmp/messages.txt
    sed -i &amp;quot;s/发生时间: /发生时间: $(date &amp;quot;+%Y-%m-%d %H:%M:%S&amp;quot;)/&amp;quot; /tmp/messages.txt
    # 把发生故障时的alertView插入alerts_view表
    alertValue=$(grep &amp;quot;异常原因&amp;quot; /tmp/messages.txt | awk -F: &amp;apos;BEGIN{ORS=&amp;quot;&amp;quot;};{for(i=3;i&amp;lt;=NF;++i) {print $i}}&amp;apos;)
    echo &amp;quot;alertValue:$alertValue&amp;quot; &amp;gt;&amp;gt; /tmp/test.txt
    mysql -u${user} -p${passwd} -h${host} -D${database} -e &amp;quot;UPDATE alerts_view set alertValue=&amp;apos;${alertValue}&amp;apos; WHERE viewid = &amp;apos;${viewid}&amp;apos;&amp;quot; 2&amp;gt;/dev/null
    sed -i &amp;apos;s/Warning/风险/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;s/Disaster/宕机/&amp;apos; /tmp/messages.txt
else
    sed -i &amp;apos;s/Trigger:/恢复对象:/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;s/Item values:/恢复内容:/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;s/影响业务/恢复业务/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Original event/d&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Trigger status:/d&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Trigger severity:/d&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;$a发生时间: &amp;apos; /tmp/messages.txt
    sed -i &amp;quot;s/发生时间: /发生时间: $(date &amp;quot;+%Y-%m-%d %H:%M:%S&amp;quot;)/&amp;quot; /tmp/messages.txt
fi


/usr/local/bin/sendEmail -f monitor@wisedu.com -t &amp;quot;$to&amp;quot; -s smtp.exmail.qq.com -u &amp;quot;$subject&amp;quot; -o message-content-type=text -o message-charset=utf-8 -o message-file=/tmp/messages.txt -xu monitor@wisedu.com -xp 123456 2&amp;gt;&amp;gt;/tmp/22.log
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.添加Media types&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/110.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.给指定的用户添加Media&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/111.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.配置Actions，为了业务需求定制Default message&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/112.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.邮件展示&lt;/strong&gt;&lt;br&gt;故障邮件展示：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/113.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;故障恢复邮件展示：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/114.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;zabbix的通知功能&quot;&gt;&lt;a href=&quot;#zabbix的通知功能&quot; class=&quot;headerlink&quot; title=&quot;zabbix的通知功能&quot;&gt;&lt;/a&gt;zabbix的通知功能&lt;/h2&gt;&lt;p&gt;在配置好监控项和触发器之后，一旦正常工作中的某触发器状态发生改变，一般意味着有异常情况发生，此时通常需要采取一定的动作(action)，如告警或者执行远程命令。&lt;br&gt;实现zabbix的通知功能，一般需要两个步骤：定义所需的“媒介”和配置一个”动作”。&lt;br&gt;媒介类型有：E-mail，SMS，Jabber和自定义的通知脚本。我这里就使用E-mail了。&lt;br&gt;
    
    </summary>
    
      <category term="Zabbix" scheme="http://yoursite.com/categories/Zabbix/"/>
    
    
      <category term="监控 zabbix" scheme="http://yoursite.com/tags/%E7%9B%91%E6%8E%A7-zabbix/"/>
    
  </entry>
  
  <entry>
    <title>zabbix监控websphere和weblogic</title>
    <link href="http://yoursite.com/2017/05/23/zabbix%E7%9B%91%E6%8E%A7websphere%E5%92%8Cweblogic/"/>
    <id>http://yoursite.com/2017/05/23/zabbix监控websphere和weblogic/</id>
    <published>2017-05-23T13:25:25.000Z</published>
    <updated>2017-06-12T07:56:20.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;zabbix-java-gateway&quot;&gt;&lt;a href=&quot;#zabbix-java-gateway&quot; class=&quot;headerlink&quot; title=&quot;zabbix java gateway&quot;&gt;&lt;/a&gt;zabbix java gateway&lt;/h1&gt;&lt;p&gt;zabbix通过JMX监控应用服务器。JMX（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等植入管理功能的框架。JMX可以跨越一系列异构操作系统平台、系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Zabbix已经集成JMX，可以用Zabbix通过JMX监控JVM，TOMCAT，Weblogic，Jboss等。要使用Zabbix监控Weblogic，我们先要了解Zabbix的JMX监控架构，Weblogic的JMX信息，最后才能去实现怎么去配置监控和报警。&lt;br&gt;Zabbix是使用了一个叫做Java Gateway的应用去监控JMX的。Java Gateway集成在zabbix官方开发发布的。所以需要在编译安装zabbix server时，需要添加一个选项–enable-java。这样安装zabbix后在/usr/local/zabbix-3.0.1/sbin目录下会有个zabbix_java目录，这个目录里面就是zabbix Java gateway的文件。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/80.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;配置和运行java-gateway&quot;&gt;&lt;a href=&quot;#配置和运行java-gateway&quot; class=&quot;headerlink&quot; title=&quot;配置和运行java gateway&quot;&gt;&lt;/a&gt;配置和运行java gateway&lt;/h1&gt;&lt;p&gt;默认情况下，Java gateway监听10052端口. 如果你计划使用不同的端口来运行Java gateway，你需要通过setting.sh脚本指定下需要的端口。&lt;br&gt;启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./startup.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;关闭：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./shutdown.sh
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;配置zabbix-server使用java-gateway&quot;&gt;&lt;a href=&quot;#配置zabbix-server使用java-gateway&quot; class=&quot;headerlink&quot; title=&quot;配置zabbix server使用java gateway&quot;&gt;&lt;/a&gt;配置zabbix server使用java gateway&lt;/h1&gt;&lt;p&gt;当前Java gateway已经运行，接下来你需要告诉Zabbix server如何找到Zabbix Java gateway. 因此你需要在 server配置文件 中指定JavaGateway及JavaGateway端口. 如果JMX应用采用Zabbix代理进行监控的话，你需要在 代理配置文件 中指定对应的连接参数。&lt;br&gt;默认情况下，server并不会派生出任何进程去进行JMX监控。如果你想使用完成JMX监控，你需要指定预派生出来的Java pollers进程数，你也可过同类的方式指定常见的pollers和trappers。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim zabbix_server.conf
JavaGateway=172.16.7.151
JavaGatewayPort=10052
StartJavaPollers=5
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/81.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在完成配置后，要重启server(或代理)：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# killall -9 zabbix_server
# ./zabbix_server
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;调整java-gateway的日志级别&quot;&gt;&lt;a href=&quot;#调整java-gateway的日志级别&quot; class=&quot;headerlink&quot; title=&quot;调整java gateway的日志级别&quot;&gt;&lt;/a&gt;调整java gateway的日志级别&lt;/h1&gt;&lt;p&gt;万一Java gateway出现了若干问题，在前段可以看到的监控项报错信息并不充分，你也可以通过查看Java gateway日志文件获得更多信息。&lt;br&gt;默认情况下，Java gateway将记录日志到/tmp/zabbix_java.log文件中，log级别为”info”。有时你觉得”info”级别得到的信息并不够，你需要修改级别为”debug”。你可以通过修改lib/logback.xml将&lt;root&gt;标签更改为”debug”以获取日志级别的增加。&lt;/root&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;root level=&amp;quot;debug&amp;quot;&amp;gt;
   &amp;lt;appender-ref ref=&amp;quot;FILE&amp;quot; /&amp;gt;
&amp;lt;/root&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;需要注意的是，并不像Zabbix server或proxy那样，修改完logback.xml并不需要重启Zabbix Java gateway. 修改后的配置将会自动被加载。当你完成了debugging,你可以将log级别替换为”info”。&lt;/p&gt;
&lt;h1 id=&quot;监控weblogic&quot;&gt;&lt;a href=&quot;#监控weblogic&quot; class=&quot;headerlink&quot; title=&quot;监控weblogic&quot;&gt;&lt;/a&gt;监控weblogic&lt;/h1&gt;&lt;h2 id=&quot;weblogic配置&quot;&gt;&lt;a href=&quot;#weblogic配置&quot; class=&quot;headerlink&quot; title=&quot;weblogic配置&quot;&gt;&lt;/a&gt;weblogic配置&lt;/h2&gt;&lt;p&gt;1.如果是监控weblogic 的admin server：&lt;br&gt;编辑WL_DOMAIN_HOME/bin/setDomainEnv.sh，在文件结尾加入下面几行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd /opt/Oracle/Middleware/user_projects/domains/ids_domain/bin
$ vim setDomainEnv.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加一句：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;JAVA_OPTIONS=&amp;quot;$JAVA_OPTIONS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9997 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后在去启动weblogic。&lt;/p&gt;
&lt;p&gt;2.如果是监控受管服务器：&lt;br&gt;进入weblogic控制台-&amp;gt;环境-&amp;gt;服务器-&amp;gt;”你新增的服务器”-&amp;gt;配置-&amp;gt;服务器启动。在“参数”的输入框内输入：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-Dcom.sun.management.jmxremote.port=JMX_PORT -Djava.rmi.server.hostname=JMX_HOST -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false -Djavax.management.builder.initial=weblogic.management.jmx.mbeanserver.WLSMBeanServerBuilder
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后控制台启动受管服务器。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/82.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;zabbix-server添加监控weblogic主机&quot;&gt;&lt;a href=&quot;#zabbix-server添加监控weblogic主机&quot; class=&quot;headerlink&quot; title=&quot;zabbix server添加监控weblogic主机&quot;&gt;&lt;/a&gt;zabbix server添加监控weblogic主机&lt;/h2&gt;&lt;p&gt;点击配置—&amp;gt;主机—&amp;gt;创建主机。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/83.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入主机信息，主要注意JMX的端口，点击添加。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/84.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;选择JMX模板。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/85.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;监控websphere&quot;&gt;&lt;a href=&quot;#监控websphere&quot; class=&quot;headerlink&quot; title=&quot;监控websphere&quot;&gt;&lt;/a&gt;监控websphere&lt;/h1&gt;&lt;h2 id=&quot;websphere配置&quot;&gt;&lt;a href=&quot;#websphere配置&quot; class=&quot;headerlink&quot; title=&quot;websphere配置&quot;&gt;&lt;/a&gt;websphere配置&lt;/h2&gt;&lt;p&gt;访问websphere控制台，点击 Server Types → WebSphere application servers → WAS_SERVER_NAME → Java and Process Management → Process definition → Java Virtual Machine.&lt;/p&gt;
&lt;p&gt;在“Generic JVM arguments”增加下面环境变量：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-Djavax.management.builder.initial=
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/86.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击 Server Types → WebSphere application servers → WAS_SERVER_NAME → Java and Process Management → Process definition → Java Virtual Machine → Custom properties.&lt;br&gt;增加下面几个环境变量：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Name: java.rmi.server.hostname
Value: JMX_HOST
Name: com.sun.management.jmxremote
Value: true
Name: com.sun.management.jmxremote.port
Value: JMX_PORT
Name: com.sun.management.jmxremote.ssl
Value: false
Name: com.sun.management.jmxremote.authenticate
Value: false
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/87.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;重启server。&lt;/p&gt;
&lt;h2 id=&quot;zabbix-server添加监控websphere主机&quot;&gt;&lt;a href=&quot;#zabbix-server添加监控websphere主机&quot; class=&quot;headerlink&quot; title=&quot;zabbix server添加监控websphere主机&quot;&gt;&lt;/a&gt;zabbix server添加监控websphere主机&lt;/h2&gt;&lt;p&gt;点击配置—&amp;gt;主机—&amp;gt;创建主机。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/88.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入主机信息，主要注意JMX的端口，点击添加。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/89.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;zabbix-java-gateway&quot;&gt;&lt;a href=&quot;#zabbix-java-gateway&quot; class=&quot;headerlink&quot; title=&quot;zabbix java gateway&quot;&gt;&lt;/a&gt;zabbix java gateway&lt;/h1&gt;&lt;p&gt;zabbix通过JMX监控应用服务器。JMX（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等植入管理功能的框架。JMX可以跨越一系列异构操作系统平台、系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。&lt;br&gt;
    
    </summary>
    
      <category term="Zabbix" scheme="http://yoursite.com/categories/Zabbix/"/>
    
    
      <category term="监控 zabbix" scheme="http://yoursite.com/tags/%E7%9B%91%E6%8E%A7-zabbix/"/>
    
  </entry>
  
  <entry>
    <title>zabbix监控Nginx</title>
    <link href="http://yoursite.com/2017/05/16/zabbix%E7%9B%91%E6%8E%A7Nginx/"/>
    <id>http://yoursite.com/2017/05/16/zabbix监控Nginx/</id>
    <published>2017-05-16T03:04:58.000Z</published>
    <updated>2017-06-12T07:56:15.000Z</updated>
    
    <content type="html">&lt;p&gt;&lt;a href=&quot;https://nginx.org/en/docs/http/ngx_http_stub_status_module.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://nginx.org/en/docs/http/ngx_http_stub_status_module.html&lt;/a&gt;&lt;br&gt;在编译Nginx的时候，需要加上参数–with-http_stub_status_module，然后在配置文件中配置开启状态页面查询。&lt;br&gt;Nginx1.9.11版本之后才支持动态加载模块，因此对于之前的版本，你都需要重新编译。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;启用nginx-status配置&quot;&gt;&lt;a href=&quot;#启用nginx-status配置&quot; class=&quot;headerlink&quot; title=&quot;启用nginx status配置&quot;&gt;&lt;/a&gt;启用nginx status配置&lt;/h1&gt;&lt;p&gt;在http段加入如下配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
        listen  80;
        server_name localhost;
        location /status {
            stub_status;
            access_log off;
            allow 114.55.29.246;
            deny all;
        }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重载Nginx。&lt;/p&gt;
&lt;h1 id=&quot;zabbix-agent端配置&quot;&gt;&lt;a href=&quot;#zabbix-agent端配置&quot; class=&quot;headerlink&quot; title=&quot;zabbix agent端配置&quot;&gt;&lt;/a&gt;zabbix agent端配置&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;# cd /usr/local/zabbix-3.0.1/etc/zabbix_agentd.conf.d/
# vim nginx_userparams.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;把下面的内容贴进去：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;UserParameter=Nginx.active[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | awk &amp;apos;/^Active/ {print $NF}&amp;apos;
UserParameter=Nginx.reading[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | grep &amp;apos;Reading&amp;apos; | cut -d&amp;quot; &amp;quot; -f2
UserParameter=Nginx.writing[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | grep &amp;apos;Writing&amp;apos; | cut -d&amp;quot; &amp;quot; -f4
UserParameter=Nginx.waiting[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | grep &amp;apos;Waiting&amp;apos; | cut -d&amp;quot; &amp;quot; -f6
UserParameter=Nginx.accepted[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | awk &amp;apos;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $$1}&amp;apos;
UserParameter=Nginx.handled[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | awk &amp;apos;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $$2}&amp;apos;
UserParameter=Nginx.requests[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | awk &amp;apos;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $$3}&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重启zabbix agent：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# killall -9 zabbix_agentd
# /usr/local/zabbix-3.0.1/sbin/zabbix_agentd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;测试，在zabbix server上使用zabbix_get获取数据：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr/local/zabbix-3.0.1/bin/
# ./zabbix_get -s 114.55.29.241 -k &amp;quot;Nginx.active[114.55.29.241,80]&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;zabbix-web-gui配置监控项&quot;&gt;&lt;a href=&quot;#zabbix-web-gui配置监控项&quot; class=&quot;headerlink&quot; title=&quot;zabbix web gui配置监控项&quot;&gt;&lt;/a&gt;zabbix web gui配置监控项&lt;/h1&gt;&lt;h2 id=&quot;创建Nginx-Template&quot;&gt;&lt;a href=&quot;#创建Nginx-Template&quot; class=&quot;headerlink&quot; title=&quot;创建Nginx Template&quot;&gt;&lt;/a&gt;创建Nginx Template&lt;/h2&gt;&lt;p&gt;点击Configuration—&amp;gt;Templates，点击右上角的Create template。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/66.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;填写模板的信息，点击Add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/67.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;创建Application&quot;&gt;&lt;a href=&quot;#创建Application&quot; class=&quot;headerlink&quot; title=&quot;创建Application&quot;&gt;&lt;/a&gt;创建Application&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;生产环境下只需要把我写好的模板文件import进去就可以了，不需要像下面那样再去创建模板，下面只是介绍下创建模板的过程。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;点击Configuration—&amp;gt;Templates，找到刚才创建的Nginx template，点击所在行的Applications列。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/68.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击右上角的Create application。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/69.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入application的名字Nginx running status，点击Add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/70.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;创建Items&quot;&gt;&lt;a href=&quot;#创建Items&quot; class=&quot;headerlink&quot; title=&quot;创建Items&quot;&gt;&lt;/a&gt;创建Items&lt;/h2&gt;&lt;p&gt;点击Configuration—&amp;gt;Templates，找到刚才创建的Nginx template，点击所在行的Items列。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/71.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击右上角的Create item。分别创建8个监控项，如下图：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当前 Nginx 正处理的活动连接数（包括等待着的连接数）&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/72.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx一共处理了的连接数&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/73.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx一共处理了的连接数(包括失败了的，因为某些限制会导致连接被拒绝，比如the worker_connections limit)&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/74.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx一共处理了的请求的个数(连接和请求是两码事，一个长连接可能会处理多个请求)&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/75.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx正在读取到客户端的Header信息数&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/76.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx正在向客户端发送响应的个数&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/77.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;开启keep-alive 的情况下，这个值等于active – (reading + writing)，意思就是 Nginx 已经处理完正在等候下一次请求指令的驻留连接&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/78.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx服务可用性&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/79.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://nginx.org/en/docs/http/ngx_http_stub_status_module.html&quot;&gt;https://nginx.org/en/docs/http/ngx_http_stub_status_module.html&lt;/a&gt;&lt;br&gt;在编译Nginx的时候，需要加上参数–with-http_stub_status_module，然后在配置文件中配置开启状态页面查询。&lt;br&gt;Nginx1.9.11版本之后才支持动态加载模块，因此对于之前的版本，你都需要重新编译。&lt;br&gt;
    
    </summary>
    
      <category term="Zabbix" scheme="http://yoursite.com/categories/Zabbix/"/>
    
    
      <category term="监控 zabbix" scheme="http://yoursite.com/tags/%E7%9B%91%E6%8E%A7-zabbix/"/>
    
  </entry>
  
  <entry>
    <title>zabbix监控实例</title>
    <link href="http://yoursite.com/2017/05/14/zabbix%E7%9B%91%E6%8E%A7%E5%AE%9E%E4%BE%8B/"/>
    <id>http://yoursite.com/2017/05/14/zabbix监控实例/</id>
    <published>2017-05-14T13:44:33.000Z</published>
    <updated>2017-06-12T07:56:29.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;zabbix-web添加主机&quot;&gt;&lt;a href=&quot;#zabbix-web添加主机&quot; class=&quot;headerlink&quot; title=&quot;zabbix web添加主机&quot;&gt;&lt;/a&gt;zabbix web添加主机&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;进入zabbix web界面，点击配置—&amp;gt;主机—&amp;gt;创建主机。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/28.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;填入下图中的信息，点击添加。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/29.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/30.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/31.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;定义Items&quot;&gt;&lt;a href=&quot;#定义Items&quot; class=&quot;headerlink&quot; title=&quot;定义Items&quot;&gt;&lt;/a&gt;定义Items&lt;/h1&gt;&lt;p&gt;要真正实现数据采集，需要定义监控项(Items)。多个Items可以归为一个组，称为Applications。定义好Items之后，还应该为Items定义Triggers(触发器)。我这里演示下创建监控网卡进入和出去的流量。&lt;/p&gt;
&lt;h2 id=&quot;创建item监控网卡出去流量&quot;&gt;&lt;a href=&quot;#创建item监控网卡出去流量&quot; class=&quot;headerlink&quot; title=&quot;创建item监控网卡出去流量&quot;&gt;&lt;/a&gt;创建item监控网卡出去流量&lt;/h2&gt;&lt;p&gt;登录zabbix web管控台，点击配置—&amp;gt;主机—&amp;gt;监控项。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/32.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击右上角的“创建监控项”。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/33.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在如下的界面填入以下内容：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/34.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;其中，在key那一栏，点击select按钮，选择key值。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/35.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/36.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;回到hosts，你会发现已经有application和item了。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/37.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;每创建一个Item，会自动帮你创建图形的。点击监控—&amp;gt;最新的数据，输入要查的主机，点击select，就可以看到为刚才我们创建的item所创建的图形。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/38.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击图形。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/39.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意:数据量从右往左走的。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;创建item监控进入网卡流量&quot;&gt;&lt;a href=&quot;#创建item监控进入网卡流量&quot; class=&quot;headerlink&quot; title=&quot;创建item监控进入网卡流量&quot;&gt;&lt;/a&gt;创建item监控进入网卡流量&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/40.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意:&lt;/strong&gt;有时候，不是一创建完item，graph那边就有数据了，你可以主要通过浏览器去访问监听在这个网卡的某个端口上的服务，然后graph就会有数据了。&lt;/p&gt;
&lt;h1 id=&quot;创建graph&quot;&gt;&lt;a href=&quot;#创建graph&quot; class=&quot;headerlink&quot; title=&quot;创建graph&quot;&gt;&lt;/a&gt;创建graph&lt;/h1&gt;&lt;p&gt;为什么要创建graph？拿上节中的网卡进出流量来举例，进和出此时都不在一张图上，这就需要Graphs自定义图像。将多个指标放在一起。&lt;/p&gt;
&lt;p&gt;点击配置—&amp;gt;主机，点击Graphs。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/41.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击右上角的创建图形。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/42.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入Name，点击图中倒数第二个add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/43.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;选择监控项。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/44.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;最后点击添加。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/45.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击监控—&amp;gt;图形，在右上角输入主机组，主机和图形。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/46.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;创建模板&quot;&gt;&lt;a href=&quot;#创建模板&quot; class=&quot;headerlink&quot; title=&quot;创建模板&quot;&gt;&lt;/a&gt;创建模板&lt;/h1&gt;&lt;p&gt;如果我们在加一个主机进来，假如说我们每一次都想监控某几个同样的指标，每台主机都要这么去定义的话，就太痛苦了。这就要使用到模板。&lt;/p&gt;
&lt;h2 id=&quot;创建模板-1&quot;&gt;&lt;a href=&quot;#创建模板-1&quot; class=&quot;headerlink&quot; title=&quot;创建模板&quot;&gt;&lt;/a&gt;创建模板&lt;/h2&gt;&lt;p&gt;点击配置—&amp;gt;模板，点击创建模板。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/47.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/48.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;创建Item&quot;&gt;&lt;a href=&quot;#创建Item&quot; class=&quot;headerlink&quot; title=&quot;创建Item&quot;&gt;&lt;/a&gt;创建Item&lt;/h2&gt;&lt;p&gt;创建完模板后，其上是没有任何Item和trigger等。所以我们需要创建这一系列监控项。但是由于这里我是要监控Elasticsearch状态，而zabbix是没有内置的key来监控elasticsearch的，所以需要自定义监控项来监控。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/49.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在elasticsearch主机定义zabbix agent的UserParameter&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# cd /usr/local/zabbix-3.0.1/etc/
[root@log1 etc]# vim zabbix_agentd.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;输入内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;UserParameter=Elasticsearch.status[*],/usr/bin/curl -s &amp;apos;http://$1:$2/_cluster/health?pretty=true&amp;apos; | awk -F&amp;apos;&amp;quot;&amp;apos; &amp;apos;/status/{print $$4}&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;重启zabbix agent&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~] # killall -9 zabbix_agentd
[root@log1 ~]# /usr/local/zabbix-3.0.1/sbin/zabbix_agentd
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在zabbix server端使用zabbix_get模拟获取数据&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# /usr/local/zabbix-3.0.1/bin/zabbix_get -s 114.55.29.86 -k &amp;quot;Elasticsearch.status[114.55.29.86,9200]&amp;quot;
green
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建模板的Item&lt;br&gt;(1)找到刚才新建的模板，点击Item。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/50.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(2)点击右上角的Create Item&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/51.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(3)输入如下的信息&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/52.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/53.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;为模板上的Item创建触发器&quot;&gt;&lt;a href=&quot;#为模板上的Item创建触发器&quot; class=&quot;headerlink&quot; title=&quot;为模板上的Item创建触发器&quot;&gt;&lt;/a&gt;为模板上的Item创建触发器&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;点击触发器。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/54.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;点击右上角的创建触发器&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/55.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;定义触发器名字，然后点击Add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/56.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;点击Select，选择对哪个Item做Trigger。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/57.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/58.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;将模板应用到主机上&quot;&gt;&lt;a href=&quot;#将模板应用到主机上&quot; class=&quot;headerlink&quot; title=&quot;将模板应用到主机上&quot;&gt;&lt;/a&gt;将模板应用到主机上&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;点击配置—&amp;gt;主机，点击log1主机。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/59.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;点击模板，点击选择。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/60.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;选择我们需要的模板，点击选择。然后在点击Add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/61.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;这是Add后显示页面，再点击Update。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/62.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这样你就可以看到这边log1主机有应用的模板的。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/63.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;查看监控数据&quot;&gt;&lt;a href=&quot;#查看监控数据&quot; class=&quot;headerlink&quot; title=&quot;查看监控数据&quot;&gt;&lt;/a&gt;查看监控数据&lt;/h2&gt;&lt;p&gt;点击监控—&amp;gt;最新数据，找到Elasticsearch status这个监控项，点击后面的History。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/64.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/65.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;zabbix-web添加主机&quot;&gt;&lt;a href=&quot;#zabbix-web添加主机&quot; class=&quot;headerlink&quot; title=&quot;zabbix web添加主机&quot;&gt;&lt;/a&gt;zabbix web添加主机&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;进入zabbix web界面，点击配置—&amp;gt;主机—&amp;gt;创建主机。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/28.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Zabbix" scheme="http://yoursite.com/categories/Zabbix/"/>
    
    
      <category term="监控 zabbix" scheme="http://yoursite.com/tags/%E7%9B%91%E6%8E%A7-zabbix/"/>
    
  </entry>
  
</feed>
