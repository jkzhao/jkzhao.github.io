<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>jkzhao&#39;s blog</title>
  <subtitle>学习 总结 思考</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-07-17T06:10:14.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Zhao Jiankai</name>
    <email>jk.zhaocoder@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Ansible条件测试</title>
    <link href="http://yoursite.com/2017/07/17/Ansible%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95/"/>
    <id>http://yoursite.com/2017/07/17/Ansible条件测试/</id>
    <published>2017-07-17T05:39:32.000Z</published>
    <updated>2017-07-17T06:10:14.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Ansible条件测试&quot;&gt;&lt;a href=&quot;#Ansible条件测试&quot; class=&quot;headerlink&quot; title=&quot;Ansible条件测试&quot;&gt;&lt;/a&gt;Ansible条件测试&lt;/h2&gt;&lt;p&gt;在ansible中还可以进行条件测试。如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试。&lt;/p&gt;
&lt;h3 id=&quot;when语句&quot;&gt;&lt;a href=&quot;#when语句&quot; class=&quot;headerlink&quot; title=&quot;when语句&quot;&gt;&lt;/a&gt;when语句&lt;/h3&gt;&lt;p&gt;在task后添加when子句即可使用条件测试：when语句支持Jinja2表达式语法。例如：&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- name: &amp;quot;shutdown Debian flavored systems&amp;quot;
  command: /sbin/shutdown -h now
  when: ansible_os_family == &amp;quot;Debian&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;when语句还可以使用Jinja2的大多“filter”，例如要忽略此前某语句额错误并基于其结果（failed或success）运行后面指定的语句，可使用类似如下形式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- command: /bin/false
  register: result
  ignore_errors: True
- command: /bin/sonmething
  when: result|failed
- command: /bin/something_else
  when: result|success
- command: /bin/still/something_else
  when: result|skipped
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此外，when语句还可以使用facts或playbook中定义的变量。facts就是主机报告上来的变量。比如：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/37.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Ansible条件测试&quot;&gt;&lt;a href=&quot;#Ansible条件测试&quot; class=&quot;headerlink&quot; title=&quot;Ansible条件测试&quot;&gt;&lt;/a&gt;Ansible条件测试&lt;/h2&gt;&lt;p&gt;在ansible中还可以进行条件测试。如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试。&lt;/p&gt;
&lt;h3 id=&quot;when语句&quot;&gt;&lt;a href=&quot;#when语句&quot; class=&quot;headerlink&quot; title=&quot;when语句&quot;&gt;&lt;/a&gt;when语句&lt;/h3&gt;&lt;p&gt;在task后添加when子句即可使用条件测试：when语句支持Jinja2表达式语法。例如：&lt;br&gt;
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>ansible playbook基础组件介绍</title>
    <link href="http://yoursite.com/2017/07/15/ansible-playbook%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2017/07/15/ansible-playbook基础组件介绍/</id>
    <published>2017-07-15T07:24:31.000Z</published>
    <updated>2017-07-17T04:14:39.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;ansible-playbook介绍&quot;&gt;&lt;a href=&quot;#ansible-playbook介绍&quot; class=&quot;headerlink&quot; title=&quot;ansible playbook介绍&quot;&gt;&lt;/a&gt;ansible playbook介绍&lt;/h2&gt;&lt;p&gt;playbook是由一个或多个“play”组成的列表(剧本是由多出戏组成的)。play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色。从根本上来讲，所谓task无非是调用ansible的一个module。将多个play组织在一个playbook中，即可以让它们联同起来按事先编排的机制同唱一台大戏。下面是一个简单示例。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- hosts: webnodes
  vars:
  http_port: 80
  max_clients: 256
remote_user: root
tasks:          
- name: ensure apache is at the latest version
  yum: name=httpd state=latest
- name: ensure apache is running
  service: name=httpd state=started
handlers:
- name: restart apache
  service: name=httpd state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，tasks是一个一个任务。&lt;/p&gt;
&lt;h2 id=&quot;ansible-playbook基础组件&quot;&gt;&lt;a href=&quot;#ansible-playbook基础组件&quot; class=&quot;headerlink&quot; title=&quot;ansible playbook基础组件&quot;&gt;&lt;/a&gt;ansible playbook基础组件&lt;/h2&gt;&lt;p&gt;Playbooks结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tasks：任务，即调用模块完成的某操作。&lt;/li&gt;
&lt;li&gt;Variables：变量&lt;/li&gt;
&lt;li&gt;Templates：模板&lt;/li&gt;
&lt;li&gt;Handlers：处理器，指的是在某条件满足时能够触发完成的功能，或者说是由某事件触发执行的操作&lt;/li&gt;
&lt;li&gt;Roles：角色。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Hosts和Users&quot;&gt;&lt;a href=&quot;#Hosts和Users&quot; class=&quot;headerlink&quot; title=&quot;Hosts和Users&quot;&gt;&lt;/a&gt;Hosts和Users&lt;/h3&gt;&lt;p&gt;playbook中的每一个play的目的都是为了让某个或某些主机以某个指定的用户身份执行任务。hosts用于指定要执行指定任务的主机，其可以是一个或多个由冒号分隔主机组；remote_user则用于指定远程主机上的执行任务的用户。如上面示例中的&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-hosts: webnodes
 remote_user: root
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;不过，remote_user也可用于各task中。也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- hosts: webnodes
 remote_user: mageedu
 tasks:
   - name: test connection
     ping:
     remote_user: mageedu
     sudo: yes
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;比如写一个最简单的playbook，里面写了两个play，一个play是在nginx组的主机上都创建一个nginx组，nginx用户，另一个play是复制一个文件到mysql组的主机上：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim nginx.yml
- hosts: nginx                                                                                                                                
  remote_user: root
  tasks:
  - name: create nginx group
    group: name=nginx system=yes gid=208
  - name: create nginx user
    user: name=nginx uid=208 group=nginx system=yes
- hosts: mysql
  remote_user: root
  tasks:
  - name: copy file to mysql hosts
    copy: src=/etc/inittab dest=/tmp/inittab.ans
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看ansible-playbook的使用方法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# man ansible-playbook
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行playbook：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-playbook nginx.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/31.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;任务列表-Tasks-和action&quot;&gt;&lt;a href=&quot;#任务列表-Tasks-和action&quot; class=&quot;headerlink&quot; title=&quot;任务列表(Tasks)和action&quot;&gt;&lt;/a&gt;任务列表(Tasks)和action&lt;/h3&gt;&lt;p&gt;play的主体部分是task list。task list中的各任务按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个任务后再开始第二个。在运行自下而下某playbook时，如果中途发生错误，所有已执行任务都可能回滚，因此，在更正playbook后重新执行一次即可。(因为具有幂等性)&lt;br&gt;task的目的是使用指定的参数执行模块，而在模块参数中可以使用变量。模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致。&lt;br&gt;每个task都应该有其name，用于playbook的执行结果输出，建议其内容尽可能清晰地描述任务执行步骤。如果未提供name，则action的结果将用于输出。&lt;br&gt;定义task的可以使用“action: module options”(这个在较新版本上才能执行)或“module: options”的格式，推荐使用后者以实现向后兼容。如果action一行的内容过多，也可以使用在行首使用几个空白字符进行换行。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- name: make sure apache is running
  service: name=httpd state=running
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在众多模块中，只有command和shell模块仅需要给定一个列表而无需使用“key=value”格式，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- name: disable selinux
  command: /sbin/setenforce 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果命令或脚本的退出码不为零，可能会阻止playbook继续往下执行可以使用如下方式替代：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- name: run this command and ignore the result
  shell: /usr/bin/somecommand || /bin/true
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;也就是说这个命令失败也是要继续往下走的，就是失败了但不要影响下面的操作。或者使用ignore_errors来忽略错误信息：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
- name: run this command and ignore the result
  shell: /usr/bin/somecommand
  ignore_errors: True        
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;handlers&quot;&gt;&lt;a href=&quot;#handlers&quot; class=&quot;headerlink&quot; title=&quot;handlers&quot;&gt;&lt;/a&gt;handlers&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;用于当关注的资源发生变化时采取一定的操作。&lt;/strong&gt;&lt;br&gt;“notify”这个action可用于在每个play的最后被触发，这样可以避免多次有改变发生时每次都执行指定的操作，取而代之，仅在所有的变化发生完成后一次性地执行指定操作。在notify中列出的操作称为handler，也即notify中调用handler中定义的操作。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- name: template configuration file
  template: src=template.j2 dest=/etc/foo.conf
  notify:
  - restart memcached
  - restart apache    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;handler是task列表，这些task与前述的task并没有本质上的不同。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;handlers:
- name: restart memcached
  service:  name=memcached state=restarted
- name: restart apache
  service: name=apache state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【举例】：比如有个配置nginx的playbook，然后利用这个来说明handlers。&lt;br&gt;1.先创建一个apache.yml，里面定义play安装启动apache&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim apache.yml
- hosts: mysql
  remote_user: root
  tasks:
  - name: install httpd package
    yum: name=httpd state=latest
  - name: install configuration file for httpd
    copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf 
  - name: start httpd service 
    service: enabled=true name=httpd state=started
[root@node1 ~]# ansible-playbook apache.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.假如说某个时刻httpd.conf发生改变了，比如说不再监听在80，而是监听在8080端口，其他没变。修改/root/conf/httpd.conf，把端口改成8080，再执行这个playbook：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-playbook apache.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;到mysql组所在的主机172.16.7.153上查看端口，发现监听端口仍然是80：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node3 ~]# ss -tnlp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/32.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;3.一个程序的配置文件发生了改变，那么程序应该重读配置文件才对。然而默认情况下，你多次唱同一个剧本，如果那个task此前执行过，为了保证幂等性，它是不会再被执行。handlers就是为了解决这种问题而生的。Handlers也是任务，但它不是上来就执行的，只有某个条件满足时才会执行。所以我们去修改apache.yml：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- hosts: mysql
  remote_user: root
  tasks:
  - name: install httpd package
    yum: name=httpd state=latest
  - name: install configuration file for httpd
    copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf 
    notify:
    - restart httpd
  - name: start httpd service 
    service: enabled=true name=httpd state=started
  handlers:
  - name: restart httpd
    service: name=httpd state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/33.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;修改/root/conf/httpd.conf，把端口改成8090，再执行这个playbook：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-playbook apache.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/34.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;到mysql组所在的主机172.16.7.153上查看端口，发现监听端口改变了，变成了8090：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/35.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;playbook中使用变量&quot;&gt;&lt;a href=&quot;#playbook中使用变量&quot; class=&quot;headerlink&quot; title=&quot;playbook中使用变量&quot;&gt;&lt;/a&gt;playbook中使用变量&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;- hosts: mysql
  remote_user: root
  vars:
  - package: nginx
  tasks:
  - name: install httpd package
    yum: name={{ package }} state=latest                                                                                                      
  - name: install configuration file for httpd
    copy: src=/root/conf/httpd.conf dest=/etc/httpd/conf/httpd.conf 
    notify:
    - restart httpd
  - name: start httpd service 
    service: enabled=true name=httpd state=started
  handlers:
  - name: restart httpd
    service: name=httpd state=restarted
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/36.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;【注意】：playbook中能使用的变量不仅仅是这里定义的变量，而是可以使用ansible中定义的所有变量。例如：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible 172.16.7.152 -m setup
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/37.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;另外，在inventory中定义的变量也可以在playbook中调用。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim /etc/ansible/hosts
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/38.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;ansible-playbook介绍&quot;&gt;&lt;a href=&quot;#ansible-playbook介绍&quot; class=&quot;headerlink&quot; title=&quot;ansible playbook介绍&quot;&gt;&lt;/a&gt;ansible playbook介绍&lt;/h2&gt;&lt;p&gt;playbook是由一个或多个“play”组成的列表(剧本是由多出戏组成的)。play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色。从根本上来讲，所谓task无非是调用ansible的一个module。将多个play组织在一个playbook中，即可以让它们联同起来按事先编排的机制同唱一台大戏。下面是一个简单示例。&lt;br&gt;
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Ansible的基础元素和YAML介绍</title>
    <link href="http://yoursite.com/2017/07/11/Ansible%E7%9A%84%E5%9F%BA%E7%A1%80%E5%85%83%E7%B4%A0%E5%92%8CYAML%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2017/07/11/Ansible的基础元素和YAML介绍/</id>
    <published>2017-07-11T10:37:28.000Z</published>
    <updated>2017-07-14T08:03:58.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;YAML&quot;&gt;&lt;a href=&quot;#YAML&quot; class=&quot;headerlink&quot; title=&quot;YAML&quot;&gt;&lt;/a&gt;YAML&lt;/h2&gt;&lt;h3 id=&quot;YAML介绍&quot;&gt;&lt;a href=&quot;#YAML介绍&quot; class=&quot;headerlink&quot; title=&quot;YAML介绍&quot;&gt;&lt;/a&gt;YAML介绍&lt;/h3&gt;&lt;p&gt;YAML是一个可读性高的用来表达资料序列的格式。YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822等。Clark Evans在2001年在首次发表了这种语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者。&lt;br&gt;YAML Ain’t Markup Language，即YAML不是XML。不过，在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）。其特性：&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;YAML的可读性好&lt;/li&gt;
&lt;li&gt;YAML和脚本语言的交互性好&lt;/li&gt;
&lt;li&gt;YAML使用实现语言的数据类型&lt;/li&gt;
&lt;li&gt;YAML有一个一致的信息模型&lt;/li&gt;
&lt;li&gt;YAML易于实现&lt;/li&gt;
&lt;li&gt;YAML可以基于流来处理&lt;/li&gt;
&lt;li&gt;YAML表达能力强，扩展性好&lt;br&gt;更多的内容及规范参见&lt;a href=&quot;http://www.yaml.org。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.yaml.org。&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;YAML语法&quot;&gt;&lt;a href=&quot;#YAML语法&quot; class=&quot;headerlink&quot; title=&quot;YAML语法&quot;&gt;&lt;/a&gt;YAML语法&lt;/h3&gt;&lt;p&gt;YAML的语法和其他高阶语言类似，并且可以简单表达清单、散列表、标量等数据结构。其结构（Structure）通过空格来展示，序列（Sequence）里的项用”-“来代表，Map里的键值对用”:”分隔。下面是一个示例。YAML是用键值对和缩进来表示的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name: John Smith
age: 41
gender: Male
spouse:                         
    name: Jane Smith
    age: 37
    gender: Female
children:                     
    - name: Jimmy Smith
      age: 17
      gender: Male
    - name: Jenny Smith
      age 13
      gender: Female
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;YAML文件扩展名通常为.yaml，如example.yaml。&lt;/p&gt;
&lt;h3 id=&quot;Ansible常用的数据类型&quot;&gt;&lt;a href=&quot;#Ansible常用的数据类型&quot; class=&quot;headerlink&quot; title=&quot;Ansible常用的数据类型&quot;&gt;&lt;/a&gt;Ansible常用的数据类型&lt;/h3&gt;&lt;p&gt;在ansible中常用的数据类型有序列(list)，也叫列表，还有字典，这些都很类似Python语言。&lt;/p&gt;
&lt;h4 id=&quot;list&quot;&gt;&lt;a href=&quot;#list&quot; class=&quot;headerlink&quot; title=&quot;list&quot;&gt;&lt;/a&gt;list&lt;/h4&gt;&lt;p&gt;列表中的所有元素都使用“-”打头，例如：A list of tasty fruits&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apple&lt;/li&gt;
&lt;li&gt;Orange&lt;/li&gt;
&lt;li&gt;Strawberry&lt;/li&gt;
&lt;li&gt;Mango&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;dictionary&quot;&gt;&lt;a href=&quot;#dictionary&quot; class=&quot;headerlink&quot; title=&quot;dictionary&quot;&gt;&lt;/a&gt;dictionary&lt;/h4&gt;&lt;h2 id=&quot;字典通过key与value进行标识，例如：&quot;&gt;&lt;a href=&quot;#字典通过key与value进行标识，例如：&quot; class=&quot;headerlink&quot; title=&quot;字典通过key与value进行标识，例如：&quot;&gt;&lt;/a&gt;字典通过key与value进行标识，例如：&lt;/h2&gt;&lt;p&gt;An employee record：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name: Example Developer
job: Developer
skill: Elite
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;也可以将key-value放置于-中进行表示，例如：&quot;&gt;&lt;a href=&quot;#也可以将key-value放置于-中进行表示，例如：&quot; class=&quot;headerlink&quot; title=&quot;也可以将key:value放置于{}中进行表示，例如：&quot;&gt;&lt;/a&gt;也可以将key:value放置于{}中进行表示，例如：&lt;/h2&gt;&lt;p&gt;An employ record：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{name: Example Developer, job: Developer, skill: Elite}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Ansible基础元素&quot;&gt;&lt;a href=&quot;#Ansible基础元素&quot; class=&quot;headerlink&quot; title=&quot;Ansible基础元素&quot;&gt;&lt;/a&gt;Ansible基础元素&lt;/h2&gt;&lt;h3 id=&quot;变量&quot;&gt;&lt;a href=&quot;#变量&quot; class=&quot;headerlink&quot; title=&quot;变量&quot;&gt;&lt;/a&gt;变量&lt;/h3&gt;&lt;h4 id=&quot;变量命名&quot;&gt;&lt;a href=&quot;#变量命名&quot; class=&quot;headerlink&quot; title=&quot;变量命名&quot;&gt;&lt;/a&gt;变量命名&lt;/h4&gt;&lt;p&gt;变量名仅能由字母、数字和下划线组成，而且只能以字母开头。&lt;/p&gt;
&lt;h4 id=&quot;facts&quot;&gt;&lt;a href=&quot;#facts&quot; class=&quot;headerlink&quot; title=&quot;facts&quot;&gt;&lt;/a&gt;facts&lt;/h4&gt;&lt;p&gt;facts是由正在通信的远程目标主机发回的信息，这些信息被保存在ansible变量中。要获取指定的远程主机所支持的所有facts，可使用如下命令进行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ansible hostname -m setup
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;register&quot;&gt;&lt;a href=&quot;#register&quot; class=&quot;headerlink&quot; title=&quot;register&quot;&gt;&lt;/a&gt;register&lt;/h4&gt;&lt;p&gt;把任务的输出定义为变量，然后用于其他任务，示例如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tasks:
  - shell: /usr/bin/foo
    register: foo_result
    ignore_errors: True
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;通过命令行传递变量&quot;&gt;&lt;a href=&quot;#通过命令行传递变量&quot; class=&quot;headerlink&quot; title=&quot;通过命令行传递变量&quot;&gt;&lt;/a&gt;通过命令行传递变量&lt;/h4&gt;&lt;p&gt;在运行playbook的时候也可以传递一些变量供playbook使用，示例如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ansible-playbook test.yml --extra-vars &amp;quot;hosts=www user=magedu&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;就是说hosts和user这两个变量可以在test.yml文件中直接调用&lt;/p&gt;
&lt;h4 id=&quot;通过roles传递变量&quot;&gt;&lt;a href=&quot;#通过roles传递变量&quot; class=&quot;headerlink&quot; title=&quot;通过roles传递变量&quot;&gt;&lt;/a&gt;通过roles传递变量&lt;/h4&gt;&lt;p&gt;当给一个主机应用角色的时候可以传递变量，然后在角色内使用这些变量，示例如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- hosts: webservers
  roles: 
      - common
      - { role: foo_app_instance, dir: &amp;apos;/web/htdocs/a.com&amp;apos;, port: 8080 }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意:role、dir、port是变量名，冒号后面的是变量值。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;Inventory&quot;&gt;&lt;a href=&quot;#Inventory&quot; class=&quot;headerlink&quot; title=&quot;Inventory&quot;&gt;&lt;/a&gt;Inventory&lt;/h3&gt;&lt;p&gt;ansible的主要功能在于批量主机操作，为了便捷地使用其中的部分主机，可以在inventory file中将其分组命名。默认的inventory file为/etc/ansible/hosts。&lt;br&gt;inventory file可以有多个，且也可以通过Dynamic Inventory来动态生成。&lt;/p&gt;
&lt;h4 id=&quot;inventory文件格式&quot;&gt;&lt;a href=&quot;#inventory文件格式&quot; class=&quot;headerlink&quot; title=&quot;inventory文件格式&quot;&gt;&lt;/a&gt;inventory文件格式&lt;/h4&gt;&lt;p&gt;inventory文件遵循INI文件风格，中括号中的字符为组名。可以将同一个主机同时归并到多个不同的组中；此外，当如若目标主机使用了非默认的SSH端口，还可以在主机名称之后使用冒号加端口号标明。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[webservers]
www1.wisedu.com:8888
www2.wisedu.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果主机名称遵循相似的命名模式，还可以使用列表的方式标识各主机，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[webservers]
www[01:50].example.com

[databases]
db-[a:f].example.com
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;主机变量&quot;&gt;&lt;a href=&quot;#主机变量&quot; class=&quot;headerlink&quot; title=&quot;主机变量&quot;&gt;&lt;/a&gt;主机变量&lt;/h4&gt;&lt;p&gt;可以在inventory中定义主机时为其添加主机变量以便于在playbook中使用，例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[webservers]
www1.wisedu.com http_port=80 maxRequestsPerChild=808
www2.wisedu.com http_port=8080 maxRequestsPerChild=909
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;组变量&quot;&gt;&lt;a href=&quot;#组变量&quot; class=&quot;headerlink&quot; title=&quot;组变量&quot;&gt;&lt;/a&gt;组变量&lt;/h4&gt;&lt;p&gt;组变量是指赋予给指定组内所有主机上的在playbook中可用的变量。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; [webservers]
 www1.wisedu.com
 www2.wisedu.com

[webservers:vars]   # 表示向webservers这组主机定义变量如下，回头这两台主机上都可以调用变量ntp_server和nfs_server
ntp_server=ntp.wisedu.com
nfs_server=ntp.wisedu.com
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;组嵌套&quot;&gt;&lt;a href=&quot;#组嵌套&quot; class=&quot;headerlink&quot; title=&quot;组嵌套&quot;&gt;&lt;/a&gt;组嵌套&lt;/h4&gt;&lt;p&gt;inventory中，组还可以包含其它的组，并且也可以向组中的主机指定变量。不过，这些变量只能在ansible-playbook中使用，而ansible不支持。例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[apache]
httpd1.wisedu.com
httpd2.wisedu.com

[nginx]
ngx1.wisedu.com
ngx2.wisedu.com

[webservers:children]     # 注意:children是固定格式
apache
nginx

[webservers:vars]
ntp_server=ntp.wisedu.com
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;inventory参数&quot;&gt;&lt;a href=&quot;#inventory参数&quot; class=&quot;headerlink&quot; title=&quot;inventory参数&quot;&gt;&lt;/a&gt;inventory参数&lt;/h4&gt;&lt;p&gt;ansible基于ssh连接inventory中指定的远程主机时，还可以通过参数指定其交互方式，这些参数如下所示：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/29.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/30.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;YAML&quot;&gt;&lt;a href=&quot;#YAML&quot; class=&quot;headerlink&quot; title=&quot;YAML&quot;&gt;&lt;/a&gt;YAML&lt;/h2&gt;&lt;h3 id=&quot;YAML介绍&quot;&gt;&lt;a href=&quot;#YAML介绍&quot; class=&quot;headerlink&quot; title=&quot;YAML介绍&quot;&gt;&lt;/a&gt;YAML介绍&lt;/h3&gt;&lt;p&gt;YAML是一个可读性高的用来表达资料序列的格式。YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822等。Clark Evans在2001年在首次发表了这种语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者。&lt;br&gt;YAML Ain’t Markup Language，即YAML不是XML。不过，在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）。其特性：&lt;br&gt;
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Ansible常见模块介绍</title>
    <link href="http://yoursite.com/2017/07/07/Ansible%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9D%97%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2017/07/07/Ansible常见模块介绍/</id>
    <published>2017-07-07T00:48:26.000Z</published>
    <updated>2017-07-07T03:06:49.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;ansible命令基础&quot;&gt;&lt;a href=&quot;#ansible命令基础&quot; class=&quot;headerlink&quot; title=&quot;ansible命令基础&quot;&gt;&lt;/a&gt;ansible命令基础&lt;/h2&gt;&lt;p&gt;语法：ansible &lt;host-pattern&gt; [-f forks] [-m module_name] [-a args] [options] &lt;/host-pattern&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;host-pattern：这次的命令对哪些主机生效；&lt;/li&gt;
&lt;li&gt;-f forks：启动的并发线程数，就是一次并行处理多少主机；&lt;/li&gt;
&lt;li&gt;-m module_name：要使用的模块；&lt;/li&gt;
&lt;li&gt;-a args：模块特有的参数。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常见的模块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;user&lt;/li&gt;
&lt;li&gt;yum&lt;/li&gt;
&lt;li&gt;copy&lt;/li&gt;
&lt;li&gt;cron&lt;/li&gt;
&lt;li&gt;command：这是默认的模块，表示在被管理主机上运行一个命令。对于command模块，-a不再是指定参数，而是命令本身。&lt;/li&gt;
&lt;li&gt;shell&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;常见模块举例&quot;&gt;&lt;a href=&quot;#常见模块举例&quot; class=&quot;headerlink&quot; title=&quot;常见模块举例&quot;&gt;&lt;/a&gt;常见模块举例&lt;/h2&gt;&lt;h3 id=&quot;etc-ansible-hosts配置文件内容&quot;&gt;&lt;a href=&quot;#etc-ansible-hosts配置文件内容&quot; class=&quot;headerlink&quot; title=&quot;/etc/ansible/hosts配置文件内容&quot;&gt;&lt;/a&gt;/etc/ansible/hosts配置文件内容&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;command模块&quot;&gt;&lt;a href=&quot;#command模块&quot; class=&quot;headerlink&quot; title=&quot;command模块&quot;&gt;&lt;/a&gt;command模块&lt;/h3&gt;&lt;p&gt;command模块是默认的模块，表示在被管理主机上运行一个命令。对于command模块，-a不再是指定参数，而是命令本身。所以这个模块有个缺陷，运行的命令中不能使用变量或者参数。&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible nginx -m command -a &amp;quot;date&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m command -a &amp;quot;tail -3 /etc/passwd&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;cron模块&quot;&gt;&lt;a href=&quot;#cron模块&quot; class=&quot;headerlink&quot; title=&quot;cron模块&quot;&gt;&lt;/a&gt;cron模块&lt;/h3&gt;&lt;p&gt;cron模块可以让每一个被管理节点能够自动生成一个定期任务计划。查看cron模块的用法：&lt;br&gt;[root@node1 ~]# ansible-doc -s cron&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/10.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;几个主要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;state：present表示安装crontab任务&lt;pre&gt;&lt;code&gt;absent表示移除crontab任务
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;job：指明运行的命令是什么&lt;/li&gt;
&lt;li&gt;&lt;p&gt;name：crontab任务的名字&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m cron -a &amp;apos;minute=&amp;quot;*/10&amp;quot; job=&amp;quot;/usr/bin/echo hello&amp;quot; name=&amp;quot;test cron job&amp;quot;&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/11.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;注意：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;所有的参数可以用””包含起来&lt;/li&gt;
&lt;li&gt;day之类的参数没有指定，默认都是*&lt;/li&gt;
&lt;li&gt;默认state参数的值为present&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/12.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;user模块&quot;&gt;&lt;a href=&quot;#user模块&quot; class=&quot;headerlink&quot; title=&quot;user模块&quot;&gt;&lt;/a&gt;user模块&lt;/h3&gt;&lt;p&gt;user模块实现用户账号管理。查看user模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s user
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;几个主要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;name=：用户名&lt;/li&gt;
&lt;li&gt;uid：用户的uid&lt;/li&gt;
&lt;li&gt;group：所属组，即私有组&lt;/li&gt;
&lt;li&gt;groups：附加组。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;state：状态。&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m user -a &amp;apos;name=&amp;quot;jack&amp;quot;&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/13.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m user -a &amp;apos;name=&amp;quot;jack&amp;quot; state=absent&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/14.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;group模块&quot;&gt;&lt;a href=&quot;#group模块&quot; class=&quot;headerlink&quot; title=&quot;group模块&quot;&gt;&lt;/a&gt;group模块&lt;/h3&gt;&lt;p&gt;group模块：组管理。查看group模块的用法：&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s group
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/15.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m group -a &amp;apos;name=mysql gid=306 system=yes&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/16.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;copy模块&quot;&gt;&lt;a href=&quot;#copy模块&quot; class=&quot;headerlink&quot; title=&quot;copy模块&quot;&gt;&lt;/a&gt;copy模块&lt;/h3&gt;&lt;p&gt;copy模块实现文件复制。查看copy模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s copy
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;几个主要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;src=：指明源文件本地路径。可以是绝对路径，也可以是相对路径。可以不使用src，使用content。就是说用content内容来生成文件。&lt;/li&gt;
&lt;li&gt;dest=：定义远程目标文件路径，只能使用绝对路径。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;content=：可以不使用src，使用content。就是说用content内容来生成文件。&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m copy -a &amp;apos;src=/etc/fstab dest=/tmp/fstab.ansible owner=root mode=640&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/17.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m copy -a &amp;apos;content=&amp;quot;Hello World\nGood boy&amp;quot; dest=/tmp/test.txt owner=root mode=640&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/18.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;file模块&quot;&gt;&lt;a href=&quot;#file模块&quot; class=&quot;headerlink&quot; title=&quot;file模块&quot;&gt;&lt;/a&gt;file模块&lt;/h3&gt;&lt;p&gt;file模块可以设定文件属性，还可以创建文件的符号链接。查看file模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s file
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;几个重要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;path=：指明对哪个文件做管理。也可以使用dest和name。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建文件的符号链接：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;src=：指明源文件&lt;/li&gt;
&lt;li&gt;&lt;p&gt;path=：指明符号链接文件路径&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;  [root@node1 ~]# ansible mysql -m file -a ‘owner=root group=mysql mode=644 path=/tmp/test.txt’&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/19.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;  [root@node1 ~]# ansible mysql -m file -a ‘path=/tmp/test.link src=/tmp/test.txt state=link’&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/20.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;ping模块&quot;&gt;&lt;a href=&quot;#ping模块&quot; class=&quot;headerlink&quot; title=&quot;ping模块&quot;&gt;&lt;/a&gt;ping模块&lt;/h3&gt;&lt;p&gt;ping模块测试指定主机是否能连接。查看ping模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s ping
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible nginx -m ping
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/21.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;service模块&quot;&gt;&lt;a href=&quot;#service模块&quot; class=&quot;headerlink&quot; title=&quot;service模块&quot;&gt;&lt;/a&gt;service模块&lt;/h3&gt;&lt;p&gt;service模块是管理服务的。查看service模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/22.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;几个重要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;enabled=：是否开机自动启动，取值为true或false；&lt;/li&gt;
&lt;li&gt;name=：服务名字；&lt;/li&gt;
&lt;li&gt;&lt;p&gt;state=：状态，取值有started，stoped    ，restarted。&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible 172.16.7.151 -m service -a &amp;apos;enabled=true name=httpd state=stopped&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/23.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;shell模块&quot;&gt;&lt;a href=&quot;#shell模块&quot; class=&quot;headerlink&quot; title=&quot;shell模块&quot;&gt;&lt;/a&gt;shell模块&lt;/h3&gt;&lt;p&gt;shell模块：和command模块类似，但是可以使用变量。用于执行一些复杂的命令。查看shell模块的使用方法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s shell
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m user -a &amp;apos;name=&amp;quot;test&amp;quot;&amp;apos;
[root@node1 ~]# ansible mysql -m command -a &amp;apos;echo wisedu | passwd --stdin test&amp;apos;
[root@node1 ~]# ansible mysql -m command -a &amp;apos;tail -1 /etc/passwd&amp;apos; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/24.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m shell -a &amp;apos;echo wisedu | passwd --stdin user1&amp;apos;
[root@node1 ~]# ansible mysql -m command -a &amp;apos;tail -1 /etc/shadow&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/25.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;所以一旦有管道、变量之类的，你最好使用shell模块，而不要用command模块。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;script模块&quot;&gt;&lt;a href=&quot;#script模块&quot; class=&quot;headerlink&quot; title=&quot;script模块&quot;&gt;&lt;/a&gt;script模块&lt;/h3&gt;&lt;p&gt;script模块将本地脚本复制到远程主机并运行之。查看script模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s script
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim test.sh
#/bin/bash                                                                                                                                    
echo &amp;quot;hello world&amp;quot; &amp;gt;/tmp/nba.txt
 [root@node1 ~]# chmod +x test.sh 
 [root@node1 ~]# ansible mysql -m script -a &amp;apos;/root/test.sh&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/26.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;yum模块&quot;&gt;&lt;a href=&quot;#yum模块&quot; class=&quot;headerlink&quot; title=&quot;yum模块&quot;&gt;&lt;/a&gt;yum模块&lt;/h3&gt;&lt;p&gt;yum模块管理程序包。查看yum模块的用法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s yum        
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;几个重要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;name=：指定要安装的程序包，可以带上版本号，否则安装最新版本；&lt;/li&gt;
&lt;li&gt;&lt;p&gt;state=：present表示安装，absent表示卸载。&lt;br&gt;&lt;strong&gt;示例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m yum -a &amp;apos;name=ksh&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/27.png&quot; alt=&quot;&quot;&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;setup模块&quot;&gt;&lt;a href=&quot;#setup模块&quot; class=&quot;headerlink&quot; title=&quot;setup模块&quot;&gt;&lt;/a&gt;setup模块&lt;/h3&gt;&lt;p&gt;setup模块：收集远程主机的facts。ansbile在管理每一个主机时，这些主机在被运行管理命令之前，会首先向ansible节点报告自己主机当前的各种可能被ansible主机用到的状态信息，如操作系统版本、ip地址等信息，这些信息都是以变量的形式，ansible主机可以在jinjia2中调用，为不同的服务器生成不同的配置文件。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible mysql -m setup
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/28.png&quot; alt=&quot;&quot;&gt;  &lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;ansible命令基础&quot;&gt;&lt;a href=&quot;#ansible命令基础&quot; class=&quot;headerlink&quot; title=&quot;ansible命令基础&quot;&gt;&lt;/a&gt;ansible命令基础&lt;/h2&gt;&lt;p&gt;语法：ansible &lt;host-pattern&gt; [-f forks] [-m module_name] [-a args] [options] &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;host-pattern：这次的命令对哪些主机生效；&lt;/li&gt;
&lt;li&gt;-f forks：启动的并发线程数，就是一次并行处理多少主机；&lt;/li&gt;
&lt;li&gt;-m module_name：要使用的模块；&lt;/li&gt;
&lt;li&gt;-a args：模块特有的参数。
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Ansible介绍及安装部署</title>
    <link href="http://yoursite.com/2017/07/05/Ansible%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/07/05/Ansible介绍及安装部署/</id>
    <published>2017-07-05T07:33:54.000Z</published>
    <updated>2017-07-07T01:17:11.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;运维工具&quot;&gt;&lt;a href=&quot;#运维工具&quot; class=&quot;headerlink&quot; title=&quot;运维工具&quot;&gt;&lt;/a&gt;运维工具&lt;/h2&gt;&lt;p&gt;作为一个Linux运维人员，需要了解大量的运维工具，并熟知这些工具的差异，能够熟练运用这些工具去解决一些手动重复的劳动，一方面是避免人工操作失误，另一方面也可以提高工作效率。同时还能将自己从这些重复的工作中解放出来，以便研究更新和更深的技术。&lt;br&gt;运维工具大体上可以分为3类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OS Provisioning：提供操作系统安装的。PXE，Cobbler(repository,distritution,profile)。&lt;/li&gt;
&lt;li&gt;OS Config：cfengine、puppet、saltstack、chef、func、Task Excute工具(fabric、func、saltstack)&lt;/li&gt;
&lt;li&gt;Deployment：capistranoc、fabric&lt;br&gt;而Ansible是一款较新的工具，可以实现OS Config、Task Excute和Deployment。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
运维工具实现远程管理的两种方式：&lt;br&gt;1.有agent：puppet、saltstack、func&lt;br&gt;2.agentless：ansible、fabric&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Ansible特性&quot;&gt;&lt;a href=&quot;#Ansible特性&quot; class=&quot;headerlink&quot; title=&quot;Ansible特性&quot;&gt;&lt;/a&gt;Ansible特性&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;学习曲线平缓；&lt;/li&gt;
&lt;li&gt;不需要agent；&lt;/li&gt;
&lt;li&gt;没有有线状态图，没有次序，我们自己定义动作间的依赖关系就行，任何一个任务出错会很快出错，你可以立即进行修改；&lt;/li&gt;
&lt;li&gt;没有代理；&lt;/li&gt;
&lt;li&gt;没有服务端；&lt;/li&gt;
&lt;li&gt;依赖ssh来工作，无需ssl，也就无需证书等功能；&lt;/li&gt;
&lt;li&gt;模块可以使用任何编程语言来编写，包括shell脚本；&lt;/li&gt;
&lt;li&gt;默认使用ssh工作；&lt;/li&gt;
&lt;li&gt;支持多级的解决方案。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Ansible架构图和核心组件&quot;&gt;&lt;a href=&quot;#Ansible架构图和核心组件&quot; class=&quot;headerlink&quot; title=&quot;Ansible架构图和核心组件&quot;&gt;&lt;/a&gt;Ansible架构图和核心组件&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;架构图：&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;ansible是Python编写的，Python有一个模块叫paramiko，paramiko组件能够实现并行地基于ssh协议远程连接至各主机的库。ansible就是用了paramiko。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核心组件：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ansible core：ansible核心。&lt;/li&gt;
&lt;li&gt;host inventory：主机池，或叫主机列表，主机归档文件。&lt;/li&gt;
&lt;li&gt;core modules：ansible核心模块。&lt;/li&gt;
&lt;li&gt;custom modules：用户可以自定义模块&lt;/li&gt;
&lt;li&gt;playbook：将多个任务写在一个yaml格式的配置文件中。支持使用Python的jinjia2来定义模板。同一个playbook应用带同一台主机上，无论你应用多少次，他们的结果都是相等的，不会重复执行。这种特性我们称为幂等性。&lt;/li&gt;
&lt;li&gt;connect plugins：连接插件&lt;/li&gt;
&lt;li&gt;plugins：其他的一些插件，比如email、logging等等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;安装Ansible&quot;&gt;&lt;a href=&quot;#安装Ansible&quot; class=&quot;headerlink&quot; title=&quot;安装Ansible&quot;&gt;&lt;/a&gt;安装Ansible&lt;/h2&gt;&lt;p&gt;可以选择源码编译安装或者yum安装。ansible的rpm包在epel源中，事先安装好epel源。我这里实验环境是CentOS 7。&lt;br&gt;安装：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install ansible -y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看安装的rpm包里有哪些文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# rpm -ql ansible | more
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;ansible配置文件：/etc/ansible/ansible.cfg&lt;br&gt;inventory文件：/etc/ansible/hosts&lt;/p&gt;
&lt;h2 id=&quot;演示使用示例&quot;&gt;&lt;a href=&quot;#演示使用示例&quot; class=&quot;headerlink&quot; title=&quot;演示使用示例&quot;&gt;&lt;/a&gt;演示使用示例&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;node1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.7.151&lt;/td&gt;
&lt;td&gt;ansible-noarh-2.2.0.0-4.el7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.7.152&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node3&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.7.153&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;配置Ansible主机登录其他主机使用密钥登录&quot;&gt;&lt;a href=&quot;#配置Ansible主机登录其他主机使用密钥登录&quot; class=&quot;headerlink&quot; title=&quot;配置Ansible主机登录其他主机使用密钥登录&quot;&gt;&lt;/a&gt;配置Ansible主机登录其他主机使用密钥登录&lt;/h3&gt;&lt;p&gt;由于Ansible默认使用ssh管理主机，所以首先需要配置Ansible所在主机登录其他被管理主机不需要输入密码。在node1主机上执行如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ssh-keygen -t rsa -P &amp;apos;&amp;apos;
[root@node1 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@172.16.7.151
[root@node1 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@172.16.7.152
[root@node1 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@172.16.7.153
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;定义主机&quot;&gt;&lt;a href=&quot;#定义主机&quot; class=&quot;headerlink&quot; title=&quot;定义主机&quot;&gt;&lt;/a&gt;定义主机&lt;/h3&gt;&lt;p&gt;每一个主机可以使用主机名，也可以使用ip地址。也可以把多个主机定义到一个组里。比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim /etc/ansible/hosts
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;使用模块&quot;&gt;&lt;a href=&quot;#使用模块&quot; class=&quot;headerlink&quot; title=&quot;使用模块&quot;&gt;&lt;/a&gt;使用模块&lt;/h3&gt;&lt;p&gt;Ansible是依赖模块进行工作的，里面有大量的模块帮助我们去完成任务。比如使用command模块：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible 172.16.7.152 -m command -a &amp;quot;date&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;如上，在执行任务时，可以指定IP，也可以指定组名，ansible有个默认的组叫all，代表/etc/ansible/hosts文件里的所有主机。&lt;/p&gt;
&lt;p&gt;列出当前主机可以使用的ansible模块：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -l
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;常用的模块有：user、yum、copy、command等。如果想知道某个模块怎么使用的，比如想知道yum怎么用：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# ansible-doc -s yum
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Ansible/6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;运维工具&quot;&gt;&lt;a href=&quot;#运维工具&quot; class=&quot;headerlink&quot; title=&quot;运维工具&quot;&gt;&lt;/a&gt;运维工具&lt;/h2&gt;&lt;p&gt;作为一个Linux运维人员，需要了解大量的运维工具，并熟知这些工具的差异，能够熟练运用这些工具去解决一些手动重复的劳动，一方面是避免人工操作失误，另一方面也可以提高工作效率。同时还能将自己从这些重复的工作中解放出来，以便研究更新和更深的技术。&lt;br&gt;运维工具大体上可以分为3类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OS Provisioning：提供操作系统安装的。PXE，Cobbler(repository,distritution,profile)。&lt;/li&gt;
&lt;li&gt;OS Config：cfengine、puppet、saltstack、chef、func、Task Excute工具(fabric、func、saltstack)&lt;/li&gt;
&lt;li&gt;Deployment：capistranoc、fabric&lt;br&gt;而Ansible是一款较新的工具，可以实现OS Config、Task Excute和Deployment。
    
    </summary>
    
      <category term="运维自动化" scheme="http://yoursite.com/categories/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ansible 运维自动化" scheme="http://yoursite.com/tags/Ansible-%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>FlumeNG介绍及安装部署</title>
    <link href="http://yoursite.com/2017/07/01/FlumeNG%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/07/01/FlumeNG介绍及安装部署/</id>
    <published>2017-07-01T12:53:40.000Z</published>
    <updated>2017-07-02T03:58:56.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Flume简介&quot;&gt;&lt;a href=&quot;#Flume简介&quot; class=&quot;headerlink&quot; title=&quot;Flume简介&quot;&gt;&lt;/a&gt;Flume简介&lt;/h2&gt;&lt;p&gt;Flume是一个分布式、可靠、高可用的海量日志聚合系统，支持在系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据的简单处理，并写到各种数据接收方的能力。&lt;br&gt;Flume在0.9.x和1.x之间有较大的架构调整，1.x版本之后的改称为Flume NG。0.9.x的称为Flume OG。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Flume OG体系架构如下，Flume OG已经不再进行版本更新：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Flume NG体系架构如下：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;最新的Flume NG是1.7.0，运行最新版本的Flume NG时，机器必须安装JDK7.0或以上的版本，并且，Flume目前在只有在Linux系统的启动脚本，没有Windows环境的启动脚本。&lt;/p&gt;
&lt;h2 id=&quot;Flume-NG核心组件&quot;&gt;&lt;a href=&quot;#Flume-NG核心组件&quot; class=&quot;headerlink&quot; title=&quot;Flume NG核心组件&quot;&gt;&lt;/a&gt;Flume NG核心组件&lt;/h2&gt;&lt;p&gt;Flume NG主要由3个重要的组件构成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source&lt;/li&gt;
&lt;li&gt;Sink&lt;/li&gt;
&lt;li&gt;Channel&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Source&quot;&gt;&lt;a href=&quot;#Source&quot; class=&quot;headerlink&quot; title=&quot;Source&quot;&gt;&lt;/a&gt;Source&lt;/h3&gt;&lt;p&gt;完成对日志数据的收集，分成transtion和event打入到channel中。&lt;br&gt;Flume提供了各种source的实现，包括Avro Source(监控端口)、Exce Source(对命令监控)、Spooling Directory Source(监控某个目录)、NetCat Source、Syslog Source、Syslog TCP Source、Syslog UDP Source、HTTP Source、HDFS Source等。&lt;br&gt;对现有程序改动最小的使用方式是使用直接读取程序原来记录的日志文件，基本可以实现无缝接入，不需要对现有程序进行任何改动。直接读取文件Source，有两种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exec Source&lt;br&gt;以运行Linux命令的方式，持续的输出最新的数据，如tail -f 文件名，在这种方式下，取的文件名必须是指定的。        &lt;/li&gt;
&lt;li&gt;Spool Source&lt;br&gt;是监测配置的目录下新增的文件，并将文件中的数据读取出来。使用Spool Source需要注意：&lt;br&gt;(1)拷贝到spool目录下的文件不可以再打开编辑。因为放进去的目录可能在一直被读，一般不可以再被打开了。&lt;br&gt;(2)spool目录下不可包含相应的子目录。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Spool Source如何使用？&lt;br&gt;在实际使用过程中，可以结合log4j使用，使用log4j的时候，将log4j的文件切割机制设为1分钟1次，将文件拷贝到spool的监控目录。log4j有一个TimeRolling的插件，可以把log4j分割的文件到spool目录。基本实现了实时的监控。Flume在传完文件之后，将会修改文件的后缀，变为.COMPLETED(后缀也可以在配置文件中灵活指定)。&lt;/p&gt;
&lt;p&gt;Exec Source和Spool Source比较？&lt;br&gt;Exec Source可以实现对日志的实时收集，但是存在Flume不运行或者指令执行出错时，将无法收集到日志数据，无法保证日志数据的完整性。&lt;br&gt;Spool Source虽然无法实现实时的收集数据，但是可以使用以分钟的方式切割文件，趋近于实时。&lt;br&gt;总结：如果应用无法实现以分钟切割文件的话，可以两种收集方式结合使用。&lt;/p&gt;
&lt;h3 id=&quot;Sink&quot;&gt;&lt;a href=&quot;#Sink&quot; class=&quot;headerlink&quot; title=&quot;Sink&quot;&gt;&lt;/a&gt;Sink&lt;/h3&gt;&lt;p&gt;Flume Sink取出Channel中的数据，进行相应的存储文件系统，数据库，或者提交到远程服务器。&lt;br&gt;Flume也提供了各种sink的实现，包括HDFS sink、Logger sink、Avro sink、File Roll sink、Null sink、HBase sink等。&lt;br&gt;Flume Sink在设置数据存储时，可以向文件系统中、数据库中、hadoop中储数据，在日志数据较少时，可以将数据存储在文件系统中，并且设定一定的时间间隔保存数据。在日志数据较多时，可以将相应的日志数据存储到Hadoop中，便于日后进行相应的数据分析。&lt;/p&gt;
&lt;h3 id=&quot;Channel&quot;&gt;&lt;a href=&quot;#Channel&quot; class=&quot;headerlink&quot; title=&quot;Channel&quot;&gt;&lt;/a&gt;Channel&lt;/h3&gt;&lt;p&gt;Flume Channel主要提供一个队列的功能，对Source提供中的数据进行简单的缓存。&lt;br&gt;Flume对于Channel，则提供了Memory Channel、JDBC Channel、File Channel等。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MemoryChannel&lt;br&gt;可以实现高速的吞吐，但是无法保证数据的完整性。&lt;/li&gt;
&lt;li&gt;MemoryRecoverChannel&lt;br&gt;官方文档建议使用FileChannel来替换。&lt;/li&gt;
&lt;li&gt;FileChannel&lt;br&gt;保证数据的完整性和一致性。在具体配置不现的FileChannel时，建议FileChannel设置的目录和程序日志文件保存的目录设成不同的磁盘，以便提高效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Flume部署种类&quot;&gt;&lt;a href=&quot;#Flume部署种类&quot; class=&quot;headerlink&quot; title=&quot;Flume部署种类&quot;&gt;&lt;/a&gt;Flume部署种类&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.单一代理流程&lt;/strong&gt;&lt;br&gt;就是只有一个agent在客户端采集。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.多代理流程&lt;/strong&gt;&lt;br&gt;就是一个agent通过中转的Avro传到下一个agent。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;3.流合并&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;4.多路复用流&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Flume单机安装&quot;&gt;&lt;a href=&quot;#Flume单机安装&quot; class=&quot;headerlink&quot; title=&quot;Flume单机安装&quot;&gt;&lt;/a&gt;Flume单机安装&lt;/h2&gt;&lt;h3 id=&quot;安装JDK1-6&quot;&gt;&lt;a href=&quot;#安装JDK1-6&quot; class=&quot;headerlink&quot; title=&quot;安装JDK1.6&quot;&gt;&lt;/a&gt;安装JDK1.6&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@log1 local]# mkdir /usr/java
[root@log1 local]# tar zxf jdk-7u80-linux-x64.gz -C /usr/java/
[root@log1 local]# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.7.0_80
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
[root@log1 local]# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装Flume-NG&quot;&gt;&lt;a href=&quot;#安装Flume-NG&quot; class=&quot;headerlink&quot; title=&quot;安装Flume NG&quot;&gt;&lt;/a&gt;安装Flume NG&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@db local]# tar zxf apache-flume-1.7.0-bin.tar.gz 
[root@db local]# cd apache-flume-1.7.0-bin
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;一个简单的例子&quot;&gt;&lt;a href=&quot;#一个简单的例子&quot; class=&quot;headerlink&quot; title=&quot;一个简单的例子&quot;&gt;&lt;/a&gt;一个简单的例子&lt;/h3&gt;&lt;p&gt;下面写一个单节点的配置文件。这个配置文件让flume接收事件，并输出到终端。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@db apache-flume-1.7.0-bin]# vim conf/example.conf
# example.conf: A single-node Flume configuration

# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444

# Describe the sink
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个配置文件定义了一个单agent名字叫a1。a1有一个source在端口44444监听数据，a1的channel是Memory channel，sink是直接输送到终端上，&lt;/p&gt;
&lt;p&gt;启动Flume NG：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@db apache-flume-1.7.0-bin]# bin/flume-ng agent --conf conf --conf-file conf/example.conf --name a1 -Dflume.root.logger=INFO,console
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;测试&quot;&gt;&lt;a href=&quot;#测试&quot; class=&quot;headerlink&quot; title=&quot;测试&quot;&gt;&lt;/a&gt;测试&lt;/h3&gt;&lt;p&gt;打开另外一个终端，telnet端口44444，然后发送一个事件：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;查看原来的终端，可以看到如下的内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2017-07-02 11:43:37,111 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: { headers:{} body: 48 65 6C 6C 6F 20 4D 61 6E 21 0D                Hello Man!. }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Flume/8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Flume简介&quot;&gt;&lt;a href=&quot;#Flume简介&quot; class=&quot;headerlink&quot; title=&quot;Flume简介&quot;&gt;&lt;/a&gt;Flume简介&lt;/h2&gt;&lt;p&gt;Flume是一个分布式、可靠、高可用的海量日志聚合系统，支持在系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据的简单处理，并写到各种数据接收方的能力。&lt;br&gt;Flume在0.9.x和1.x之间有较大的架构调整，1.x版本之后的改称为Flume NG。0.9.x的称为Flume OG。&lt;br&gt;
    
    </summary>
    
      <category term="数据采集" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"/>
    
    
      <category term="Flume 数据采集" scheme="http://yoursite.com/tags/Flume-%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch安全问题</title>
    <link href="http://yoursite.com/2017/06/29/Elasticsearch%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2017/06/29/Elasticsearch安全问题/</id>
    <published>2017-06-29T03:51:51.000Z</published>
    <updated>2017-06-29T07:42:19.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;Elasticsearch设计之初就定位在纯私网环境而不做权限和安全控制，虽然有个叫Security Manager的配置，但是显然是不够的。但是后来专门出了个收费的shield来保护Elasticsearch，可是毕竟是收费的。当然我们也有替代品：search-guard。下面介绍下 Elasticsearch 围绕安全方面的的几点使用事项：&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;修改默认的-Elasticsearch-集群名称&quot;&gt;&lt;a href=&quot;#修改默认的-Elasticsearch-集群名称&quot; class=&quot;headerlink&quot; title=&quot;修改默认的 Elasticsearch 集群名称&quot;&gt;&lt;/a&gt;修改默认的 Elasticsearch 集群名称&lt;/h2&gt;&lt;p&gt;Elasticsearch 默认的集群名称是 elasticsearch，请在生成环境上一定要修改成其他的名称，并且不同的环境和不同的集群要保证不相同，监控集群节点情况，如果有未知节点加入，一定要及时预警。&lt;/p&gt;
&lt;h2 id=&quot;不要暴露-Elasticsearch-在公网上&quot;&gt;&lt;a href=&quot;#不要暴露-Elasticsearch-在公网上&quot; class=&quot;headerlink&quot; title=&quot;不要暴露 Elasticsearch 在公网上&quot;&gt;&lt;/a&gt;不要暴露 Elasticsearch 在公网上&lt;/h2&gt;&lt;p&gt;Elasticsearch默认的http.port是9200，集群各节点间的通信端口transport.tcp.port是9300。建议修改这两个端口。&lt;/p&gt;
&lt;p&gt;所以强烈建议替换掉Elasticsearch的监控端口，就像是给你家金库做了个“暗门”，骇客想要进入金库至少先得找到门路才行。&lt;/p&gt;
&lt;h2 id=&quot;不要以-root-身份运行-Elasticsearch&quot;&gt;&lt;a href=&quot;#不要以-root-身份运行-Elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;不要以 root 身份运行 Elasticsearch&quot;&gt;&lt;/a&gt;不要以 root 身份运行 Elasticsearch&lt;/h2&gt;&lt;p&gt;一定不要以 root 身份来运行 Elasticsearch，另外，要不和其他的服务公用相同的用户，然后还要保证该用户的权限要最小化。&lt;/p&gt;
&lt;h2 id=&quot;定期对-Elasticsearch-进行备份&quot;&gt;&lt;a href=&quot;#定期对-Elasticsearch-进行备份&quot; class=&quot;headerlink&quot; title=&quot;定期对 Elasticsearch 进行备份&quot;&gt;&lt;/a&gt;定期对 Elasticsearch 进行备份&lt;/h2&gt;&lt;p&gt;使用 Elasticsearch 提供的备份还原机制，定期对 Elasticsearch 的数据进行快照备份，以备不时之需。官网的备份介绍：&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装Elasticsearch的权限系统插件-SearchGuard&quot;&gt;&lt;a href=&quot;#安装Elasticsearch的权限系统插件-SearchGuard&quot; class=&quot;headerlink&quot; title=&quot;安装Elasticsearch的权限系统插件-SearchGuard&quot;&gt;&lt;/a&gt;安装Elasticsearch的权限系统插件-SearchGuard&lt;/h2&gt;&lt;p&gt;search-guard是elastcisearch的一款插件，提供加密，身份验证和授权，基于search guard SSL，另外提供可插入的身份验证/授权模块，search-guard是shield的替代品，可免费提供所有的基本安全功能，其功能特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于用户和角色的权限控制&lt;/li&gt;
&lt;li&gt;支持SSL和TLS方式安全认证&lt;/li&gt;
&lt;li&gt;支持LDAP认证&lt;br&gt;项目地址：&lt;a href=&quot;https://github.com/floragunncom/search-guard&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/floragunncom/search-guard&lt;/a&gt;&lt;br&gt;依赖关系：&lt;a href=&quot;https://github.com/floragunncom/search-guard/wiki&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/floragunncom/search-guard/wiki&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;安装插件&quot;&gt;&lt;a href=&quot;#安装插件&quot; class=&quot;headerlink&quot; title=&quot;安装插件&quot;&gt;&lt;/a&gt;安装插件&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;注意：插件版本需要和你使用的Elasticsearch版本对应。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/plugin install -b com.floragunn/search-guard-2/2.3.3.10
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/16.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/plugin install -b com.floragunn/search-guard-ssl/2.3.3.19
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意:以上两步在集群每个节点都要执行。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;证书&quot;&gt;&lt;a href=&quot;#证书&quot; class=&quot;headerlink&quot; title=&quot;证书&quot;&gt;&lt;/a&gt;证书&lt;/h3&gt;&lt;p&gt;根据自身情况修改官方脚本生成admin证书、node证书、根证书，将 node 证书和根证书放在 elasticsearch 配置文件目录下，同时将admin证书和根证书放到search-guard 配置文件目录下。&lt;br&gt;1.集群中任意一台机器下载 searchguard-ssl 的包，里面包含自动创建证书的脚本：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ wget https://github.com/floragunncom/search-guard-ssl/archive/v2.3.3.19.zip  
[es@log1 elasticsearch]$ unzip -oq v2.3.3.19.zip
[es@log1 elasticsearch]$ cd search-guard-ssl-2.3.3.19/example-pki-scripts/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;有三个脚本：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gen_client_node_cert.sh 创建客户端证书&lt;/li&gt;
&lt;li&gt;gen_node_cert.sh        创建节点证书&lt;/li&gt;
&lt;li&gt;gen_root_ca.sh          创建根证书&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.生成证书&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#生成文件：
./example.sh
#管理员的证书：
./gen_client_node_cert.sh admin changeit capass
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;命令会生成一个admin-keystore.jks的文件，把truststore.jks、admin-keystore.jks拷贝到${ES_HOME}/plugins/search-guard-2/sgconfig目录下&lt;/p&gt;
&lt;p&gt;给plugins/search-guard-2/tools/sgadmin.sh执行权限：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ chmod +x plugins/search-guard-2/tools/sgadmin.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将example-pki-scripts下生成的truststore.jks文件复制到ES集群中各个节点的config目录下，且把生成的node-&lt;em&gt;-keystore.jks文件复制到各个节点的config目录下。&lt;em&gt;*注意: The keystore files are specific per node. Copy node-0-keystore.jks to the config directory of your first ES node, node-1-keystore.jks to the second and so forth.&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 example-pki-scripts]$ cp truststore.jks node-0-keystore.jks /usr/local/elasticsearch/config/
[es@log1 example-pki-scripts]$ scp -p truststore.jks node-1-keystore.jks es@log2:/usr/local/elasticsearch/config/
[es@log1 example-pki-scripts]$ scp -p truststore.jks node-2-keystore.jks es@log3:/usr/local/elasticsearch/config/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.在Elasticsearch中添加search-guard和search-guard-ssl的配置项&lt;br&gt;找到config/elasticsearch.yml文件，添加以下配置项：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##########################################################
# SEARCH GUARD SSL                                                                             
# Configuration
##########################################################
################## Transport layer SSL ###################                        
####节点下放的是node-*，这里就写哪个
searchguard.ssl.transport.enabled: true
searchguard.ssl.transport.keystore_filepath: node-0-keystore.jks
searchguard.ssl.transport.keystore_password: changeit
searchguard.ssl.transport.truststore_filepath: truststore.jks
searchguard.ssl.transport.truststore_password: changeit
searchguard.ssl.transport.enforce_hostname_verification: false
searchguard.ssl.transport.resolve_hostname: false
searchguard.ssl.transport.enabled_protocols:
 - &amp;quot;TLSv1&amp;quot;
 - &amp;quot;TLSv1.1&amp;quot;
 - &amp;quot;TLSv1.2&amp;quot;

################# HTTP/REST layer SSL ####################
searchguard.ssl.http.enabled: true
searchguard.ssl.http.keystore_filepath: node-0-keystore.jks
searchguard.ssl.http.truststore_filepath: truststore.jks
searchguard.ssl.http.truststore_password: changeit
searchguard.ssl.http.enabled_protocols:
 - &amp;quot;TLSv1&amp;quot;
 - &amp;quot;TLSv1.1&amp;quot;
 - &amp;quot;TLSv1.2&amp;quot;

##### 管理员账号配置
searchguard.authcz.admin_dn:
  - &amp;quot;CN=admin, OU=client, O=client, L=Test, C=DE&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意：配置文件的node-x-keystore.jks对应每台config目录下放置的文件。&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;4.重启集群中的各台Elasticsearch然后初始化search-guard的配置项&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/elasticsearch -d
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3台集群中的节点都要重启。重启后，elasticsearch 之间的连接已经是加密的了。&lt;/p&gt;
&lt;p&gt;在log1上初始化searchguard索引：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd /usr/local/elasticsearch
$ plugins/search-guard-2/tools/sgadmin.sh -cd plugins/search-guard-2/sgconfig -ts plugins/search-guard-2/sgconfig/truststore.jks -ks  plugins/search-guard-2/sgconfig/admin-keystore.jks -kspass changeit -tspass changeit  -icl -nhnv -h 114.55.253.15 
Will connect to 114.55.253.15:9300 ... done
Contacting elasticsearch cluster &amp;apos;elasticsearch&amp;apos; and wait for YELLOW clusterstate ...
Clustername: wisedu
Clusterstate: GREEN
Number of nodes: 3
Number of data nodes: 3
searchguard index does not exists, attempt to create it ... done (with 2 replicas, auto expand replicas is off)
Populate config from /usr/local/elasticsearch/plugins/search-guard-2/sgconfig
Will update &amp;apos;config&amp;apos; with plugins/search-guard-2/sgconfig/sg_config.yml
   SUCC: Configuration for &amp;apos;config&amp;apos; created or updated
Will update &amp;apos;roles&amp;apos; with plugins/search-guard-2/sgconfig/sg_roles.yml
   SUCC: Configuration for &amp;apos;roles&amp;apos; created or updated
Will update &amp;apos;rolesmapping&amp;apos; with plugins/search-guard-2/sgconfig/sg_roles_mapping.yml
   SUCC: Configuration for &amp;apos;rolesmapping&amp;apos; created or updated
Will update &amp;apos;internalusers&amp;apos; with plugins/search-guard-2/sgconfig/sg_internal_users.yml
   SUCC: Configuration for &amp;apos;internalusers&amp;apos; created or updated
Will update &amp;apos;actiongroups&amp;apos; with plugins/search-guard-2/sgconfig/sg_action_groups.yml
   SUCC: Configuration for &amp;apos;actiongroups&amp;apos; created or updated
Done with success 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里的-icl是忽略集群的名称，不加会报错。&lt;br&gt;&lt;strong&gt;注意1：如果修改了searchguard，则需要重新加载配置执行。&lt;br&gt;注意2：search-guard配置的相关改动不需要重启elasticsearch，相关的配置实际上存储在searchguard 的indice下了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;其中 sg_internal_users.yml 保存着默认的用户和密码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ cd plugins/search-guard-2/sgconfig/
[es@log1 sgconfig]$ head -n 5  sg_internal_users.yml
# This is the internal user database
# The hash value is a bcrypt hash and can be generated with plugin/tools/hash.sh
admin:
  hash: $2a$12$VcCDgh2NDk07JGN0rjGbM.Ad41qVR/YFJcgHp0UGns5JDymv..TOG
  #password is: admin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;浏览器输入&lt;a href=&quot;https://114.55.253.15:9200/，输入用户名和密码admin/admin&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://114.55.253.15:9200/，输入用户名和密码admin/admin&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/17.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/18.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;HTTP和Java-Api方式访问ElasticSearch&quot;&gt;&lt;a href=&quot;#HTTP和Java-Api方式访问ElasticSearch&quot; class=&quot;headerlink&quot; title=&quot;HTTP和Java Api方式访问ElasticSearch&quot;&gt;&lt;/a&gt;HTTP和Java Api方式访问ElasticSearch&lt;/h3&gt;&lt;h4 id=&quot;HTTP方式访问Elasticsearch&quot;&gt;&lt;a href=&quot;#HTTP方式访问Elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;HTTP方式访问Elasticsearch&quot;&gt;&lt;/a&gt;HTTP方式访问Elasticsearch&lt;/h4&gt;&lt;p&gt;1.在浏览器上访问Elasticsearch，会直接出弹窗，输入用户名密码即可。&lt;br&gt;2.在服务器上使用curl的话需要加上参数-u adminName，类似如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -u adminName:adminname -XGET &amp;quot;http://114.55.253.15:9200/blog/article/1?pretty&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;Java-API中使用search-guard&quot;&gt;&lt;a href=&quot;#Java-API中使用search-guard&quot; class=&quot;headerlink&quot; title=&quot;Java API中使用search-guard&quot;&gt;&lt;/a&gt;Java API中使用search-guard&lt;/h4&gt;&lt;p&gt;1.加入jar包&lt;br&gt;进到/usr/local/elasticsearch/plugins/search-guard-ssl目录下拷贝以下jar包加到CLASSPATH中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;search-guard-ssl-2.3.4.14.jar
netty-buffer-4.0.37.Final.jar
netty-codec-4.0.37.Final.jar
netty-common-4.0.37.Final.jar
netty-handler-4.0.37.Final.jar
netty-transport-4.0.37.Final.jar
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.修改setting&lt;br&gt;以下部分需要从ES节点的这个目录下复制出来放到工程中，并且修改为你实际的路径。&lt;br&gt;目录：/usr/local/elasticsearch/plugins/search-guard-2/sgconfig中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.net.InetAddress;
import java.net.InetSocketAddress;
import org.elasticsearch.action.admin.cluster.node.info.NodesInfoRequest;
import org.elasticsearch.common.transport.InetSocketTransportAddress;
import com.floragunn.searchguard.ssl.SearchGuardSSLPlugin;

Settings settings = Settings.settingsBuilder()
        .put(&amp;quot;path.home&amp;quot;, &amp;quot;.&amp;quot;)
        .put(&amp;quot;cluster.name&amp;quot;, &amp;quot;wisedu&amp;quot;)
        .put(&amp;quot;searchguard.ssl.transport.enabled&amp;quot;, true)
        .put(&amp;quot;searchguard.ssl.transport.keystore_filepath&amp;quot;, &amp;quot;I:/Work/WorkSpace/ultrasearch/plugins/search-guard-2/sgconfig/admin-keystore.jks&amp;quot;)
        .put(&amp;quot;searchguard.ssl.transport.truststore_filepath&amp;quot;, &amp;quot;I:/Work/WorkSpace/ultrasearch/plugins/search-guard-2/sgconfig/truststore.jks&amp;quot;)
        .put(&amp;quot;searchguard.ssl.transport.enforce_hostname_verification&amp;quot;, false)              
        .build();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.修改client&lt;br&gt;以下为你想要连接的ES节点的ip和port，请修改为你实际的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;TransportClient client = TransportClient.builder().settings(settings).addPlugin(SearchGuardSSLPlugin.class).build();
TransportClient addTransportAddress = client.addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress(&amp;quot;114.55.253.15&amp;quot;, 9300)));
//do something with tc
NodesInfoRequest nodesInfoRequest= new NodesInfoRequest();
nodesInfoRequest.putHeader(&amp;quot;sg.impersonate.as&amp;quot;, &amp;quot;worf&amp;quot;);
client.admin().cluster().nodesInfo(new NodesInfoRequest()).actionGet();                               
client.admin().cluster().nodesInfo(nodesInfoRequest).actionGet();
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;search-guard中的用户权限管理&quot;&gt;&lt;a href=&quot;#search-guard中的用户权限管理&quot; class=&quot;headerlink&quot; title=&quot;search-guard中的用户权限管理&quot;&gt;&lt;/a&gt;search-guard中的用户权限管理&lt;/h3&gt;&lt;p&gt;相关配置文件的介绍:&lt;br&gt;searchguard 主要有5个配置文件在/ultra/ES/elasticsearch-2.3.4/plugins/search-guard-2/sgconfig 下：&lt;br&gt;1.sg_config.yml：主配置文件不需要做改动。&lt;/p&gt;
&lt;p&gt;2.sg_internal_users.yml：本地用户文件，定义用户密码以及对应的权限。例如：对于 ELK 我们需要一个 kibana 登录用户和一个 logstash 用户，如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kibana4:
  hash: $2a$12$xZOcnwYPYQ3zIadnlQIJ0eNhX1ngwMkTN.oMwkKxoGvDVPn4/6XtO
  #password is: kirk
  roles:
    - kibana4
logstash:
  hash: $2a$12$xZOcnwYPYQ3zIadnlQIJ0eNhX1ngwMkTN.oMwkKxoGvDVPn4/6XtO
  roles:
    - logstash
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意：用户的密码可用plugins/search-guard-2/tools/hash.sh生成。比如修改admin用户的默认密码为wisedu123：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 tools]$ ./hash.sh -p wisedu123
$2a$12$AmrZnl1wYGLGNODLDMY5/O86wmYE9eBcXtVa6AQjfzsF1gcKhkXqe
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.sg_roles.yml：权限配置文件，以下为kibana4 和 logstash 的权限样例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#&amp;lt;sg_role_name&amp;gt;:
#  cluster:
#    - &amp;apos;&amp;lt;permission&amp;gt;&amp;apos;
#  indices:
#    &amp;apos;&amp;lt;indexname or alias&amp;gt;&amp;apos;:
#      &amp;apos;&amp;lt;type&amp;gt;&amp;apos;:  
#        - &amp;apos;&amp;lt;permission&amp;gt;&amp;apos;
#      _dls_: &amp;apos;&amp;lt;querydsl query&amp;gt;&amp;apos;
#      _fls_:
#        - &amp;apos;&amp;lt;field&amp;gt;&amp;apos;
#        - &amp;apos;&amp;lt;field&amp;gt;&amp;apos;
sg_kibana4:
  cluster:
      - cluster:monitor/nodes/info
      - cluster:monitor/health
  indices:
    &amp;apos;*&amp;apos;:
      &amp;apos;*&amp;apos;:
        - indices:admin/mappings/fields/get
        - indices:admin/validate/query
        - indices:data/read/search
        - indices:data/read/msearch
        - indices:admin/get
        - indices:data/read/field_stats
    &amp;apos;?kibana&amp;apos;:
      &amp;apos;*&amp;apos;:
        - indices:admin/exists
        - indices:admin/mapping/put
        - indices:admin/mappings/fields/get
        - indices:admin/refresh
        - indices:admin/validate/query
        - indices:data/read/get
sg_logstash:
  cluster:
    - indices:admin/template/get
    - indices:admin/template/put
  indices:
    &amp;apos;logstash-*&amp;apos;:
      &amp;apos;*&amp;apos;:
        - WRITE
        - indices:data/write/bulk
        - indices:data/write/delete
        - indices:data/write/update
        - indices:data/read/search
        - indices:data/read/scroll
        - CREATE_INDEX
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.sg_roles_mapping.yml:定义用户的映射关系，添加 kibana 及 logstash 用户对应的映射如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sg_logstash:
  users:
    - logstash
sg_kibana4:
  backendroles:
    - kibana
  users:
    - kibana4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;5.sg_action_groups.yml：定义权限。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;补充一点：Search Guard可以实现和Logstash、Kibana的完美结合，对于使用ELK的用户大可不必担心，修改集成很容易的。&lt;br&gt;并且，Elasticsearch在5.x之后，对Search Guard、Search Guard SSL （当然还有Logstash 、Kibana）等插件的版本号都做了统一，变得更加的简单直观了。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;利用操作系统防火墙设置规避9200端口开放问题&quot;&gt;&lt;a href=&quot;#利用操作系统防火墙设置规避9200端口开放问题&quot; class=&quot;headerlink&quot; title=&quot;利用操作系统防火墙设置规避9200端口开放问题&quot;&gt;&lt;/a&gt;利用操作系统防火墙设置规避9200端口开放问题&lt;/h2&gt;&lt;p&gt;对于search-guard插件配置繁琐，也可以使用操作系统防火墙对访问源IP进行隔离控制。&lt;br&gt;架设Nginx反向代理服务器，ES主机防火墙设置仅允许Nginx所在主机访问ES主机的9200端口。&lt;/p&gt;
&lt;h3 id=&quot;安装防火墙&quot;&gt;&lt;a href=&quot;#安装防火墙&quot; class=&quot;headerlink&quot; title=&quot;安装防火墙&quot;&gt;&lt;/a&gt;安装防火墙&lt;/h3&gt;&lt;p&gt;在centos7上停止firewalld，启用iptables。&lt;br&gt;停止firewalld：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl stop firewalld.service   #停止firewall
# systemctl disable firewalld.service    #禁止firewall开机启动
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;安装iptables防火墙：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install -y iptables-services
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;配置防火墙&quot;&gt;&lt;a href=&quot;#配置防火墙&quot; class=&quot;headerlink&quot; title=&quot;配置防火墙&quot;&gt;&lt;/a&gt;配置防火墙&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;# vim /etc/sysconfig/iptables     #修改默认的配置文件

*filter
:INPUT ACCEPT [1837:149118]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [1656:224717]
-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT
-A INPUT -s 114.55.248.157/32 -p tcp -m tcp --dport 9200 -j ACCEPT
-A INPUT -p tcp -m tcp --dport 9200 -j DROP
COMMIT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/19.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;其实也就是加了两条规则：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;iptables -A INPUT -s 114.55.248.157 -p TCP --dport 9200 -j ACCEPT
iptables -A INPUT -p TCP --dport 9200 -j DROP
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动防火墙和设置开机启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl start iptables.service      
# systemctl enable iptables.service    
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;配置Nginx&quot;&gt;&lt;a href=&quot;#配置Nginx&quot; class=&quot;headerlink&quot; title=&quot;配置Nginx&quot;&gt;&lt;/a&gt;配置Nginx&lt;/h3&gt;&lt;p&gt;Nginx主要配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;upstream elasticsearch_servers {
        server 114.55.253.15:9200;
        server 114.55.132.143:9200;
        server 114.55.252.185:9200;
}

server {
        listen  8080;
        access_log logs/es_access.log main;

        location = /* {
            deny all;
        }

        location / {
            proxy_pass http://elasticsearch_servers;
        }

}
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;Elasticsearch设计之初就定位在纯私网环境而不做权限和安全控制，虽然有个叫Security Manager的配置，但是显然是不够的。但是后来专门出了个收费的shield来保护Elasticsearch，可是毕竟是收费的。当然我们也有替代品：search-guard。下面介绍下 Elasticsearch 围绕安全方面的的几点使用事项：&lt;br&gt;
    
    </summary>
    
      <category term="搜索引擎" scheme="http://yoursite.com/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
      <category term="Elasticsearch 搜索引擎" scheme="http://yoursite.com/tags/Elasticsearch-%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch介绍及安装部署</title>
    <link href="http://yoursite.com/2017/06/20/Elasticsearch%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/06/20/Elasticsearch介绍及安装部署/</id>
    <published>2017-06-20T03:29:04.000Z</published>
    <updated>2017-06-29T05:32:18.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Elasticsearch介绍&quot;&gt;&lt;a href=&quot;#Elasticsearch介绍&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch介绍&quot;&gt;&lt;/a&gt;Elasticsearch介绍&lt;/h2&gt;&lt;p&gt;Elasticsearch是一个分布式搜索服务，提供Restful API，底层基于Lucene，采用多shard的方式保证数据安全，并且提供自动resharding的功能，加之github等大型的站点也采用 Elasticsearch作为其搜索服务。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Elasticsearch集群安装部署&quot;&gt;&lt;a href=&quot;#Elasticsearch集群安装部署&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch集群安装部署&quot;&gt;&lt;/a&gt;Elasticsearch集群安装部署&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;JDK1.7、elasticsearch-2.2.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;JDK1.7、elasticsearch-2.2.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log3&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.253.15&lt;/td&gt;
&lt;td&gt;JDK1.7、elasticsearch-2.2.3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;安装JDK1-8&quot;&gt;&lt;a href=&quot;#安装JDK1-8&quot; class=&quot;headerlink&quot; title=&quot;安装JDK1.8&quot;&gt;&lt;/a&gt;安装JDK1.8&lt;/h3&gt;&lt;p&gt;版本是Elasticsearch 2.2.3，官方建议jdk是1.8。&lt;br&gt;&lt;strong&gt;3台机器都需要安装jdk1.7，添加新用户es。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# mkdir /usr/java
[root@log1 local]# tar zxf jdk-8u73-linux-x64.gz -C /usr/java/
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;添加用户&quot;&gt;&lt;a href=&quot;#添加用户&quot; class=&quot;headerlink&quot; title=&quot;添加用户&quot;&gt;&lt;/a&gt;添加用户&lt;/h3&gt;&lt;p&gt;Elasticsearch不能使用root用户去启动。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# groupadd -g 510 es
[root@log1 local]# useradd -g 510 -u 510 es
[root@log1 local]# echo &amp;quot;wisedu123&amp;quot; | passwd --stdin es &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;用新创建的用户登录shell，配置PATH环境变量。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 ~]$ vim ~/.bashrc
export JAVA_HOME=/usr/java/jdk1.8.0_73
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
[es@log1 ~]$ source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建安装elasticsearch的目录。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mkdir /usr/local/elasticsearch
# chown -R es.es elasticsearch
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;下载安装elasticsearch&quot;&gt;&lt;a href=&quot;#下载安装elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;下载安装elasticsearch&quot;&gt;&lt;/a&gt;下载安装elasticsearch&lt;/h3&gt;&lt;p&gt;es用户登录shell，下载安装elasticsearch。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 ~]$ cd /usr/local/elasticsearch/
[es@log1 elasticsearch]$ wget https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.2.3/elasticsearch-2.2.3.tar.gz 
[es@log1 elasticsearch]$ tar zxf elasticsearch-2.2.3.tar.gz 
[es@log1 elasticsearch]$ mv elasticsearch-2.2.1/* ./
[es@log1 elasticsearch]$ rm -rf elasticsearch-2.2.1
[es@log1 elasticsearch]$ rm -f elasticsearch-2.2.1.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;配置elasticsearch&quot;&gt;&lt;a href=&quot;#配置elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;配置elasticsearch&quot;&gt;&lt;/a&gt;配置elasticsearch&lt;/h3&gt;&lt;p&gt;1.配置elasticsearch 堆内存，编辑bin/elasticsearch.in.sh&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ vim bin/elasticsearch.in.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将参数：ES_MIN_MEM、ES_MAX_MEM设置为当前物理机内存的一半（注意单位，并保证两个值相等）&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;2.配置Elasticsearch集群名称以及节点名称、是否为主节点、path data等信息&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ vim config/elasticsearch.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;3.配置保护Elasticsearch使用的内存防止其被swapped。&lt;br&gt;在memory section下，启用配置：bootstrap.mlockall: true&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4.配置network host&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;【注意】:另外，请在Network段在多加两个配置，内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;network.bind_host: 114.55.29.86
# Set the address other nodes will use to communicate with this node. If not 
# set, it is automatically derived. It must point to an actual IP address.
network.publish_host: 114.55.29.86
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;如果不加上如上的配置，程序在连接时会报错：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;^A[2016-03-28 16:18:08.791] [ERROR] [godseye] [godseye] [RMI TCP Connection(2)-127.0.0.1] [com.wisedu.godseye.search.util.SearchUtil] [buildIndex:70] NoNodeAvailableException[None of the configured nodes are available: [{#transport#-1}{114.55.29.86}{114.55.29.86:9300}]]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;5.配置Elasticsearch的自动发现机制&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;另外两台也是做如上的安装配置。只不过在配置中需要修改下面几处。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/8.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Elasticsearch优化&quot;&gt;&lt;a href=&quot;#Elasticsearch优化&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch优化&quot;&gt;&lt;/a&gt;Elasticsearch优化&lt;/h2&gt;&lt;p&gt;1.检验配置中的bootstrap.mlockall: true是否生效&lt;br&gt;启动Elasticsearch：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ bin/elasticsearch -d
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在shell终端执行命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl http://114.55.29.86:9200/_nodes/process?pretty
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;关注这个这个请求返回数据中的mlockall的值，如果为false，则说明锁定内存失败，这可能由于运行elasticsearch的用户不具备这样的权限。解决该问题的方法是：&lt;br&gt;在运行elasticsearch之前，以root身份执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ulimit -l unlimited
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后再次重启elasticsearch。并查看上面的请求中的mlockall的值是否为true。&lt;br&gt;&lt;strong&gt;【注意】：这时候需要在root执行ulimit -l unlimited的shell终端上su - es，然后重启elasticsearch。因为这是命令行设置的ulimit -l unlimited，只对当前会话生效。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# ulimit -l unlimited
[root@log1 ~]# su - es
[es@log1 ~]$ ps -ef|grep elasticsearch
[es@log1 ~]$ kill -9 27189
[es@log1 ~]$ /usr/local/elasticsearch/bin/elasticsearch -d
[es@log1 ~]$ curl http://114.55.29.86:9200/_nodes/process?pretty
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/10.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;如果仍然是false，可能是下面的原因：&lt;br&gt;Another possible reason why mlockall can fail is that the temporary directory (usually /tmp) is mounted with the noexec option. This can be solved by specifying a new temp directory, by starting Elasticsearch with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./bin/elasticsearch -Djna.tmpdir=/path/to/new/dir
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;要想永久修改锁定内存大小无限制，需修改/etc/security/limits.conf，添加下面的内容，改完不需要重启系统，但是需要重新打开一个shell建立会话。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;es - memlock -1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，es代表运行elasticsearch的用户，-表示同时设置了soft和hard，memlock代表设置的是”锁定内存”这个类型，-1(unlimited或者infinity)代表没限制。&lt;/p&gt;
&lt;p&gt;2.配置操作系统文件描述符数&lt;br&gt;查看elasticsearch能打开的最大文件描述符个数：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl http://114.55.29.86:9200/_nodes/stats/process?pretty
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看参数：max_file_descriptors&lt;br&gt;推荐设置到32K甚至64K。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/11.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;或者输入下面的命令进行查看：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ulimit -a
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/12.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;设置需要修改：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim /etc/security/limits.conf
es               -       nofile          65535
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.增大虚拟内存mmap count配置&lt;br&gt;备注：如果你以.deb或.rpm包安装，则默认不需要设置此项，因为已经被自动设置，查看方式为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sysctl vm.max_map_count
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果是手动安装，以root身份执行如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sysctl vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;并修改文件使设置永久生效：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# vim /etc/sysctl.conf    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加一行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vm.max_map_count = 262144
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使生效：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# sysctl -p
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;改完后，重启elasticsearch。&lt;br&gt;在浏览器输入&lt;a href=&quot;http://ip:9200/，查看页面信息，是否正常启动。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ip:9200/，查看页面信息，是否正常启动。&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/13.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;另外两台也需要做这些优化。&lt;/p&gt;
&lt;h2 id=&quot;安装插件：中文分词器ik&quot;&gt;&lt;a href=&quot;#安装插件：中文分词器ik&quot; class=&quot;headerlink&quot; title=&quot;安装插件：中文分词器ik&quot;&gt;&lt;/a&gt;安装插件：中文分词器ik&lt;/h2&gt;&lt;p&gt;elasticsearch-analysis-ik 是一款中文的分词插件，支持自定义词库。项目地址为：&lt;a href=&quot;https://github.com/medcl/elasticsearch-analysis-ik&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/medcl/elasticsearch-analysis-ik&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装Maven&quot;&gt;&lt;a href=&quot;#安装Maven&quot; class=&quot;headerlink&quot; title=&quot;安装Maven&quot;&gt;&lt;/a&gt;安装Maven&lt;/h3&gt;&lt;p&gt;由于该项目使用了Maven来管理，源代码放到github上。所以要先在服务器上面安装Maven，便可以直接在服务器上面生成项目jar包，部署起来更加方便了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# yum install -y maven
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装ik&quot;&gt;&lt;a href=&quot;#安装ik&quot; class=&quot;headerlink&quot; title=&quot;安装ik&quot;&gt;&lt;/a&gt;安装ik&lt;/h3&gt;&lt;p&gt;注意分词插件的版本，2.2.3对应的插件版本是1.9.3&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/14.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 ~]$ git clone https://github.com/medcl/elasticsearch-analysis-ik.git
[es@log1 ~]$ cd elasticsearch-analysis-ik/
[es@log1 elasticsearch-analysis-ik]$ mvn package
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;拷贝和解压&quot;&gt;&lt;a href=&quot;#拷贝和解压&quot; class=&quot;headerlink&quot; title=&quot;拷贝和解压&quot;&gt;&lt;/a&gt;拷贝和解压&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch-analysis-ik]$ mkdir -p /usr/local/elasticsearch/plugins/ik
[es@log1 elasticsearch-analysis-ik]$ cp target/releases/elasticsearch-analysis-ik-1.9.3.zip /usr/local/elasticsearch/plugins/ik
[es@log1 ~]$ cd /usr/local/elasticsearch/plugins/ik/
[es@log1 ik]$ unzip -oq elasticsearch-analysis-ik-1.9.3.zip
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;重启elasticsearch&quot;&gt;&lt;a href=&quot;#重启elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;重启elasticsearch&quot;&gt;&lt;/a&gt;重启elasticsearch&lt;/h3&gt;&lt;p&gt;直接重启就可以了，不需要在Elasticsearch中添加配置index.analysis.analyzer.ik.type : “ik”  。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 ik]$ cd /usr/local/elasticsearch/bin/
[es@log1 bin]$ jps
20221 Jps
14910 Elasticsearch
[es@log1 bin]$ kill -9 14910
[es@log1 elasticsearch]$ bin/elasticsearch -d
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;另外两台也需要解压这个插件进去，重新启动。&lt;/p&gt;
&lt;h3 id=&quot;分词测试&quot;&gt;&lt;a href=&quot;#分词测试&quot; class=&quot;headerlink&quot; title=&quot;分词测试&quot;&gt;&lt;/a&gt;分词测试&lt;/h3&gt;&lt;p&gt;①    创建一个索引，名为index&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@log1 elasticsearch]$ curl -XPUT http://114.55.29.86:9200/index
{&amp;quot;acknowledged&amp;quot;:true}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;②    index some docs&lt;br&gt;命令行输入以下内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -XPOST http://114.55.29.86:9200/index/fulltext/1 -d&amp;apos;
{&amp;quot;content&amp;quot;:&amp;quot;美国留给伊拉克的是个烂摊子吗&amp;quot;}
&amp;apos;

curl -XPOST http://114.55.29.86:9200/index/fulltext/2 -d&amp;apos;
{&amp;quot;content&amp;quot;:&amp;quot;公安部：各地校车将享最高路权&amp;quot;}
&amp;apos;

curl -XPOST http:// 114.55.29.86:9200/index/fulltext/3 -d&amp;apos;
{&amp;quot;content&amp;quot;:&amp;quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船&amp;quot;}
&amp;apos;

curl -XPOST http:// 114.55.29.86:9200/index/fulltext/4 -d&amp;apos;
{&amp;quot;content&amp;quot;:&amp;quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&amp;quot;}
&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;③    测试&lt;br&gt;命令行输入：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -XPOST http://114.55.29.86:9200/index/fulltext/_search  -d&amp;apos;
{
    &amp;quot;query&amp;quot; : { &amp;quot;term&amp;quot; : { &amp;quot;content&amp;quot; : &amp;quot;中国&amp;quot; }},
    &amp;quot;highlight&amp;quot; : {
        &amp;quot;pre_tags&amp;quot; : [&amp;quot;&amp;lt;tag1&amp;gt;&amp;quot;, &amp;quot;&amp;lt;tag2&amp;gt;&amp;quot;],
        &amp;quot;post_tags&amp;quot; : [&amp;quot;&amp;lt;/tag1&amp;gt;&amp;quot;, &amp;quot;&amp;lt;/tag2&amp;gt;&amp;quot;],
        &amp;quot;fields&amp;quot; : {
            &amp;quot;content&amp;quot; : {}
        }
    }
}
&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;took&amp;quot;:74,&amp;quot;timed_out&amp;quot;:false,&amp;quot;_shards&amp;quot;:{&amp;quot;total&amp;quot;:5,&amp;quot;successful&amp;quot;:5,&amp;quot;failed&amp;quot;:0},&amp;quot;hits&amp;quot;:{&amp;quot;total&amp;quot;:2,&amp;quot;max_score&amp;quot;:1.5,&amp;quot;hits&amp;quot;:[{&amp;quot;_index&amp;quot;:&amp;quot;index&amp;quot;,&amp;quot;_type&amp;quot;:&amp;quot;fulltext&amp;quot;,&amp;quot;_id&amp;quot;:&amp;quot;4&amp;quot;,&amp;quot;_score&amp;quot;:1.5,&amp;quot;_source&amp;quot;:
{&amp;quot;content&amp;quot;:&amp;quot;中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&amp;quot;}
,&amp;quot;highlight&amp;quot;:{&amp;quot;content&amp;quot;:[&amp;quot;&amp;lt;tag1&amp;gt;中国&amp;lt;/tag1&amp;gt;驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首&amp;quot;]}},{&amp;quot;_index&amp;quot;:&amp;quot;index&amp;quot;,&amp;quot;_type&amp;quot;:&amp;quot;fulltext&amp;quot;,&amp;quot;_id&amp;quot;:&amp;quot;3&amp;quot;,&amp;quot;_score&amp;quot;:0.53699243,&amp;quot;_source&amp;quot;:
{&amp;quot;content&amp;quot;:&amp;quot;中韩渔警冲突调查：韩警平均每天扣1艘中国渔船&amp;quot;}
,&amp;quot;highlight&amp;quot;:{&amp;quot;content&amp;quot;:[&amp;quot;中韩渔警冲突调查：韩警平均每天扣1艘&amp;lt;tag1&amp;gt;中国&amp;lt;/tag1&amp;gt;渔船&amp;quot;]}}]}}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Elasticsearch/15.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Elasticsearch介绍&quot;&gt;&lt;a href=&quot;#Elasticsearch介绍&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch介绍&quot;&gt;&lt;/a&gt;Elasticsearch介绍&lt;/h2&gt;&lt;p&gt;Elasticsearch是一个分布式搜索服务，提供Restful API，底层基于Lucene，采用多shard的方式保证数据安全，并且提供自动resharding的功能，加之github等大型的站点也采用 Elasticsearch作为其搜索服务。&lt;br&gt;
    
    </summary>
    
      <category term="搜索引擎" scheme="http://yoursite.com/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
      <category term="搜索 Elasticsearch" scheme="http://yoursite.com/tags/%E6%90%9C%E7%B4%A2-Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Storm介绍及安装部署</title>
    <link href="http://yoursite.com/2017/06/10/Storm%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/06/10/Storm介绍及安装部署/</id>
    <published>2017-06-10T02:39:13.000Z</published>
    <updated>2017-06-12T04:36:51.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Apache-Storm是什么&quot;&gt;&lt;a href=&quot;#Apache-Storm是什么&quot; class=&quot;headerlink&quot; title=&quot;Apache Storm是什么&quot;&gt;&lt;/a&gt;Apache Storm是什么&lt;/h2&gt;&lt;p&gt;Apache Storm是自由开源的分布式实时计算系统，擅长处理海量数据，适用于数据实时处理而非批处理。&lt;br&gt;批处理使用的大多是鼎鼎大名的hadoop或者hive，作为一个批处理系统，hadoop以其吞吐量大、自动容错等优点，在海量数据处理上得到了广泛的使用。但是，hadoop不擅长实时计算，因为它天然就是为批处理而生的，这也是业界一致的共识。否则最近几年也不会有s4,storm,puma这些实时计算系统如雨后春笋般冒出来啦。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;举个搜索场景中的例子，当一个卖家发布了一条宝贝信息时，他希望的当然是这个宝贝马上就可以被卖家搜索出来、点击、购买啦，相反，如果这个宝贝要等到第二天或者更久才可以被搜出来，估计就会有不少损失了。&lt;br&gt;再举一个推荐的例子，如果用户昨天在淘宝上买了一双袜子，今天想买一副泳镜去游泳，但是却发现系统在不遗余力地给他推荐袜子、鞋子，根本对他今天寻找泳镜的行为视而不见，这样商家的利益就有所损失。这是因为后台系统做的是每天一次的全量处理，而且大多是在夜深人静之时做的，那么客户今天白天做的事情要到明天才能反映出来。这也就是为什么需要实时处理的原因。&lt;/p&gt;
&lt;h2 id=&quot;Apache-Storm核心概念&quot;&gt;&lt;a href=&quot;#Apache-Storm核心概念&quot; class=&quot;headerlink&quot; title=&quot;Apache Storm核心概念&quot;&gt;&lt;/a&gt;Apache Storm核心概念&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Nimbus：Storm集群主节点，负责资源分配和任务调度。我们提交任务和截止任务都是在Nimbus上操作的。一个Storm集群只有一个Nimbus节点。&lt;/li&gt;
&lt;li&gt;Supervisor：Storm集群工作节点，接受Nimbus分配任务，管理所有Worker。&lt;/li&gt;
&lt;li&gt;Worker：工作进程，每个工作进程中都有多个Task。&lt;/li&gt;
&lt;li&gt;Task：任务，每个Spout和Bolt都是一个任务，每个任务都是一个线程。&lt;/li&gt;
&lt;li&gt;Topology：计算拓扑，包含了应用程序的逻辑。&lt;/li&gt;
&lt;li&gt;Stream：消息流，关键抽象，是没有边界的Tuple序列。&lt;/li&gt;
&lt;li&gt;Spout：消息流的源头，Topology的消息生产者。&lt;/li&gt;
&lt;li&gt;Bolt：消息处理单元，可以过滤、聚合、查询数据库。&lt;/li&gt;
&lt;li&gt;Stream grouping：消息分发策略，一共6种，定义每个Bolt接受何种输入。&lt;/li&gt;
&lt;li&gt;Reliability：可靠性，Storm保证每个Tuple都会被处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Storm原理架构&quot;&gt;&lt;a href=&quot;#Storm原理架构&quot; class=&quot;headerlink&quot; title=&quot;Storm原理架构&quot;&gt;&lt;/a&gt;Storm原理架构&lt;/h2&gt;&lt;h3 id=&quot;Storm集群架构图&quot;&gt;&lt;a href=&quot;#Storm集群架构图&quot; class=&quot;headerlink&quot; title=&quot;Storm集群架构图&quot;&gt;&lt;/a&gt;Storm集群架构图&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Zookeeper集群在Storm集群中的作用：&lt;br&gt;Zookeeper集群负责Nimbus节点和Supervior节点之间的通信，监控各个节点之间的状态。比如通常我们提交任务的时候是在Nimbus节点上执行的，Nimbus节点通过zk集群将任务分发下去，而Supervisor是真正执行任务的地方。Nimbus节点通过zk集群监控各个Supervisor节点的状态，当某个Supervisor节点出现故障的时候，Nimbus节点就会通过zk集群将那个Supervisor节点上的任务重新分发，在其他Supervisor节点上执行。这就意味着Storm集群也是高可用集群，如果Nimbus节点出现故障的时候，整个任务并不会停止，但是任务的管理会出现影响，通常这种情况下我们只需要将Nimbus节点恢复就可以了。Nimbus节点不支持高可用，这也是Storm目前面临的问题之一。不过一般情况下，Nimbus节点的压力不大，通常不会出现问题。&lt;br&gt;一般情况下，Zookeeper集群的压力并不大，一般只需要部署3台就够了。Zookeeper集群在Storm集群中逻辑上是独立的，但在实际部署的时候，一般会将zk节点部署在Nimbus节点或Supervisor节点上。&lt;/p&gt;
&lt;h3 id=&quot;数据处理流程图&quot;&gt;&lt;a href=&quot;#数据处理流程图&quot; class=&quot;headerlink&quot; title=&quot;数据处理流程图&quot;&gt;&lt;/a&gt;数据处理流程图&lt;/h3&gt;&lt;p&gt;storm处理数据的特点：数据源源不断，不断处理。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;拓扑图分析&quot;&gt;&lt;a href=&quot;#拓扑图分析&quot; class=&quot;headerlink&quot; title=&quot;拓扑图分析&quot;&gt;&lt;/a&gt;拓扑图分析&lt;/h3&gt;&lt;p&gt;storm中是没有数据存储结构的，我们需要自己设计数据落地接口，指明数据存储到哪一部分中。Storm本身是不存储数据的。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Storm集群安装部署&quot;&gt;&lt;a href=&quot;#Storm集群安装部署&quot; class=&quot;headerlink&quot; title=&quot;Storm集群安装部署&quot;&gt;&lt;/a&gt;Storm集群安装部署&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6、apache-storm-1.0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6、apache-storm-1.0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log3&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.253.15&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6、apache-storm-1.0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;安装Zookeeper集群&quot;&gt;&lt;a href=&quot;#安装Zookeeper集群&quot; class=&quot;headerlink&quot; title=&quot;安装Zookeeper集群&quot;&gt;&lt;/a&gt;安装Zookeeper集群&lt;/h3&gt;&lt;p&gt;见之前的文章《Zookeeper介绍及安装部署》。&lt;/p&gt;
&lt;h3 id=&quot;安装Storm集群&quot;&gt;&lt;a href=&quot;#安装Storm集群&quot; class=&quot;headerlink&quot; title=&quot;安装Storm集群&quot;&gt;&lt;/a&gt;安装Storm集群&lt;/h3&gt;&lt;p&gt;log1、log2和log3部署storm集群，log1作为Nimbus节点，log2和log3作为surpervisor节点。&lt;/p&gt;
&lt;p&gt;1.下载安装软件并解压&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# wget http://apache.fayea.com/storm/apache-storm-1.0.0/apache-storm-1.0.0.tar.gz
[root@log1 local]# tar zxf apache-storm-1.0.0.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.配置storm&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# cd /usr/local/apache-storm-1.0.0/
[root@log1 apache-storm-1.0.0]# vim conf/storm.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(1)配置Zookeeper地址&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意: 如果Zookeeper集群使用的不是默认端口，那么还需要配置storm.zookeeper.port。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(2)storm.local.dir: The Nimbus and Supervisor daemons require a directory on the local disk to store small amounts of state (like jars, confs, and things like that).&lt;br&gt;添加一行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;storm.local.dir: &amp;quot;/usr/local/apache-storm-1.0.0/status&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这个status目录在storm启动的时候会自动创建，当然也可以提前创建好。&lt;/p&gt;
&lt;p&gt;(3)配置nimbus.seeds：用于配置主控节点的地址，可以配置多个。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;(4)配置supervisor.slots.ports&lt;br&gt;supervisor.slots.ports:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- 6700
- 6701
- 6702
- 6703
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;配置工作节点上的进程端口。你配置一个端口，意味着工作节点上启动一个worker，在实际的生产环境中，我们需要根据实际的物理配置以及每个节点上的负载情况来配置这个端口的数量。在这里每个节点我象征性的配置4个端口。&lt;br&gt;&lt;strong&gt;注意:以上配置，凡是有冒号的地方，冒号后都要有个空格。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;log2和log3主机也是同样的配置。拷贝这台机器的storm包到log2和log2主机：&lt;br&gt;[root@log1 local]# scp -pr apache-storm-1.0.0 root@114.55.29.241:/usr/local/&lt;br&gt;[root@log1 local]# scp -pr apache-storm-1.0.0 root@114.55.253.15:/usr/local/&lt;br&gt;(5)对于两台supervisor node，我们额外开启JMX支持，在配置文件中加入如下配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;supervisor.childopts: -verbose:gc -XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=9998
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/8.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;9998就是用于通过JMX收集supervisior JVM指标的端口。&lt;/p&gt;
&lt;p&gt;3.配置storm环境变量&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 apache-storm-0.10.0]# vim /etc/profile
export STORM_HOME=/usr/local/apache-storm-0.10.0
export PATH=$STORM_HOME/bin:$PATH
[root@log1 apache-storm-0.10.0]# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;启动storm-ui、Nimbus和Supervisor&quot;&gt;&lt;a href=&quot;#启动storm-ui、Nimbus和Supervisor&quot; class=&quot;headerlink&quot; title=&quot;启动storm ui、Nimbus和Supervisor&quot;&gt;&lt;/a&gt;启动storm ui、Nimbus和Supervisor&lt;/h2&gt;&lt;p&gt;log1节点启动nimbus和storm ui：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# nohup storm ui &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
[root@log1 ~]# nohup storm nimbus &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;log2和log3主机启动Supervisor节点：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 ~]# nohup storm supervisor &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
[root@log3 ~]# nohup storm supervisor &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;访问ui页面：&lt;br&gt;&lt;a href=&quot;http://114.55.29.86:8080/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://114.55.29.86:8080/&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Storm/9.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;界面介绍：&lt;br&gt;Used slots：使用的worker数。&lt;br&gt;Free slots：空闲的worker数。&lt;br&gt;Executors：每个worker的物理线程数。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Apache-Storm是什么&quot;&gt;&lt;a href=&quot;#Apache-Storm是什么&quot; class=&quot;headerlink&quot; title=&quot;Apache Storm是什么&quot;&gt;&lt;/a&gt;Apache Storm是什么&lt;/h2&gt;&lt;p&gt;Apache Storm是自由开源的分布式实时计算系统，擅长处理海量数据，适用于数据实时处理而非批处理。&lt;br&gt;批处理使用的大多是鼎鼎大名的hadoop或者hive，作为一个批处理系统，hadoop以其吞吐量大、自动容错等优点，在海量数据处理上得到了广泛的使用。但是，hadoop不擅长实时计算，因为它天然就是为批处理而生的，这也是业界一致的共识。否则最近几年也不会有s4,storm,puma这些实时计算系统如雨后春笋般冒出来啦。&lt;br&gt;
    
    </summary>
    
      <category term="实时处理" scheme="http://yoursite.com/categories/%E5%AE%9E%E6%97%B6%E5%A4%84%E7%90%86/"/>
    
    
      <category term="Storm 实时处理" scheme="http://yoursite.com/tags/Storm-%E5%AE%9E%E6%97%B6%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ介绍及安装部署</title>
    <link href="http://yoursite.com/2017/06/04/RabbitMQ%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/06/04/RabbitMQ介绍及安装部署/</id>
    <published>2017-06-04T12:45:36.000Z</published>
    <updated>2017-07-16T08:01:05.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;RabbitMQ介绍&quot;&gt;&lt;a href=&quot;#RabbitMQ介绍&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ介绍&quot;&gt;&lt;/a&gt;RabbitMQ介绍&lt;/h2&gt;&lt;p&gt;消息系统通过将消息的发送和接收分离来实现应用程序的异步和解偶。&lt;br&gt;或许你正在考虑进行数据投递，非阻塞操作或推送通知。或许你想要实现发布／订阅，异步处理，或者工作队列。所有这些都属于消息系统的模式。&lt;br&gt;RabbitMQ是一个消息代理，一个消息系统的媒介。它可以为你的应用提供一个通用的消息发送和接收平台，并且保证消息再传输过程中的安全。&lt;br&gt;RabbitMQ是一个在AMQP协议标准上完整的、可复用的企业消息系统。它遵循Mozilla Public License开源协议，采用Erlang语言实现的工业级的消息队列。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;RabbitMQ运行原理&quot;&gt;&lt;a href=&quot;#RabbitMQ运行原理&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ运行原理&quot;&gt;&lt;/a&gt;RabbitMQ运行原理&lt;/h2&gt;&lt;p&gt;RabbitMQ的两大核心组件是Exchange和Queue，以下是它的运行原理图：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;RabbitMQ重要术语&quot;&gt;&lt;a href=&quot;#RabbitMQ重要术语&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ重要术语&quot;&gt;&lt;/a&gt;RabbitMQ重要术语&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.Server(broker):&lt;/strong&gt; 接受客户端连接，实现AMQP消息队列和路由功能的进程。&lt;br&gt;&lt;strong&gt;2.Vitual Host:&lt;/strong&gt; 这是一个虚拟概念，类似于权限控制组，一个Vitual Host里面可以有若干个Exchange和Queue，但是权限控制的最小粒度是Vitual Host。&lt;br&gt;&lt;strong&gt;3.Exchange:&lt;/strong&gt; 接收生产者发送的消息，并根据Binding规则将消息路由给服务器中的队列。ExchangeType决定了Exchange路由消息的行为，例如，在RabbitMQ中，ExchangeType有direct、Fanout和Topic三种，不同类型的Exchange路由的行为是不一样的。&lt;br&gt;&lt;strong&gt;4.Message Queue:&lt;/strong&gt; 消息队列，用于存储还未被消费者消费的消息。&lt;br&gt;&lt;strong&gt;5.Message:&lt;/strong&gt; 由Header和Body组成，Header是由生产者添加的各种属性的集合，包括Message是否被持久化、由哪个Message Queue接受、优先级是多少等。而body是真正需要传输的APP数据。&lt;br&gt;&lt;strong&gt;6.BindingKey:&lt;/strong&gt; 所谓绑定就是将一个特定的一个Exchange和一个特定的Queue绑定起来，绑定关键字称为BindingKey。&lt;/p&gt;
&lt;h2 id=&quot;三种ExchangeType&quot;&gt;&lt;a href=&quot;#三种ExchangeType&quot; class=&quot;headerlink&quot; title=&quot;三种ExchangeType&quot;&gt;&lt;/a&gt;三种ExchangeType&lt;/h2&gt;&lt;p&gt;RabbitMQ消息模型的核心理念是：发布者（producer）不会直接发送任何消息给队列。事实上，发布者（producer）甚至不知道消息是否已经被投递到队列。&lt;br&gt;发布者（producer）只需要把消息发送给一个交换机（exchange）。交换机非常简单，它一边从发布者方接收消息，一边把消息推送到队列。交换机必须知道如何处理它接收到的消息，是应该推送到指定的队列还是是多个队列，或者是直接忽略消息。这些规则是通过交换机类型（exchange type）来定义的。&lt;/p&gt;
&lt;h3 id=&quot;直接式交换器类型-Direct&quot;&gt;&lt;a href=&quot;#直接式交换器类型-Direct&quot; class=&quot;headerlink&quot; title=&quot;直接式交换器类型(Direct)&quot;&gt;&lt;/a&gt;直接式交换器类型(Direct)&lt;/h3&gt;&lt;p&gt;Direct Exchange：直接交互式处理路由键。需要将一个队列绑定到交换机上，要求该消息与一个特定的路由键完全匹配，这是一个完整的匹配。路由键就是BindingKey。如果一个队列绑定到该交换机上要求路由键“dog”，则只有被标记为“dog”的消息才被转发，不会转发dog.puppy，也不会转发dog.guard，只会转发dog。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;广播式交换机类型-Fanout&quot;&gt;&lt;a href=&quot;#广播式交换机类型-Fanout&quot; class=&quot;headerlink&quot; title=&quot;广播式交换机类型(Fanout)&quot;&gt;&lt;/a&gt;广播式交换机类型(Fanout)&lt;/h3&gt;&lt;p&gt;Fanout Exchange：广播式路由键。你只需要简单的将队列绑定到交换机上。一个发送到交换机的消息都被转发到与该交换机绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。Fanout交换机转发消息是最快的。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;主题式交换金类型-Topic&quot;&gt;&lt;a href=&quot;#主题式交换金类型-Topic&quot; class=&quot;headerlink&quot; title=&quot;主题式交换金类型(Topic)&quot;&gt;&lt;/a&gt;主题式交换金类型(Topic)&lt;/h3&gt;&lt;p&gt;Topic Exchange：主题式交换器。通过消息的路由关键字和绑定关键字的模式匹配，将消息路由到被绑定的队列中。这种路由器类型可以被用来支持经典的发布/订阅消息传输类型——使用主题名字空间作为消息寻址模式，将消息传递给那些部分或者全部匹配主题模式的多个消费者。主题交换器类型的工作方式如下：绑定关键字用零个或多个标记构成，每一个标记之间用“.”字符分隔。绑定关键字必须用这种形式明确说明，并支持通配符：“&lt;em&gt;”匹配一个词组，“#”零个或多个词组。因此绑定关键字“&lt;/em&gt;.stock.#”匹配路由关键字“usd.stock”和“eur.stock.db”，但是不匹配“stock.nasdaq”。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;RabbitMQ集群种类&quot;&gt;&lt;a href=&quot;#RabbitMQ集群种类&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ集群种类&quot;&gt;&lt;/a&gt;RabbitMQ集群种类&lt;/h2&gt;&lt;p&gt;RabbitMQ是用erlang开发的，集群非常方便，因为erlang天生就是一门分布式语言,但其本身并不支持负载均衡。&lt;br&gt;Rabbit模式大概分为以下三种：单一模式、普通模式、镜像模式。&lt;br&gt;&lt;strong&gt;1.单一模式：&lt;/strong&gt;最简单的情况，非集群模式。&lt;br&gt;&lt;strong&gt;2.普通模式：&lt;/strong&gt;默认的集群模式。&lt;br&gt;对于Queue来说，消息实体只存在于其中一个节点，A、B两个节点仅有相同的元数据，即队列结构。&lt;br&gt;当消息进入A节点的Queue中后，consumer从B节点拉取时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。&lt;br&gt;所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连A或B，出口总在A，会产生瓶颈。&lt;br&gt;该模式存在一个问题就是当A节点故障后，B节点无法取到A节点中还未消费的消息实体。&lt;br&gt;如果做了消息持久化，那么得等A节点恢复，然后才可被消费；如果没有持久化的话，然后就没有然后了……&lt;br&gt;&lt;strong&gt;3.镜像模式：&lt;/strong&gt;把需要的队列做成镜像队列，存在于多个节点，属于RabbitMQ的HA方案。&lt;br&gt;该模式解决了上述问题，其实质和普通模式不同之处在于，消息实体会主动在镜像节点间同步，而不是在consumer取数据时临时拉取。&lt;br&gt;该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉。&lt;br&gt;所以在对可靠性要求较高的场合中适用。&lt;/p&gt;
&lt;h2 id=&quot;集群基本概念&quot;&gt;&lt;a href=&quot;#集群基本概念&quot; class=&quot;headerlink&quot; title=&quot;集群基本概念&quot;&gt;&lt;/a&gt;集群基本概念&lt;/h2&gt;&lt;p&gt;RabbitMQ的集群节点包括内存节点、磁盘节点。内存节点就是将所有数据放在内存，磁盘节点将数据放在磁盘。不过，如果在投递消息时，打开了消息的持久化，那么即使是内存节点，数据还是安全的放在磁盘。&lt;br&gt;一个rabbitmq集群中可以共享 user，vhost，queue，exchange等，所有的数据和状态都是必须在所有节点上复制的，一个例外是，那些当前只属于创建它的节点的消息队列，尽管它们可见且可被所有节点读取。rabbitmq节点可以动态的加入到集群中，一个节点它可以加入到集群中，也可以从集群环集群会进行一个基本的负载均衡。&lt;br&gt;集群中有两种节点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内存节点：只保存状态到内存（一个例外的情况是：持久的queue的持久内容将被保存到disk）&lt;/li&gt;
&lt;li&gt;磁盘节点：保存状态到内存和磁盘。&lt;br&gt;内存节点虽然不写入磁盘，但是它执行比磁盘节点要好。集群中，只需要一个磁盘节点来保存状态就足够了。&lt;br&gt;如果集群中只有内存节点，那么不能停止它们，否则所有的状态，消息等都会丢失。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;镜像模式部署集群&quot;&gt;&lt;a href=&quot;#镜像模式部署集群&quot; class=&quot;headerlink&quot; title=&quot;镜像模式部署集群&quot;&gt;&lt;/a&gt;镜像模式部署集群&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;console&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.248.157&lt;/td&gt;
&lt;td&gt;haproxy-1.5.14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;erlang、rabbitmq-server-3.5.0-1.noarch.rpm&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;erlang、rabbitmq-server-3.5.0-1.noarch.rpm&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;【环境说明】:集群中有3台机器，console主机作为反向代理，另外两台是rabbitmq server，一台使用磁盘模式，一台使用内存模式。&lt;br&gt;【注意】:请确保两台rabbitmq server主机的/etc/hosts里有ip地址和主机名的对应关系。如：&lt;br&gt;114.55.29.86 log1&lt;br&gt;114.55.29.241 log2&lt;/p&gt;
&lt;h3 id=&quot;集群每个节点安装rabbitmq-server&quot;&gt;&lt;a href=&quot;#集群每个节点安装rabbitmq-server&quot; class=&quot;headerlink&quot; title=&quot;集群每个节点安装rabbitmq server&quot;&gt;&lt;/a&gt;集群每个节点安装rabbitmq server&lt;/h3&gt;&lt;p&gt;log1和log2分别安装rabbitmq server。&lt;br&gt;1.配置好epel源&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rpm -Uvh http://download.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.安装依赖包&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# yum install erlang –y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.安装rabbitMq&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.5.0/rabbitmq-server-3.5.0-1.noarch.rpm
[root@log1 local]# yum localinstall rabbitmq-server-3.5.0-1.noarch.rpm -y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.添加开机启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# chkconfig rabbitmq-server on
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;5.启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# service rabbitmq-server start
Starting rabbitmq-server: SUCCESS
rabbitmq-server.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;6.开启web管理界面&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# rabbitmq-plugins enable rabbitmq_management
The following plugins have been enabled:
  mochiweb
  webmachine
  rabbitmq_web_dispatch
  amqp_client
  rabbitmq_management_agent
  rabbitmq_management

Applying plugin configuration to rabbit@log1... started 6 plugins.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;7.修改配置文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# cp /usr/share/doc/rabbitmq-server-3.5.0/rabbitmq.config.example /etc/rabbitmq/rabbitmq.config
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;修改用户配置 让其可以通过远程访问 不限于localhost。注意：rabbitmq从3.3.0开始禁止使用guest/guest权限通过除localhost外的访问。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# vim /etc/rabbitmq/rabbitmq.config
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;{loopback_users, []} 删除前面的注释%%，同时注意后面的逗号，只有一个配置项的时候，请删除后面的逗号。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;以上7步在log2主机上都要执行&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;8.因为默认用户为guest，要添加其他的管理账户。&lt;br&gt;&lt;strong&gt;注意:如果是集群的话，只要在一台主机设置即可，其它会自动同步。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# rabbitmqctl add_user zxadmin wisedu@2016
Creating user &amp;quot;zxadmin&amp;quot; ...
[root@log1 local]# rabbitmqctl set_user_tags zxadmin administrator
Setting tags for user &amp;quot;zxadmin&amp;quot; to [administrator] ...
[root@log1 local]# rabbitmqctl set_permissions -p / zxadmin &amp;quot;.*&amp;quot; &amp;quot;.*&amp;quot; &amp;quot;.*&amp;quot;
Setting permissions for user &amp;quot;zxadmin&amp;quot; in vhost &amp;quot;/&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;9.重启rabbitMQ&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# service rabbitmq-server restart
Restarting rabbitmq-server: SUCCESS
rabbitmq-server.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;10.访问管控台&lt;br&gt;浏览器输入URL：&lt;a href=&quot;http://ip/15672&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ip/15672&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;设置每个节点Cookie&quot;&gt;&lt;a href=&quot;#设置每个节点Cookie&quot; class=&quot;headerlink&quot; title=&quot;设置每个节点Cookie&quot;&gt;&lt;/a&gt;设置每个节点Cookie&lt;/h3&gt;&lt;p&gt;Rabbitmq的集群是依赖于erlang的集群来工作的，所以必须先构建起erlang的集群环境。Erlang的集群中各节点是通过一个magic cookie来实现的，这个cookie存放在  /var/lib/rabbitmq/.erlang.cookie 中，文件是400的权限。所以必须保证各节点cookie保持一致，否则节点之间就无法通信。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/8.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;将其中一台节点上的.erlang.cookie值复制下来保存到其他节点上。或者使用scp的方法也可，但是要注意文件的权限和属主属组。我这里将log1中的cookie 复制到log2中。&lt;br&gt;1.因为.erlang.cookie是只读的，先修改下log2中的.erlang.cookie权限&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 rabbitmq]# chmod 777 .erlang.cookie
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.copy log1主机上的.erlang.cookie到log2主机/var/lib/rabbitmq/目录下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 rabbitmq]# scp -p .erlang.cookie root@114.55.29.241:/var/lib/rabbitmq/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.停止所有节点RabbitMq服务，然后使用detached参数独立运行，这步很关键，尤其增加节点停止节点后再次启动遇到无法启动都可以参照这个顺序。&lt;br&gt;停止：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 rabbitmq]# service rabbitmq-server stop
[root@log2 rabbitmq]# service rabbitmq-server stop
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 rabbitmq]# rabbitmq-server -detached
Warning: PID file not written; -detached was passed.
[root@log2 rabbitmq]# rabbitmq-server -detached
Warning: PID file not written; -detached was passed.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.分别查看下每个节点&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 rabbitmq]# rabbitmqctl cluster_status
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 rabbitmq]# rabbitmqctl cluster_status
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/10.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;5.将log2作为内存节点与log1连接起来，在log2上执行如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 rabbitmq]# rabbitmqctl stop_app
[root@log2 rabbitmq]# rabbitmqctl join_cluster --ram rabbit@log1
[root@log2 rabbitmq]# rabbitmqctl start_app
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上述命令先停掉rabbitmq应用，然后调用cluster命令，将log2连接到log1，使两者成为一个集群，最后重启log2的rabbitmq应用。在这个cluster命令下，log2是内存节点，log1是磁盘节点（RabbitMQ启动后，默认是磁盘节点）。&lt;br&gt;log1如果要使log2在集群里也是磁盘节点，join_cluster 命令去掉–ram参数即可：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 rabbitmq]# rabbitmqctl join_cluster rabbit@log1 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;只要在节点列表里包含了自己，它就成为一个磁盘节点。在RabbitMQ集群里，必须至少有一个磁盘节点存在。&lt;/p&gt;
&lt;p&gt;6.再次查看各节点状态&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 rabbitmq]# rabbitmqctl cluster_status
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/11.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 rabbitmq]# rabbitmqctl cluster_status
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/12.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这样RabbitMQ集群就正常工作了。可以访问任意一个web管控台：&lt;a href=&quot;http://ip/15672&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ip/15672&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/13.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;添加镜像模式配置&quot;&gt;&lt;a href=&quot;#添加镜像模式配置&quot; class=&quot;headerlink&quot; title=&quot;添加镜像模式配置&quot;&gt;&lt;/a&gt;添加镜像模式配置&lt;/h3&gt;&lt;p&gt;上面配置RabbitMQ默认集群模式，但并不保证队列的高可用性，尽管交换机、绑定这些可以复制到集群里的任何一个节点，但是队列内容不会复制，虽然该模式解决一部分节点压力，但队列节点宕机直接导致该队列无法使用，只能等待重启，所以要想在队列节点宕机或故障也能正常使用，就要复制队列内容到集群里的每个节点，需要创建镜像队列。&lt;br&gt;1.安装haproxy&lt;br&gt;haproxy是在主机名为console上安装的。可以选择源代码编译安装或者yum安装，在这里我选择了yum安装。安装版本：haproxy-1.5.14-3.el7.x86_64 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# yum install -y haproxy
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.修改配置/etc/haproxy/haproxy.cfg&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# vim /etc/haproxy/haproxy.cfg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;删除 main frontend which proxys to the backends以下的所有内容，并添加&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;listen rabbitmq_cluster 0.0.0.0:5672
    mode tcp
    balance roundrobin
    server   rqslave1 114.55.29.241:5672 check inter 2000 rise 2 fall 3
    server   rqmaster 114.55.29.86:5672 check inter 2000 rise 2 fall 3
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果有3台或3台以上，可以把disc节点注释掉，原因就是让rabbitmq性能最佳化。这样负载均衡器会监听5672端口，轮询多个内存节点的5672端口，磁盘节点可以只做备份不提供给生产者、消费者使用，当然如果我们服务器资源充足情况也可以配置多个磁盘节点。此外，还需要修改defaults段配置：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/14.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;检查配置文件语法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# haproxy -c -f /etc/haproxy/haproxy.cfg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动haproxy：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# service haproxy start
Redirecting to /bin/systemctl start  haproxy.service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.配置策略：设置ha模式&lt;br&gt;使用Rabbit镜像功能，需要基于rabbitmq策略来实现，政策是用来控制和修改群集范围的某个vhost队列行为和Exchange行为。&lt;br&gt;其中ha-mode有三种模式:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;all: 同步至所有的；&lt;/li&gt;
&lt;li&gt;exactly: 同步最多N个机器. 当现有集群机器数小于N时,同步所有,大于等于N时则不进行同步. N需要额外通过ha-params来指定；&lt;/li&gt;
&lt;li&gt;&lt;p&gt;nodes: 只同步至符合指定名称的nodes. N需要额外通过ha-params来指定。&lt;br&gt;在cluster中任意节点启用策略，策略会自动同步到集群节点。我这里设置的是同步全部的queue, 可以按需自己选择指定的queue。语法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rabbitmqctl set_policy  [-p  vhostpath ] { name } { pattern } { definition } [ priority ]
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在log1主机上执行如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# rabbitmqctl set_policy ha-all &amp;quot;^&amp;quot; &amp;apos;{&amp;quot;ha-mode&amp;quot;:&amp;quot;all&amp;quot;}&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/RabbitMQ/15.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这行命令创建了一个策略，策略名称为ha-all,策略模式为 all ，即复制到所有节点，包含新增节点，策略正则表达式为 “^” 表示所有匹配所有队列名称。&lt;/p&gt;
&lt;h3 id=&quot;集群退出&quot;&gt;&lt;a href=&quot;#集群退出&quot; class=&quot;headerlink&quot; title=&quot;集群退出&quot;&gt;&lt;/a&gt;集群退出&lt;/h3&gt;&lt;p&gt;假设要把log2退出集群。&lt;br&gt;在log2上执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#rabbitmqctl stop_app
#rabbitmqctl reset
#rabbitmqctl start_app 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在集群主节点上执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# rabbitmqctl forget_cluster_node rabbit@log2
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;RabbitMQ介绍&quot;&gt;&lt;a href=&quot;#RabbitMQ介绍&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ介绍&quot;&gt;&lt;/a&gt;RabbitMQ介绍&lt;/h2&gt;&lt;p&gt;消息系统通过将消息的发送和接收分离来实现应用程序的异步和解偶。&lt;br&gt;或许你正在考虑进行数据投递，非阻塞操作或推送通知。或许你想要实现发布／订阅，异步处理，或者工作队列。所有这些都属于消息系统的模式。&lt;br&gt;RabbitMQ是一个消息代理，一个消息系统的媒介。它可以为你的应用提供一个通用的消息发送和接收平台，并且保证消息再传输过程中的安全。&lt;br&gt;RabbitMQ是一个在AMQP协议标准上完整的、可复用的企业消息系统。它遵循Mozilla Public License开源协议，采用Erlang语言实现的工业级的消息队列。&lt;br&gt;
    
    </summary>
    
      <category term="消息队列" scheme="http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="消息队列" scheme="http://yoursite.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Kafka介绍及安装部署</title>
    <link href="http://yoursite.com/2017/05/28/Kafka%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/05/28/Kafka介绍及安装部署/</id>
    <published>2017-05-28T11:46:22.000Z</published>
    <updated>2017-07-15T02:11:35.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;消息中间件&quot;&gt;&lt;a href=&quot;#消息中间件&quot; class=&quot;headerlink&quot; title=&quot;消息中间件&quot;&gt;&lt;/a&gt;消息中间件&lt;/h2&gt;&lt;p&gt;消息中间件是在消息的传输过程中保存消息的容器。消息中间件在将消息从消息生产者到消费者时充当中间人的作用。队列的主要目的是提供路由并保证消息的传送；如果发送消息时接收者不可用，消息对列会保留消息，直到可以成功地传递它为止，当然，消息队列保存消息也是有期限的。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;消息中间件特点&quot;&gt;&lt;a href=&quot;#消息中间件特点&quot; class=&quot;headerlink&quot; title=&quot;消息中间件特点&quot;&gt;&lt;/a&gt;消息中间件特点&lt;/h2&gt;&lt;p&gt;1.采用异步处理模式&lt;br&gt;消息发送者可以发送一个消息而无须等待响应。消息发送者将消息发送到一条虚拟的通道（主题或者队列）上，消息接收者则订阅或者监听该通道。一条消息可能最终转发给一个或多个消息接收者，这些接收者都无需对消息发送者做出同步回应。整个过程是异步的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比如用户信息注册。注册完成后过段时间发送邮件或者短信。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.应用程序和应用程序调用关系为松耦合关系&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;发送者和接收者不必要了解对方、只需要确认消息&lt;/li&gt;
&lt;li&gt;发送者和接收者不必同时在线&lt;br&gt;比如在线交易系统为了保证数据的最终一致，在支付系统处理完成后会把支付结果放到信息中间件里通知订单系统修改订单支付状态。两个系统通过消息中间件解耦。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;消息中间件的传递模型&quot;&gt;&lt;a href=&quot;#消息中间件的传递模型&quot; class=&quot;headerlink&quot; title=&quot;消息中间件的传递模型&quot;&gt;&lt;/a&gt;消息中间件的传递模型&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.点对点模型(PTP)&lt;/strong&gt;&lt;br&gt;点对点模型用于消息生产者和消息消费者之间点对点的通信。消息生产者将消息发送到由某个名字标识的特定消费者。这个名字实际上对应于消费服务中的一个队列(Queue)，在消息传递给消费者之前它被存储在这个队列中。队列消息可以放在内存中也可以是持久的，以保证在消息服务出现故障时仍然能够传递消息。&lt;br&gt;点对点模型特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消息只有一个消费者&lt;/li&gt;
&lt;li&gt;发送者和接受者没有时间依赖&lt;/li&gt;
&lt;li&gt;接受者确认消息接受和处理成功&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/1.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.发布—订阅模型(Pub/Sub)&lt;/strong&gt;&lt;br&gt;发布者/订阅者模型支持向一个特定的消息主题生产消息。0或多个订阅者可能对接收来自特定消息主题的消息感兴趣。在这种模型下，发布者和订阅者彼此不知道对方。这种模式好比是匿名公告板。这种模式被概括为：多个消费者可以获得消息。在发布者和订阅者之间存在时间依赖性。发布者需要建立一个订阅(subscription)，以便能够让消费者订阅。订阅者必须保持持续的活动状态以接收消息，除非订阅者建立了持久的订阅。在这种情况下，在订阅者未连接时发布的消息将在订阅者重新连接时重新发布。&lt;br&gt;其实消息中间件，像MySQL其实也可以作为消息中间件，只要你把消息中间件原理搞清楚，你会发现目前所有的存储，包括NoSQL，只要支持顺序性东西的，就可以作为一个消息中间件。就看你怎么去利用它了。就像redis里面那个队列list，就可以作为一个消息队列。&lt;br&gt;发布—订阅模型特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消息可以有多个订阅者&lt;/li&gt;
&lt;li&gt;客户端只有订阅后才能接收到消息&lt;/li&gt;
&lt;li&gt;持久订阅和非持久订阅&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(1)发布者和订阅者有时间依赖&lt;br&gt;接收者和发布者只有建立订阅关系才能收到消息。&lt;br&gt;(2)持久订阅&lt;br&gt;订阅关系建立后，消息就不会消失，不管订阅者是否在线。&lt;br&gt;(3)非持久订阅&lt;br&gt;订阅者为了接收消息，必须一直在线&lt;br&gt;当只有一个订阅者时约等于点对点模式。&lt;br&gt;&lt;strong&gt;大部分情况下会使用持久订阅。常用的消息队列有Kafka、RabbitMQ、ActiveMQ、metaq等&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Kafka介绍&quot;&gt;&lt;a href=&quot;#Kafka介绍&quot; class=&quot;headerlink&quot; title=&quot;Kafka介绍&quot;&gt;&lt;/a&gt;Kafka介绍&lt;/h2&gt;&lt;p&gt;Kafka是一种分布式消息系统，由LinkedIn使用Scala编写，用作LinkedIn的活动流(Activity Stream)和运营数据处理管道(Pipeline)的基础，具有高水平扩展和高吞吐量。&lt;br&gt;目前越来越多的开源分布式处理系统如Apache flume、Apache Storm、Spark、Elasticsearch都支持与Kafka集成。&lt;/p&gt;
&lt;h2 id=&quot;安装部署Kafka集群&quot;&gt;&lt;a href=&quot;#安装部署Kafka集群&quot; class=&quot;headerlink&quot; title=&quot;安装部署Kafka集群&quot;&gt;&lt;/a&gt;安装部署Kafka集群&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;JDK1.7、kafka_2.11-0.9.0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;JDK1.7、kafka_2.11-0.9.0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log3&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.253.15&lt;/td&gt;
&lt;td&gt;JDK1.7、kafka_2.11-0.9.0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;安装JDK1-7&quot;&gt;&lt;a href=&quot;#安装JDK1-7&quot; class=&quot;headerlink&quot; title=&quot;安装JDK1.7&quot;&gt;&lt;/a&gt;安装JDK1.7&lt;/h3&gt;&lt;p&gt;3台机器都需要安装JDK1.7。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# mkdir /usr/java
[root@log1 local]# tar zxf jdk-7u80-linux-x64.gz -C /usr/java/
[root@log1 local]# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.7.0_80
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
[root@log1 local]# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装集群&quot;&gt;&lt;a href=&quot;#安装集群&quot; class=&quot;headerlink&quot; title=&quot;安装集群&quot;&gt;&lt;/a&gt;安装集群&lt;/h3&gt;&lt;p&gt;需要先安装好Zookeeper集群，见之前的文章《Zookeeper介绍及安装部署》。&lt;br&gt;1.创建消息持久化目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# mkdir /kafkaLogs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.下载解压kafka，版本是kafka_2.11-0.9.0.1&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# wget http://mirrors.cnnic.cn/apache/kafka/0.9.0.1/kafka_2.11-0.9.0.1.tgz
[root@log1 local]# tar zxf kafka_2.11-0.9.0.1.tgz
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.修改配置&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# cd kafka_2.11-0.9.0.1/config/
[root@log1 config]# vim server.properties
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(1)修改broker.id&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(2)修改kafka监听地址&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意: advertised.host.name参数用来配置返回的host.name值，把这个参数配置为IP地址。这样客户端在使用java.net.InetAddress.getCanonicalHostName()获取时拿到的就是ip地址而不是主机名。&lt;/strong&gt;&lt;br&gt;(3)修改消息持久化目录&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(4)修改zk地址&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(5)添加启用删除topic配置&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(6)关闭自动创建topic&lt;br&gt;是否允许自动创建topic。如果设为true，那么produce，consume或者fetch metadata一个不存在的topic时，就会自动创建一个默认replication factor和partition number的topic。默认是true。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;auto.create.topics.enable=false
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4.把log1的配置好的kafka拷贝到log2和log3上&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# scp -rp kafka_2.11-0.9.0.1 root@114.55.29.241:/usr/local/
[root@log1 local]# scp -rp kafka_2.11-0.9.0.1 root@114.55.253.15:/usr/local/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;5.log2和log3主机上创建消息持久化目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 ~]# mkdir /kafkaLogs
[root@log3 ~]# mkdir /kafkaLogs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;6.修改log2配置文件中的broker.id为1，log3主机的为2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 config]# vim server.properties
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;启动集群&quot;&gt;&lt;a href=&quot;#启动集群&quot; class=&quot;headerlink&quot; title=&quot;启动集群&quot;&gt;&lt;/a&gt;启动集群&lt;/h3&gt;&lt;p&gt;log1主机启动kafka：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# cd /usr/local/kafka_2.11-0.9.0.1/
[root@log1 kafka_2.11-0.9.0.1]# JMX_PORT=9997 bin/kafka-server-start.sh -daemon config/server.properties &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/10.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;log2主机启动kafka：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 ~]# cd /usr/local/kafka_2.11-0.9.0.1/
[root@log2 kafka_2.11-0.9.0.1]# JMX_PORT=9997 bin/kafka-server-start.sh -daemon config/server.properties &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;log3主机启动kafka：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log3 ~]# cd /usr/local/kafka_2.11-0.9.0.1/
[root@log3 kafka_2.11-0.9.0.1]# JMX_PORT=9997 bin/kafka-server-start.sh -daemon config/server.properties &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;脚本定期清理logs下的日志文件&quot;&gt;&lt;a href=&quot;#脚本定期清理logs下的日志文件&quot; class=&quot;headerlink&quot; title=&quot;脚本定期清理logs下的日志文件&quot;&gt;&lt;/a&gt;脚本定期清理logs下的日志文件&lt;/h3&gt;&lt;p&gt;默认kafka是按天切割日志的，而且不删除：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/11.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这里写一个简单的脚本来清理这些日志，主要是清理server.log和controller.log。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# cd /usr/local/kafka_2.11-0.9.0.1/
[root@log1 kafka_2.11-0.9.0.1]# vim clean_kafkalog.sh
#!/bin/bash
###Description:This script is used to clear kafka logs, not message file.
###Written by: jkzhao - jkzhao@wisedu.com  
###History: 2016-04-18 First release.

# log file dir.
logDir=/usr/local/kafka_2.11-0.9.0.1/logs

# Reserved 7 files.
COUNT=7

ls -t $logDir/server.log* | tail -n +$[$COUNT+1] | xargs rm -f
ls -t $logDir/controller.log* | tail -n +$[$COUNT+1] | xargs rm -f
ls -t $logDir/state-change.log* | tail -n +$[$COUNT+1] | xargs rm -f
ls -t $logDir/log-cleaner.log* | tail -n +$[$COUNT+1] | xargs rm –f
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;赋予脚本执行权限：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 kafka_2.11-0.9.0.1]# chmod +x clean_kafkalog.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;周期性任务策略：每周日的0点0分去执行这个脚本。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 logs]# crontab -e
0 0 * * 0 /usr/local/kafka_2.11-0.9.0.1/clean_kafkalog.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/12.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;把清理日志的脚本拷贝到第二台和第三台主机：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 kafka_2.11-0.9.0.1]# scp -p clean_kafkalog.sh root@114.55.29.241:/usr/local/kafka_2.11-0.9.0.1
[root@log1 kafka_2.11-0.9.0.1]# scp -p clean_kafkalog.sh root@114.55.253.15:/usr/local/kafka_2.11-0.9.0.1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同样的需要配置周期性任务策略。&lt;/p&gt;
&lt;h3 id=&quot;停止kafka命令&quot;&gt;&lt;a href=&quot;#停止kafka命令&quot; class=&quot;headerlink&quot; title=&quot;停止kafka命令&quot;&gt;&lt;/a&gt;停止kafka命令&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@log1 ~]# /usr/local/kafka_2.11-0.9.0.1/bin/kafka-server-stop.sh
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;测试集群&quot;&gt;&lt;a href=&quot;#测试集群&quot; class=&quot;headerlink&quot; title=&quot;测试集群&quot;&gt;&lt;/a&gt;测试集群&lt;/h3&gt;&lt;p&gt;1.log1主机上创建一个名为test的topic&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 kafka_2.11-0.9.0.1]# bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.log2和log3主机上利用命令行工具创建一个consumer程序&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 kafka_2.11-0.9.0.1]# bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
[root@log2 kafka_2.11-0.9.0.1]# bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.log1主机上利用命令行工具创建一个producer程序&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 kafka_2.11-0.9.0.1]# bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;log1主机上终端输入message，然后到log2和log3主机的终端查看&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/13.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/14.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;创建生产环境topic&quot;&gt;&lt;a href=&quot;#创建生产环境topic&quot; class=&quot;headerlink&quot; title=&quot;创建生产环境topic&quot;&gt;&lt;/a&gt;创建生产环境topic&lt;/h3&gt;&lt;p&gt;如果kafka集群是3台，我们创建一个名为business的Topic，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 3 --topic business
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意:为Topic创建分区时，–partitions(分区数)最好是broker数量的整数倍，这样才能使一个Topic的分区均匀的分布在整个Kafka集群中。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;Kafka常用命令&quot;&gt;&lt;a href=&quot;#Kafka常用命令&quot; class=&quot;headerlink&quot; title=&quot;Kafka常用命令&quot;&gt;&lt;/a&gt;Kafka常用命令&lt;/h3&gt;&lt;p&gt;1.启动kafka&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nohup bin/kafka-server-start.sh config/server.properties &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.查看topic&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bin/kafka-topics.sh --list --zookeeper localhost:2181
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.控制台消费&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic middleware --from-beginning
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.删除topic&lt;br&gt;(1)删除kafka存储目录（server.properties文件log.dirs配置，默认为”/tmp/kafka-logs”）相关topic目录&lt;br&gt;(2)如果配置了delete.topic.enable=true直接通过命令删除，如果命令删除不掉，直接通过zookeeper-client 删除掉”/brokers/topics/“目录下相关topic节点。&lt;br&gt;&lt;strong&gt;注意: 如果你要删除一个topic并且重建，那么必须重新启动kafka，否则新建的topic在zookeeper的/brokers/topics/test-topic/目录下没有partitions这个目录，也就是没有分区信息。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装Yahoo-kafka-manager&quot;&gt;&lt;a href=&quot;#安装Yahoo-kafka-manager&quot; class=&quot;headerlink&quot; title=&quot;安装Yahoo kafka manager&quot;&gt;&lt;/a&gt;安装Yahoo kafka manager&lt;/h2&gt;&lt;h3 id=&quot;Yahoo-kafka-manager介绍&quot;&gt;&lt;a href=&quot;#Yahoo-kafka-manager介绍&quot; class=&quot;headerlink&quot; title=&quot;Yahoo kafka manager介绍&quot;&gt;&lt;/a&gt;Yahoo kafka manager介绍&lt;/h3&gt;&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/yahoo/kafka-manager&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/yahoo/kafka-manager&lt;/a&gt;&lt;br&gt;Requirements：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 0.8.1.1 or 0.8.2.*&lt;/li&gt;
&lt;li&gt;sbt 0.13.x&lt;/li&gt;
&lt;li&gt;Java 8+&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kafka Manager是一个管控台，这款工具主要支持以下几个功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;管理多个不同的集群；&lt;/li&gt;
&lt;li&gt;很容易地检查集群的状态(topics, brokers, 副本的分布, 分区的分布)；&lt;/li&gt;
&lt;li&gt;选择副本；&lt;/li&gt;
&lt;li&gt;产生分区分配(Generate partition assignments)基于集群的当前状态；&lt;/li&gt;
&lt;li&gt;重新分配分区。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;环境信息-1&quot;&gt;&lt;a href=&quot;#环境信息-1&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;console&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.246&lt;/td&gt;
&lt;td&gt;JDK1.8、kafka-manager-1.3.0.6.zip&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Kafka Manager可以装在任何一台机器上，我这里部署在一台单独的机器上。&lt;/p&gt;
&lt;h3 id=&quot;安装jdk1-8&quot;&gt;&lt;a href=&quot;#安装jdk1-8&quot; class=&quot;headerlink&quot; title=&quot;安装jdk1.8&quot;&gt;&lt;/a&gt;安装jdk1.8&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console local]# tar zxf jdk-8u73-linux-x64.gz -C /usr/java/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置PATH环境变量:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.8.0_73
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装sbt0-13-9&quot;&gt;&lt;a href=&quot;#安装sbt0-13-9&quot; class=&quot;headerlink&quot; title=&quot;安装sbt0.13.9&quot;&gt;&lt;/a&gt;安装sbt0.13.9&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console ~]# curl https://bintray.com/sbt/rpm/rpm | sudo tee /etc/yum.repos.d/bintray-sbt-rpm.repo
[root@console ~]# yum install -y sbt
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;构建kafka-manager包&quot;&gt;&lt;a href=&quot;#构建kafka-manager包&quot; class=&quot;headerlink&quot; title=&quot;构建kafka manager包&quot;&gt;&lt;/a&gt;构建kafka manager包&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console ~]# git clone https://github.com/yahoo/kafka-manager.git
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/15.png&quot; alt=&quot;&quot;&gt;    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# unzip -oq kafka-manager-upgrade-to-90.zip
[root@console ~]# mv kafka-manager-upgrade-to-90 kafka-manager
[root@console ~]# cd kafka-manager
[root@console kafka-manager]# sbt clean dist
The command below will create a zip file which can be used to deploy the application. 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用sbt编译打包的时候时间可能会比较长。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/16.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这个需要翻墙才能完成。配置代理：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# vim /usr/share/sbt-launcher-packaging/conf/sbtconfig.txt
-Dhttp.proxyHost=proxy
-Dhttp.proxyPort=8080
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;再次运行这个命令，依然需要等待较长的时间，有可能还会失败。如果失败就多次尝试打包：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console kafka-manager]# sbt clean dist
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/17.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/18.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;打包完成后会创建一个zip压缩包，而这个压缩包可以用来部署该应用。生成的包会在kafka-manager/target/universal 下面。生成的包只需要java环境就可以运行了，在以后部署到其他机器上不需要安装sbt进行打包构建了。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/19.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装kafka-manager&quot;&gt;&lt;a href=&quot;#安装kafka-manager&quot; class=&quot;headerlink&quot; title=&quot;安装kafka manager&quot;&gt;&lt;/a&gt;安装kafka manager&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console kafka-manager]# cp target/universal/kafka-manager-1.3.0.6.zip ~/
[root@console kafka-manager]# cd
[root@console ~]# unzip -oq kafka-manager-1.3.0.6.zip
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;配置kafka-manager&quot;&gt;&lt;a href=&quot;#配置kafka-manager&quot; class=&quot;headerlink&quot; title=&quot;配置kafka-manager&quot;&gt;&lt;/a&gt;配置kafka-manager&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console ~]# cd kafka-manager-1.3.0.6/
[root@console kafka-manager-1.3.0.6]# vim conf/application.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;设置zkhosts：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kafka-manager.zkhosts=&amp;quot;114.55.29.246:2181,114.55.29.86:2181,114.55.29.241:2181&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/20.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;启动kafka-manager&quot;&gt;&lt;a href=&quot;#启动kafka-manager&quot; class=&quot;headerlink&quot; title=&quot;启动kafka-manager&quot;&gt;&lt;/a&gt;启动kafka-manager&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@console kafka-manager-1.3.0.6]# bin/kafka-manager
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/21.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;默认监听的端口是9000。你也可以在启动时指定配置文件和监听端口：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# bin/kafka-manager -Dconfig.file=/path/to/application.conf -Dhttp.port=8080
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动并置于后台运行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[kmanager@console kafka-manager-1.3.0.6]$ nohup bin/kafka-manager &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;kafka-manager添加kafka-cluster&quot;&gt;&lt;a href=&quot;#kafka-manager添加kafka-cluster&quot; class=&quot;headerlink&quot; title=&quot;kafka-manager添加kafka cluster&quot;&gt;&lt;/a&gt;kafka-manager添加kafka cluster&lt;/h2&gt;&lt;p&gt;浏览器输入地址访问：&lt;a href=&quot;http://114.55.29.246:9000/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://114.55.29.246:9000/&lt;/a&gt;&lt;br&gt;&lt;strong&gt;注意:安装完成后需要手动添加Cluster。添加Cluster是指添加一个已有的Kafka集群进入监控列表，而非通过Kafka Manager部署一个新的Kafka Cluster，这一点与Cloudera Manager不同。&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/22.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/23.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/24.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/25.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kafka/26.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;消息中间件&quot;&gt;&lt;a href=&quot;#消息中间件&quot; class=&quot;headerlink&quot; title=&quot;消息中间件&quot;&gt;&lt;/a&gt;消息中间件&lt;/h2&gt;&lt;p&gt;消息中间件是在消息的传输过程中保存消息的容器。消息中间件在将消息从消息生产者到消费者时充当中间人的作用。队列的主要目的是提供路由并保证消息的传送；如果发送消息时接收者不可用，消息对列会保留消息，直到可以成功地传递它为止，当然，消息队列保存消息也是有期限的。&lt;br&gt;
    
    </summary>
    
      <category term="消息队列" scheme="http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="消息队列 Kafka 大数据" scheme="http://yoursite.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-Kafka-%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper介绍及安装部署</title>
    <link href="http://yoursite.com/2017/05/26/Zookeeper%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2017/05/26/Zookeeper介绍及安装部署/</id>
    <published>2017-05-26T01:20:04.000Z</published>
    <updated>2017-07-06T06:29:26.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Zookeeper介绍&quot;&gt;&lt;a href=&quot;#Zookeeper介绍&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper介绍&quot;&gt;&lt;/a&gt;Zookeeper介绍&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;是一个针对大型分布式系统的可靠协调系统；&lt;/li&gt;
&lt;li&gt;提供的功能包括：配置维护、名字服务、分布式同步、组服务等；&lt;/li&gt;
&lt;li&gt;目标就是封装好复杂易出错的关键职务，将简单易用的接口和性能高效、功能稳定的系统提供给用户；&lt;/li&gt;
&lt;li&gt;Zookeeper已经成为Hadoop生态系统中的基础组件。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Zookeeper特点&quot;&gt;&lt;a href=&quot;#Zookeeper特点&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper特点&quot;&gt;&lt;/a&gt;Zookeeper特点&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;最终一致性：为客户端展示同一视图，这是Zookeeper最重要的性能；&lt;/li&gt;
&lt;li&gt;可靠性：如果消息被一台服务器接受，那么它将被所有的服务器接受；&lt;/li&gt;
&lt;li&gt;原子性：更新只能成功或失败，没有中间状态；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Zookeeper应用场景&quot;&gt;&lt;a href=&quot;#Zookeeper应用场景&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper应用场景&quot;&gt;&lt;/a&gt;Zookeeper应用场景&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;一、统一命名服务&lt;/strong&gt;&lt;br&gt;1.分布式环境下，经常需要对应用/服务进行统一命名，便于识别不同的服务&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;类似于域名与ip之间对应关系，域名容易记住；&lt;/li&gt;
&lt;li&gt;通过名称来获取资源或服务的地址，提供者信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.按照层次结构组织服务/应用名称&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可将服务名称以及地址信息写在Zookeeper上，客户端通过Zookeeper获取可用服务列表。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;二、配置管理&lt;/strong&gt;&lt;br&gt;1.分布式环境下，配置文件管理和同步是一个常见问题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个集群中，所有节点的配置信息是一致的，比如Hadoop；&lt;/li&gt;
&lt;li&gt;对配置文件修改后，希望能够快速同步到各个节点上。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.配置管理可交由Zookeeper实现&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可将配置信息写入Zookeeper的一个znode上；&lt;/li&gt;
&lt;li&gt;各个节点监听这个znode&lt;/li&gt;
&lt;li&gt;一旦znode中的数据被修改，Zookeeper将会通知各个节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;三、集群管理&lt;/strong&gt;&lt;br&gt;1.分布式环境下，实时掌握每个节点的状态是必要的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可根据节点实时状态做出一些调整。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.可交由Zookeeper实现&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可将节点信息写入Zookeeper的一个znode上；&lt;/li&gt;
&lt;li&gt;监听这个znode可获得它的实时状态变化。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3.典型应用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HBase中Master状态的监控与选举。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;四、分布式通知/协调&lt;/strong&gt;&lt;br&gt;原理其实就是发布/订阅。&lt;br&gt;1.分布式环境下经常存在一个服务需要知道它所管理的子服务的状态&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NameNode需要知道各DataNode的状态&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.心跳检测机制可通过Zookeeper实现&lt;/p&gt;
&lt;p&gt;3.信息推送可由Zookeeper实现(发布/订阅模式)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;五、分布式锁&lt;/strong&gt;&lt;br&gt;1.Zookeeper是强一致性的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多个客户端同时在Zookeeper上创建相同znode，只有一个创建成功。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.实现锁的独占性&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多个客户端同时在Zookeeper上创建相同znode，创建成功的那个客户端得到锁，其他客户端等待。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3.控制锁的时序&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;各个客户端在某个znode下创建临时znode(类型为CreateMode.EPHEMERAL_SEQUENTIAL)，这样，该znode可掌握全局访问时序。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;用到了Zookeeper的一些系统&quot;&gt;&lt;a href=&quot;#用到了Zookeeper的一些系统&quot; class=&quot;headerlink&quot; title=&quot;用到了Zookeeper的一些系统&quot;&gt;&lt;/a&gt;用到了Zookeeper的一些系统&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;HDFS&lt;/li&gt;
&lt;li&gt;YARN&lt;/li&gt;
&lt;li&gt;Storm&lt;/li&gt;
&lt;li&gt;HBase&lt;/li&gt;
&lt;li&gt;Flume&lt;/li&gt;
&lt;li&gt;Dubbo&lt;/li&gt;
&lt;li&gt;metaq&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Zookeeper集群安装部署&quot;&gt;&lt;a href=&quot;#Zookeeper集群安装部署&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper集群安装部署&quot;&gt;&lt;/a&gt;Zookeeper集群安装部署&lt;/h2&gt;&lt;p&gt;下面开始介绍Zookeeper的安装部署。安装部署分三种模式：单机模式、伪分布式模式和分布式模式。&lt;br&gt;单机模式和为分布式比较简单，多用于本地测试调试，下面介绍分布式模式安装部署。&lt;br&gt;&lt;strong&gt;注意：3台机器都需要安装zk。对于Zookeeper集群的话，官方推荐的最小节点数为3个。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;console&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.246&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;JDK1.7、zookeeper-3.4.6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;安装jdk1-7&quot;&gt;&lt;a href=&quot;#安装jdk1-7&quot; class=&quot;headerlink&quot; title=&quot;安装jdk1.7&quot;&gt;&lt;/a&gt;安装jdk1.7&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;3台机器都需要安装jdk1.7&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 local]# mkdir /usr/java
[root@log1 local]# tar zxf jdk-7u80-linux-x64.gz -C /usr/java/
[root@log1 local]# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.7.0_80
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
[root@log1 local]# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装配置zk&quot;&gt;&lt;a href=&quot;#安装配置zk&quot; class=&quot;headerlink&quot; title=&quot;安装配置zk&quot;&gt;&lt;/a&gt;安装配置zk&lt;/h3&gt;&lt;p&gt;1.配置zk节点的hosts文件：配置3台机器的ip地址和主机名的对应关系。以下以console主机为例，其hosts文件添加下面3行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;114.55.29.246 console
114.55.29.86 log1
114.55.29.241 log2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.解压安装配置第一台zk&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console local]# tar zxf zookeeper-3.4.6.tar.gz
[root@console local]# cd zookeeper-3.4.6
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建快照日志存放目录：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console zookeeper-3.4.6]# mkdir -p dataDir 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建事务日志存放目录：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console zookeeper-3.4.6]# mkdir dataLogDir
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【注意】:如果不配置dataLogDir，那么事务日志也会写在dataDir目录中。这样会严重影响zk的性能。因为在zk吞吐量很高的时候，产生的事务日志和快照日志太多。&lt;br&gt;修改配置文件，添加如下内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console zookeeper-3.4.6]# cd conf 
[root@console conf]# mv zoo_sample.cfg zoo.cfg 
[root@console conf]# vim zoo.cfg
# 存放数据文件
dataDir=/usr/local/zookeeper-3.4.6/dataDir
# 存放日志文件
dataLogDir=/usr/local/zookeeper-3.4.6/dataLogDir
# zookeeper cluster，2888为选举端口，3888为心跳端口
server.1=console:2888:3888
server.2=log1:2888:3888
server.3=log2:2888:3888
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在我们配置的dataDir指定的目录下面，创建一个myid文件，里面内容为一个数字，用来标识当前主机，conf/zoo.cfg文件中配置的server.X中X为什么数字，则myid文件中就输入这个数字：&lt;br&gt;console主机：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# echo &amp;quot;1&amp;quot; &amp;gt; /usr/local/zookeeper-3.4.6/dataDir/myid
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.远程复制第一台的zk到另外两台上，并修改myid文件为2和3&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console local]# scp -rp zookeeper-3.4.6 root@114.55.29.86:/usr/local/
[root@console local]# scp -rp zookeeper-3.4.6 root@114.55.29.241:/usr/local/
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;启动和关闭zk&quot;&gt;&lt;a href=&quot;#启动和关闭zk&quot; class=&quot;headerlink&quot; title=&quot;启动和关闭zk&quot;&gt;&lt;/a&gt;启动和关闭zk&lt;/h3&gt;&lt;p&gt;在ZooKeeper集群的每个结点上，执行启动ZooKeeper服务的脚本，如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console bin]# ./zkServer.sh start 
[root@log1 bin]# ./zkServer.sh start
[root@log2 bin]# ./zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;日志可查询：/usr/local/zookeeper-3.4.6/bin/zookeeper.out&lt;br&gt;可以通过命令jps查看Zookeeper进程：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Zookeeper/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;停止zk命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# /usr/local/zookeeper-3.4.6/bin/zkServer.sh stop
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;测试zk集群&quot;&gt;&lt;a href=&quot;#测试zk集群&quot; class=&quot;headerlink&quot; title=&quot;测试zk集群&quot;&gt;&lt;/a&gt;测试zk集群&lt;/h3&gt;&lt;p&gt;可以通过ZooKeeper的脚本来查看启动状态，包括集群中各个结点的角色（或是Leader，或是Follower）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console bin]# ./zkServer.sh status
JMX enabled by default
Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg
Mode: follower
[root@log1 bin]# ./zkServer.sh status
JMX enabled by default
Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg
Mode: leader
[root@log2 bin]# ./zkServer.sh status
JMX enabled by default
Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg
Mode: follower
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过上面状态查询结果可见，log1是集群的Leader，其余的两个结点是Follower。&lt;br&gt;另外，可以通过客户端脚本，连接到ZooKeeper集群上。对于客户端来说，ZooKeeper是一个整体，连接到ZooKeeper集群实际上感觉在独享整个集群的服务，所以，你可以在任何一个结点上建立到服务集群的连接。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 bin]# ./zkCli.sh -server log1:2181
Connecting to log1:2181
2016-03-08 14:21:31,502 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-03-08 14:21:31,505 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=log2
2016-03-08 14:21:31,505 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.7.0_80
2016-03-08 14:21:31,507 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation
2016-03-08 14:21:31,507 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/usr/java/jdk1.7.0_80/jre
2016-03-08 14:21:31,507 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/usr/local/zookeeper-3.4.6/bin/../build/classes:/usr/local/zookeeper-3.4.6/bin/../build/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/usr/local/zookeeper-3.4.6/bin/../lib/log4j-1.2.16.jar:/usr/local/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/usr/local/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/usr/local/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../conf:.:/usr/java/jdk1.7.0_80/lib/dt.jar:/usr/java/jdk1.7.0_80/lib/tools.jar
2016-03-08 14:21:31,507 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/tmp
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&amp;lt;NA&amp;gt;
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Linux
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=amd64
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=3.10.0-123.9.3.el7.x86_64
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=root
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/root
2016-03-08 14:21:31,508 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/usr/local/zookeeper-3.4.6/bin
2016-03-08 14:21:31,510 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=log1:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@ee01430
Welcome to ZooKeeper!
2016-03-08 14:21:31,534 [myid:] - INFO  [main-SendThread(log1:2181):ClientCnxn$SendThread@975] - Opening socket connection to server log1/114.55.29.86:2181. Will not attempt to authenticate using SASL (unknown error)
2016-03-08 14:21:31,539 [myid:] - INFO  [main-SendThread(log1:2181):ClientCnxn$SendThread@852] - Socket connection established to log1/114.55.29.86:2181, initiating session
JLine support is enabled
[zk: log1:2181(CONNECTING) 0] 2016-03-08 14:21:31,572 [myid:] - INFO  [main-SendThread(log1:2181):ClientCnxn$SendThread@1235] - Session establishment complete on server log1/114.55.29.86:2181, sessionid = 0x25354db0d430000, negotiated timeout = 30000

WATCHER::

WatchedEvent state:SyncConnected type:None path:null

[zk: log1:2181(CONNECTED) 0]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;脚本定期清理zk快照和日志文件&quot;&gt;&lt;a href=&quot;#脚本定期清理zk快照和日志文件&quot; class=&quot;headerlink&quot; title=&quot;脚本定期清理zk快照和日志文件&quot;&gt;&lt;/a&gt;脚本定期清理zk快照和日志文件&lt;/h3&gt;&lt;p&gt;正常运行过程中，ZK会不断地把快照数据和事务日志输出到dataDir和dataLogDir这两个目录，并且如果没有人为操作的话，ZK自己是不会清理这些文件的。&lt;br&gt;我这里采用脚本切割。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# cd /usr/local/zookeeper-3.4.6/
[root@log1 zookeeper-3.4.6]# vim clean_zklog.sh
#!/bin/bash
###Description:This script is used to clear zookeeper snapshot file and transaction logs.
###Written by: jkzhao - jkzhao@wisedu.com  
###History: 2016-04-08 First release.

# Snapshot file dir.
dataDir=/usr/local/zookeeper-3.4.6/dataDir/version-2

# Transaction logs dir.
dataLogDir=/usr/local/zookeeper-3.4.6/dataLogDir/version-2

# Reserved 5 files.
COUNT=5

ls -t $dataDir/snapshot.* | tail -n +$[$COUNT+1] | xargs rm -f
ls -t $dataLogDir/log.* | tail -n +$[$COUNT+1] | xargs rm -f

[root@log1 zookeeper-3.4.6]# chmod +x clean_zklog.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;每个Zookeeper集群节点配置周期性任务，每个星期日的0点0分执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console zookeeper-3.4.6]# crontab -e
0 0 * * 0 /usr/local/zookeeper-3.4.6/clean_zklog.sh
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Zookeeper介绍&quot;&gt;&lt;a href=&quot;#Zookeeper介绍&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper介绍&quot;&gt;&lt;/a&gt;Zookeeper介绍&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;是一个针对大型分布式系统的可靠协调系统；&lt;/li&gt;
&lt;li&gt;提供的功能包括：配置维护、名字服务、分布式同步、组服务等；&lt;/li&gt;
&lt;li&gt;目标就是封装好复杂易出错的关键职务，将简单易用的接口和性能高效、功能稳定的系统提供给用户；&lt;/li&gt;
&lt;li&gt;Zookeeper已经成为Hadoop生态系统中的基础组件。
    
    </summary>
    
      <category term="分布式" scheme="http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="大数据 Zookeeper" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE-Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>zabbix的通知功能以及自定义脚本告警</title>
    <link href="http://yoursite.com/2017/05/24/zabbix%E7%9A%84%E9%80%9A%E7%9F%A5%E5%8A%9F%E8%83%BD%E4%BB%A5%E5%8F%8A%E8%87%AA%E5%AE%9A%E4%B9%89%E8%84%9A%E6%9C%AC%E5%91%8A%E8%AD%A6/"/>
    <id>http://yoursite.com/2017/05/24/zabbix的通知功能以及自定义脚本告警/</id>
    <published>2017-05-24T01:35:41.000Z</published>
    <updated>2017-06-12T07:56:05.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;zabbix的通知功能&quot;&gt;&lt;a href=&quot;#zabbix的通知功能&quot; class=&quot;headerlink&quot; title=&quot;zabbix的通知功能&quot;&gt;&lt;/a&gt;zabbix的通知功能&lt;/h2&gt;&lt;p&gt;在配置好监控项和触发器之后，一旦正常工作中的某触发器状态发生改变，一般意味着有异常情况发生，此时通常需要采取一定的动作(action)，如告警或者执行远程命令。&lt;br&gt;实现zabbix的通知功能，一般需要两个步骤：定义所需的“媒介”和配置一个”动作”。&lt;br&gt;媒介类型有：E-mail，SMS，Jabber和自定义的通知脚本。我这里就使用E-mail了。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;定义媒介&quot;&gt;&lt;a href=&quot;#定义媒介&quot; class=&quot;headerlink&quot; title=&quot;定义媒介&quot;&gt;&lt;/a&gt;定义媒介&lt;/h2&gt;&lt;p&gt;登录zabbix web管理控制台，点击Administration—&amp;gt; Media types，可以看到有3个定义好了的媒介，不用这3个，点击右上角的”Create media type”。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/90.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;填写信息：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/91.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;定义接收告警的用户&quot;&gt;&lt;a href=&quot;#定义接收告警的用户&quot; class=&quot;headerlink&quot; title=&quot;定义接收告警的用户&quot;&gt;&lt;/a&gt;定义接收告警的用户&lt;/h2&gt;&lt;h3 id=&quot;创建用户组&quot;&gt;&lt;a href=&quot;#创建用户组&quot; class=&quot;headerlink&quot; title=&quot;创建用户组&quot;&gt;&lt;/a&gt;创建用户组&lt;/h3&gt;&lt;p&gt;点击Administration—&amp;gt; User groups，点击右上角的Create user group。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/92.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入组名，点击Add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/93.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;创建用户&quot;&gt;&lt;a href=&quot;#创建用户&quot; class=&quot;headerlink&quot; title=&quot;创建用户&quot;&gt;&lt;/a&gt;创建用户&lt;/h3&gt;&lt;p&gt;点击Administration—&amp;gt; Users，点击右上角的Create user。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/94.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在User列填入个人信息：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/95.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击Media，点击Add，选择媒介和接收邮件的时间等信息：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/96.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/97.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击Permissions，根据这个新添的用户给予合适的权限&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/98.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;定义Action&quot;&gt;&lt;a href=&quot;#定义Action&quot; class=&quot;headerlink&quot; title=&quot;定义Action&quot;&gt;&lt;/a&gt;定义Action&lt;/h2&gt;&lt;p&gt;点击Configuration—&amp;gt; Actions，点击右上角的Create action：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/99.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Action配置：&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/100.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conditions配置：&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/101.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/102.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/103.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Operations配置：&lt;/strong&gt;&lt;br&gt;在一个action中，可以定义多个Operation。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/104.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/105.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;上面的Operation type有两种：Send message和Remote command。&lt;/p&gt;
&lt;h2 id=&quot;Zabbix自定义脚本发送报警邮件&quot;&gt;&lt;a href=&quot;#Zabbix自定义脚本发送报警邮件&quot; class=&quot;headerlink&quot; title=&quot;Zabbix自定义脚本发送报警邮件&quot;&gt;&lt;/a&gt;Zabbix自定义脚本发送报警邮件&lt;/h2&gt;&lt;p&gt;Zabbix发送报警邮件还可以采用自定义的脚本来发送。&lt;/p&gt;
&lt;h3 id=&quot;Python脚本发邮件&quot;&gt;&lt;a href=&quot;#Python脚本发邮件&quot; class=&quot;headerlink&quot; title=&quot;Python脚本发邮件&quot;&gt;&lt;/a&gt;Python脚本发邮件&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.定义Media types&lt;/strong&gt;&lt;br&gt;如下图，添加以下3个参数，分别对应sendEmail.sh脚本需要的3个参数：收件人地址、主题、详细内容&lt;br&gt;{ALERT.SENDTO}&lt;br&gt;{ALERT.SUBJECT}&lt;br&gt;{ALERT.MESSAGE}&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/106.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;【注意】: 很多人安装zabbix 3.0之后，写的脚本一直发信不成功,手动执行时可以的。那是因为zabbix3.0之后，可以自定义参数了。所以不写参数，它是不会传参数的。在2.x版本不存在这个问题，默认会传3个参数。脚本中可以使用$1, $2, $3来调用 action 中的 邮件的收件人, Default Subject, Default Message&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.定义Users的Media&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/107.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.python报警脚本&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr/local/zabbix-3.0.1/share/zabbix/alertscripts/
# vim zabbix_sendmail.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;脚本内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/python
# coding:utf-8 

import smtplib
from email.mime.text import MIMEText
import sys

# 邮箱服务器地址
mail_host = &amp;apos;smtp.exmail.qq.com&amp;apos;
# 邮箱用户名
mail_user = &amp;apos;01115009@wisedu.com&amp;apos;
# 邮箱密码
mail_pass = &amp;apos;123123123&amp;apos;
mail_postfix = &amp;apos;wisedu.com&amp;apos;

 def send_mail(to_list,subject,content):
     me = mail_user+&amp;quot;&amp;lt;&amp;quot;+mail_user+&amp;quot;@&amp;quot;+mail_postfix+&amp;quot;&amp;gt;&amp;quot;
     msg = MIMEText(content)
     msg[&amp;apos;Subject&amp;apos;] = subject
     msg[&amp;apos;From&amp;apos;] = me
     msg[&amp;apos;to&amp;apos;] = to_list

try:
    s = smtplib.SMTP()
    s.connect(mail_host)
    s.login(mail_user,mail_pass)
    s.sendmail(me,to_list,msg.as_string())
    s.close()
    return True
except Exception,e:
    print str(e)
    return False

if __name__ == &amp;quot;__main__&amp;quot;:
    send_mail(sys.argv[1], sys.argv[2], sys.argv[3])
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; 修改脚本权限：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# chmod +x zabbix_sendmail.py
# chown -R zabbix.zabbix zabbix_sendmail.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;4.修改zabbix_server配置&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /usr/local/zabbix-3.0.1/etc/zabbix_server.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加如下配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;### Option: AlertScriptsPath
AlertScriptsPath=/usr/local/zabbix-3.0.1/share/zabbix/alertscripts
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重启zabbix_server。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.配置Actions&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/108.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;【注意】:每触发一次Action，都会在Reports—&amp;gt;Action log看到记录：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/109.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;shell脚本发邮件&quot;&gt;&lt;a href=&quot;#shell脚本发邮件&quot; class=&quot;headerlink&quot; title=&quot;shell脚本发邮件&quot;&gt;&lt;/a&gt;shell脚本发邮件&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.先安装sendEmail&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@care local]# tar zxf sendEmail-v1.56.tar.gz
[root@care local]# cp sendEmail-v1.56/sendEmail /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将写好的脚本上传到/usr/local/zabbix-3.0.1/share/zabbix/alertscripts。这里为了业务需求，需要定制化发送邮件的内容，脚本内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
###Description:This script is used to alarm.
###Written by: jkzhao - jkzhao@wisedu.com  
###History: 2016-08-10 Second release.
###Modification: Please modify the variables host, user and passwd.

# 获取默认的邮件接收者，邮件主题，邮件正文
to=$1
subject=$2
bodyOrgin=$3

# 获取eventid
#eventid=grep &amp;quot;event ID&amp;quot; $bodyOrgin |awk &amp;apos;{print $4}&amp;apos;
eventid=$(echo $bodyOrgin | grep &amp;quot;event ID&amp;quot; |awk &amp;apos;{print $NF}&amp;apos;)
echo &amp;quot;eventid:$eventid&amp;quot; &amp;gt; /tmp/test.txt

# shell调用存储过程，获取主键viewid，传入参数：eventid，输出：viewid
host=172.16.9.112
user=root
passwd=zabbix
database=zabbix

viewid=$(mysql -u${user} -p${passwd} -h${host} -D${database} -e &amp;quot;call generateAlertView($eventid,@result)&amp;quot; 2&amp;gt;/dev/null | awk &amp;apos;NR&amp;gt;1&amp;apos;)
echo &amp;quot;viewid:$viewid&amp;quot; &amp;gt;&amp;gt; /tmp/test.txt
group=$(mysql -u${user} -p${passwd} -h${host} -D${database} -e &amp;quot;select alerts_view_group.group from alerts_view_group where viewid = $viewid&amp;quot; 2&amp;gt;/dev/null | awk &amp;apos;NR&amp;gt;1&amp;apos;)
echo &amp;quot;group:$group&amp;quot; &amp;gt;&amp;gt; /tmp/test.txt
body=$bodyOrgin&amp;quot;; 影响业务: &amp;quot;$group


# 因为需要格式化发送邮件的内容，将拼接好的body信息写入文件中再做处理
echo $body | awk -F&amp;apos;;&amp;apos; &amp;apos;{for(i=1;i&amp;lt;=NF;i++){print $i}}&amp;apos; &amp;gt; /tmp/messages.txt
# 将文件中出现的^M删除掉
sed -i &amp;apos;s/\x0D//g&amp;apos; /tmp/messages.txt
# 删除以空格开头的行前面的空格
sed -i &amp;apos;s/^\s*//g&amp;apos; /tmp/messages.txt

# 由于zabbix无论是故障还是恢复都是要发邮件的，但是对于故障和恢复的邮件内容需要定制为不同的内容，因此需要先获取到是故障还是恢复
state=$(echo $subject | awk -F: &amp;apos;{print $2}&amp;apos;)

# 按照安心守护要求修改邮件正文内容
if [ $state == &amp;quot;PROBLEM&amp;quot; ]; then
    sed -i &amp;apos;s/Trigger:/异常对象:/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Trigger severity:/{h;d};/Item values:/{G}&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;s/Trigger severity:/异常等级:/&amp;apos; /tmp/messages.txt 
    sed -i &amp;apos;s/Item values:/异常原因:/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Original event/d&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Trigger status:/d&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;$a发生时间: &amp;apos; /tmp/messages.txt
    sed -i &amp;quot;s/发生时间: /发生时间: $(date &amp;quot;+%Y-%m-%d %H:%M:%S&amp;quot;)/&amp;quot; /tmp/messages.txt
    # 把发生故障时的alertView插入alerts_view表
    alertValue=$(grep &amp;quot;异常原因&amp;quot; /tmp/messages.txt | awk -F: &amp;apos;BEGIN{ORS=&amp;quot;&amp;quot;};{for(i=3;i&amp;lt;=NF;++i) {print $i}}&amp;apos;)
    echo &amp;quot;alertValue:$alertValue&amp;quot; &amp;gt;&amp;gt; /tmp/test.txt
    mysql -u${user} -p${passwd} -h${host} -D${database} -e &amp;quot;UPDATE alerts_view set alertValue=&amp;apos;${alertValue}&amp;apos; WHERE viewid = &amp;apos;${viewid}&amp;apos;&amp;quot; 2&amp;gt;/dev/null
    sed -i &amp;apos;s/Warning/风险/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;s/Disaster/宕机/&amp;apos; /tmp/messages.txt
else
    sed -i &amp;apos;s/Trigger:/恢复对象:/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;s/Item values:/恢复内容:/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;s/影响业务/恢复业务/&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Original event/d&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Trigger status:/d&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;/Trigger severity:/d&amp;apos; /tmp/messages.txt
    sed -i &amp;apos;$a发生时间: &amp;apos; /tmp/messages.txt
    sed -i &amp;quot;s/发生时间: /发生时间: $(date &amp;quot;+%Y-%m-%d %H:%M:%S&amp;quot;)/&amp;quot; /tmp/messages.txt
fi


/usr/local/bin/sendEmail -f monitor@wisedu.com -t &amp;quot;$to&amp;quot; -s smtp.exmail.qq.com -u &amp;quot;$subject&amp;quot; -o message-content-type=text -o message-charset=utf-8 -o message-file=/tmp/messages.txt -xu monitor@wisedu.com -xp 123456 2&amp;gt;&amp;gt;/tmp/22.log
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.添加Media types&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/110.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.给指定的用户添加Media&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/111.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.配置Actions，为了业务需求定制Default message&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/112.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.邮件展示&lt;/strong&gt;&lt;br&gt;故障邮件展示：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/113.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;故障恢复邮件展示：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/114.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;zabbix的通知功能&quot;&gt;&lt;a href=&quot;#zabbix的通知功能&quot; class=&quot;headerlink&quot; title=&quot;zabbix的通知功能&quot;&gt;&lt;/a&gt;zabbix的通知功能&lt;/h2&gt;&lt;p&gt;在配置好监控项和触发器之后，一旦正常工作中的某触发器状态发生改变，一般意味着有异常情况发生，此时通常需要采取一定的动作(action)，如告警或者执行远程命令。&lt;br&gt;实现zabbix的通知功能，一般需要两个步骤：定义所需的“媒介”和配置一个”动作”。&lt;br&gt;媒介类型有：E-mail，SMS，Jabber和自定义的通知脚本。我这里就使用E-mail了。&lt;br&gt;
    
    </summary>
    
      <category term="Zabbix" scheme="http://yoursite.com/categories/Zabbix/"/>
    
    
      <category term="监控 zabbix" scheme="http://yoursite.com/tags/%E7%9B%91%E6%8E%A7-zabbix/"/>
    
  </entry>
  
  <entry>
    <title>zabbix监控websphere和weblogic</title>
    <link href="http://yoursite.com/2017/05/23/zabbix%E7%9B%91%E6%8E%A7websphere%E5%92%8Cweblogic/"/>
    <id>http://yoursite.com/2017/05/23/zabbix监控websphere和weblogic/</id>
    <published>2017-05-23T13:25:25.000Z</published>
    <updated>2017-06-12T07:56:20.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;zabbix-java-gateway&quot;&gt;&lt;a href=&quot;#zabbix-java-gateway&quot; class=&quot;headerlink&quot; title=&quot;zabbix java gateway&quot;&gt;&lt;/a&gt;zabbix java gateway&lt;/h1&gt;&lt;p&gt;zabbix通过JMX监控应用服务器。JMX（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等植入管理功能的框架。JMX可以跨越一系列异构操作系统平台、系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;Zabbix已经集成JMX，可以用Zabbix通过JMX监控JVM，TOMCAT，Weblogic，Jboss等。要使用Zabbix监控Weblogic，我们先要了解Zabbix的JMX监控架构，Weblogic的JMX信息，最后才能去实现怎么去配置监控和报警。&lt;br&gt;Zabbix是使用了一个叫做Java Gateway的应用去监控JMX的。Java Gateway集成在zabbix官方开发发布的。所以需要在编译安装zabbix server时，需要添加一个选项–enable-java。这样安装zabbix后在/usr/local/zabbix-3.0.1/sbin目录下会有个zabbix_java目录，这个目录里面就是zabbix Java gateway的文件。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/80.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;配置和运行java-gateway&quot;&gt;&lt;a href=&quot;#配置和运行java-gateway&quot; class=&quot;headerlink&quot; title=&quot;配置和运行java gateway&quot;&gt;&lt;/a&gt;配置和运行java gateway&lt;/h1&gt;&lt;p&gt;默认情况下，Java gateway监听10052端口. 如果你计划使用不同的端口来运行Java gateway，你需要通过setting.sh脚本指定下需要的端口。&lt;br&gt;启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./startup.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;关闭：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./shutdown.sh
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;配置zabbix-server使用java-gateway&quot;&gt;&lt;a href=&quot;#配置zabbix-server使用java-gateway&quot; class=&quot;headerlink&quot; title=&quot;配置zabbix server使用java gateway&quot;&gt;&lt;/a&gt;配置zabbix server使用java gateway&lt;/h1&gt;&lt;p&gt;当前Java gateway已经运行，接下来你需要告诉Zabbix server如何找到Zabbix Java gateway. 因此你需要在 server配置文件 中指定JavaGateway及JavaGateway端口. 如果JMX应用采用Zabbix代理进行监控的话，你需要在 代理配置文件 中指定对应的连接参数。&lt;br&gt;默认情况下，server并不会派生出任何进程去进行JMX监控。如果你想使用完成JMX监控，你需要指定预派生出来的Java pollers进程数，你也可过同类的方式指定常见的pollers和trappers。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim zabbix_server.conf
JavaGateway=172.16.7.151
JavaGatewayPort=10052
StartJavaPollers=5
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/81.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在完成配置后，要重启server(或代理)：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# killall -9 zabbix_server
# ./zabbix_server
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;调整java-gateway的日志级别&quot;&gt;&lt;a href=&quot;#调整java-gateway的日志级别&quot; class=&quot;headerlink&quot; title=&quot;调整java gateway的日志级别&quot;&gt;&lt;/a&gt;调整java gateway的日志级别&lt;/h1&gt;&lt;p&gt;万一Java gateway出现了若干问题，在前段可以看到的监控项报错信息并不充分，你也可以通过查看Java gateway日志文件获得更多信息。&lt;br&gt;默认情况下，Java gateway将记录日志到/tmp/zabbix_java.log文件中，log级别为”info”。有时你觉得”info”级别得到的信息并不够，你需要修改级别为”debug”。你可以通过修改lib/logback.xml将&lt;root&gt;标签更改为”debug”以获取日志级别的增加。&lt;/root&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;root level=&amp;quot;debug&amp;quot;&amp;gt;
   &amp;lt;appender-ref ref=&amp;quot;FILE&amp;quot; /&amp;gt;
&amp;lt;/root&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;需要注意的是，并不像Zabbix server或proxy那样，修改完logback.xml并不需要重启Zabbix Java gateway. 修改后的配置将会自动被加载。当你完成了debugging,你可以将log级别替换为”info”。&lt;/p&gt;
&lt;h1 id=&quot;监控weblogic&quot;&gt;&lt;a href=&quot;#监控weblogic&quot; class=&quot;headerlink&quot; title=&quot;监控weblogic&quot;&gt;&lt;/a&gt;监控weblogic&lt;/h1&gt;&lt;h2 id=&quot;weblogic配置&quot;&gt;&lt;a href=&quot;#weblogic配置&quot; class=&quot;headerlink&quot; title=&quot;weblogic配置&quot;&gt;&lt;/a&gt;weblogic配置&lt;/h2&gt;&lt;p&gt;1.如果是监控weblogic 的admin server：&lt;br&gt;编辑WL_DOMAIN_HOME/bin/setDomainEnv.sh，在文件结尾加入下面几行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd /opt/Oracle/Middleware/user_projects/domains/ids_domain/bin
$ vim setDomainEnv.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加一句：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;JAVA_OPTIONS=&amp;quot;$JAVA_OPTIONS -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9997 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后在去启动weblogic。&lt;/p&gt;
&lt;p&gt;2.如果是监控受管服务器：&lt;br&gt;进入weblogic控制台-&amp;gt;环境-&amp;gt;服务器-&amp;gt;”你新增的服务器”-&amp;gt;配置-&amp;gt;服务器启动。在“参数”的输入框内输入：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-Dcom.sun.management.jmxremote.port=JMX_PORT -Djava.rmi.server.hostname=JMX_HOST -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false -Djavax.management.builder.initial=weblogic.management.jmx.mbeanserver.WLSMBeanServerBuilder
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后控制台启动受管服务器。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/82.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;zabbix-server添加监控weblogic主机&quot;&gt;&lt;a href=&quot;#zabbix-server添加监控weblogic主机&quot; class=&quot;headerlink&quot; title=&quot;zabbix server添加监控weblogic主机&quot;&gt;&lt;/a&gt;zabbix server添加监控weblogic主机&lt;/h2&gt;&lt;p&gt;点击配置—&amp;gt;主机—&amp;gt;创建主机。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/83.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入主机信息，主要注意JMX的端口，点击添加。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/84.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;选择JMX模板。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/85.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;监控websphere&quot;&gt;&lt;a href=&quot;#监控websphere&quot; class=&quot;headerlink&quot; title=&quot;监控websphere&quot;&gt;&lt;/a&gt;监控websphere&lt;/h1&gt;&lt;h2 id=&quot;websphere配置&quot;&gt;&lt;a href=&quot;#websphere配置&quot; class=&quot;headerlink&quot; title=&quot;websphere配置&quot;&gt;&lt;/a&gt;websphere配置&lt;/h2&gt;&lt;p&gt;访问websphere控制台，点击 Server Types → WebSphere application servers → WAS_SERVER_NAME → Java and Process Management → Process definition → Java Virtual Machine.&lt;/p&gt;
&lt;p&gt;在“Generic JVM arguments”增加下面环境变量：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-Djavax.management.builder.initial=
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/86.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击 Server Types → WebSphere application servers → WAS_SERVER_NAME → Java and Process Management → Process definition → Java Virtual Machine → Custom properties.&lt;br&gt;增加下面几个环境变量：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Name: java.rmi.server.hostname
Value: JMX_HOST
Name: com.sun.management.jmxremote
Value: true
Name: com.sun.management.jmxremote.port
Value: JMX_PORT
Name: com.sun.management.jmxremote.ssl
Value: false
Name: com.sun.management.jmxremote.authenticate
Value: false
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/87.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;重启server。&lt;/p&gt;
&lt;h2 id=&quot;zabbix-server添加监控websphere主机&quot;&gt;&lt;a href=&quot;#zabbix-server添加监控websphere主机&quot; class=&quot;headerlink&quot; title=&quot;zabbix server添加监控websphere主机&quot;&gt;&lt;/a&gt;zabbix server添加监控websphere主机&lt;/h2&gt;&lt;p&gt;点击配置—&amp;gt;主机—&amp;gt;创建主机。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/88.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入主机信息，主要注意JMX的端口，点击添加。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/89.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;zabbix-java-gateway&quot;&gt;&lt;a href=&quot;#zabbix-java-gateway&quot; class=&quot;headerlink&quot; title=&quot;zabbix java gateway&quot;&gt;&lt;/a&gt;zabbix java gateway&lt;/h1&gt;&lt;p&gt;zabbix通过JMX监控应用服务器。JMX（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等植入管理功能的框架。JMX可以跨越一系列异构操作系统平台、系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。&lt;br&gt;
    
    </summary>
    
      <category term="Zabbix" scheme="http://yoursite.com/categories/Zabbix/"/>
    
    
      <category term="监控 zabbix" scheme="http://yoursite.com/tags/%E7%9B%91%E6%8E%A7-zabbix/"/>
    
  </entry>
  
  <entry>
    <title>zabbix监控Nginx</title>
    <link href="http://yoursite.com/2017/05/16/zabbix%E7%9B%91%E6%8E%A7Nginx/"/>
    <id>http://yoursite.com/2017/05/16/zabbix监控Nginx/</id>
    <published>2017-05-16T03:04:58.000Z</published>
    <updated>2017-06-12T07:56:15.000Z</updated>
    
    <content type="html">&lt;p&gt;&lt;a href=&quot;https://nginx.org/en/docs/http/ngx_http_stub_status_module.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://nginx.org/en/docs/http/ngx_http_stub_status_module.html&lt;/a&gt;&lt;br&gt;在编译Nginx的时候，需要加上参数–with-http_stub_status_module，然后在配置文件中配置开启状态页面查询。&lt;br&gt;Nginx1.9.11版本之后才支持动态加载模块，因此对于之前的版本，你都需要重新编译。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;启用nginx-status配置&quot;&gt;&lt;a href=&quot;#启用nginx-status配置&quot; class=&quot;headerlink&quot; title=&quot;启用nginx status配置&quot;&gt;&lt;/a&gt;启用nginx status配置&lt;/h1&gt;&lt;p&gt;在http段加入如下配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
        listen  80;
        server_name localhost;
        location /status {
            stub_status;
            access_log off;
            allow 114.55.29.246;
            deny all;
        }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重载Nginx。&lt;/p&gt;
&lt;h1 id=&quot;zabbix-agent端配置&quot;&gt;&lt;a href=&quot;#zabbix-agent端配置&quot; class=&quot;headerlink&quot; title=&quot;zabbix agent端配置&quot;&gt;&lt;/a&gt;zabbix agent端配置&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;# cd /usr/local/zabbix-3.0.1/etc/zabbix_agentd.conf.d/
# vim nginx_userparams.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;把下面的内容贴进去：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;UserParameter=Nginx.active[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | awk &amp;apos;/^Active/ {print $NF}&amp;apos;
UserParameter=Nginx.reading[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | grep &amp;apos;Reading&amp;apos; | cut -d&amp;quot; &amp;quot; -f2
UserParameter=Nginx.writing[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | grep &amp;apos;Writing&amp;apos; | cut -d&amp;quot; &amp;quot; -f4
UserParameter=Nginx.waiting[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | grep &amp;apos;Waiting&amp;apos; | cut -d&amp;quot; &amp;quot; -f6
UserParameter=Nginx.accepted[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | awk &amp;apos;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $$1}&amp;apos;
UserParameter=Nginx.handled[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | awk &amp;apos;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $$2}&amp;apos;
UserParameter=Nginx.requests[*], /usr/bin/curl -s &amp;quot;http://$1:$2/status&amp;quot; | awk &amp;apos;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $$3}&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重启zabbix agent：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# killall -9 zabbix_agentd
# /usr/local/zabbix-3.0.1/sbin/zabbix_agentd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;测试，在zabbix server上使用zabbix_get获取数据：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr/local/zabbix-3.0.1/bin/
# ./zabbix_get -s 114.55.29.241 -k &amp;quot;Nginx.active[114.55.29.241,80]&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;zabbix-web-gui配置监控项&quot;&gt;&lt;a href=&quot;#zabbix-web-gui配置监控项&quot; class=&quot;headerlink&quot; title=&quot;zabbix web gui配置监控项&quot;&gt;&lt;/a&gt;zabbix web gui配置监控项&lt;/h1&gt;&lt;h2 id=&quot;创建Nginx-Template&quot;&gt;&lt;a href=&quot;#创建Nginx-Template&quot; class=&quot;headerlink&quot; title=&quot;创建Nginx Template&quot;&gt;&lt;/a&gt;创建Nginx Template&lt;/h2&gt;&lt;p&gt;点击Configuration—&amp;gt;Templates，点击右上角的Create template。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/66.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;填写模板的信息，点击Add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/67.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;创建Application&quot;&gt;&lt;a href=&quot;#创建Application&quot; class=&quot;headerlink&quot; title=&quot;创建Application&quot;&gt;&lt;/a&gt;创建Application&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;生产环境下只需要把我写好的模板文件import进去就可以了，不需要像下面那样再去创建模板，下面只是介绍下创建模板的过程。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;点击Configuration—&amp;gt;Templates，找到刚才创建的Nginx template，点击所在行的Applications列。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/68.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击右上角的Create application。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/69.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入application的名字Nginx running status，点击Add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/70.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;创建Items&quot;&gt;&lt;a href=&quot;#创建Items&quot; class=&quot;headerlink&quot; title=&quot;创建Items&quot;&gt;&lt;/a&gt;创建Items&lt;/h2&gt;&lt;p&gt;点击Configuration—&amp;gt;Templates，找到刚才创建的Nginx template，点击所在行的Items列。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/71.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击右上角的Create item。分别创建8个监控项，如下图：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当前 Nginx 正处理的活动连接数（包括等待着的连接数）&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/72.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx一共处理了的连接数&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/73.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx一共处理了的连接数(包括失败了的，因为某些限制会导致连接被拒绝，比如the worker_connections limit)&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/74.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx一共处理了的请求的个数(连接和请求是两码事，一个长连接可能会处理多个请求)&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/75.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx正在读取到客户端的Header信息数&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/76.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx正在向客户端发送响应的个数&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/77.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;开启keep-alive 的情况下，这个值等于active – (reading + writing)，意思就是 Nginx 已经处理完正在等候下一次请求指令的驻留连接&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/78.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;Nginx服务可用性&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/79.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://nginx.org/en/docs/http/ngx_http_stub_status_module.html&quot;&gt;https://nginx.org/en/docs/http/ngx_http_stub_status_module.html&lt;/a&gt;&lt;br&gt;在编译Nginx的时候，需要加上参数–with-http_stub_status_module，然后在配置文件中配置开启状态页面查询。&lt;br&gt;Nginx1.9.11版本之后才支持动态加载模块，因此对于之前的版本，你都需要重新编译。&lt;br&gt;
    
    </summary>
    
      <category term="Zabbix" scheme="http://yoursite.com/categories/Zabbix/"/>
    
    
      <category term="监控 zabbix" scheme="http://yoursite.com/tags/%E7%9B%91%E6%8E%A7-zabbix/"/>
    
  </entry>
  
  <entry>
    <title>zabbix监控实例</title>
    <link href="http://yoursite.com/2017/05/14/zabbix%E7%9B%91%E6%8E%A7%E5%AE%9E%E4%BE%8B/"/>
    <id>http://yoursite.com/2017/05/14/zabbix监控实例/</id>
    <published>2017-05-14T13:44:33.000Z</published>
    <updated>2017-06-12T07:56:29.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;zabbix-web添加主机&quot;&gt;&lt;a href=&quot;#zabbix-web添加主机&quot; class=&quot;headerlink&quot; title=&quot;zabbix web添加主机&quot;&gt;&lt;/a&gt;zabbix web添加主机&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;进入zabbix web界面，点击配置—&amp;gt;主机—&amp;gt;创建主机。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/28.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;填入下图中的信息，点击添加。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/29.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/30.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/31.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;定义Items&quot;&gt;&lt;a href=&quot;#定义Items&quot; class=&quot;headerlink&quot; title=&quot;定义Items&quot;&gt;&lt;/a&gt;定义Items&lt;/h1&gt;&lt;p&gt;要真正实现数据采集，需要定义监控项(Items)。多个Items可以归为一个组，称为Applications。定义好Items之后，还应该为Items定义Triggers(触发器)。我这里演示下创建监控网卡进入和出去的流量。&lt;/p&gt;
&lt;h2 id=&quot;创建item监控网卡出去流量&quot;&gt;&lt;a href=&quot;#创建item监控网卡出去流量&quot; class=&quot;headerlink&quot; title=&quot;创建item监控网卡出去流量&quot;&gt;&lt;/a&gt;创建item监控网卡出去流量&lt;/h2&gt;&lt;p&gt;登录zabbix web管控台，点击配置—&amp;gt;主机—&amp;gt;监控项。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/32.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击右上角的“创建监控项”。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/33.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在如下的界面填入以下内容：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/34.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;其中，在key那一栏，点击select按钮，选择key值。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/35.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/36.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;回到hosts，你会发现已经有application和item了。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/37.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;每创建一个Item，会自动帮你创建图形的。点击监控—&amp;gt;最新的数据，输入要查的主机，点击select，就可以看到为刚才我们创建的item所创建的图形。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/38.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击图形。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/39.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意:数据量从右往左走的。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;创建item监控进入网卡流量&quot;&gt;&lt;a href=&quot;#创建item监控进入网卡流量&quot; class=&quot;headerlink&quot; title=&quot;创建item监控进入网卡流量&quot;&gt;&lt;/a&gt;创建item监控进入网卡流量&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/40.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意:&lt;/strong&gt;有时候，不是一创建完item，graph那边就有数据了，你可以主要通过浏览器去访问监听在这个网卡的某个端口上的服务，然后graph就会有数据了。&lt;/p&gt;
&lt;h1 id=&quot;创建graph&quot;&gt;&lt;a href=&quot;#创建graph&quot; class=&quot;headerlink&quot; title=&quot;创建graph&quot;&gt;&lt;/a&gt;创建graph&lt;/h1&gt;&lt;p&gt;为什么要创建graph？拿上节中的网卡进出流量来举例，进和出此时都不在一张图上，这就需要Graphs自定义图像。将多个指标放在一起。&lt;/p&gt;
&lt;p&gt;点击配置—&amp;gt;主机，点击Graphs。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/41.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击右上角的创建图形。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/42.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;输入Name，点击图中倒数第二个add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/43.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;选择监控项。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/44.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;最后点击添加。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/45.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击监控—&amp;gt;图形，在右上角输入主机组，主机和图形。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/46.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;创建模板&quot;&gt;&lt;a href=&quot;#创建模板&quot; class=&quot;headerlink&quot; title=&quot;创建模板&quot;&gt;&lt;/a&gt;创建模板&lt;/h1&gt;&lt;p&gt;如果我们在加一个主机进来，假如说我们每一次都想监控某几个同样的指标，每台主机都要这么去定义的话，就太痛苦了。这就要使用到模板。&lt;/p&gt;
&lt;h2 id=&quot;创建模板-1&quot;&gt;&lt;a href=&quot;#创建模板-1&quot; class=&quot;headerlink&quot; title=&quot;创建模板&quot;&gt;&lt;/a&gt;创建模板&lt;/h2&gt;&lt;p&gt;点击配置—&amp;gt;模板，点击创建模板。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/47.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/48.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;创建Item&quot;&gt;&lt;a href=&quot;#创建Item&quot; class=&quot;headerlink&quot; title=&quot;创建Item&quot;&gt;&lt;/a&gt;创建Item&lt;/h2&gt;&lt;p&gt;创建完模板后，其上是没有任何Item和trigger等。所以我们需要创建这一系列监控项。但是由于这里我是要监控Elasticsearch状态，而zabbix是没有内置的key来监控elasticsearch的，所以需要自定义监控项来监控。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/49.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在elasticsearch主机定义zabbix agent的UserParameter&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~]# cd /usr/local/zabbix-3.0.1/etc/
[root@log1 etc]# vim zabbix_agentd.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;输入内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;UserParameter=Elasticsearch.status[*],/usr/bin/curl -s &amp;apos;http://$1:$2/_cluster/health?pretty=true&amp;apos; | awk -F&amp;apos;&amp;quot;&amp;apos; &amp;apos;/status/{print $$4}&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;重启zabbix agent&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log1 ~] # killall -9 zabbix_agentd
[root@log1 ~]# /usr/local/zabbix-3.0.1/sbin/zabbix_agentd
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在zabbix server端使用zabbix_get模拟获取数据&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# /usr/local/zabbix-3.0.1/bin/zabbix_get -s 114.55.29.86 -k &amp;quot;Elasticsearch.status[114.55.29.86,9200]&amp;quot;
green
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建模板的Item&lt;br&gt;(1)找到刚才新建的模板，点击Item。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/50.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(2)点击右上角的Create Item&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/51.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(3)输入如下的信息&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/52.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/53.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;为模板上的Item创建触发器&quot;&gt;&lt;a href=&quot;#为模板上的Item创建触发器&quot; class=&quot;headerlink&quot; title=&quot;为模板上的Item创建触发器&quot;&gt;&lt;/a&gt;为模板上的Item创建触发器&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;点击触发器。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/54.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;点击右上角的创建触发器&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/55.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;定义触发器名字，然后点击Add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/56.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;点击Select，选择对哪个Item做Trigger。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/57.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/58.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;将模板应用到主机上&quot;&gt;&lt;a href=&quot;#将模板应用到主机上&quot; class=&quot;headerlink&quot; title=&quot;将模板应用到主机上&quot;&gt;&lt;/a&gt;将模板应用到主机上&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;点击配置—&amp;gt;主机，点击log1主机。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/59.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;点击模板，点击选择。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/60.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;选择我们需要的模板，点击选择。然后在点击Add。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/61.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;这是Add后显示页面，再点击Update。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/62.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这样你就可以看到这边log1主机有应用的模板的。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/63.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;查看监控数据&quot;&gt;&lt;a href=&quot;#查看监控数据&quot; class=&quot;headerlink&quot; title=&quot;查看监控数据&quot;&gt;&lt;/a&gt;查看监控数据&lt;/h2&gt;&lt;p&gt;点击监控—&amp;gt;最新数据，找到Elasticsearch status这个监控项，点击后面的History。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/64.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/65.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;zabbix-web添加主机&quot;&gt;&lt;a href=&quot;#zabbix-web添加主机&quot; class=&quot;headerlink&quot; title=&quot;zabbix web添加主机&quot;&gt;&lt;/a&gt;zabbix web添加主机&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;进入zabbix web界面，点击配置—&amp;gt;主机—&amp;gt;创建主机。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/28.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Zabbix" scheme="http://yoursite.com/categories/Zabbix/"/>
    
    
      <category term="监控 zabbix" scheme="http://yoursite.com/tags/%E7%9B%91%E6%8E%A7-zabbix/"/>
    
  </entry>
  
  <entry>
    <title>zabbix安装配置</title>
    <link href="http://yoursite.com/2017/05/10/zabbix%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoursite.com/2017/05/10/zabbix安装配置/</id>
    <published>2017-05-10T02:53:23.000Z</published>
    <updated>2017-06-12T07:55:42.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;实验环境&quot;&gt;&lt;a href=&quot;#实验环境&quot; class=&quot;headerlink&quot; title=&quot;实验环境&quot;&gt;&lt;/a&gt;实验环境&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;console&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.246&lt;/td&gt;
&lt;td&gt;Httpd、Nginx、MySQL、Zabbix&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;Zabbix agent&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;Zabbix agent&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;安装准备&quot;&gt;&lt;a href=&quot;#安装准备&quot; class=&quot;headerlink&quot; title=&quot;安装准备&quot;&gt;&lt;/a&gt;安装准备&lt;/h1&gt;&lt;p&gt;为了安全考虑，zabbix只使用普通用户运行，如果你的系统没有名叫zabbix的用户，你需要创建一个用户，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console local]# groupadd zabbix
[root@console local]# useradd -g zabbix zabbix
[root@console local]# id zabbix
uid=1000(zabbix) gid=1000(zabbix) groups=1000(zabbix)
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;安装MySQL&quot;&gt;&lt;a href=&quot;#安装MySQL&quot; class=&quot;headerlink&quot; title=&quot;安装MySQL&quot;&gt;&lt;/a&gt;安装MySQL&lt;/h1&gt;&lt;p&gt;console主机安装mysql5.6。下载地址：&lt;a href=&quot;http://mirrors.sohu.com/mysql&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://mirrors.sohu.com/mysql&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;安装依赖包&lt;pre&gt;&lt;code&gt;[root@console local]# yum install libaio* -y
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;解压安装&lt;pre&gt;&lt;code&gt;[root@console local]# tar zxf mysql-5.6.27-linux-glibc2.5-x86_64.tar.gz 
[root@console local]# ln -sv mysql-5.6.27-linux-glibc2.5-x86_64 mysql
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;新建用户&lt;br&gt;运行mysql最好不要用root去运行，而以普通用户身份。添加用户mysql。&lt;pre&gt;&lt;code&gt;[root@console local]# groupadd -r -g 300 mysql
[root@console local]# useradd -g mysql -r -s /sbin/nologin -u 300 mysql
[root@console local]# id mysql
uid=300(mysql) gid=300(mysql) groups=300(mysql)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;修改mysql文件权限为mysql.mysql&lt;pre&gt;&lt;code&gt;[root@console local]# cd mysql
[root@console mysql]# chown -R mysql.mysql ./*
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;执行初始化操作，生成一个系统库叫mysql，它里面保存着有当前所有能够使用mysql服务器的用户帐号、所有数据库的名字、每个库中表的名字、表中字段的名字等等。&lt;br&gt;脚本路径：/usr/local/mysql/scripts&lt;br&gt;创建数据文件目录：&lt;pre&gt;&lt;code&gt;[root@console mysql]# mkdir -pv /data/{mydata,binlog}
[root@console mysql]# scripts/mysql_install_db --user=mysql --basedir=/usr/local/mysql --datadir=/data/mydata
[root@console mysql]# ls /data/mydata
&lt;/code&gt;&lt;/pre&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/1.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;修改mysql目录下的文件属主为root，属组为mysql&lt;pre&gt;&lt;code&gt;[root@console mysql]# chown -R root .
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;修改data目录属主、属组为mysql&lt;pre&gt;&lt;code&gt;[root@console mysql]# chown -R mysql.mysql /data
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;拷贝修改mysql的配置文件&lt;br&gt;copy写好的my.cnf到/etc/目录下。&lt;/li&gt;
&lt;li&gt;拷贝mysql的启动脚本，并加入系统服务&lt;pre&gt;&lt;code&gt;[root@console mysql]# cp support-files/mysql.server /etc/init.d/mysqld 
[root@console mysql]# chkconfig --add mysqld
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;启动mysql&lt;pre&gt;&lt;code&gt;[root@console mysql]# service mysqld start
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;配置环境变量，配置完重新打开一个shell&lt;pre&gt;&lt;code&gt;[root@console mysql]# vim /etc/profile.d/mysql.sh
export PATH=/usr/local/mysql/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;修改root密码，因为一装完root密码是空的&lt;pre&gt;&lt;code&gt;[root@console ~]# mysql -uroot mysql 
&lt;/code&gt;&lt;/pre&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/2.png&quot; alt=&quot;&quot;&gt;&lt;pre&gt;&lt;code&gt;mysql&amp;gt; UPDATE user SET Password=PASSWORD(&amp;apos;wisedu123&amp;apos;) where USER=&amp;apos;root&amp;apos;;
mysql&amp;gt; FLUSH PRIVILEGES;
&lt;/code&gt;&lt;/pre&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;此时再以root登录就需要密码了。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/4.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;li&gt;删除两个匿名帐号&lt;pre&gt;&lt;code&gt;mysql&amp;gt; use mysql
mysql&amp;gt; SELECT host,user,password FROM user;
&lt;/code&gt;&lt;/pre&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/5.png&quot; alt=&quot;&quot;&gt;&lt;pre&gt;&lt;code&gt;mysql&amp;gt; DROP USER &amp;apos;&amp;apos;@localhost;
mysql&amp;gt; DROP USER &amp;apos;&amp;apos;@console;
&lt;/code&gt;&lt;/pre&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;h1 id=&quot;安装Zabbix3-0-1&quot;&gt;&lt;a href=&quot;#安装Zabbix3-0-1&quot; class=&quot;headerlink&quot; title=&quot;安装Zabbix3.0.1&quot;&gt;&lt;/a&gt;安装Zabbix3.0.1&lt;/h1&gt;官方说3.0以上版本是在redhat7以上运行的，我之前在redhat6.6尝试编译安装也是可以的。&lt;h2 id=&quot;安装依赖包&quot;&gt;&lt;a href=&quot;#安装依赖包&quot; class=&quot;headerlink&quot; title=&quot;安装依赖包&quot;&gt;&lt;/a&gt;安装依赖包&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;[root@console ~]# yum install net-snmp-devel libxml2-devel libcurl-devel  libssh2-devel unixODBC-devel -y
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;安装JDK&quot;&gt;&lt;a href=&quot;#安装JDK&quot; class=&quot;headerlink&quot; title=&quot;安装JDK&quot;&gt;&lt;/a&gt;安装JDK&lt;/h2&gt;如果zabbix需要监控JMX应用的程序，在编译zabbix的时候就需要–enable-java，同时也需要安装配置好JDK。&lt;pre&gt;&lt;code&gt;# mkdir /usr/java
# tar zxf jdk-8u73-linux-x64.gz -C /usr/java/
# vim /etc/profile
# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;安装php环境&quot;&gt;&lt;a href=&quot;#安装php环境&quot; class=&quot;headerlink&quot; title=&quot;安装php环境&quot;&gt;&lt;/a&gt;安装php环境&lt;/h2&gt;zabbix的服务端程序是用php写的，因此需要一个支持LAMP架构的服务器平台。&lt;br&gt;&lt;strong&gt;CentOS 6：&lt;/strong&gt;&lt;br&gt;CenOS 6的yum源中自带的php解释器版本过低，是 5.3版本，需要&amp;gt;=5.4版本才可以。这里使用 Webtatic EL6的YUM源来安装php5.4,我们首先安装Webtatic EL6 YUM源：&lt;pre&gt;&lt;code&gt;# rpm -Uvh http://repo.webtatic.com/yum/el6/latest.rpm 
# yum install php54w php54w-mysql php54w-mbstring php54w-bcmath php54w-gd php54w-xml -y
&lt;/code&gt;&lt;/pre&gt;&lt;strong&gt;CentOS 7：&lt;/strong&gt;&lt;pre&gt;&lt;code&gt;# yum install php php-fpm php-mysql php-mbstring php-bcmath php-gd php-xml -y
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;编译安装zabbix-server&quot;&gt;&lt;a href=&quot;#编译安装zabbix-server&quot; class=&quot;headerlink&quot; title=&quot;编译安装zabbix server&quot;&gt;&lt;/a&gt;编译安装zabbix server&lt;/h2&gt;&lt;p&gt;如果仅安装server，并支持将数据放入mysql数据中，可使用类似如下配置命令：&lt;br&gt;./configure –enable-server –with-mysql –with-net-snmp –with-libcurl&lt;br&gt;如果仅安装proxy，并支持将数据放入mysql数据中，可使用类似如下配置命令：&lt;br&gt;./configure –prefix=/usr –enable-proxy –with-net-snmp –with-mysql –with-ssh2&lt;br&gt;如果仅安装agent，可使用类似如下配置命令：&lt;br&gt;./configure –enable-agent&lt;br&gt;在console主机上同时安装server和agent，并支持将数据放入mysql数据中：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console local]# cd /usr/local/
[root@console local]# wget http://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/3.0.1/zabbix-3.0.1.tar.gz
[root@console local]# tar zxf zabbix-3.0.1.tar.gz 
[root@console local]# cd zabbix-3.0.1/
[root@console zabbix-3.0.1]# ./configure --prefix=/usr/local/zabbix-3.0.1/ --enable-server --enable-agent --with-mysql --with-net-snmp --with-libcurl --with-libxml2 --enable-ipv6 --with-ssh2 --enable-java --with-unixodbc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console zabbix-3.0.1]# make &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;初始化数据库&quot;&gt;&lt;a href=&quot;#初始化数据库&quot; class=&quot;headerlink&quot; title=&quot;初始化数据库&quot;&gt;&lt;/a&gt;初始化数据库&lt;/h2&gt;&lt;p&gt;For Zabbix server and proxy daemons, as well as Zabbix frontend, a database is required. It is not needed to run Zabbix agent.&lt;br&gt;数据库初始化脚本在/usr/local/zabbix-3.0.1/database/mysql，分别是data.sql、images.sql和schema.sql。&lt;br&gt;&lt;strong&gt;注意:&lt;/strong&gt;导入顺序不能变。&lt;br&gt;先在MySQL中创建zabbix数据库：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# mysql -uroot -p
mysql&amp;gt; create database zabbix default charset utf8;
mysql&amp;gt; grant all on zabbix.* to zabbix@localhost identified by &amp;apos;wisedu&amp;apos;;
mysql&amp;gt; grant all on zabbix.* to zabbix@&amp;apos;%.%.%.%&amp;apos; identified by &amp;apos;wisedu&amp;apos;;
mysql&amp;gt; flush privileges;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后退出，使用zabbix用户登录mysql并导入数据：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# mysql -uzabbix -p
mysql&amp;gt; use zabbix;
mysql&amp;gt; source /usr/local/zabbix-3.0.1/database/mysql/schema.sql
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果你仅仅是初始化proxy的数据库，那么schema.sql够了。如果初始化server，那么接着导入下面两个sql：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; source /usr/local/zabbix-3.0.1/database/mysql/images.sql
mysql&amp;gt; source /usr/local/zabbix-3.0.1/database/mysql/data.sql
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果是初始化agent，就不需要导入任何脚本。&lt;/p&gt;
&lt;h2 id=&quot;配置zabbix-server&quot;&gt;&lt;a href=&quot;#配置zabbix-server&quot; class=&quot;headerlink&quot; title=&quot;配置zabbix server&quot;&gt;&lt;/a&gt;配置zabbix server&lt;/h2&gt;&lt;p&gt;因为上面我在编译加了–prefix=/usr/local/zabbix-3.0.1/参数，所以配置文件路径在：/usr/local/zabbix-3.0.1/etc。如果在编译时没有加这个参数，默认配置文件在/usr/local/etc/。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console mysql]# cd /usr/local/zabbix-3.0.1/etc/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/8.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;修改server配置文件，备份原配置文件，然后去掉注释：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console etc]# mv zabbix_server.conf zabbix_server.conf.bak
[root@console etc]# cat zabbix_server.conf.bak | grep -v &amp;quot;#&amp;quot; | grep -v &amp;quot;^$&amp;quot; &amp;gt; zabbix_server.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最终改后的配置文件内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console etc]# cat zabbix_server.conf
LogFile=/var/log/zabbix_server.log
DBHost=localhost
DBName=zabbix
DBUser=zabbix
DBPassword=wisedu
# 注意mysql服务器上的mysql.sock文件路径，一般zabbix server和mysql在同一台就改为/tmp/mysql.sock，否则不修改
DBSocket=/tmp/mysql.sock
Timeout=4
LogSlowQueries=3000
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/9.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;修改agent配置文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console etc]# mv zabbix_agentd.conf zabbix_agentd.conf.bak
[root@console etc]# cat zabbix_agentd.conf.bak | grep -v &amp;quot;#&amp;quot; | grep -v &amp;quot;^$&amp;quot; &amp;gt; zabbix_agentd.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;agent配置文件内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console etc]# cat zabbix_agentd.conf
LogFile=/var/log/zabbix_agentd.log
Server=114.55.29.246
# 主动向zabbix server发送监控内容
ServerActive=114.55.29.246
Hostname=console
Include=/usr/local/zabbix-3.0.1/etc/zabbix_agentd.conf.d/*.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建日志文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console etc]# touch /var/log/{zabbix_server.log,zabbix_agentd.log} 
[root@console etc]# chmod 777 /var/log/zabbix_*
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;启动zabbix-server&quot;&gt;&lt;a href=&quot;#启动zabbix-server&quot; class=&quot;headerlink&quot; title=&quot;启动zabbix server&quot;&gt;&lt;/a&gt;启动zabbix server&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;[root@console ~]# cd /usr/local/zabbix-3.0.1/sbin/
[root@console sbin]# ./zabbix_server
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看10051端口，端口默认是10051。&lt;br&gt;一大堆进程。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/10.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可以查看启动日志：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log sbin]# tail -100f /var/log/zabbix_server.log
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;常见启动错误：&lt;br&gt;./zabbix_server: error while loading shared libraries: libmysqlclient.so.18: cannot open shared object file: No such file or directory&lt;br&gt;解决：    &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ln -s /usr/local/mysql/lib/libmysqlclient.so.18  /usr/lib64/
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;停止zabbix-server&quot;&gt;&lt;a href=&quot;#停止zabbix-server&quot; class=&quot;headerlink&quot; title=&quot;停止zabbix server&quot;&gt;&lt;/a&gt;停止zabbix server&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;# killall -9 zabbix_server
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;安装zabbix-web界面-和server端装在一台机器&quot;&gt;&lt;a href=&quot;#安装zabbix-web界面-和server端装在一台机器&quot; class=&quot;headerlink&quot; title=&quot;安装zabbix web界面(和server端装在一台机器)&quot;&gt;&lt;/a&gt;安装zabbix web界面(和server端装在一台机器)&lt;/h2&gt;&lt;p&gt;zabbix的服务端程序是用php写的，因此需要一个支持LAMP架构的服务器平台。Web服务器可以使用Httpd或者Nginx。&lt;br&gt;鉴于zabbix最近爆出来的漏洞：zabbix的jsrpc的profileldx2参数存在insert方式的SQL注入漏洞，攻击者可以无需授权登陆即可登陆zabbix管理系统，也可通过script等功能轻易直接获取zabbix服务器的操作系统权限。建议升级到最新的zabbix-3.0.4版本，或者使用nginx，这样可以在server段加入如下配置处理这个漏洞：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if ($request_uri ~ ^(.+\.php)(.*)$) {
        set $req $2;
}
if ($req ~* &amp;quot;union[+|(%20)]&amp;quot;) {
        return 503;
}
if ($req ~* &amp;quot;and[+|(%20)]&amp;quot;) { 
       return 503;
}
if ($req ~* &amp;quot;select[+|(%20)]&amp;quot;) { 
       return 503;
}
if ($req ~* &amp;quot;or[+|(%20)]&amp;quot;) { 
       return 503;
}
if ($req ~* &amp;quot;concat[+|(%20)]&amp;quot;) { 
       return 503;
}
if ($req ~* &amp;quot;cost[+|(%20)]&amp;quot;) { 
       return 503;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;使用httpd&quot;&gt;&lt;a href=&quot;#使用httpd&quot; class=&quot;headerlink&quot; title=&quot;使用httpd&quot;&gt;&lt;/a&gt;使用httpd&lt;/h3&gt;&lt;h4 id=&quot;安装httpd&quot;&gt;&lt;a href=&quot;#安装httpd&quot; class=&quot;headerlink&quot; title=&quot;安装httpd&quot;&gt;&lt;/a&gt;安装httpd&lt;/h4&gt;&lt;p&gt;我这里使用httpd2.4。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# yum install -y httpd
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;部署zabbix-web&quot;&gt;&lt;a href=&quot;#部署zabbix-web&quot; class=&quot;headerlink&quot; title=&quot;部署zabbix web&quot;&gt;&lt;/a&gt;部署zabbix web&lt;/h4&gt;&lt;p&gt;将ZABBIX安装目录下 frontends/php 下面的php源代码文件拷贝到web服务器html文件目录下面。&lt;br&gt;先建立一个子目录，将zabbix终端php文件拷贝到该子目录里面，执行下面的命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# cd /var/www/html/
[root@console html]# mkdir /var/www/html/zabbix
[root@console html]# cp -ar /usr/local/zabbix-3.0.1/frontends/php/* ./zabbix/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动httpd：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console html]# systemctl start httpd.service
[root@console ~]# systemctl enable httpd.service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;访问：&lt;br&gt;&lt;a href=&quot;http://114.55.29.246/zabbix/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://114.55.29.246/zabbix/&lt;/a&gt;&lt;br&gt; (1) You should see the first screen of the frontend installation wizard.&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/11.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(2) 检查环境&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/12.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;查看到几处不符合要求，需修改该PHP文件配置文件参数:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/php.ini
post_max_size = 16M
max_execution_time = 300
max_input_time = 300
date.timezone = Asia/Shanghai
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后重启httpd和mysql，不重启mysql下面sql连接时还是会报错。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# systemctl restart httpd.service 
[root@console ~]# service mysqld restart
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重新访问，全部依赖都通过：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/13.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(3) 输入之前在MYSQL后台设置的zabbix数据库信息:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DBName=zabbix
DBUser=zabbix
DBPassword=wisedu
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/14.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;报错：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/15.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;解决：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# mkdir /var/lib/mysql
[root@console ~]# ln -s /tmp/mysql.sock /var/lib/mysql/mysql.sock
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;点击下一步，还是报错：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/16.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;解决：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; grant all on zabbix.* to &amp;apos;zabbix&amp;apos;@&amp;apos;console&amp;apos; identified by &amp;apos;wisedu&amp;apos;;
mysql&amp;gt; flush privileges;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果以上方法试过后，还报下面的错误：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error connecting to database: Can&amp;apos;t connect to MySQL server on &amp;apos;&amp;apos;114.55.29.246&amp;apos;&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;请检查SELinux是否关闭。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# /usr/sbin/sestatus -v
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/17.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;关闭SELinux：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# setenforce 0
[root@console ~]# vim /etc/sysconfig/selinux
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/18.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/19.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(4) 输入zabbix服务器端的详细信息&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/20.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(5) 检查一下设置情况&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/21.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(6) 下载配置文件，并把它放置在/var/www/html/zabbix/conf/ 目录下&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/22.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Alternatively, you can install it manually:&lt;br&gt;Download the configuration file&lt;br&gt;Save it as “/var/www/html/zabbix/conf/zabbix.conf.php”&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/23.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console conf]# cd /var/www/html/zabbix/conf/
[root@console conf]# chown zabbix.zabbix zabbix.conf.php
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(7) 点击Finish&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/24.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;(8) Zabbix frontend is ready! The default user name is Admin, password zabbix.&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/25.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/26.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;使用Nginx&quot;&gt;&lt;a href=&quot;#使用Nginx&quot; class=&quot;headerlink&quot; title=&quot;使用Nginx&quot;&gt;&lt;/a&gt;使用Nginx&lt;/h3&gt;&lt;h4 id=&quot;安装openresty&quot;&gt;&lt;a href=&quot;#安装openresty&quot; class=&quot;headerlink&quot; title=&quot;安装openresty&quot;&gt;&lt;/a&gt;安装openresty&lt;/h4&gt;&lt;p&gt;log2主机上安装openresty&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install readline-devel pcre-devel openssl-devel gcc -y
# cd /usr/local
# tar zxf openresty-1.9.7.3.tar.gz
# cd openresty-1.9.7.3/
# ./configure --with-http_stub_status_module
# gmake &amp;amp;&amp;amp; gmake install
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;安装完成后，在/usr/local/下多了个openresty目录，nginx部署安装在/usr/local/openresty/nginx。&lt;br&gt;将nginx加入系统服务：&lt;br&gt;&lt;strong&gt;Redhat7之前的版本：&lt;/strong&gt;&lt;br&gt;(1)    上传nginx启动脚本到/etc/init.d/目录下&lt;br&gt;(2)    授权脚本执行权限&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 init.d]# chmod a+x nginx
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(3)    加入系统服务&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 init.d]# chkconfig --add nginx
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(4)    nginx开启自启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 init.d]# chkconfig nginx on
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(5)    nginx启停重载&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;service nginx start/stop/restart/reload
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Redhat7版本：&lt;/strong&gt;&lt;br&gt;(1)    启动服务单元&lt;br&gt;把写好的nginx.service放到/etc/systemd/system/目录下。&lt;br&gt;(2)    设置开机启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 ~]# systemctl enable nginx.service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(3)    启动/停止/重载nginx服务&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl start/stop/reload nginx.service
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;启动php&quot;&gt;&lt;a href=&quot;#启动php&quot; class=&quot;headerlink&quot; title=&quot;启动php&quot;&gt;&lt;/a&gt;启动php&lt;/h4&gt;&lt;p&gt;Nginx是没办法以模块化方式或者CGI方式跟php结合的，php就可以工作在fastcgi模式下。即单独启动为服务。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/php.ini
post_max_size = 16M
max_execution_time = 300
max_input_time = 300
date.timezone = Asia/Shanghai
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl start php-fpm.service
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;部署zabbix-web-1&quot;&gt;&lt;a href=&quot;#部署zabbix-web-1&quot; class=&quot;headerlink&quot; title=&quot;部署zabbix web&quot;&gt;&lt;/a&gt;部署zabbix web&lt;/h4&gt;&lt;p&gt;将zabbix安装目录下 frontends/php 下面的php源代码文件拷贝到web服务器html文件目录下面。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mkdir /usr/local/openresty/nginx/html/zabbix
# cp -ar /usr/local/zabbix-3.0.1/frontends/php/* /usr/local/openresty/nginx/html//zabbix/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;修改nginx配置文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr/local/openresty/nginx/conf/
# cp nginx.conf nginx.conf.bak
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置文件内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#user  nobody;
worker_processes  1;

error_log  logs/error.log info;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

#pid        logs/nginx.pid;

events {
        worker_connections  1024;
}

http {
        include       mime.types;
        default_type  application/octet-stream;

        log_format  main  &amp;apos;$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; &amp;apos; &amp;apos;$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; &amp;apos; &amp;apos;&amp;quot;$http_user_agent&amp;quot; &amp;quot;$http_x_forwarded_for&amp;quot;&amp;apos;;

        #access_log  logs/access.log  main;

        proxy_buffer_size  128k;
        proxy_buffers   32 32k; 
        proxy_busy_buffers_size 128k;

           sendfile        on;
           #tcp_nopush     on;

        #keepalive_timeout  0;
        keepalive_timeout  65;

        #gzip  on;

           server {
                listen       80;
                    server_name  zabbix.wisedu.com;

                     #charset koi8-r;

                     access_log  logs/zabbix.access.log  main;

                      index index.php index.html index.html;
                     root /usr/local/openresty/nginx/html;

                  if ($request_uri ~ ^(.+\.php)(.*)$) {
                                set $req $2;
                     }
                     if ($req ~* &amp;quot;union[+|(%20)]&amp;quot;) {
                                return 503;
                     }
                     if ($req ~* &amp;quot;and[+|(%20)]&amp;quot;) { 
                                return 503;
                    }
                     if ($req ~* &amp;quot;select[+|(%20)]&amp;quot;) { 
                                return 503;
                    }
                     if ($req ~* &amp;quot;or[+|(%20)]&amp;quot;) { 
                                return 503;
                    }
                     if ($req ~* &amp;quot;concat[+|(%20)]&amp;quot;) { 
                                return 503;
                    }
                     if ($req ~* &amp;quot;cost[+|(%20)]&amp;quot;) { 
                                return 503;
                    }

                     location / {
                                try_files $uri $uri/ /index.php?$args;
                      }

                     location ~ .*\.(php)?$ {
                                fastcgi_buffer_size 128k;
                                fastcgi_buffers 4 256k;
                                fastcgi_busy_buffers_size 256k;
                              expires -1s;
                              try_files $uri =404;
                                fastcgi_split_path_info ^(.+\.php)(/.+)$;
                                include fastcgi_params;
                                fastcgi_param PATH_INFO $fastcgi_path_info;
                                fastcgi_index index.php;
                                fastcgi_param SCRIPT_FILENAME $document_root $fastcgi_script_name;
                                fastcgi_pass 127.0.0.1:9000;
                    }

                       error_page   500 502 503 504  /50x.html;
                   location = /50x.html {
                                 root   html;
                       }
                }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;浏览器访问url进行安装，安装过程和上面httpd一样。&lt;/p&gt;
&lt;h4 id=&quot;切割Nginx日志&quot;&gt;&lt;a href=&quot;#切割Nginx日志&quot; class=&quot;headerlink&quot; title=&quot;切割Nginx日志&quot;&gt;&lt;/a&gt;切割Nginx日志&lt;/h4&gt;&lt;p&gt;如果开启Nginx的debug日志，就需要考虑到切割日志：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /etc/logrotate.d/
# vim nginx
/usr/local/openresty/nginx/logs/*.log {
        notifempty
        weekly
        rotate 4
        nocompress
        copytruncate
        postrotate
        service nginx reload
        endscript
}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;其他主机安装agent&quot;&gt;&lt;a href=&quot;#其他主机安装agent&quot; class=&quot;headerlink&quot; title=&quot;其他主机安装agent&quot;&gt;&lt;/a&gt;其他主机安装agent&lt;/h1&gt;&lt;p&gt;log1和log2主机安装agent。&lt;/p&gt;
&lt;h2 id=&quot;添加用户&quot;&gt;&lt;a href=&quot;#添加用户&quot; class=&quot;headerlink&quot; title=&quot;添加用户&quot;&gt;&lt;/a&gt;添加用户&lt;/h2&gt;&lt;p&gt;Zabbix agent也不能用root用户运行，要以zabbix用户身份运行。否则：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ./zabbix_agentd
zabbix_agentd [15530]: user zabbix does not exist
zabbix_agentd [15530]: cannot run as root!
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加用户：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# groupadd zabbix
# useradd -g zabbix zabbix
# id zabbix
uid=1000(zabbix) gid=1000(zabbix) groups=1000(zabbix)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;安装agent&quot;&gt;&lt;a href=&quot;#安装agent&quot; class=&quot;headerlink&quot; title=&quot;安装agent&quot;&gt;&lt;/a&gt;安装agent&lt;/h2&gt;&lt;p&gt;从console主机上将zabbix源代码包copy过来：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console local]# scp -p zabbix-3.0.1.tar.gz root@114.55.29.86:/usr/local/
[root@console local]# scp -p zabbix-3.0.1.tar.gz root@114.55.29.241:/usr/local/

# yum install -y gcc
# cd /usr/local/
# tar zxf zabbix-3.0.1.tar.gz
# cd zabbix-3.0.1/
# ./configure --prefix=/usr/local/zabbix-3.0.1/ --enable-agent
# make &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;配置agent&quot;&gt;&lt;a href=&quot;#配置agent&quot; class=&quot;headerlink&quot; title=&quot;配置agent&quot;&gt;&lt;/a&gt;配置agent&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;# cd /usr/local/zabbix-3.0.1/etc/
# mv zabbix_agentd.conf zabbix_agentd.conf.bak
# cat zabbix_agentd.conf.bak | grep -v &amp;quot;#&amp;quot; | grep -v &amp;quot;^$&amp;quot; &amp;gt; zabbix_agentd.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;修改后的agent配置文件内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat zabbix_agentd.conf
LogFile=/var/log/zabbix_agentd.log
Server=114.55.29.246
# 主动向zabbix server发送监控内容
ServerActive=114.55.29.246
# 本机的主机名或IP地址
Hostname=log1
Include=/usr/local/zabbix-3.0.1/etc/zabbix_agentd.conf.d/*.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;创建日志文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# touch /var/log/zabbix_agentd.log
# chmod 777 /var/log/zabbix_agentd.log
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;启动agent&quot;&gt;&lt;a href=&quot;#启动agent&quot; class=&quot;headerlink&quot; title=&quot;启动agent&quot;&gt;&lt;/a&gt;启动agent&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;# cd /usr/local/zabbix-3.0.1/sbin/
# ./zabbix_agentd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看端口是否监听，默认agent端口是10050：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# lsof -i :10050
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/zabbix/27.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以查看日志：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# tail -100f /var/log/zabbix_agentd.log
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;停止agent&quot;&gt;&lt;a href=&quot;#停止agent&quot; class=&quot;headerlink&quot; title=&quot;停止agent&quot;&gt;&lt;/a&gt;停止agent&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;# killall -9 zabbix_agentd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;具体的监控配置实例见下一篇文章。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;实验环境&quot;&gt;&lt;a href=&quot;#实验环境&quot; class=&quot;headerlink&quot; title=&quot;实验环境&quot;&gt;&lt;/a&gt;实验环境&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;console&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.246&lt;/td&gt;
&lt;td&gt;Httpd、Nginx、MySQL、Zabbix&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log1&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.86&lt;/td&gt;
&lt;td&gt;Zabbix agent&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log2&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.241&lt;/td&gt;
&lt;td&gt;Zabbix agent&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
    
    </summary>
    
      <category term="Zabbix" scheme="http://yoursite.com/categories/Zabbix/"/>
    
    
      <category term="监控 zabbix" scheme="http://yoursite.com/tags/%E7%9B%91%E6%8E%A7-zabbix/"/>
    
  </entry>
  
  <entry>
    <title>速成RPM包制作</title>
    <link href="http://yoursite.com/2017/04/21/%E9%80%9F%E6%88%90RPM%E5%8C%85%E5%88%B6%E4%BD%9C/"/>
    <id>http://yoursite.com/2017/04/21/速成RPM包制作/</id>
    <published>2017-04-21T06:38:46.000Z</published>
    <updated>2017-04-21T09:43:10.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;FPM&quot;&gt;&lt;a href=&quot;#FPM&quot; class=&quot;headerlink&quot; title=&quot;FPM&quot;&gt;&lt;/a&gt;FPM&lt;/h1&gt;&lt;p&gt;由于很多软件在安装时需要编译，这会浪费不少的时间，为了提升部署效率，于是就想到制作rpm包。&lt;br&gt;通常rpm包的制作是使用rpmbuild命令来制作，但是你需要知道它的语法，比较繁琐。这就用到了FPM。&lt;br&gt;FPM功能简单说就是将一种类型的包转换成另一种类型。FPM是Ruby模块，其实打包时也是调用rpmbuild命令。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;&lt;strong&gt;支持的源类型包：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;dir 将目录打包成所需要的类型，可以用于源码编译安装的软件包&lt;/li&gt;
&lt;li&gt;rpm 对rpm进行转换&lt;/li&gt;
&lt;li&gt;gem 对rubygem包进行转换&lt;/li&gt;
&lt;li&gt;python 将python模块打包成相应的类型&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;支持的目标类型包：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;rpm 转换成rpm包&lt;/li&gt;
&lt;li&gt;deb 转换成deb包&lt;/li&gt;
&lt;li&gt;solaris 转换成solaris包&lt;/li&gt;
&lt;li&gt;puppet 转换成puppet模块&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;安装FPM&quot;&gt;&lt;a href=&quot;#安装FPM&quot; class=&quot;headerlink&quot; title=&quot;安装FPM&quot;&gt;&lt;/a&gt;安装FPM&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装依赖包&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# yum -y install ruby rubygems ruby-devel&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;添加仓库&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# gem sources -a http://gems.ruby-china.org/&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;移除原有的仓库&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# gem sources --remove https://rubygems.org/&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查看仓库是不是只有自己添加的那个仓库地址&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# gem sources -l &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;https://gems.ruby-china.org&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;安装fpm&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# gem install fpm&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;如何查看fpm帮助&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# fpm --help&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;常用参数：&lt;/strong&gt;&lt;br&gt;-s 指定源类型&lt;br&gt;-t 指定目标类型&lt;br&gt;-n 指定包的名字&lt;br&gt;-v 指定包的版本号&lt;br&gt;-C 指定打包的相对路径 change directory to here before searching for files&lt;br&gt;-d 指定依赖于哪些包&lt;br&gt;-f 第二次打包时目录下如果有同名安装包存在，则覆盖它&lt;br&gt;-p 输出的安装包的目录，不想放在当前目录下就需要指定&lt;br&gt;–post-install 软件包安装完成之后所要运行的脚本，同–after-install&lt;br&gt;–pre-install 软件包安装完成之前所要运行的脚本，同–before-install&lt;br&gt;–post-uninstall 软件包卸载之后所要运行的脚本，同–after-install&lt;br&gt;–pre-uninstall 软件包卸载之前所要运行的脚本，同–before-install&lt;/p&gt;
&lt;h1 id=&quot;打包示例&quot;&gt;&lt;a href=&quot;#打包示例&quot; class=&quot;headerlink&quot; title=&quot;打包示例&quot;&gt;&lt;/a&gt;打包示例&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;打包MySQL&lt;br&gt;事先安装好MySQL，MySQL安装过程这里不在详述。命令行终端输入以下命令，然后等待rpm包制作完成。&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# fpm -s dir -t rpm -n mysql -v 5.6.27 --description &amp;apos;author: jkzhao&amp;apos; -d &amp;apos;libaio&amp;apos; -d &amp;apos;libaio-devel&amp;apos; --pre-install /usr/local/mysql/mysql_pre_init.sh --post-install /usr/local/mysql/mysql_post_init.sh  /usr/local/mysql /usr/local/mysql-5.6.27-linux-glibc2.5-x86_64 /data&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：默认打好的包是在当前目录下。&lt;br&gt;&lt;strong&gt;命令说明：&lt;/strong&gt;&lt;br&gt;    -s dir：指定源文件是目录的形式&lt;br&gt;    -t rpm：指定打包的格式&lt;br&gt;    -n：指定打包后名称&lt;br&gt;    -v：版本号&lt;br&gt;   –description：描述信息&lt;br&gt;    -d：指定需要依赖的包。安装MySQL前需要在系统上安装libaio、libaio-devel。当你安装fpm打包成的rpm包时，它会先去检测系统上是否安装了这两个包，如果没有安装会给出提示，并终止rpm的安装。&lt;br&gt;    –pre-install：安装rpm包前需要执行的脚本&lt;br&gt;    –post-install：安装rpm包后需要执行的脚本 &lt;br&gt;&lt;br&gt;其中，mysql_pre_init.sh的内容如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#!/bin/bash&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;user=mysql&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;group=mysql&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# create group if not exists.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;egrep &amp;quot;^$group&amp;quot; /etc/group &amp;gt;&amp;amp; /dev/null&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;if [ $? -ne 0 ]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;then&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    groupadd -r -g 300 $group&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;fi&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# create user if not exists.  &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;egrep &amp;quot;^$user&amp;quot; /etc/passwd &amp;gt;&amp;amp; /dev/null&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;if [ $? -ne 0 ]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;then&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    useradd -g $group -r -s /sbin/nologin -u 300 $user&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;fi&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;mysql_post_init.sh的内容如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#!/bin/bash&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# cp my.cnf force.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;\cp /usr/local/mysql/my.cnf /etc/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# start/stop/restart script.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;\cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;chkconfig --add mysqld&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# MySQL Client PATH.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;\cp /usr/local/mysql/mysql.sh /etc/profile.d/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;cd /usr/local/mysql&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;chown -R root.mysql .&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;chown -R mysql.mysql /data&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;打包完成后正常安装，如：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# rpm -ivh mysql-5.6.27-1.x86_64.rpm&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;打包openresty&lt;br&gt;事先安装好openresty。命令行终端输入以下命令，然后等待rpm包制作完成。&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# fpm -s dir -t rpm -n openresty -v 1.9.7.3 --description &amp;apos;author: jkzhao&amp;apos; -d &amp;apos;openssl-devel&amp;apos; -d &amp;apos;readline-devel&amp;apos; -d &amp;apos;pcre-devel&amp;apos; -d &amp;apos;gcc&amp;apos; --post-install /usr/local/openresty/openresty_init.sh  /usr/local/openresty&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中，openresty_init.sh的内容如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#!/bin/bash&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;mv /usr/local/openresty/nginx.service /etc/systemd/system/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;systemctl enable nginx.service&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;如何卸载FPM打包好的rpm包&quot;&gt;&lt;a href=&quot;#如何卸载FPM打包好的rpm包&quot; class=&quot;headerlink&quot; title=&quot;如何卸载FPM打包好的rpm包&quot;&gt;&lt;/a&gt;如何卸载FPM打包好的rpm包&lt;/h1&gt;&lt;p&gt;如果重新安装rpm，必须先卸载rpm包，然后删除相应的目录及文件，否则再次安装时会报错。&lt;br&gt;&lt;strong&gt;注意：&lt;/strong&gt;卸载不要直接删除目录和文件，否则你再次安装这个包时会说已安装，冲突了。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# rpm -e --nodeps  mysql-5.6.27-1.x86_64.rpm&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后再去删除各个目录和配置文件。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;FPM&quot;&gt;&lt;a href=&quot;#FPM&quot; class=&quot;headerlink&quot; title=&quot;FPM&quot;&gt;&lt;/a&gt;FPM&lt;/h1&gt;&lt;p&gt;由于很多软件在安装时需要编译，这会浪费不少的时间，为了提升部署效率，于是就想到制作rpm包。&lt;br&gt;通常rpm包的制作是使用rpmbuild命令来制作，但是你需要知道它的语法，比较繁琐。这就用到了FPM。&lt;br&gt;FPM功能简单说就是将一种类型的包转换成另一种类型。FPM是Ruby模块，其实打包时也是调用rpmbuild命令。&lt;br&gt;
    
    </summary>
    
    
      <category term="rpm" scheme="http://yoursite.com/tags/rpm/"/>
    
  </entry>
  
  <entry>
    <title>vpn简介及openvpn搭建</title>
    <link href="http://yoursite.com/2016/09/06/vpn%E7%AE%80%E4%BB%8B%E5%8F%8Aopenvpn%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/2016/09/06/vpn简介及openvpn搭建/</id>
    <published>2016-09-06T03:33:59.000Z</published>
    <updated>2017-06-12T07:52:21.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;VPN介绍&quot;&gt;&lt;a href=&quot;#VPN介绍&quot; class=&quot;headerlink&quot; title=&quot;VPN介绍&quot;&gt;&lt;/a&gt;VPN介绍&lt;/h1&gt;&lt;h2 id=&quot;VPN概述&quot;&gt;&lt;a href=&quot;#VPN概述&quot; class=&quot;headerlink&quot; title=&quot;VPN概述&quot;&gt;&lt;/a&gt;VPN概述&lt;/h2&gt;&lt;p&gt;VPN(全称Virtual Private Network)虚拟专用网络，是依靠ISP和其他的NSP，在公共网络中建立专用的数据通信网络的技术，可以为企业之间或者个人与企业之间提供安全的数据传输隧道服务。在VPN中任意两点之间的连接并没有传统专网所需的端到端的物理链路，而是利用公共网络资源动态组成的，可以理解为通过私有的隧道技术在公共数据网络上模拟出来的和专网有同样功能的点到点的专线技术。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;VPN的主要应用场景&quot;&gt;&lt;a href=&quot;#VPN的主要应用场景&quot; class=&quot;headerlink&quot; title=&quot;VPN的主要应用场景&quot;&gt;&lt;/a&gt;VPN的主要应用场景&lt;/h2&gt;&lt;p&gt;我们根据VPN的常见企业应用，将VPN分为以下4类应用：&lt;/p&gt;
&lt;h3 id=&quot;出差在外访问公司内部资源&quot;&gt;&lt;a href=&quot;#出差在外访问公司内部资源&quot; class=&quot;headerlink&quot; title=&quot;出差在外访问公司内部资源&quot;&gt;&lt;/a&gt;出差在外访问公司内部资源&lt;/h3&gt;&lt;p&gt;企业内部员工出差、休假或特殊情况下在远离办公室的时候，又有需求访问公司的内部网络获取相关资源，就可以通过VPN拨号到公司内部。此时远程拨号的员工和办公室内的员工以及其他拨号的员工之间都相当于在一个局域网内。例如：访问内部的域控制器，文件服务器，OA系统，ERP，HTTP服务，内网飞秋聊天工具等局域网服务应用。&lt;br&gt;&lt;br&gt;运维人员需要个人电脑远程拨号到企业网站的IDC机房，远程维护IDC内网服务器。&lt;br&gt;&lt;br&gt;&lt;strong&gt;外出办公的人如何连接内网服务器呢？&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;没有VPN&lt;br&gt;先登录到外网服务器组中一台服务器，然后在这个外网服务器上SSH到内网服务器。&lt;/li&gt;
&lt;li&gt;有VPN&lt;br&gt;把VPN搭在某一台外网服务器(外网服务器有公网ip)上，这样外出办公人员可以通过vpn拨号到这台机器上，然后在自己笔记本上输入内网服务器的IP:port访问内网服务器。同时有了vpn，可以把外网服务器的远程连接SSH全部屏蔽起来，黑客就不能通过SSH服务来攻击公司的外网服务器。而公司的人员通过vpn拨号拨到这个装了vpn的外网服务器上去，然后访问内网服务器。访问外网服务器通过访问内网ip地址去访问。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;企业内部网络之间VPN服务&quot;&gt;&lt;a href=&quot;#企业内部网络之间VPN服务&quot; class=&quot;headerlink&quot; title=&quot;企业内部网络之间VPN服务&quot;&gt;&lt;/a&gt;企业内部网络之间VPN服务&lt;/h3&gt;&lt;p&gt;在公司的分支机构的局域网和公司内部LAN之间的VPN连接。通过公网Internet建立VPN将公司在各地的分支机构的LAN连接到公司总部的LAN。例如：各大超市之间业务结算等。&lt;br&gt;&lt;br&gt;这是由于地域的原因而产生的VPN需求，通过VPN让不同地域内的机器可以互相访问，就好像是一个局域网一样。例如：办公室互联协同办公，机房互联数据同步及业务访问。&lt;/p&gt;
&lt;h3 id=&quot;互联网公司多IDC机房之间VPN服务&quot;&gt;&lt;a href=&quot;#互联网公司多IDC机房之间VPN服务&quot; class=&quot;headerlink&quot; title=&quot;互联网公司多IDC机房之间VPN服务&quot;&gt;&lt;/a&gt;互联网公司多IDC机房之间VPN服务&lt;/h3&gt;&lt;p&gt;这是运维架构人员需要考虑的问题，不同机房之间业务管理和业务访问，数据流动。&lt;/p&gt;
&lt;h3 id=&quot;企业外部VPN服务&quot;&gt;&lt;a href=&quot;#企业外部VPN服务&quot; class=&quot;headerlink&quot; title=&quot;企业外部VPN服务&quot;&gt;&lt;/a&gt;企业外部VPN服务&lt;/h3&gt;&lt;p&gt;在供应商、合作伙伴的LAN和本公司的LAN之间建立的VPN服务。&lt;br&gt;&lt;br&gt;企业内部网络之间的VPN服务、企业内部网络之间VPN服务和企业外部VPN服务是一套系统，不同的场景。&lt;/p&gt;
&lt;h3 id=&quot;翻墙&quot;&gt;&lt;a href=&quot;#翻墙&quot; class=&quot;headerlink&quot; title=&quot;翻墙&quot;&gt;&lt;/a&gt;翻墙&lt;/h3&gt;&lt;p&gt;翻墙的原理：比如有个VPS，有美国的ip地址。各位的笔记本或台式机通过vpn访问到美国的vps的机器，然后通过这个vitual private server出去访问美国的网站。在网站看来，你的源ip是美国的vps的地址，而你笔记本和vps之间的通信是加密的，走的是vpn协议。vps和后端的网站之间走的是http协议。&lt;/p&gt;
&lt;h2 id=&quot;实现vpn功能的常见开源产品&quot;&gt;&lt;a href=&quot;#实现vpn功能的常见开源产品&quot; class=&quot;headerlink&quot; title=&quot;实现vpn功能的常见开源产品&quot;&gt;&lt;/a&gt;实现vpn功能的常见开源产品&lt;/h2&gt;&lt;h3 id=&quot;PPTP-VPN&quot;&gt;&lt;a href=&quot;#PPTP-VPN&quot; class=&quot;headerlink&quot; title=&quot;PPTP VPN&quot;&gt;&lt;/a&gt;PPTP VPN&lt;/h3&gt;&lt;p&gt;PPTP VPN的最大优点是，不需要在windows客户端单独安装vpn客户端软件，windows默认就支持PPTP VPN拨号连接功能。PPTP VPN属于点对点方式的应用，比较适合远程的企业用户拨号到企业进行办公等的应用，但是很多网络设备不支持PPTP，导致无法访问。典型的Linux平台上的开源软件是pptp。&lt;/p&gt;
&lt;h3 id=&quot;SSL-VPN&quot;&gt;&lt;a href=&quot;#SSL-VPN&quot; class=&quot;headerlink&quot; title=&quot;SSL VPN&quot;&gt;&lt;/a&gt;SSL VPN&lt;/h3&gt;&lt;p&gt;PPTP主要为那些经常外出移动或家庭办公的用户考虑的，而OpenVPN不但可以使用于PPTP的应用场景，还适合针对企业异地两地总分公司之间的VPN不间断按需连接，例如：ERP，OA，及时通讯工具等在总分企业中的应用。但是需要在系统上单独安装客户端软件。典型的Linux平台的开源软件是openvpn。&lt;/p&gt;
&lt;h3 id=&quot;IPSEC-VPN&quot;&gt;&lt;a href=&quot;#IPSEC-VPN&quot; class=&quot;headerlink&quot; title=&quot;IPSEC VPN&quot;&gt;&lt;/a&gt;IPSEC VPN&lt;/h3&gt;&lt;p&gt;IPSEC VPN也适合针对企业异地两地总分公司或多个IDC机房之间的VPN不间断连接，并且在部署使用上更加方便，典型的Linux平台上IPSEC VPN的开源产品是openswan。&lt;/p&gt;
&lt;h1 id=&quot;Linux平台搭建OpenVPN&quot;&gt;&lt;a href=&quot;#Linux平台搭建OpenVPN&quot; class=&quot;headerlink&quot; title=&quot;Linux平台搭建OpenVPN&quot;&gt;&lt;/a&gt;Linux平台搭建OpenVPN&lt;/h1&gt;&lt;h2 id=&quot;环境规划&quot;&gt;&lt;a href=&quot;#环境规划&quot; class=&quot;headerlink&quot; title=&quot;环境规划&quot;&gt;&lt;/a&gt;环境规划&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;th&gt;运行的进程&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;odsee&lt;/td&gt;
&lt;td&gt;172.16.4.81&lt;/td&gt;
&lt;td&gt;CentOS 6.3&lt;/td&gt;
&lt;td&gt;openvpn-2.2.2.tar.gz&lt;/td&gt;
&lt;td&gt;openvpn&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;配置vpn-server时间同步&quot;&gt;&lt;a href=&quot;#配置vpn-server时间同步&quot; class=&quot;headerlink&quot; title=&quot;配置vpn server时间同步&quot;&gt;&lt;/a&gt;配置vpn server时间同步&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee ~]# /usr/sbin/ntpdate pool.ntp.org&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;加入到定时任务:&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee ~]# echo &amp;apos;#time sync&amp;apos; &amp;gt;&amp;gt; /var/spool/cron/root&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee ~]#  echo &amp;apos;*/5 * * * * /usr/sbin/ntpdate pool.ntp.org &amp;gt;/dev/null 2&amp;gt;&amp;amp;1&amp;apos; &amp;gt;&amp;gt;/var/spool/cron/root&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意:&lt;/strong&gt;如果vpn服务器和拨号的计算机客户端时间不一致，可能会导致VPN连接失败。&lt;/p&gt;
&lt;h2 id=&quot;安装openvpn&quot;&gt;&lt;a href=&quot;#安装openvpn&quot; class=&quot;headerlink&quot; title=&quot;安装openvpn&quot;&gt;&lt;/a&gt;安装openvpn&lt;/h2&gt;&lt;p&gt;1.建立openvpn软件存放目录，并上传软件 &lt;br&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee ~]# cd /usr/local/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee local]# mkdir openvpn&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee local]# cd openvpn/&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意:&lt;/strong&gt;openvpn网上用的最多的是lzo-2.0.2和openvpn-2.0.9，这两个也是最稳定的。&lt;/p&gt;
&lt;p&gt;2.安装lzo压缩模块 &lt;br&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn]# tar zxf lzo-2.06.tar.gz&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn]# cd lzo-2.06&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee lzo-2.06]# ./configure&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee lzo-2.06]# make&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee lzo-2.06]# make install&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;3.安装openvpn软件 &lt;br&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee lzo-2.06]# cd ..&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn]# tar zxf openvpn-2.2.2.tar.gz&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn]# cd openvpn-2.2.2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;查看依赖包有没有安装，openvpn需要ssl支持：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn-2.2.2]# rpm -qa|grep openssl&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn-2.2.2]# ./configure --with-lzo-headers=/usr/local/include --with-lzo-lib=/usr/local/lib&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn-2.2.2]# make&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn-2.2.2]# make install&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;4.配置openvpn server，建立CA证书 &lt;br&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn-2.2.2]# cd easy-rsa/2.0/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# cp vars.bak vars20151204.bak&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# vim vars&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;修改完vars文件后，执行source vars使修改生效：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;清除所有证书keys：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# ./clean-all&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;创建新的ca证书：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/8.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# vim vars&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/9.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# source vars&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/10.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# ./clean-all&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# ./build-ca&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/11.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;查看生成的证书：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/12.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;5.生成服务器端证书和密钥key文件 &lt;br&gt;&lt;br&gt;[root@odsee 2.0]# ./build-key-server server&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/13.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/14.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;也可以输入密码。 &lt;br&gt;&lt;br&gt;查看创建的服务端证书：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/15.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;6.生成客户端证书和key文件 &lt;br&gt;&lt;br&gt;生成client证书和key文件。若建立多个客户端证书，则重复如下步骤即可。只需修改Common Name项的名称。 &lt;br&gt;&lt;br&gt;在openvpn中，这种配置方法是每一个登陆的VPN客户端需要一个证书，每个证书在同一时刻只能供一个客户端连接。下面建立1份客户端证书，key的名字叫test。在工作中一般名字为人的名字。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/16.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/17.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/18.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;.crt是证书，.key是密钥文件。这两个都是客户端需要的。 &lt;br&gt;&lt;br&gt;&lt;strong&gt;注意:&lt;/strong&gt;使用build-key给客户端生成证书和密钥，客户端拨号是不需要密码的。但是也可以加密码，使用build-key-pass脚本创建证书和密钥文件，这样你在客户端拨号的时候需要加密码，密码是拨号vpn的密码。 &lt;br&gt;&lt;br&gt;下面使用build-key-pass创建另一个客户端证书和密钥文件。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee ~]# cd /usr/local/openvpn/openvpn-2.2.2/easy-rsa/2.0&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/19.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/20.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;7.生成vpn密钥协议交换文件 &lt;br&gt;&lt;br&gt;生成传输进行密钥交换时用到的交换密钥协议文件：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# ./build-dh&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/21.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;查看生成的文件：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/22.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;8.详解服务器及客户端的证书各文件用途 &lt;br&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/23.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;为了防止恶意攻击(如DOS、UDP port flooding)，我们生成一个“HMAC firewall”：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# openvpn --genkey --secret keys/ta.key&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/24.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;到此文件生成工作完成了。&lt;/p&gt;
&lt;p&gt;9.详解服务器端VPN重要命令 &lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;vars脚本：是用来创建环境变量，设置所需要的变量的脚本&lt;/li&gt;
&lt;li&gt;clean-all脚本：清理生成ca证书及密钥文件&lt;/li&gt;
&lt;li&gt;build-ca脚本：生成ca证书(交互)&lt;/li&gt;
&lt;li&gt;build-key-server脚本：生成服务器端密钥(交互)&lt;/li&gt;
&lt;li&gt;build-key脚本：生成客户端密钥(交互)&lt;/li&gt;
&lt;li&gt;build-key-pass脚本：生成客户端带密码的密钥文件(交互)&lt;/li&gt;
&lt;li&gt;build-dh脚本：脚本生成Diffie-Hellman文件(交互)&lt;/li&gt;
&lt;li&gt;pkitool脚本：直接使用vars的环境变量设置，直接生成证书(非交互)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;10.详解openvpn服务端重要配置参数 &lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拷贝keys及配置&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# mkdir /etc/openvpn/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# cp -ap keys/ /etc/openvpn/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# cd /usr/local/openvpn/openvpn-2.2.2/sample-config-files/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee sample-config-files]# cp client.conf server.conf /etc/openvpn/&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/25.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;修改服务端配置文件&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# cd /etc/openvpn/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn]# grep -vE &amp;quot;;|#|^$&amp;quot; server.conf &amp;gt;tmp.log&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn]# cat tmp.log &amp;gt;server.conf&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/26.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;常用的配置说明：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;配置参数&lt;/th&gt;
&lt;th&gt;参数说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;local 10.0.0.28(外网卡地址)&lt;/td&gt;
&lt;td&gt;哪一个本地地址要被openvpn进行监听&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;port 52115&lt;/td&gt;
&lt;td&gt;监听的端口，默认是1194，这里为了安全起见，修改为52115&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;proto udp&lt;/td&gt;
&lt;td&gt;指定监听的协议，当并发访问多时，推荐tcp&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dev tun&lt;/td&gt;
&lt;td&gt;vpn server的模式采用路由模式，可选tap或tun&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ca ca.crt&lt;/td&gt;
&lt;td&gt;ca证书，注意此文件和server.conf在一个目录下，否则要用绝对路径调用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cert server.crt&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;key server.key&lt;/td&gt;
&lt;td&gt;this file should be kept secret&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dh dh1024.pem&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;server 10.8.0.0&lt;/td&gt;
&lt;td&gt;这个是vpn server动态分配给vpn client的地址池，一般不需要更改。这个段不要和任何网络地址段冲突或者重复&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ifconfig-pool-persist ipp.txt&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;push “route 172.16.1.0 255.255.255.0”&lt;/td&gt;
&lt;td&gt;这个是vpn server所在的内网网段，如果有多个可以写多个push，注意，此命令实际作用是在vpn client本地生成vpn sever所在的内网网段路由，确保能够和vpn server所在的内网网段通信&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;client-to-client&lt;/td&gt;
&lt;td&gt;允许拨号的多个vpn client互相通信&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;duplicate-cn&lt;/td&gt;
&lt;td&gt;允许多个客户端使用同一个帐号连接&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;keepalive 10 20&lt;/td&gt;
&lt;td&gt;每10秒ping一次，若是120秒未收到包，即认定客户端断线&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;comp-lzo&lt;/td&gt;
&lt;td&gt;开启压缩功能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;persist-key&lt;/td&gt;
&lt;td&gt;当vpn超时后，当重新启动vpn后，保持上一次使用的私钥，而不重新读取私钥&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;persist-tun&lt;/td&gt;
&lt;td&gt;通过keepalive检测vpn超时后，当重新启动vpn后，保持tun或者tap设备自动连接状态&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;status openvpn-status.log&lt;/td&gt;
&lt;td&gt;openvpn日志状态信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;log /var/log/openvpn.log&lt;/td&gt;
&lt;td&gt;日志文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;verb 3&lt;/td&gt;
&lt;td&gt;指定日志文件冗余&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;配置调试vpn并运行vpn服务&quot;&gt;&lt;a href=&quot;#配置调试vpn并运行vpn服务&quot; class=&quot;headerlink&quot; title=&quot;配置调试vpn并运行vpn服务&quot;&gt;&lt;/a&gt;配置调试vpn并运行vpn服务&lt;/h2&gt;&lt;p&gt;1.取消防火墙对vpnserver端口的限制以及允许服务转发。或者先关闭防火墙，调好VPN，在开启防火墙 &lt;br&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee ~]# service iptables stop&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;2.开启内核转发功能 &lt;br&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee ~]# sed -i &amp;apos;s#net.ipv4.ip_forward = 0#net.ipv4.ip_forward = 1#&amp;apos; /etc/sysctl.conf&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/27.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee ~]# sysctl -p&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意:&lt;/strong&gt;iptables和内核的ip_forward都需要开启允许转发。&lt;/p&gt;
&lt;p&gt;3.关闭SELinux &lt;br&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee ~]# setenforce 0&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee ~]# vim /etc/sysconfig/selinux&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/28.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4.启动服务端的VPN服务 &lt;br&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn]# /usr/local/sbin/openvpn --config /etc/openvpn/server.conf &amp;amp;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn]# netstat -anp|grep vpn&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/29.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;查看日志：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/30.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;5.服务端查看虚拟网卡 &lt;br&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/31.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;安装windows-VPN客户端，配置VPN连接&quot;&gt;&lt;a href=&quot;#安装windows-VPN客户端，配置VPN连接&quot; class=&quot;headerlink&quot; title=&quot;安装windows VPN客户端，配置VPN连接&quot;&gt;&lt;/a&gt;安装windows VPN客户端，配置VPN连接&lt;/h1&gt;&lt;h2 id=&quot;下载安装客户端&quot;&gt;&lt;a href=&quot;#下载安装客户端&quot; class=&quot;headerlink&quot; title=&quot;下载安装客户端&quot;&gt;&lt;/a&gt;下载安装客户端&lt;/h2&gt;&lt;p&gt;下载地址：&lt;a href=&quot;http://swupdate.openvpn.org/community/releases/openvpn-2.2.2-install.exe&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://swupdate.openvpn.org/community/releases/openvpn-2.2.2-install.exe&lt;/a&gt; &lt;br&gt;&lt;br&gt;安装过程中，有一步骤需要信任，见下图：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/32.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;配置客户端证书&quot;&gt;&lt;a href=&quot;#配置客户端证书&quot; class=&quot;headerlink&quot; title=&quot;配置客户端证书&quot;&gt;&lt;/a&gt;配置客户端证书&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee keys]# cd /usr/local/openvpn/openvpn-2.2.2/easy-rsa/2.0/keys/&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;先从vpnserver上把那个登录不需要密码的证书和密钥传下来：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee keys]# sz ca.crt test.crt test.key&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee keys]# cd /usr/local/openvpn/openvpn-2.2.2/sample-config-files/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee sample-config-files]# sz client.conf&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;把这些文件放到一个文件夹里：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/33.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/34.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;把这个文件夹放到OpenVPN安装目录的config目录下：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/35.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;配置客户端的配置文件Client-conf&quot;&gt;&lt;a href=&quot;#配置客户端的配置文件Client-conf&quot; class=&quot;headerlink&quot; title=&quot;配置客户端的配置文件Client.conf&quot;&gt;&lt;/a&gt;配置客户端的配置文件Client.conf&lt;/h2&gt;&lt;p&gt;备份配置文件：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/36.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可以在服务器上过滤配置文件，查看默认配置：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee openvpn]# egrep -v &amp;quot;^#|^;|^$&amp;quot; client.conf&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/37.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/38.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;新建一个文件test.ovpn文件，然后贴入下面的内容：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/39.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;client&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;dev tun&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;proto tcp&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;remote 172.16.4.81 52115&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;resolv-retry infinite&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;nobind&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;persist-key&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;persist-tun&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;ca ca.crt&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;cert test.crt&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;key test.key&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;ns-cert-type server&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;comp-lzo&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;verb 3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;拨号连接调试&quot;&gt;&lt;a href=&quot;#拨号连接调试&quot; class=&quot;headerlink&quot; title=&quot;拨号连接调试&quot;&gt;&lt;/a&gt;拨号连接调试&lt;/h2&gt;&lt;p&gt;在windows上拨号远程连接openvpn服务，先双击如下图标：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/40.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;然后右下角右击图标，点击connect：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/41.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/42.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;但是发现上不了网，能连上，查看连接vpn前的路由和连接vpn后的路由：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/43.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;测试vpn客户端连接vpn server连通性的方法：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/44.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;原因是：没有设置客户端的默认网关通过vpn出去：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/45.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/46.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;最后改完的配置如下：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/47.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;为什么dns不用8.8.8.8？因为这台vpn server(172.16.4.81) ping不通8.8.8.8&lt;/p&gt;
&lt;h1 id=&quot;常见问题&quot;&gt;&lt;a href=&quot;#常见问题&quot; class=&quot;headerlink&quot; title=&quot;常见问题&quot;&gt;&lt;/a&gt;常见问题&lt;/h1&gt;&lt;p&gt;1.拨号后地址也获取到了，但是就是访问别人时地址，别人那边看到的访问记录还是你原来的ip地址？ &lt;br&gt;&lt;br&gt;解决：以管理员身份运行软件，在拨号上网。&lt;/p&gt;
&lt;p&gt;2.长时间不去生成证书，再次生成证书时如下： &lt;br&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/48.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;解决：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# source vars&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;NOTE: If you run ./clean-all, I will be doing a rm -rf on /usr/local/openvpn/openvpn-2.2.2/easy-rsa/2.0/keys&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@odsee 2.0]# ./build-key-pass ldh&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/49.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;把生成的3个证书copy到/etc/openvpn/keys目录下。然后给别人用时给.crt .key以及ca.crt3个文件。&lt;/p&gt;
&lt;p&gt;3.win10启动openvpn报错： &lt;br&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/50.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;解决：&lt;br&gt;到openvpn安装后的bin下依次以管理员身份执行：delalltap.bat和addtap.bat &lt;br&gt;&lt;br&gt;如果解决上面的问题，还是报错：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/OpenVPN/51.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;解决：&lt;br&gt;以管理员运行openvpn客户端。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;VPN介绍&quot;&gt;&lt;a href=&quot;#VPN介绍&quot; class=&quot;headerlink&quot; title=&quot;VPN介绍&quot;&gt;&lt;/a&gt;VPN介绍&lt;/h1&gt;&lt;h2 id=&quot;VPN概述&quot;&gt;&lt;a href=&quot;#VPN概述&quot; class=&quot;headerlink&quot; title=&quot;VPN概述&quot;&gt;&lt;/a&gt;VPN概述&lt;/h2&gt;&lt;p&gt;VPN(全称Virtual Private Network)虚拟专用网络，是依靠ISP和其他的NSP，在公共网络中建立专用的数据通信网络的技术，可以为企业之间或者个人与企业之间提供安全的数据传输隧道服务。在VPN中任意两点之间的连接并没有传统专网所需的端到端的物理链路，而是利用公共网络资源动态组成的，可以理解为通过私有的隧道技术在公共数据网络上模拟出来的和专网有同样功能的点到点的专线技术。&lt;br&gt;
    
    </summary>
    
      <category term="VPN" scheme="http://yoursite.com/categories/VPN/"/>
    
    
      <category term="vpn, openvpn" scheme="http://yoursite.com/tags/vpn-openvpn/"/>
    
  </entry>
  
  <entry>
    <title>安装部署Apache Hadoop (完全分布式模式并且实现NameNode HA和ResourceManager HA)</title>
    <link href="http://yoursite.com/2016/08/07/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Apache%20Hadoop%20(%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%BC%8F%E5%B9%B6%E4%B8%94%E5%AE%9E%E7%8E%B0NameNode%20HA%E5%92%8CResourceManager%20HA)/"/>
    <id>http://yoursite.com/2016/08/07/安装部署Apache Hadoop (完全分布式模式并且实现NameNode HA和ResourceManager HA)/</id>
    <published>2016-08-07T08:51:08.000Z</published>
    <updated>2017-06-13T00:53:43.000Z</updated>
    
    <content type="html">&lt;p&gt;关于Apache Hadoop的介绍以本地模式、伪分布式安装部署请参见上篇博文，本篇博文主要记录完全分布式部署，并实现NameNode高可用和ResourceManager高可用。&lt;/p&gt;
&lt;h1 id=&quot;环境规划&quot;&gt;&lt;a href=&quot;#环境规划&quot; class=&quot;headerlink&quot; title=&quot;环境规划&quot;&gt;&lt;/a&gt;环境规划&lt;/h1&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;th&gt;运行的进程&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;hadoop16&lt;/td&gt;
&lt;td&gt;172.16.206.16&lt;/td&gt;
&lt;td&gt;CentOS 7.2&lt;/td&gt;
&lt;td&gt;JDK1.7、hadoop-2.7.2&lt;/td&gt;
&lt;td&gt;NameNode、DFSZKFailoverController(zkfc)、ResourceManager&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hadoop26&lt;/td&gt;
&lt;td&gt;172.16.206.26&lt;/td&gt;
&lt;td&gt;CentOS 6.5&lt;/td&gt;
&lt;td&gt;JDK1.7、hadoop-2.7.2&lt;/td&gt;
&lt;td&gt;NameNode、DFSZKFailoverController(zkfc)、ResourceManager&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hadoop27&lt;/td&gt;
&lt;td&gt;172.16.206.27&lt;/td&gt;
&lt;td&gt;CentOS 6.5&lt;/td&gt;
&lt;td&gt;JDK1.7、hadoop-2.7.2、Zookeeper&lt;/td&gt;
&lt;td&gt;DataNode、NodeManager、JournalNode、QuorumPeerMain&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hadoop28&lt;/td&gt;
&lt;td&gt;172.16.206.28&lt;/td&gt;
&lt;td&gt;CentOS 6.5&lt;/td&gt;
&lt;td&gt;JDK1.7、hadoop-2.7.2、Zookeeper&lt;/td&gt;
&lt;td&gt;DataNode、NodeManager、JournalNode、QuorumPeerMain&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hadoop29&lt;/td&gt;
&lt;td&gt;172.16.206.29&lt;/td&gt;
&lt;td&gt;CentOS 6.5&lt;/td&gt;
&lt;td&gt;JDK1.7、hadoop-2.7.2、Zookeeper&lt;/td&gt;
&lt;td&gt;DataNode、NodeManager、JournalNode、QuorumPeerMain&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;这里由于机器紧张，将NameNode和ResourceManager安装在一台机器上。在hadoop16主机上安装NameNode和ResourceManager使其处于active状态，在hadoop26上安装NameNode和ResourceManager使其处于standby状态。&lt;/p&gt;
&lt;p&gt;环境拓扑：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/32.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;注意：&lt;/strong&gt;这里由于实验环境，所以将NameNode和ResourceManager放在了一起，生产环境下应该将NameNode和ResourceManager放在单独的机器上。&lt;br&gt;&lt;br&gt;Hadoop2.0官方提供了两种HDFS HA的解决方案，一种是NFS，另一种是QJM。这两种共享数据的方案，NFS是操作系统层面的，JournalNode是hadoop层面的，这里我们使用简单的QJM集群进行数据共享。在该方案中，主备NameNode之间通过一组JournalNode同步元数据信息，一条数据只要成功写入多数JournalNode即认为写入成功。通常配置奇数个JournalNode。&lt;br&gt;&lt;br&gt;这里还配置了一个zookeeper集群(27,28,29主机)，用于ZKFC（DFSZKFailoverController）故障转移，当Active NameNode挂掉了，会自动切换Standby NameNode和ResourceManager为standby状态。同时27,28,29主机作为DataNode节点。&lt;/p&gt;
&lt;h1 id=&quot;配置集群各节点hosts文件&quot;&gt;&lt;a href=&quot;#配置集群各节点hosts文件&quot; class=&quot;headerlink&quot; title=&quot;配置集群各节点hosts文件&quot;&gt;&lt;/a&gt;配置集群各节点hosts文件&lt;/h1&gt;&lt;p&gt;在各节点，编辑hosts文件，配置好各节点主机名和ip地址的对应关系：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# vim /etc/hosts&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;172.16.206.16 hadoop16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;172.16.206.26 hadoop26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;172.16.206.27 hadoop27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;172.16.206.28 hadoop28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;172.16.206.29 hadoop29&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;安装JDK1-7&quot;&gt;&lt;a href=&quot;#安装JDK1-7&quot; class=&quot;headerlink&quot; title=&quot;安装JDK1.7&quot;&gt;&lt;/a&gt;安装JDK1.7&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Hadoop Java Versions&lt;/strong&gt; &lt;br&gt;&lt;br&gt;Version 2.7 and later of Apache Hadoop requires Java 7. It is built and tested on both OpenJDK and Oracle (HotSpot)’s JDK/JRE. &lt;br&gt;&lt;br&gt;Earlier versions (2.6 and earlier) support Java 6.&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# mkdir /usr/java&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# tar zxf /usr/local/jdk-7u80-linux-x64.gz -C /usr/java/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# vim /etc/profile&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;export JAVA_HOME=/usr/java/jdk1.7.0_80&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;export PATH=$JAVA_HOME/bin:$PATH&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# source /etc/profile&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;安装依赖包ssh和rsync&quot;&gt;&lt;a href=&quot;#安装依赖包ssh和rsync&quot; class=&quot;headerlink&quot; title=&quot;安装依赖包ssh和rsync&quot;&gt;&lt;/a&gt;安装依赖包ssh和rsync&lt;/h1&gt;&lt;p&gt;对于Redhat/CentOS系列的，安装系统时一般都会默认安装openssh软件，里面包含了ssh客户端和ssh服务端，所以先检查下这个软件包是否安装了：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# yum list all openssh&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;如果没有安装，安装：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# yum install -y openssh&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在检查rsync软件包是否安装：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# yum list all rsync&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;各节点时间同步&quot;&gt;&lt;a href=&quot;#各节点时间同步&quot; class=&quot;headerlink&quot; title=&quot;各节点时间同步&quot;&gt;&lt;/a&gt;各节点时间同步&lt;/h1&gt;&lt;p&gt;采用NTP(Network Time Protocol)方式来实现, 选择一台机器, 作为集群的时间同步服务器, 然后分别配置服务端和集群其他机器。我这里以hadoop16机器时间为准，其他机器同这台机器时间做同步。&lt;/p&gt;
&lt;h2 id=&quot;NTP服务端&quot;&gt;&lt;a href=&quot;#NTP服务端&quot; class=&quot;headerlink&quot; title=&quot;NTP服务端&quot;&gt;&lt;/a&gt;NTP服务端&lt;/h2&gt;&lt;p&gt;1.安装ntp服务&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# yum install ntp -y&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;2.配置/etc/ntp.conf，这边采用本地机器作为时间的原点&lt;br&gt;注释server列表：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;server 0.centos.pool.ntp.org iburst&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;server 1.centos.pool.ntp.org iburst&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;server 2.centos.pool.ntp.org iburst&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;server 3.centos.pool.ntp.org iburst&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;添加如下内容：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;server 127.127.1.0 prefer&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;fudge 127.127.1.0 stratum 8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;logfile /var/log/ntp.log&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;3.启动ntpd服务&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# systemctl start ntpd&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;4.查看ntp服务状态&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# systemctl status ntpd&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;5.加入开机启动&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# systemctl enable ntpd&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;NTP客户端&quot;&gt;&lt;a href=&quot;#NTP客户端&quot; class=&quot;headerlink&quot; title=&quot;NTP客户端&quot;&gt;&lt;/a&gt;NTP客户端&lt;/h2&gt;&lt;p&gt;1.安装ntp&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# yum install ntpdate&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;2.配置crontab任务主动同步&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# crontab -e&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;*/10 * * * * /usr/sbin/ntpdate 172.16.206.16;hwclock -w&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;安装Zookeeper集群&quot;&gt;&lt;a href=&quot;#安装Zookeeper集群&quot; class=&quot;headerlink&quot; title=&quot;安装Zookeeper集群&quot;&gt;&lt;/a&gt;安装Zookeeper集群&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;对于Zookeeper集群的话，官方推荐的最小节点数为3个。&lt;/p&gt;
&lt;h2 id=&quot;安装配置zk&quot;&gt;&lt;a href=&quot;#安装配置zk&quot; class=&quot;headerlink&quot; title=&quot;安装配置zk&quot;&gt;&lt;/a&gt;安装配置zk&lt;/h2&gt;&lt;p&gt;1.配置zk节点的hosts文件&lt;br&gt;配置zk节点的hosts文件：配置3台机器的ip地址和主机名的对应关系。上面已经做过了。这里选择3台安装zk：hadoop27，hadoop28，hadoop29。&lt;/p&gt;
&lt;p&gt;2.解压安装配置第一台zk&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# cd /usr/local/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# tar zxf zookeeper-3.4.6.tar.gz&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# cd zookeeper-3.4.6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;创建快照日志存放目录：&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# mkdir dataDir&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;创建事务日志存放目录：&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# mkdir dataLogDir&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;如果不配置dataLogDir，那么事务日志也会写在dataDir目录中。这样会严重影响zk的性能。因为在zk吞吐量很高的时候，产生的事务日志和快照日志太多。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# cd conf&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# mv zoo_sample.cfg zoo.cfg&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# vim zoo.cfg&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# 存放数据文件&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;dataDir=/usr/local/zookeeper-3.4.6/dataDir&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# 存放日志文件&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;dataLogDir=/usr/local/zookeeper-3.4.6/dataLogDir&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# zookeeper cluster，2888为选举端口，3888为心跳端口&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;server.1=hadoop27:2888:3888&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;server.2=hadoop28:2888:3888&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;server.3=hadoop29:2888:3888&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/33.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在我们配置的dataDir指定的目录下面，创建一个myid文件，里面内容为一个数字，用来标识当前主机，conf/zoo.cfg文件中配置的server.X中X为什么数字，则myid文件中就输入这个数字： &lt;br&gt;&lt;br&gt;hadoop27主机：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# echo &amp;quot;1&amp;quot; &amp;gt; /usr/local/zookeeper-3.4.6/dataDir/myid&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;3.远程复制第一台的zk到另外两台上，并修改myid文件为2和3&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# cd /usr/local/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# scp -rp zookeeper-3.4.6 root@172.16.206.28:/usr/local/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# echo &amp;quot;2&amp;quot; &amp;gt; /usr/local/zookeeper-3.4.6/dataDir/myid&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# scp -rp zookeeper-3.4.6 root@172.16.206.29:/usr/local/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# echo &amp;quot;3&amp;quot; &amp;gt; /usr/local/zookeeper-3.4.6/dataDir/myid&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;启动和关闭zk&quot;&gt;&lt;a href=&quot;#启动和关闭zk&quot; class=&quot;headerlink&quot; title=&quot;启动和关闭zk&quot;&gt;&lt;/a&gt;启动和关闭zk&lt;/h2&gt;&lt;p&gt;在ZooKeeper集群的每个结点上，执行启动ZooKeeper服务的脚本，如下所示：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop27 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh start&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop28 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh start&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop29 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh start&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;查看启动的进程：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/34.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;停止zk命令：&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# /usr/local/zookeeper-3.4.6/bin/zkServer.sh stop&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;测试zk集群&quot;&gt;&lt;a href=&quot;#测试zk集群&quot; class=&quot;headerlink&quot; title=&quot;测试zk集群&quot;&gt;&lt;/a&gt;测试zk集群&lt;/h2&gt;&lt;p&gt;可以通过ZooKeeper的脚本来查看启动状态，包括集群中各个结点的角色（或是Leader，或是Follower）：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop27 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh status&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;JMX enabled by default&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Mode: follower&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop28 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh status&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;JMX enabled by default&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Mode: leader&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop29 ~]# /usr/local/zookeeper-3.4.6/bin/zkServer.sh status&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;JMX enabled by default&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Using config: /usr/local/zookeeper-3.4.6/bin/../conf/zoo.cfg&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Mode: follower&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;通过上面状态查询结果可见，hadoop28是集群的Leader，其余的两个结点是Follower。&lt;br&gt;&lt;br&gt;另外，可以通过客户端脚本，连接到ZooKeeper集群上。对于客户端来说，ZooKeeper是一个整体，连接到ZooKeeper集群实际上感觉在独享整个集群的服务，所以，你可以在任何一个结点上建立到服务集群的连接。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;36&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;37&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;38&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;39&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;40&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;41&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;42&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;43&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;44&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;45&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;46&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;47&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop29 ~]# /usr/local/zookeeper-3.4.6/bin/zkCli.sh -server hadoop27:2181&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Connecting to localhost:2181&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,647 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,650 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=hadoop29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,650 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.7.0_80&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,652 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,652 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/usr/java/jdk1.7.0_80/jre&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,652 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/usr/local/zookeeper-3.4.6/bin/../build/classes:/usr/local/zookeeper-3.4.6/bin/../build/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/usr/local/zookeeper-3.4.6/bin/../lib/log4j-1.2.16.jar:/usr/local/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/usr/local/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/usr/local/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../conf:.:/usr/java/jdk1.7.0_80/lib/dt.jar:/usr/java/jdk1.7.0_80/lib/tools.jar&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,652 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/tmp&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&amp;lt;NA&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Linux&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=amd64&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=2.6.32-431.el6.x86_64&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=root&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/root&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,653 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/root&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:26:57,654 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@279ac931&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop29 ~]# /usr/local/zookeeper-3.4.6/bin/zkCli.sh -server hadoop27:2181&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Connecting to hadoop27:2181&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,216 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,219 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=hadoop29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,219 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.7.0_80&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/usr/java/jdk1.7.0_80/jre&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/usr/local/zookeeper-3.4.6/bin/../build/classes:/usr/local/zookeeper-3.4.6/bin/../build/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/usr/local/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/usr/local/zookeeper-3.4.6/bin/../lib/log4j-1.2.16.jar:/usr/local/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/usr/local/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/usr/local/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/usr/local/zookeeper-3.4.6/bin/../conf:.:/usr/java/jdk1.7.0_80/lib/dt.jar:/usr/java/jdk1.7.0_80/lib/tools.jar&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/tmp&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&amp;lt;NA&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Linux&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,221 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=amd64&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,222 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=2.6.32-431.el6.x86_64&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,222 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=root&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,222 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/root&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,222 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/root&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,223 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=hadoop27:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@194d62f1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Welcome to ZooKeeper!&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,245 [myid:] - INFO  [main-SendThread(hadoop27:2181):ClientCnxn$SendThread@975] - Opening socket connection to server hadoop27/172.16.206.27:2181. Will not attempt to authenticate using SASL (unknown error)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2016-07-18 21:29:48,249 [myid:] - INFO  [main-SendThread(hadoop27:2181):ClientCnxn$SendThread@852] - Socket connection established to hadoop27/172.16.206.27:2181, initiating session&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;JLine support is enabled&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[zk: hadoop27:2181(CONNECTING) 0] 2016-07-18 21:29:48,356 [myid:] - INFO  [main-SendThread(hadoop27:2181):ClientCnxn$SendThread@1235] - Session establishment complete on server hadoop27/172.16.206.27:2181, sessionid = 0x155fc2e082e0000, negotiated timeout = 30000&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;WATCHER::&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;WatchedEvent state:SyncConnected type:None path:null&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[zk: hadoop27:2181(CONNECTED) 0]&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;输入quit，可以退出。&lt;/p&gt;
&lt;h2 id=&quot;脚本定期清理zk快照和日志文件&quot;&gt;&lt;a href=&quot;#脚本定期清理zk快照和日志文件&quot; class=&quot;headerlink&quot; title=&quot;脚本定期清理zk快照和日志文件&quot;&gt;&lt;/a&gt;脚本定期清理zk快照和日志文件&lt;/h2&gt;&lt;p&gt;正常运行过程中，ZK会不断地把快照数据和事务日志输出到dataDir和dataLogDir这两个目录，并且如果没有人为操作的话，ZK自己是不会清理这些文件的。&lt;br&gt;&lt;br&gt;我这里采用脚本切割。将脚本上传到/usr/local/zookeeper-3.4.6/目录下。脚本内容如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#!/bin/bash&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;###Description:This script is used to clear zookeeper snapshot file and transaction logs.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;###Written by: jkzhao - jkzhao@wisedu.com&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;###History: 2016-04-08 First release.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# Snapshot file dir.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;dataDir=/usr/local/zookeeper-3.4.6/dataDir/version-2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# Transaction logs dir.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;dataLogDir=/usr/local/zookeeper-3.4.6/dataLogDir/version-2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# Reserved 5 files.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;COUNT=5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;ls -t $dataDir/snapshot.* | tail -n +$[$COUNT+1] | xargs rm -f&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;ls -t $dataLogDir/log.* | tail -n +$[$COUNT+1] | xargs rm -f&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;赋予脚本执行权限：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# chmod +x clean_zklog.sh&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;配置周期性任务，每个星期日的0点0分执行：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# crontab -e&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;0 0 * * 0 /usr/local/zookeeper-3.4.6/clean_zklog.sh&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;所有zk节点都得配置脚本和周期性任务。&lt;/p&gt;
&lt;h1 id=&quot;添加Hadoop运行用户&quot;&gt;&lt;a href=&quot;#添加Hadoop运行用户&quot; class=&quot;headerlink&quot; title=&quot;添加Hadoop运行用户&quot;&gt;&lt;/a&gt;添加Hadoop运行用户&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# groupadd hadoop&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# useradd -g hadoop hadoop&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# echo &amp;quot;wisedu&amp;quot; | passwd --stdin hadoop &amp;amp;&amp;gt; /dev/null&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;所有节点都得添加hadoop用户。&lt;/p&gt;
&lt;h1 id=&quot;配置主节点登录自己和其他节点不需要输入密码&quot;&gt;&lt;a href=&quot;#配置主节点登录自己和其他节点不需要输入密码&quot; class=&quot;headerlink&quot; title=&quot;配置主节点登录自己和其他节点不需要输入密码&quot;&gt;&lt;/a&gt;配置主节点登录自己和其他节点不需要输入密码&lt;/h1&gt;&lt;p&gt;这里的主节点指的是NameNode，ResourceManager。配置hadoop16主机(Active)登录hadoop16，hadoop26，hadoop27，hadoop28，hadoop29主机免密码。还要配置hadoop26主机(Standby)登录hadoop16，hadoop26,hadoop27，hadoop28，hadoop29主机免密码。 (也可以不配置，每个节点一个一个启动服务，最好不要这样做）。&lt;/p&gt;
&lt;p&gt;hadoop用户登录shell：&lt;br&gt;1.配置hadoop16主机(Active)登录hadoop16，hadoop26，hadoop27，hadoop28，hadoop29主机免密码&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-keygen -t rsa -P &amp;apos;&amp;apos;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop29&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;2.配置hadoop26主机(Standby)登录hadoop16，hadoop26，hadoop27，hadoop28，hadoop29主机免密码&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-keygen -t rsa -P &amp;apos;&amp;apos;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@hadoop29&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;安装hadoop&quot;&gt;&lt;a href=&quot;#安装hadoop&quot; class=&quot;headerlink&quot; title=&quot;安装hadoop&quot;&gt;&lt;/a&gt;安装hadoop&lt;/h1&gt;&lt;h2 id=&quot;安装配置master节点-hadoop16主机&quot;&gt;&lt;a href=&quot;#安装配置master节点-hadoop16主机&quot; class=&quot;headerlink&quot; title=&quot;安装配置master节点(hadoop16主机)&quot;&gt;&lt;/a&gt;安装配置master节点(hadoop16主机)&lt;/h2&gt;&lt;p&gt;1.将安装包上传至//usr/local目录下并解压&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop16 ~]# cd /usr/local/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop16 local]# tar zxf hadoop-2.7.2.tar.gz&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop16 local]# ln -sv hadoop-2.7.2 hadoop&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop16 local]# cd hadoop&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop16 hadoop]# mkdir logs&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop16 hadoop]# chmod g+w logs&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop16 hadoop]# chown -R hadoop:hadoop ./*&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop16 hadoop]# chown -R hadoop:hadoop /usr/local/hadoop-2.7.2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;2.配置hadoop环境变量&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@hadoop16 hadoop]# vim /etc/profile&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# HADOOP&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;export HADOOP_HOME=/usr/local/hadoop&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;export PATH=$PATH:$&amp;#123;HADOOP_HOME&amp;#125;/bin:$&amp;#123;HADOOP_HOME&amp;#125;/sbin&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;3.修改文件hadoop-env.sh和yarn-env.sh&lt;br&gt;Hadoop的各守护进程依赖于JAVA_HOME环境变量，可在这两个文件中配置特定的JAVA环境。此处仅需要修改hadoop-env.sh文件。此外，Hadoop大多数守护进程默认使用的堆大小为1GB，但现实应用中，可能需要对其各类进程的堆内存大小做出调整，这只需要编辑这两个文件中的相关环境变量值即可，例如HADOOP_HEAPSIZE、HADOOP_JOB_HISTORY_HEAPSIZE、JAVA_HEAP_SIZE和YARN_HEAP_SIZE等。&lt;br&gt;&lt;br&gt;hadoop用户登录shell，或者root用户登录，su - hadoop。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/35.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4.修改配置文件&lt;br&gt;hadoop用户登录shell，或者root用户登录，su - hadoop。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ cd /usr/local/hadoop/etc/hadoop/&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修改core-site.xml，&lt;/strong&gt;该文件包含了NameNode主机地址以及其监听RPC端口等信息，对于伪分布式模式的安装来说，其主机地址是localhost；对于完全分布式中master节点的主机名称或者ip地址；如果配置NameNode是HA，指定HDFS的nameservice为一个自定义名称，然后在hdfs-site.xml配置NameNode节点的主机信息。NameNode默认的RPC端口是8020。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- 指定hdfs的nameservice为ns1 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hdfs://ns1&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- 指定hadoop临时目录 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;/usr/local/hadoop/tmp&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- 指定zookeeper地址 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;ha.zookeeper.quorum&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hadoop27:2181,hadoop28:2181,hadoop29:2181&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修改hdfs-site.xml，&lt;/strong&gt;该文件主要用于配置HDFS相关的属性，例如复制因子（即数据块的副本数）、NN和DN用于存储数据的目录等。数据块的副本数对于伪分布式的Hadoop应该为1，完全分布式模式下默认数据副本是3份。在这个配置文件中还可以配置NN和DN用于存储的数据的目录。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;36&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;37&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;38&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;39&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;40&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;41&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;42&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;43&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;44&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;45&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;46&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;47&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;48&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;49&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;50&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;51&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;52&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;53&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;54&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;55&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;56&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;57&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;58&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;59&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;60&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;61&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;62&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;63&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;64&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;65&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;66&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;67&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;68&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;69&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;70&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.nameservices&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;ns1&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.ha.namenodes.ns1&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;nn1,nn2&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- nn1的RPC通信地址 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.namenode.rpc-address.ns1.nn1&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hadoop16:9000&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- nn1的http通信地址 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.namenode.http-address.ns1.nn1&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hadoop16:50070&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- nn2的RPC通信地址 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.namenode.rpc-address.ns1.nn2&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hadoop26:9000&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- nn2的http通信地址 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.namenode.http-address.ns1.nn2&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;hadoop26:50070&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.namenode.shared.edits.dir&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;qjournal://hadoop27:8485;hadoop28:8485;hadoop29:8485/ns1&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.journalnode.edits.dir&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;/usr/local/hadoop/journaldata&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- 开启NameNode失败自动切换 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.ha.automatic-failover.enabled&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- 配置失败自动切换实现方式 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.client.failover.proxy.provider.ns1&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.ha.fencing.methods&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                        sshfence&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                        shell(/bin/true)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.ha.fencing.ssh.private-key-files&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;/home/hadoop/.ssh/id_rsa&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;!-- 配置sshfence隔离机制超时时间 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;name&amp;gt;dfs.ha.fencing.ssh.connect-timeout&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                &amp;lt;value&amp;gt;30000&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;如果需要其它用户对hdfs有写入权限，还需要在hdfs-site.xml添加一项属性定义。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;     &amp;lt;name&amp;gt;dfs.permissions&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;     &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;/property&amp;gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修改mapred-site.xml，&lt;/strong&gt;该文件用于配置集群的MapReduce framework，此处应该指定yarn，另外的可用值还有local和classic。mapred-site.xml默认是不存在，但有模块文件mapred-site.xml.template，只需要将其复制mapred-site.xml即可。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 hadoop]$ cp mapred-site.xml.template mapred-site.xml&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 hadoop]$ vim mapred-site.xml&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;!-- 指定mr框架为yarn方式 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;		&amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;		&amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;修改yarn-site.xml，&lt;/strong&gt;该文件用于配置YARN进程及YARN的相关属性。首先需要指定ResourceManager守护进程的主机和监听的端口，对于伪分布式模型来来讲，其主机为localhost，默认的端口是8032；其次需要指定ResourceManager使用的scheduler，以及NodeManager的辅助服务。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;!-- 开启RM高可用 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.ha.enabled&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;!-- 指定RM的cluster id --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.cluster-id&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;yrc&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;!-- 指定RM的名字 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.ha.rm-ids&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;rm1,rm2&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;!-- 分别指定RM的地址 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.hostname.rm1&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;hadoop16&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.hostname.rm2&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;hadoop26&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;!-- 指定zk集群地址 --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.resourcemanager.zk-address&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;hadoop27:2181,hadoop28:2181,hadoop29:2181&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	   &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;	&amp;lt;/property&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修改slaves，&lt;/strong&gt;该文件存储了当前集群的所有slave节点的列表，对于伪分布式模型，其文件内容仅应该是你localhost，这也的确是这个文件的默认值。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 hadoop]$ vim slaves&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;hadoop27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;hadoop28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;hadoop29&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装配置其他节点&quot;&gt;&lt;a href=&quot;#安装配置其他节点&quot; class=&quot;headerlink&quot; title=&quot;安装配置其他节点&quot;&gt;&lt;/a&gt;安装配置其他节点&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;这里由于节点数目少，没有使用ansible等自动化工具。&lt;br&gt;&lt;strong&gt;重复操作解压、配置环境变量，参照前面。&lt;/strong&gt;&lt;br&gt;Hadoop集群的各节点配置文件都是一样的，我们可以将master节点上的配置文件scp到其他节点上：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ scp -p /usr/local/hadoop/etc/hadoop/* hadoop@hadoop26:/usr/local/hadoop/etc/hadoop/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ scp -p /usr/local/hadoop/etc/hadoop/* hadoop@hadoop27:/usr/local/hadoop/etc/hadoop/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ scp -p /usr/local/hadoop/etc/hadoop/* hadoop@hadoop28:/usr/local/hadoop/etc/hadoop/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ scp -p /usr/local/hadoop/etc/hadoop/* hadoop@hadoop29:/usr/local/hadoop/etc/hadoop/&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;启动hadoop&quot;&gt;&lt;a href=&quot;#启动hadoop&quot; class=&quot;headerlink&quot; title=&quot;启动hadoop&quot;&gt;&lt;/a&gt;启动hadoop&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;请严格按照下面的步骤启动。&lt;/p&gt;
&lt;h2 id=&quot;启动Zookeeper集群&quot;&gt;&lt;a href=&quot;#启动Zookeeper集群&quot; class=&quot;headerlink&quot; title=&quot;启动Zookeeper集群&quot;&gt;&lt;/a&gt;启动Zookeeper集群&lt;/h2&gt;&lt;p&gt;分别在hadoop27、hadoop28、hadoop29上启动zk，前面已经启动好了，不再重复。&lt;/p&gt;
&lt;h2 id=&quot;启动journalnode&quot;&gt;&lt;a href=&quot;#启动journalnode&quot; class=&quot;headerlink&quot; title=&quot;启动journalnode&quot;&gt;&lt;/a&gt;启动journalnode&lt;/h2&gt;&lt;p&gt;hadoop用户登录shell，分别在在hadoop27、hadoop28、hadoop29上执行：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop27 ~]$ /usr/local/hadoop/sbin/hadoop-daemon.sh start journalnode&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;运行jps命令检验，hadoop27、hadoop28、hadoop29上多了JournalNode进程。&lt;/p&gt;
&lt;h2 id=&quot;格式化HDFS&quot;&gt;&lt;a href=&quot;#格式化HDFS&quot; class=&quot;headerlink&quot; title=&quot;格式化HDFS&quot;&gt;&lt;/a&gt;格式化HDFS&lt;/h2&gt;&lt;p&gt;在HDFS的NN启动之前需要先初始化其用于存储数据的目录，可以在hdfs-site.xml配置文件中使用dfs.namenode.name.dir属性定义HDFS元数据持久存储路径，默认为${hadoop.tmp.dir}/dfs/name，这里是存放在JournalNode中；dfs.datanode.data.dir属性定义DataNode用于存储数据块的目录路径，默认为${hadoop.tmp.dir}/dfs/data。如果指定的目录不存在，格式化命令会自动创建之；如果事先存在，请确保其权限设置正确，此时格式化操作会清除其内部的所有数据并重新建立一个新的文件系统。 &lt;br&gt;&lt;br&gt;在hadoop16(Active)上执行命令:&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ hdfs namenode -format&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/36.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/usr/local/hadoop/tmp。&lt;br&gt;&lt;br&gt;启动hadoop16主机上的NameNode：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ hadoop-daemon.sh start namenode&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后在hadoop26(Standby)主机上执行如下命令，同步hadoop16主机上的NameNode元数据信息：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ hdfs namenode –bootstrapStandby&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;同步完成后，停止hadoop16主机上的NameNode：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ hadoop-daemon.sh stop namenode&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这里如果不启动Active的NameNode，就在Standby主机上同步，会报如下的错误：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/37.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这是因为没有启动active namenode，因为standby namenode是通过active namenode的9000端口通讯的。若active namenode没有启动，则9000没有程序监听提供服务。 &lt;br&gt;&lt;br&gt;当然也可以不启动Active NameNode就进行同步元数据信息，就是直接用命令拷贝Active主机上的元数据信息目录到Standby主机上，但是不建议这么做：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 hadoop]$ scp -r tmp/ hadoop@hadoop26:/usr/local/hadoop&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&quot;格式化ZKFC-仅在hadoop16上执行即可&quot;&gt;&lt;a href=&quot;#格式化ZKFC-仅在hadoop16上执行即可&quot; class=&quot;headerlink&quot; title=&quot;格式化ZKFC(仅在hadoop16上执行即可)&quot;&gt;&lt;/a&gt;格式化ZKFC(仅在hadoop16上执行即可)&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ hdfs zkfc -formatZK&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/38.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;启动HDFS-在hadoop16上执行&quot;&gt;&lt;a href=&quot;#启动HDFS-在hadoop16上执行&quot; class=&quot;headerlink&quot; title=&quot;启动HDFS(在hadoop16上执行)&quot;&gt;&lt;/a&gt;启动HDFS(在hadoop16上执行)&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ /usr/local/hadoop/sbin/start-dfs.sh&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/39.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;可以在各主机执行jps，查看启动的进程：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/40.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/41.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/42.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;启动YARN&quot;&gt;&lt;a href=&quot;#启动YARN&quot; class=&quot;headerlink&quot; title=&quot;启动YARN&quot;&gt;&lt;/a&gt;启动YARN&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;注意：还是在hadoop16上执行start-yarn.sh，这是因为没有把namenode和resourcemanager分开，生产环境需要把他们分开，他们分开了就要分别在不同的机器上启动。&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;启动yarn(在hadoop16上)：&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ /usr/local/hadoop/sbin/start-yarn.sh&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/43.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;启动yarn standby(在hadoop26上)：&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$  /usr/local/hadoop/sbin/yarn-daemon.sh start resourcemanager&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;可以在各节点执行jps，查看启动的进程：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/44.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/45.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/hadoop/46.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;停止hadoop&quot;&gt;&lt;a href=&quot;#停止hadoop&quot; class=&quot;headerlink&quot; title=&quot;停止hadoop&quot;&gt;&lt;/a&gt;停止hadoop&lt;/h1&gt;&lt;p&gt;停止HDFS集群：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ stop-dfs.sh&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;停止YARN集群：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop16 ~]$ stop-yarn.sh&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;停止ResourceManager(Standby)：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[hadoop@hadoop26 ~]$ yarn-daemon.sh stop resourcemanager&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;关于Apache Hadoop的介绍以本地模式、伪分布式安装部署请参见上篇博文，本篇博文主要记录完全分布式部署，并实现NameNode高可用和ResourceManager高可用。&lt;/p&gt;
&lt;h1 id=&quot;环境规划&quot;&gt;&lt;a href=&quot;#环境规划&quot; class=&quot;headerlink&quot; title=&quot;环境规划&quot;&gt;&lt;/a&gt;环境规划&lt;/h1&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="大数据，Hadoop" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%EF%BC%8CHadoop/"/>
    
  </entry>
  
</feed>
