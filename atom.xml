<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>jkzhao&#39;s blog</title>
  <subtitle>学习 总结 思考</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-03-20T11:41:40.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Zhao Jiankai</name>
    <email>jk.zhaocoder@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CentOS 7安装mysql 5.7.21(二进制版本)</title>
    <link href="http://yoursite.com/2018/03/20/CentOS-7%E5%AE%89%E8%A3%85mysql-5-7-21-%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%89%88%E6%9C%AC/"/>
    <id>http://yoursite.com/2018/03/20/CentOS-7安装mysql-5-7-21-二进制版本/</id>
    <published>2018-03-20T01:45:45.000Z</published>
    <updated>2018-03-20T11:41:40.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;安装依赖&quot;&gt;&lt;a href=&quot;#安装依赖&quot; class=&quot;headerlink&quot; title=&quot;安装依赖&quot;&gt;&lt;/a&gt;安装依赖&lt;/h2&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;# yum install libaio* -y
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;下载安装MySQL二进制版本&quot;&gt;&lt;a href=&quot;#下载安装MySQL二进制版本&quot; class=&quot;headerlink&quot; title=&quot;下载安装MySQL二进制版本&quot;&gt;&lt;/a&gt;下载安装MySQL二进制版本&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://dev.mysql.com/downloads/mysql/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;MySQL社区版下载地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.下载解压&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr/local/
# wget https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.21-linux-glibc2.12-x86_64.tar.gz
# tar zxf mysql-5.7.21-linux-glibc2.12-x86_64.tar.gz
# ln -sv mysql-5.7.21-linux-glibc2.12-x86_64 mysql
‘mysql’ -&amp;gt; ‘mysql-5.7.21-linux-glibc2.12-x86_64’
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.新建用户&lt;/strong&gt;&lt;br&gt;运行mysql最好不要用root去运行，而以普通用户身份。添加用户mysql。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# groupadd -r -g 300 mysql
# useradd -g mysql -r -s /sbin/nologin -u 300 mysql
# id mysql
uid=300(mysql) gid=300(mysql) groups=300(mysql)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3.创建目录并授权&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr/local/mysql
# mkdir data
# chown -R mysql:mysql .
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;4.初始化MySQL&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data
2018-03-20T10:19:23.020203Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).
2018-03-20T10:19:24.877676Z 0 [Warning] InnoDB: New log files created, LSN=45790
2018-03-20T10:19:25.111211Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.
2018-03-20T10:19:25.181304Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 2a1f5e46-2c28-11e8-8a64-00163e13578e.
2018-03-20T10:19:25.189269Z 0 [Warning] Gtid table is not ready to be used. Table &amp;apos;mysql.gtid_executed&amp;apos; cannot be opened.
2018-03-20T10:19:25.189787Z 1 [Note] A temporary password is generated for root@localhost: 77a.Fue3IeIg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;注意mysql临时密码在上面日志的最后一行的末尾：77a.Fue3IeIg，请先记下来。&lt;/strong&gt;&lt;br&gt;查看初始化后data目录生成的文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ls data/
auto.cnf  ib_buffer_pool  ibdata1  ib_logfile0  ib_logfile1  mysql  performance_schema  sys
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;5.生成RSA私钥，可以跳过此步骤&lt;/strong&gt;&lt;br&gt;mysql_ssl_rsa_setup需要openssl支持，用于启用数据量ssl连接，需要进一步配置。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# bin/mysql_ssl_rsa_setup --datadir=/usr/local/mysql/data
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;6.配置my.cnf&lt;/strong&gt;&lt;br&gt;将修改好的配置文件my.cnf传到/etc/目录下。my.cnf内容如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[mysql]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;socket          = /usr/local/mysql/mysql.sock&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# The MySQL server&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[mysqld]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;port            = 3306&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;socket          = /usr/local/mysql/mysql.sock&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;#skip-grant-tables&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;datadir=/usr/local/mysql/data&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;log-error=/usr/local/mysql/db.err&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;pid-file=/usr/local/mysql/mysqld.pid&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;character-set-server = utf8&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7.拷贝启动脚本文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cp support-files/mysql.server /etc/init.d/mysqld 
# chkconfig --add mysqld
# service mysqld start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;8.设置开机启动&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# chkconfig mysqld on
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;9.配置环境变量，配置完重新打开一个shell&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/profile.d/mysql.sh
export PATH=/usr/local/mysql/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;9.登录mysql，设置密码&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mysql -uroot -p77a.Fue3IeIg
密码是上面记录下来的临时密码
MySQL [(none)]&amp;gt; ALTER USER &amp;apos;root&amp;apos;@&amp;apos;localhost&amp;apos; identified by &amp;apos;test&amp;apos;;
MySQL [(none)]&amp;gt; flush privileges;
MySQL [(none)]&amp;gt; quit;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;10.在 Linux 下为了安全，默认是不允许 MySQL 服务器本机以外的机器访问 MySQL 数据库服务的，因此需要重新授权 root 账号。方便其他机器远程访问 MySQL 服务器，MySQL 命令如下：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;MySQL [(none)]&amp;gt; grant all privileges on *.* to root@&amp;apos;%&amp;apos; identified by &amp;apos;Wisedu123@2018&amp;apos;;
MySQL [(none)]&amp;gt; flush privileges;
MySQL [(none)]&amp;gt; quit;
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;安装依赖&quot;&gt;&lt;a href=&quot;#安装依赖&quot; class=&quot;headerlink&quot; title=&quot;安装依赖&quot;&gt;&lt;/a&gt;安装依赖&lt;/h2&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL介绍及安装部署</title>
    <link href="http://yoursite.com/2018/03/18/MySQL%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2018/03/18/MySQL介绍及安装部署/</id>
    <published>2018-03-18T04:08:49.000Z</published>
    <updated>2018-03-23T08:41:38.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;MySQL产品&quot;&gt;&lt;a href=&quot;#MySQL产品&quot; class=&quot;headerlink&quot; title=&quot;MySQL产品&quot;&gt;&lt;/a&gt;MySQL产品&lt;/h2&gt;&lt;p&gt;当年Sun公司买下了MySQL，后来Sun公司被Oracle收购了。也就是MySQL也变成Oracle的了。Oracle向来视MySQL为眼中钉，所以Oracle在收购Sun的时候遭到了欧盟的极力反对，他们担心MySQL。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;Oracle有前科的，对于自己的产品，有竞争对手的，把对方公司收购，在把产品打入冷宫，不卖了。Oracle当前做出承诺，5年内花人力物力研发MySQL。Oracle也的确这么做了，但是MySQL有两个版本：社区版和商业版。在Oracle收购Sun之后，在不到两年的时间，商业版价格翻了4倍。好在Oracle在收购Sun的时候还收购了一个Openoffice的组件，是Linux上的一个办公套件。Oracle收购之后第一件事，就是openoffice不再开源，开始收钱了。很遗憾的是，Oracle毙掉之后，大家不认账，没人买他的。后来，openoffice那个团队又在早期的openoffice基础上做了另外一套office叫Libreoffice，比openoffice还要好，依然开源。没过多久，Oracle把openoffice又开源了，但是没人在用了。所以不知道MySQL会不会面临这个命运。MySQL的原作者当前在Oracle收购Sun时就极力反对，在Sun被收购后，他又组织了当年的开源团队，在早期MySQL的基础上重新创建了另外一套叫做MariaDB。MariaDB开源，并且其在设计上比早期的MySQL更先进。而且其API和MySQL完全兼容，所以Redhat7不再附带MySQL，而是MariaDB。现在MySQL家族的产品主要有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL Server（mysqld、mysql）&lt;/li&gt;
&lt;li&gt;MySQL Cluster&lt;/li&gt;
&lt;li&gt;MySQL Proxy&lt;/li&gt;
&lt;li&gt;MySQL Adminitrator&lt;/li&gt;
&lt;li&gt;MySQL Query Browser&lt;/li&gt;
&lt;li&gt;MySQL Workbench    &lt;/li&gt;
&lt;li&gt;MySQL Migration Toolkit&lt;/li&gt;
&lt;li&gt;MySQL Embedded Server&lt;/li&gt;
&lt;li&gt;MySQL Drivers and Connectors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;MySQL Server：&lt;/strong&gt;分为企业级DB和社区版DB。&lt;br&gt;&lt;strong&gt;MySQL Cluster：&lt;/strong&gt;市面上几乎没有使用这种企业级集群。&lt;br&gt;&lt;strong&gt;MySQL Proxy：&lt;/strong&gt;由代理来判断谁能被读，谁能被写。&lt;br&gt;对于我们来说，会用到MySQL Server、MySQL Proxy和MySQL Drivers and Connectors。&lt;/p&gt;
&lt;h2 id=&quot;MySQL逻辑架构&quot;&gt;&lt;a href=&quot;#MySQL逻辑架构&quot; class=&quot;headerlink&quot; title=&quot;MySQL逻辑架构&quot;&gt;&lt;/a&gt;MySQL逻辑架构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt; MySQL是个多用户服务器，支持多个连接同时连接进来。可以通过线程池来定义最多可以有多少个用户同时连进来。多余的连接请求放在连接队列中，线程池里出去一个，就从队列里进去线程池一个。据说oracle为mysql的商业版引入了很强大的线程池机制。连接/线程处理是MySQL的重要组成部分。&lt;br&gt;    用户请求接进来以后，如果是个select语句，先查询缓存(mysql缓存是根据查询语句的hash码对比的，select的大小写都会导致hash码不一样)。如果命中，直接返回结果，如果未命中，接下来分析器做语句分析，分析之后缓存中还有可能命中。所以分析器分析后仍然要去查缓存。如果缓存还是未命中，接下来交给优化器，优化以后由执行引擎交给存储引擎做查询操作。&lt;br&gt;    优化器优化之后，真正负责执行语句的是存储引擎。mysql是插件式存储引擎的，所以不同的表可以使用不同的存储引擎。&lt;/p&gt;
&lt;h2 id=&quot;MySQL逻辑组件&quot;&gt;&lt;a href=&quot;#MySQL逻辑组件&quot; class=&quot;headerlink&quot; title=&quot;MySQL逻辑组件&quot;&gt;&lt;/a&gt;MySQL逻辑组件&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Connection Pool：Authentication, Thread Reuse, Connection Limits, Check Memory, Caches。&lt;br&gt;认证，线程重用， 连接限制， 检查内存， 实现连接缓存。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;存储引擎将数据转换成存储在文件系统中的文件，文件系统可以是NTFS、ufs、ext2/3、NFS、SAN、NAS。文件系统上的文件表现为文件和日志。文件有数据文件和索引文件。日志有重做、撤销、二进制、错误、查询和慢查询日志，一般不涉及撤销日志，所以这边日志有5种。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;备份工具、安全工具、恢复工具复制工具、集群工具等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;用户请求接进来了，&lt;strong&gt;连接管理器&lt;/strong&gt;负责接收用户请求，接进来后，&lt;strong&gt;线程管理器&lt;/strong&gt;需要生成一个线程响应用户请求(MySQL是单进程多线程模型的)，用户输入了帐号和密码后，需要一个&lt;strong&gt;用户模块&lt;/strong&gt;，用户肯定需要和用户模块打交道的，因为需要认证。只要连接进来，后续的sql语句也是和用户模块打交道，而不会和连接管理器打交道了。&lt;br&gt;    用户认证后，会发出很多SQL命令，由&lt;strong&gt;命令派发器&lt;/strong&gt;来派发给&lt;strong&gt;查询缓存&lt;/strong&gt;，查询缓存如果命中了则直接返回结果，当然完成了就需要&lt;strong&gt;记录日志&lt;/strong&gt;(记录日志是可选步骤)。如果查询缓存没命中，就要交给&lt;strong&gt;分析器&lt;/strong&gt;分析了。用户的语句有DDL、DML，分析结束后，如果是select就交给&lt;strong&gt;优化器&lt;/strong&gt;，如果是update、insert、delete、replace就交给&lt;strong&gt;表修改模块&lt;/strong&gt;，如果是repair就交给&lt;strong&gt;表维护模块&lt;/strong&gt;，如果是replication类操作就交给复制模块，还需要个&lt;strong&gt;状态报告模块&lt;/strong&gt;报告服务器执行状态。&lt;br&gt;    这些组件最终由&lt;strong&gt;访问控制模块&lt;/strong&gt;来控制，你到底有没有权限来操作，这个模块是做访问检查的。前面那个用户模块是做认证检查的，帐号密码没问题不代表可以访问里面的数据。访问控制模块检查没问题后，接下来就真正执行操作了。&lt;strong&gt;表管理器接口&lt;/strong&gt;的真正执行的操作依赖于&lt;strong&gt;存储引擎&lt;/strong&gt;。所以接下来要交给存储引擎的抽象接口。存储引擎抽象接口将用户请求在转发给各存储引擎。&lt;/p&gt;
&lt;h2 id=&quot;MySQL安装部署&quot;&gt;&lt;a href=&quot;#MySQL安装部署&quot; class=&quot;headerlink&quot; title=&quot;MySQL安装部署&quot;&gt;&lt;/a&gt;MySQL安装部署&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.MySQL的安装方式&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;源码编译&lt;/li&gt;
&lt;li&gt;rpm包：&lt;ul&gt;
&lt;li&gt;OS Vendor提供的&lt;/li&gt;
&lt;li&gt;MySQL官方提供的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;通用二进制格式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.MySQL版本&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GA（General Availability）：要选择GA版&lt;/li&gt;
&lt;li&gt;RC（Release Candidate）：候选版，马上要发布为GA版本&lt;/li&gt;
&lt;li&gt;beta：公测版&lt;/li&gt;
&lt;li&gt;alpha：内测版&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.MySQL官方提供的rpm包&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL-devel：开发需要的头文件和额外的库文件。&lt;/li&gt;
&lt;li&gt;MySQL-embedded：嵌入式环境下专用的。&lt;/li&gt;
&lt;li&gt;MySQL-ndb-management：MySQL集群管理器。&lt;/li&gt;
&lt;li&gt;MySQL-shared：被各种应用程序所依赖的贡献库。&lt;/li&gt;
&lt;li&gt;MySQL-shared-compat：兼容库。有些老的应用程序可能依赖mysql老版本的库。&lt;/li&gt;
&lt;li&gt;MySQL-test：测试套件。包含一些压测工具等等。&lt;/li&gt;
&lt;li&gt;MySQL-VERSION.PLATFORM.src.rpm：源代码包。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对我们而言，需要MySQL-client、MySQL-server、MySQL-shared、MySQL-shared-compat和MySQL-test。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.二进制方式部署MySQL 5.6&lt;/strong&gt;&lt;br&gt;下载地址：&lt;a href=&quot;http://mirrors.sohu.com/mysql&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://mirrors.sohu.com/mysql&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;console&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;114.55.29.246&lt;/td&gt;
&lt;td&gt;mysql-5.6.27-linux-glibc2.5-x86_64.tar.gz&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;（1）安装依赖包&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console local]# yum install libaio* -y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;（2）解压安装&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console local]# tar zxf mysql-5.6.27-linux-glibc2.5-x86_64.tar.gz 
[root@console local]# ln -sv mysql-5.6.27-linux-glibc2.5-x86_64 mysql
‘mysql’ -&amp;gt; ‘mysql-5.6.27-linux-glibc2.5-x86_64’
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;（3）新建用户&lt;/strong&gt;&lt;br&gt;运行mysql最好不要用root去运行，而以普通用户身份。添加用户mysql。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console local]# groupadd -r -g 300 mysql
[root@console local]# useradd -g mysql -r -s /sbin/nologin -u 300 mysql
[root@console local]# id mysql
uid=300(mysql) gid=300(mysql) groups=300(mysql)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;（4）修改mysql文件权限为mysql.mysql&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console local]# cd mysql
[root@console mysql]# chown -R mysql.mysql ./*
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;（5）执行初始化操作，生成一个系统库叫mysql，它里面保存着有当前所有能够使用mysql服务器的用户帐号、所有数据库的名字、每个库中表的名字、表中字段的名字等等。&lt;/strong&gt;&lt;br&gt;脚本路径：/usr/local/mysql/scripts&lt;br&gt;创建数据文件目录：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console mysql]# mkdir -pv /data/{mydata,binlog}
[root@console mysql]# scripts/mysql_install_db --user=mysql --basedir=/usr/local/mysql --datadir=/data/mydata
[root@console mysql]# ls /data/mydata
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;（6）修改mysql目录下的文件属主为root，属组为mysql&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console mysql]# chown -R root .
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;（7）修改data目录属主、属组为mysql&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console mysql]# chown -R mysql.mysql /data
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;（8）拷贝修改mysql的配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;copy写好的my.cnf到/etc/目录下。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;36&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;37&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;38&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;39&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;40&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;41&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;42&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;43&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;44&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;45&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;46&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;47&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;48&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;49&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;50&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;51&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;52&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;53&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;54&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;55&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;56&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;57&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# The following options will be passed to all MySQL clients&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[client]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;#password       = your_password&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;port            = 3306&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;socket          = /tmp/mysql.sock&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# The MySQL server&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[mysqld]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;port            = 3306&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;socket          = /tmp/mysql.sock&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;skip-external-locking&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;key_buffer_size = 256M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;max_allowed_packet = 1M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;table_open_cache = 256&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;sort_buffer_size = 1M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;read_buffer_size = 1M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;read_rnd_buffer_size = 4M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;myisam_sort_buffer_size = 64M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;thread_cache_size = 8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;query_cache_size= 16M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# Try number of CPU&amp;apos;s*2 for thread_concurrency&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;thread_concurrency = 4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;datadir=/data/mydata&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;character-set-server = utf8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;max_connections = 1000&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# Replication Master Server (default)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# binary logging is required for replication&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;log-bin=/data/binlog/master-bin&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# binary logging format - mixed recommended&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;binlog_format=mixed&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# required unique id between 1 and 2^32 - 1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# defaults to 1 if master-host is not set&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# but will not function as a master if omitted&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;server-id       = 1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[mysqldump]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;quick&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;max_allowed_packet = 16M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[mysql]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;no-auto-rehash&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[myisamchk]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;key_buffer_size = 128M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;sort_buffer_size = 128M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;read_buffer = 2M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;write_buffer = 2M&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[mysqlhotcopy]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;interactive-timeout&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（9）拷贝mysql的启动脚本，并加入系统服务&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console mysql]# cp support-files/mysql.server /etc/init.d/mysqld 
[root@console mysql]# chkconfig --add mysqld
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;（10）启动mysql&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console mysql]# service mysqld start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;（11）配置环境变量，配置完重新打开一个shell&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console mysql]# vim /etc/profile.d/mysql.sh
export PATH=/usr/local/mysql/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;（12）修改root密码，因为一装完root密码是空的&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@console ~]# mysql -uroot mysql 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; UPDATE user SET Password=PASSWORD(&amp;apos;wisedu123&amp;apos;) where USER=&amp;apos;root&amp;apos;;
mysql&amp;gt; FLUSH PRIVILEGES;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/9.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;此时再以root登录就需要密码了。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/10.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（13）删除两个匿名帐号&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; use mysql
mysql&amp;gt; SELECT host,user,password FROM user;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/11.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; DROP USER &amp;apos;&amp;apos;@localhost;   #注意’’@localhost是两个单引号
mysql&amp;gt; DROP USER &amp;apos;&amp;apos;@console; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/12.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;MySQL初始化&quot;&gt;&lt;a href=&quot;#MySQL初始化&quot; class=&quot;headerlink&quot; title=&quot;MySQL初始化&quot;&gt;&lt;/a&gt;MySQL初始化&lt;/h2&gt;&lt;p&gt;MySQL是基于TCP的3306端口。虽然如此，但是还支持其他的通信方式，比如socket、memory、pipe。tcp是远程通信时用的，Linux或unix本机是基于socket，windows本机是基于memory或pipe。&lt;br&gt;MySQL服务器无论是通用二进制方式安装还是编译的方式安装，安装完成后要做MySQL的初始化。系统初始化时，默认库是mysql。这个库存储了当前mysql的各种元数据。这些初始化包含以下工作：&lt;/p&gt;
&lt;h3 id=&quot;提供配置文件&quot;&gt;&lt;a href=&quot;#提供配置文件&quot; class=&quot;headerlink&quot; title=&quot;提供配置文件&quot;&gt;&lt;/a&gt;提供配置文件&lt;/h3&gt;&lt;p&gt;配置文件：.cnf结尾 &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集中式的配置:多个应用程序共用的配置文件&lt;ul&gt;
&lt;li&gt;[mysqld]&lt;/li&gt;
&lt;li&gt;[mysqld_safe]&lt;/li&gt;
&lt;li&gt;[client]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用配置文件的方式（安装mysql的方式不同，读取配置文件的顺序可能不同）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1.它依次查找每个需要查找的文件，结果是所有文件并集；&lt;/li&gt;
&lt;li&gt;2.如果某参数在多个文件中出现多次，后读取的最终生效；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;配置文件顺序：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# /usr/local/mysql/bin/mysqld --help --verbose | head -20
Default options are read from the following files in the given order:
/etc/mysql/my.cnf  /etc/my.cnf  ~/.my.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;删除所有匿名用户（5-7之前的版本）&quot;&gt;&lt;a href=&quot;#删除所有匿名用户（5-7之前的版本）&quot; class=&quot;headerlink&quot; title=&quot;删除所有匿名用户（5.7之前的版本）&quot;&gt;&lt;/a&gt;删除所有匿名用户（5.7之前的版本）&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;mysql&amp;gt; DROP USER &amp;apos;&amp;apos;@&amp;apos;localhost&amp;apos;;
mysql&amp;gt; DROP USER &amp;apos;&amp;apos;@&amp;apos;www.abc.com&amp;apos;; #www.abc.com为主机名
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;用户帐号由两部分组成：username@host，host指所能够远程访问时使用的客户端主机&lt;br&gt;host还可以使用通配符：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;%: 任意长度的任意字符&lt;/li&gt;
&lt;li&gt;_: 匹配任意单个字符&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;给所有的root用户设定密码（5-7之前的版本）&quot;&gt;&lt;a href=&quot;#给所有的root用户设定密码（5-7之前的版本）&quot; class=&quot;headerlink&quot; title=&quot;给所有的root用户设定密码（5.7之前的版本）&quot;&gt;&lt;/a&gt;给所有的root用户设定密码（5.7之前的版本）&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.第一种方式&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SET PASSWORD FOR username@host = PASSWORD(&amp;apos;your_passwrod&amp;apos;);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.第二种方式&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; UPDATE user SET password = PASSWORD(&amp;apos;your_password&amp;apos;) WHERE user = &amp;apos;root&amp;apos;;   ——这是修改授权表
mysql&amp;gt; FLUSH PRIVILEGES;   ——通知mysqld重读授权表
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3.第三种方式： 命令行mysqladmin工具&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mysqladmin -uUserName -hHost password &amp;apos;new_password&amp;apos; -p    ——这里的host指mysqld服务器的ip，并不是帐号中的主机地址
# mysqladmin -uUserName -hHost -p flush-privileges
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;客户端工具&quot;&gt;&lt;a href=&quot;#客户端工具&quot; class=&quot;headerlink&quot; title=&quot;客户端工具&quot;&gt;&lt;/a&gt;客户端工具&lt;/h2&gt;&lt;p&gt;mysql, mysqladmin, mysqldump, mysqlcheck, mysqlimport&lt;br&gt;配置文件中[client]下面的配置是所有mysql客户端共享的配置&lt;br&gt;命令行客户端的通用的选项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-u, –user=&lt;/li&gt;
&lt;li&gt;-h, –host=&lt;/li&gt;
&lt;li&gt;-p, –password=&lt;/li&gt;
&lt;li&gt;–protocol={tcp|socket|memory|pipe}&lt;/li&gt;
&lt;li&gt;–port=&lt;/li&gt;
&lt;li&gt;–socket=    例如：/tmp/mysql.sock &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;非客户端类的管理工具：myisamchk, myisampack。 都是在mysql服务器上运行的，不能基于客户端服务器端通信方式进行使用的。myisamchk是检测工具，检测myisam表是不是有不一致的情况。myisampack是打包压缩工具。&lt;/p&gt;
&lt;h3 id=&quot;mysql客户端&quot;&gt;&lt;a href=&quot;#mysql客户端&quot; class=&quot;headerlink&quot; title=&quot;mysql客户端&quot;&gt;&lt;/a&gt;mysql客户端&lt;/h3&gt;&lt;p&gt;mysql这个命令行客户端工作模式: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;交互式模式 mysql&amp;gt; &lt;/li&gt;
&lt;li&gt;脚本模式(批处理模式) mysql &amp;lt; /path/to/mysql_script.sql&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1.mysql交互式模式&lt;/strong&gt;&lt;br&gt;（1）客户端命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; help  ——获取客户端命令帮助
mysql&amp;gt; \?    ——获取客户端命令帮助
       \c
       \g
       \G
       \q
       \!
       \s
       \. /path/to/mysql_script.sql
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当然，客户端命令里面偶尔可能还会用到其他的，比如”rehash    (#) Rebuild completion hash.”，MySQL其实也支持命令补全的，比如说你有一个库叫mysql，或者叫其他的库，等会我们去use设定某个默认库时，或者只要但凡用到库名的时候，你可以不用写全了，它可以自动给你补全。但是这一功能在mysql启动时默认是关闭的，因为要想能够实现此种功能意义上的补全，需要让mysql服务器启动时读取每一个mysql对象并且给它们生成一个hash表才能补全。这通常会导致mysql启动时被卡住，尤其是非常大的mysql数据库时。启动后如果想用补全，就使用#，重新生成补全的hash表的hash码。&lt;/p&gt;
&lt;p&gt;（2）服务器端命令：需要把命令写全后一并发送给服务器端执行的，因此需要命令结束符，默认为分号(;)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.mysql的快捷键&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ctrl + w: 删除光标之前的单词&lt;/li&gt;
&lt;li&gt;Ctrl + u: 删除光标之前至命令行首的所有内容&lt;/li&gt;
&lt;li&gt;Ctrl + y: 粘贴使用Ctrl+w或Ctrl+u删除的内容&lt;/li&gt;
&lt;li&gt;Ctrl + a: 移动光标至行首&lt;/li&gt;
&lt;li&gt;Ctrl + e: 移动光标至行尾&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;mysqldmin工具&quot;&gt;&lt;a href=&quot;#mysqldmin工具&quot; class=&quot;headerlink&quot; title=&quot;mysqldmin工具&quot;&gt;&lt;/a&gt;mysqldmin工具&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;mysqladmin [options] command [arg] [command [arg]] ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;command:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;create DB_NAME&lt;/li&gt;
&lt;li&gt;drop DB_NAME&lt;/li&gt;
&lt;li&gt;debug: 打开调试日志并记录于error log中；如果我们启动mysql总是出错的话，你可以使用mysqladmin debug，它可以限定通知mysql服务器运行过程中的所有信息都送往mysql的error log。&lt;/li&gt;
&lt;li&gt;status：显示mysql运行的简要状态信息&lt;ul&gt;
&lt;li&gt;–sleep #: 指定间隔时长刷新状态信息&lt;/li&gt;
&lt;li&gt;–count #: 显示的批次，显示几次。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;extended-status: 输出mysqld的各状态变量及其值，相当于执行“mysql&amp;gt; SHOW GLOBAL STATUS”&lt;/li&gt;
&lt;li&gt;variables: 输出mysqld的各服务器变量&lt;/li&gt;
&lt;li&gt;flush-hosts: 清空主机相关的缓存：DNS解析缓存，此前因为连接错误次数过多而被拒绝访问mysqld的主机列表。如果我们在某台客户端主机上连服务器，mysql默认好像是10次，在有限时间内错误过多可能就被放到黑名单中去了。此后再发连接请求，直接拒绝。一旦出现这种情况，就得去mysql服务器端flush-hosts。&lt;/li&gt;
&lt;li&gt;flush-logs: 日志滚动，只二进制日志和中继日志。&lt;/li&gt;
&lt;li&gt;refresh: 相当于同时使用flush-logs和flush-hosts&lt;/li&gt;
&lt;li&gt;flush-privileges: 通知服务器重读授权表。&lt;/li&gt;
&lt;li&gt;reload: 功能同flush-privileges。&lt;/li&gt;
&lt;li&gt;flush-status: 重置服务器状态变量的值。重置extended-status显示的变量值，不是所有变量。&lt;/li&gt;
&lt;li&gt;flush-tables: 关闭当前打开的表文件句柄。&lt;/li&gt;
&lt;li&gt;flush-threads：清空线程缓存。&lt;/li&gt;
&lt;li&gt;kill:　给线程id，杀死指定的线程，可以一次杀死多个线程，以逗号分隔，但不能有多余空格。mysql是单进程多线程的。&lt;/li&gt;
&lt;li&gt;password: 修改当前用户的密码。&lt;/li&gt;
&lt;li&gt;ping: 探测服务器是否在线。&lt;/li&gt;
&lt;li&gt;processlist：显示mysql服务器的线程列表。&lt;/li&gt;
&lt;li&gt;shutdown: 关闭mysqld进程。所以mysqladmin是个很危险的命令。&lt;/li&gt;
&lt;li&gt;start-slave&lt;/li&gt;
&lt;li&gt;stop-slave: 启动/关闭从服务器线程&lt;/li&gt;
&lt;li&gt;version：显示mysqld的版本。  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;【示例】：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@osb30 ~]# mysqladmin -uroot -p create testdb
Enter password: 
[root@osb30 ~]# mysqladmin -uroot -p status
Enter password: 
Uptime: 15116890  Threads: 23  Questions: 144580431  Slow queries: 12904887  Opens: 380  Flush tables: 1  Open tables: 338  Queries per second avg: 9.564
[root@osb30 ~]# mysqladmin -uroot -p version
Enter password: 
mysqladmin  Ver 8.42 Distrib 5.6.27, for Linux on x86_64
Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Server version          5.6.27
Protocol version        10
...
[root@osb30 ~]# mysqladmin -uroot -p ping
Enter password: 
mysqld is alive
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;GUI客户端工具：&quot;&gt;&lt;a href=&quot;#GUI客户端工具：&quot; class=&quot;headerlink&quot; title=&quot;GUI客户端工具：&quot;&gt;&lt;/a&gt;GUI客户端工具：&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Navicat for mysql      商业版的&lt;/li&gt;
&lt;li&gt;Toad for mysql          &lt;/li&gt;
&lt;li&gt;mysql front            商业版的&lt;/li&gt;
&lt;li&gt;sqlyog                 商业版的&lt;/li&gt;
&lt;li&gt;phpMyAdmin             基于php的开源工具&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;mysql忘记root密码怎么办&quot;&gt;&lt;a href=&quot;#mysql忘记root密码怎么办&quot; class=&quot;headerlink&quot; title=&quot;mysql忘记root密码怎么办&quot;&gt;&lt;/a&gt;mysql忘记root密码怎么办&lt;/h2&gt;&lt;p&gt;在my.cnf文件中加入如下配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;skip-grant-tables=1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后用空密码方式使用root用户登录 MySQL：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql -u root
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;修改root用户的密码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; update mysql.user set password=PASSWORD(&amp;apos;newpassword&amp;apos;) where User=&amp;apos;root&amp;apos;;  
mysql&amp;gt; flush privileges;  
mysql&amp;gt; quit 
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;MySQL产品&quot;&gt;&lt;a href=&quot;#MySQL产品&quot; class=&quot;headerlink&quot; title=&quot;MySQL产品&quot;&gt;&lt;/a&gt;MySQL产品&lt;/h2&gt;&lt;p&gt;当年Sun公司买下了MySQL，后来Sun公司被Oracle收购了。也就是MySQL也变成Oracle的了。Oracle向来视MySQL为眼中钉，所以Oracle在收购Sun的时候遭到了欧盟的极力反对，他们担心MySQL。
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>关系数据库理论基础</title>
    <link href="http://yoursite.com/2018/03/13/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"/>
    <id>http://yoursite.com/2018/03/13/关系数据库理论基础/</id>
    <published>2018-03-13T05:51:55.000Z</published>
    <updated>2018-03-18T04:05:28.000Z</updated>
    
    <content type="html">&lt;blockquote&gt;
&lt;p&gt;最近开始做报表，于是把之前学习的mysql相关知识整理回顾下，温故而知新。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;数据库&quot;&gt;&lt;a href=&quot;#数据库&quot; class=&quot;headerlink&quot; title=&quot;数据库&quot;&gt;&lt;/a&gt;数据库&lt;/h2&gt;&lt;p&gt;程序=指令+数据&lt;br&gt;    指令是CPU能够逐条解析运行的命令，CPU运行指令的主要目的是处理数据的。其实对于CPU所能够执行的程序，无论是指令还是数据都在内存当中。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;但是数据从何而来，数据是需要持久存储的。假设我们不需要用户通过键盘输入数据，程序的执行结果有可能产生输出。任何程序都很依赖I/O，说白了I/O提供数据，并保存数据。&lt;br&gt;    数据从何而来？第一种方式是程序员在开发程序时初始化的一些变量值，但是这些变量值在初始化时给到的数据量是很小的。还有其他的方式，文件、交互式输入，这两种都是I/O中的I。&lt;br&gt;    那么输出呢？当程序处理结束了，它的所有处理结果都在内存中，如果这个时候我们把进程终止了，所有数据都会丢失了，我们应该把输出保存在一个持久存储中。&lt;br&gt;    但是要考虑一个问题，我们如何将持久存储中的数据原样不动的载入内存中？能够存储在文件中的数据通常要做扁平化或者流式化的。要把这些扁平化或流式化的数据还原到内存中，如何还原？所有保存在文件中的内容都是字符。当然这里指的是文本文件，就算是二进制文件，里面就是01字节码。但是有些时候，比如我们希望读进内存时不是字符，而是数值。很显然一个文本文件是不能提供这个功能的。&lt;br&gt;    在考虑一种场景，现在有一个用户帐号文件，用户帐号200或者300个，我们把这些帐号密码保存到文本文件中。当用户登录时，我们需要去文件中逐个比较用户输入的字符串，前提是得把整个文件装入内存。就算你grep “root” /etc/passwd，也是需要先把/etc/passwd装入到内存中才行。如果用户数增加到1000万个，这个文本文件可能有10个G，而我们为了查找一个用户得把10个G从磁盘产生大量I/O调入内存，性能奇差。这显然也是无法想象的，无法接受。&lt;br&gt;    因此我们需要在更高层次的逻辑结构上将数据分割成片。如果我们把数据存于一个单个文件，而访问接口又只是文件接口的话，每次访问这个文件的数据，都得把整个文件装入内存。因此需要在文件的物理结构的基础之上在提供一层逻辑结构，在这个逻辑视角上，把物理层次所保存的所有数据切割成块，或者切割成片。当需要查找用户信息时，我们没必要把整个文件载入内存，而只要把那个数据所在的一个片或多个片装入内存。因此我们在文件系统层次更高级别之上提供一层逻辑性的管理机制，这种机制能够使得我们去装载数据时而不用牵一发而动全身。而提供这个管理机制的工具，向下负责管理这个文件，将文件切割成片，向上将文件切割成片的结果用一种用户习惯的方式展示给用户。用户看到的将是数据。这样的工具就是数据库管理系统(DBMS)。&lt;/p&gt;
&lt;h2 id=&quot;数据模型&quot;&gt;&lt;a href=&quot;#数据模型&quot; class=&quot;headerlink&quot; title=&quot;数据模型&quot;&gt;&lt;/a&gt;数据模型&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;要从逻辑层把数据映射到物理层上，那么这个软件自身必须要能够完成对物理层到逻辑层之间的数据组织，而在数据组织上，有3种数据组织模型。
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;层次模型：早期的层次型数据库。倒置树状结构。&lt;/li&gt;
&lt;li&gt;网状模型：和层次模型一样，对于数据冗余和彼此间建立关联关系都很困难，而且网状模型异常复杂。&lt;/li&gt;
&lt;li&gt;关系模型：海量数据时，关联的数据库表太多，反而开销很大。&lt;br&gt;库和表，库是由表组成的。一个表可以没有行，只不过是个空表。但是不可以没有列，没有列怎么组织成表呢。我们又把列称为字段(field)。&lt;/li&gt;
&lt;li&gt;非关系型数据库模型：反关系型数据库，NoSQL：不仅仅是SQL，不要以为它不是SQL。NoSQL是一个技术流派，而不是一个数据库，有各种各样的流派。NoSQL不是新概念，它只不过是利用现代互联网海量数据视角重新焕发了青春。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;无论是上面4种中的哪种模型，都遵循上面介绍的数据库设计理念。无非就是背后物理层的数据组织以及在逻辑层映射的功能可能大为不同或略有不同而已。对于用户来看，通常都是两种接口，命令行和API。而API通常为程序员所使用。&lt;/p&gt;
&lt;h2 id=&quot;数据库分类&quot;&gt;&lt;a href=&quot;#数据库分类&quot; class=&quot;headerlink&quot; title=&quot;数据库分类&quot;&gt;&lt;/a&gt;数据库分类&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;文件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据冗余和不一致型：比如/etc/passwd，我们可以创建两个完全相同的用户，也是能保存进去的，这就是数据冗余。    &lt;/li&gt;
&lt;li&gt;数据访问困难：十万个帐号放在文本数据库中，想找其中的一个会很困难。使用grep去实现查找。&lt;/li&gt;
&lt;li&gt;数据孤立&lt;/li&gt;
&lt;li&gt;完整性问题&lt;/li&gt;
&lt;li&gt;原子性问题：一个机制，能够把多个操作当成一个操作，要么同时能执行，要么都不能执行。这就是原子性问题。    &lt;/li&gt;
&lt;li&gt;并发访问异常&lt;/li&gt;
&lt;li&gt;安全性问题 &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;DBMS&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;层次模型&lt;/li&gt;
&lt;li&gt;网状模型&lt;/li&gt;
&lt;li&gt;关系模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;RDBMS&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关系型数据库：将数据组织在一个有字段和记录组成的二维关系表中，并且在这个关系表之外提供了很多辅助性工具以完成关系表中关系的维持及数据访问等功能。核心是二维关系表。&lt;br&gt;    一个数据库管理系统还应该提供安全性的机制，所以我们还得为管理系统提供认证、授权等功能。&lt;br&gt;    我们要想实现对数据访问时载入有限片的数据而不用是所有数据，还要提供索引等。&lt;br&gt;    对于用户来讲，需要只看到自己需要的数据，还要提供视图等。&lt;br&gt;    但是关系型数据库还遇到一个问题，如何把文件存入到数据库中？不大可能，除非把图片编码重新编码成字符保存到数据库中。如果不能，我们可以把一个文件在文件系统中的路径(字符串)存在表中。&lt;br&gt;    &lt;strong&gt;【注意】:关系型数据库只是一种概念，只是一种设计理念，能够把这种理念实现的通常是软件。这和前面讲协议是一样的，http是一种协议，其实现是由httpd、nginx等等来实现的。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;常见的关系型数据库产品&quot;&gt;&lt;a href=&quot;#常见的关系型数据库产品&quot; class=&quot;headerlink&quot; title=&quot;常见的关系型数据库产品&quot;&gt;&lt;/a&gt;常见的关系型数据库产品&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;SQL Server&lt;/li&gt;
&lt;li&gt;DB2&lt;/li&gt;
&lt;li&gt;MySQL&lt;/li&gt;
&lt;li&gt;MariaDB&lt;/li&gt;
&lt;li&gt;PostgreSQL&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1.早期三巨头&lt;/strong&gt;&lt;br&gt;Sybase  —&amp;gt;早期和Microsoft合作过。一起研发了一个面向windows的关系型数据库产品，后来Sybase不玩了。Microsoft就买断发展，后来就成了SQL Server。今天Sybase今天依然存在。&lt;br&gt;Informix  —&amp;gt;被IBM收购了。IBM有自己的DB2。&lt;br&gt;Oracle  —&amp;gt;oracle的产品不一定是最好的，但是oracle的销售做的是最好的。所以你把技术做的在牛在精，卖不出去就是没用。所以刚开始工作时9分靠技术，1分靠沟通。而两年到三年以后，工作业绩7分靠沟通，3分靠技术。当然，技术做好安身立命没问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.MySQL —&amp;gt; MariaDB&lt;/strong&gt;&lt;br&gt;    早期属于瑞典的AB公司，2009年卖给了sun公司，不幸的是sun被oracle收购了。oracle有些很不光彩的前科，把竞争对手买下来然后打入冷宫。虽然oracle承诺了5年不下手，但实际上这期间MySQL已经被蹂躏了无数遍。到今天为止，和MySQL合作的，用MySQL软件的，比如Facebook、Google、Twitter都在纷纷转向MariaDB。&lt;br&gt;    MySQL的原作者在sun被oracle收购以后，就另立门户了。在早期MySQL的基础上重新提供了另外一个分支MariaDB。MariaDB在兼容MySQL的基础上而且又整合了开源社区中的很强大的技术力量。比如早期MySQL整合进的存储引擎中有个innodb，innodb属于innobase公司，而innobase早在2008年被oracle收购了。但好在percona公司致力于MySQL优化方面，这个组织在改进早期innodb的基础上提供了增强版的innodb叫xtradb。而MariaDB中用的就是xtradb。&lt;br&gt;    早些年Facebook、Google、Twitter(还有一家公司，记不得了)内部的研发团队所研发出来的一些新技术不断的反馈回MySQL社区，但是MySQL可能变成oracle的商用产品，这些公司肯定也是不同意的。因此双方在MySQL的发展上产生了很大的分歧，所以这几家公司中的工程师整合了后来他们所研发的新技术又开发了另外一个分支，专门为互联网应用而生的增强版的、支持多主复制等的新产品，叫webscaledb。专门为web应用而生的数据库管理系统。诞生时间2014年。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.另外一个开源产品：PostgreSQL，简称pgsql&lt;/strong&gt;&lt;br&gt;    前身是互联网上最早的一批关系型数据库产品egresql，早期诞生在加州大学伯克利分校的。只是egresql在商业运作上和oracle竞争时完全败下阵来。以至于后来销声匿迹的比Sybase和Informix还早。&lt;br&gt;    事实上，就关系型数据库本身来讲，pgsql比mysql在技术上要优秀的多。不过市场决定一切。&lt;br&gt;    RHEL7内置不在是MySQL，而是MariaDB。&lt;br&gt;    这个世界唯一不变的是”不断的变化”。&lt;/p&gt;
&lt;p&gt;以上讲的产品都是C/S架构，以mysql为例，有客户端，也有服务端。两者之间的通信时通过mysql协议来通信的。另外一种独立的产品叫sqlite。这仅是一个简单的、工作在本地的、非服务化的、纯粹基于API的关系型数据库接口。【注意】:sqlite仅是一个引擎。说白了就是讲，你通过它能够将数据组织成关系型数据库的格式，背后仍然是把数据存于文件中。因此我们要通过sqlite存储数据怎么办呢？sqlite不监听在任何服务上，只有API。因此只有程序员在开发程序时调用这个API，就能够基于sqlite这个引擎来完成基于关系型数据库模式的数据存储了。所以它尤其适用于嵌入式平台上。&lt;/p&gt;
&lt;h2 id=&quot;关系型数据库分析&quot;&gt;&lt;a href=&quot;#关系型数据库分析&quot; class=&quot;headerlink&quot; title=&quot;关系型数据库分析&quot;&gt;&lt;/a&gt;关系型数据库分析&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.一个通用的关系型数据库管理系统应该具有的逻辑架构&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/MySQL/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;首先作为一个数据库管理系统来讲，必须要能接收用户发出的请求，而用户的请求的来源方式有多种。大多是通过sql协议来的，只不过通过sql协议连进来的有这么两种模式，一种是基于API接口的，一种是基于交互式客户端的。而sqlite这种只有一种方式就是基于API。&lt;br&gt;    对于关系型数据库来讲，怎么接进来？对于sqlite来讲，它没有监听在C/S模式下，只要调用API。但是对于MySQL来讲，需要支持更大的并发连接请求，sqlite就没有并发的概念。所以前端应该有一个连接管理器，需要对用户发来的sql语句进行解析。SQL(Structure Query Language)语句分为以下几类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DDL: CREATE, DROP, ALTER    ——数据定义语言：操作数据库对象的。比如库、表、索引、视图等。&lt;/li&gt;
&lt;li&gt;DML: SELECT, INSERT, UPDATE, DELETE    ——数据操作语言：管理数据的。&lt;/li&gt;
&lt;li&gt;DCL: GRANT, REVOKE    ——授权&lt;br&gt;  现在几乎所有的关系型数据库向外的接口都是通过sql语句输出的，只不过联络方式有所不同而已。因此一旦一个sql语句来了，查询求解引擎分析语法，然后执行语句，说白了就是mysql的解释器。这个执行引擎就类似于Linux内核，这和我们通过shell运行命令类似。这个解释器应该具备的功能包括：分析器、优化器、操作求解器和计划执行器等。当然这种分类并不严格。&lt;br&gt;  数据最后一定是存放在磁盘的文件中。因此这个查询执行引擎要和文件打交道，于是就有了文件访问接口，也就是文件存取方法接口。但是怎么样能避免I/O给系统带来的影响呢？把数据缓存到内存中操作，并且通过一些比较靠谱的机制保证这些数据不会因为系统断电丢失，或者说不会因为断电导致数据不一致。因此我们就需要缓存管理器。&lt;br&gt;  这些数据文件存放的是单个文件还是多个文件，我们需要一个磁盘空间管理器。怎么管理磁盘空间，怎么组织文件为一个文件还是多个文件等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.一个关系型数据库管理系统必然会面临以下几个问题：&lt;/strong&gt;&lt;br&gt;数据一致性、提供事务机制、提高性能等。&lt;br&gt;事务：事务就是 管理并发过程中，万一出现问题怎么办的。&lt;br&gt;ACID&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A: 原子性&lt;/li&gt;
&lt;li&gt;C: 一致性&lt;/li&gt;
&lt;li&gt;I：隔离性&lt;/li&gt;
&lt;li&gt;D：持久性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;隔离：隔离级别&lt;/strong&gt;    ——隔离事务，自上而下，级别越来越高。不同的数据库管理系统，必须有一个默认的事务隔离级别的。很多的关系型数据库，其默认隔离级别都是第二个读提交，这样性能会好一点。而MySQL是第三个可重读的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读未提交：read uncommitted&lt;/li&gt;
&lt;li&gt;读提交：  read committed&lt;/li&gt;
&lt;li&gt;可重读：  repeatable read&lt;/li&gt;
&lt;li&gt;串行化：  serializable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;机械式硬盘：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;随机读写&lt;/li&gt;
&lt;li&gt;顺序读写      &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这两种方式对内存而言没什么影响，但是对机械硬盘来讲就不一样了。很多时候对数据的写操作都是随机的，性能非常差。为了避免这种情况，所有的写操作先在内存中完成，也就是在缓存中完成。也就是说当需要写入数据时不是直接往数据库文件上写的，而是往日志中写。也就是说日志是补充性的存储空间，通常还不止一个，可能是一组。当你执行写操作时，不管你是往哪个数据库中写的，也无论你写的是什么，都先往日志文件上写，这个日志文件通常是大小固定的，在磁盘上有连续的存储空间。所以缓存管理器一旦缓存1秒钟的数据，或者一旦有个事务提交了，先把这个数据放到日志文件中。因为日志文件是连续的存储空间，所以存起来速度快多了。&lt;strong&gt;但是这有个前提，写的是事务日志。&lt;/strong&gt;日志文件会定期向磁盘上数据文件同步。同步完日志文件里的数据就清掉了。这些事务日志很重要，通常放在有硬件冗余的设备上。这就是通过事务日志把随机I/O转换成顺序I/O以提高用户体验的。&lt;br&gt;日志分为事务日志和历史日志。&lt;/p&gt;
&lt;p&gt;【考虑一种场景】：&lt;br&gt;万一事务走了一半，它里面有80个语句都发生了写操作，已经执行了50个，这50可能会导致一个日志文件存不下，日志文件中的某些数据已经存到磁盘中的数据文件中去了，这个时候服务器进程崩溃了，或者系统断电了，下次启动起来后，这个事务其实并没有完成，怎么办呢？应该撤回才对。事务本身有两种状态：提交/未提交。把这些未完成的事务都回滚回去，因此需要一个恢复管理器。恢复管理器不需要用户手动参与，下次开机以后会自动发现哪些事务提交了，还在日志文件中，它会把这些数据同步到磁盘文件中。而那些未提交的事务都回滚到事务执行前的状态。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;索引：&lt;/strong&gt;将数据库中表的某个字段抽取出来创建成索引，这个一般是排好序的。&lt;strong&gt;索引怎么存呢？树状结构，B树。索引可能有n种数据格式，看场景。对于MySQL而言，通常是B树索引，但也有空间索引。&lt;/strong&gt;微信可以摇一摇，它开始找离你比较近的，你想过这个问题没有？什么人，在哪个数据库中找，怎么标注他是离你比较近的？这必须要根据你的空间地址位置。要计算你当前所在位置，然后根据距离做测算。所以索引有很多种存储机制。&lt;br&gt;    如果索引查询到，文件依然很大，可能有2G，所以还需要对索引在索引。所以索引有很多种类型。&lt;/p&gt;
&lt;h2 id=&quot;数据库范式&quot;&gt;&lt;a href=&quot;#数据库范式&quot; class=&quot;headerlink&quot; title=&quot;数据库范式&quot;&gt;&lt;/a&gt;数据库范式&lt;/h2&gt;&lt;p&gt;数据库设计遵循数据库范式。&lt;br&gt;&lt;strong&gt;RDMBS设计范式：&lt;/strong&gt;&lt;br&gt;设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同的范式，各种范式呈递次规范，越高的范式数据库冗余越小。&lt;br&gt;目前关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴德斯科范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称完美范式）。满足最低要求的范式是第一范式（1NF）。在第一范式的基础上进一步满足更多规范要求的称为第二范式（2NF），其余范式以次类推。一般说来，数据库只需满足第三范式(3NF）就行了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(1) 第一范式（1NF）&lt;/strong&gt;&lt;br&gt;    所谓第一范式（1NF）是指在关系模型中，对域(指的是字段)添加的一个规范要求，所有的域都应该是原子性的，即数据库表的每一列都是不可分割的原子数据项，而不能是集合，数组，记录等非原子数据项。即实体中的某个属性有多个值时，必须拆分为不同的属性。在符合第一范式（1NF）表中的每个域值只能是实体的一个属性或一个属性的一部分。简而言之，第一范式就是无重复的域。&lt;br&gt;【说明】：在任何一个关系数据库中，第一范式（1NF）是对关系模式的设计基本要求，一般设计中都必须满足第一范式（1NF）。不过有些关系模型中突破了1NF的限制，这种称为非1NF的关系模型。换句话说，是否必须满足1NF的最低要求，主要依赖于所使用的关系模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(2) 第二范式(2NF)&lt;/strong&gt;&lt;br&gt;    第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。第二范式（2NF）要求数据库表中的每个实例或记录必须可以被唯一地区分。选取一个能区分每个实体的属性或属性组，作为实体的唯一标识。&lt;br&gt;    第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。简而言之，第二范式就是在第一范式的基础上属性完全依赖于主键。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(3) 第三范式（3NF）&lt;/strong&gt;&lt;br&gt;    第三范式（3NF）是第二范式（2NF）的一个子集，即满足第三范式（3NF）必须满足第二范式（2NF）。简而言之，第三范式（3NF）要求一个关系中不包含已在其它关系已包含的非主关键字信息。简而言之，第三范式就是属性不依赖于其它非主属性，也就是在满足2NF的基础上，任何非主属性不得传递依赖于主属性。&lt;/p&gt;
&lt;p&gt;【总结】:关系型数据库设计前三范式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;字段的原子性&lt;/li&gt;
&lt;li&gt;主键&lt;/li&gt;
&lt;li&gt;非主属性不允许重复&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;SQL&quot;&gt;&lt;a href=&quot;#SQL&quot; class=&quot;headerlink&quot; title=&quot;SQL&quot;&gt;&lt;/a&gt;SQL&lt;/h2&gt;&lt;p&gt;SQL: 是一种规范。早期只提供C/C++的API，后来IBM公司的一个研究员率先为关系型数据库引入SQL接口这种机制，这种规范，在后来，其他的关系型数据库都纷纷引入了SQL机制。这就像shell一样，bash、csh、ksh、zsh使用方式不尽相同，但是命令机制命令语法都是一样的。ANSI指定标准。&lt;br&gt;   SQL-86， SQL-89， SQL-92， SQL-99， SQL-03&lt;br&gt;MySQL遵循的是SQL-99。MySQL支持XML。&lt;/p&gt;
&lt;p&gt;关系数据库的约束：&lt;br&gt;    主键约束，外键约束，惟一键约束，条件约束，非空约束。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;最近开始做报表，于是把之前学习的mysql相关知识整理回顾下，温故而知新。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;数据库&quot;&gt;&lt;a href=&quot;#数据库&quot; class=&quot;headerlink&quot; title=&quot;数据库&quot;&gt;&lt;/a&gt;数据库&lt;/h2&gt;&lt;p&gt;程序=指令+数据&lt;br&gt;    指令是CPU能够逐条解析运行的命令，CPU运行指令的主要目的是处理数据的。其实对于CPU所能够执行的程序，无论是指令还是数据都在内存当中。
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>基于Keepalived实现Nginx高可用</title>
    <link href="http://yoursite.com/2018/02/05/%E5%9F%BA%E4%BA%8EKeepalived%E5%AE%9E%E7%8E%B0Nginx%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    <id>http://yoursite.com/2018/02/05/基于Keepalived实现Nginx高可用/</id>
    <published>2018-02-05T09:07:21.000Z</published>
    <updated>2018-03-01T09:16:13.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;高可用集群介绍&quot;&gt;&lt;a href=&quot;#高可用集群介绍&quot; class=&quot;headerlink&quot; title=&quot;高可用集群介绍&quot;&gt;&lt;/a&gt;高可用集群介绍&lt;/h2&gt;&lt;p&gt;前面介绍的Nginx可以实现对后端服务的负载均衡，Nginx就是调度器。但是我们还要考虑一个，调度器本身在工作的时候仍然会有一个风险，因为我们把整个站点的请求的依赖性都建立在了调度器上，调度器坏了怎么办？&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;只要是设备，都有可能会损坏。它一挂，整个服务器集群就挂了，我们不能允许这情况出现。怎么办？做一个备用的调度器，只是备用。随时监控祝调度器的心跳，只要它挂了就接替。调度器本身也是个服务，怎么工作成调度器。把主调度器的地址夺过来，自身启动调度服务，由它来负责调度。主调度器通过网络连接把自己的心跳信息随时向外传输，只要辅调度器能收到。这也是一种集群，高可用集群（HA，High Availability）。但是高可用集群必然有一台空闲着，资源浪费。&lt;br&gt;负载均衡集群具有高可用能力(但不是高可用集群)，因为比如说用户请求被分发到第三台服务器上，而这时候第三台挂了，调度器只需要重新分发请求到好的服务器上就可以了。&lt;br&gt;HA集群，每一个主节点(就是指服务器)需要向其他节点通知自己的心跳信息，但是LB集群的节点是没有的。所以LB集群具有高可用能力，而这个能力不是依赖于后面的服务器的，而是依赖于前端服务器调度的。现在的问题是如果前端服务器不知道这第三台服务器挂了依然将用户请求分发至第三台怎么办？这种机制称为后端服务器的健康状况检查。检查好了到坏了，也检查坏的到好的。一般说来前端主机都应该具备这样的能力，这才是一个正常情况下的负载集群。&lt;br&gt;负载均衡集群是以提高服务的并发处理能力为根本着眼点的，而高可用集群是以提供服务始终在线能力为根本着眼点的，它不管你能应付多个个请求，但是一定要让你随时在线，不会因为宕机而使服务不用用了。&lt;br&gt;如何衡量一个服务的可用性？服务正常在线时间/(正常在线时间+故障处理时间)=可用性。&lt;/p&gt;
&lt;h2 id=&quot;实现高可用集群的一些开源方案&quot;&gt;&lt;a href=&quot;#实现高可用集群的一些开源方案&quot; class=&quot;headerlink&quot; title=&quot;实现高可用集群的一些开源方案&quot;&gt;&lt;/a&gt;实现高可用集群的一些开源方案&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;heartbeat&lt;/li&gt;
&lt;li&gt;corosync(openais分裂出来的一个项目)&lt;/li&gt;
&lt;li&gt;cman&lt;/li&gt;
&lt;li&gt;keepalived&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;前面的3套组件工作模式基本都是相同的，keepalived则不相同。keepalived最初的诞生是为了给ipvs提供高可用性。而ipvs说白了就是内核中的一些规则而已，keepalived最初的主要目的就是能够自己调用ipvs的adm命令来生成规则，并且能够自动实现将用户所请求的访问地址转移到其他节点上实现的。&lt;/p&gt;
&lt;h2 id=&quot;Keepalived介绍&quot;&gt;&lt;a href=&quot;#Keepalived介绍&quot; class=&quot;headerlink&quot; title=&quot;Keepalived介绍&quot;&gt;&lt;/a&gt;Keepalived介绍&lt;/h2&gt;&lt;p&gt;对于Master和Backup来讲，Master这个节点会不停的向另外一个节点通告自己的心跳，但是通告机制是基于VRRP协议实现的，backup一旦接收不到主节点的心跳，就会把vip资源抢过来。而在backup节点，只需要把本地keepalived中那个生效的服务中某一个模块，把它生效起来就可以了。所以keepalived自身是模块化设计的，它有着诸多模块，有些模块就是去监控并生效ipvs规则的。而且keepalived还可以实现后端realserver的健康状况检查。&lt;br&gt;    虽然一开始是为了ipvs提供高可用，但是后来慢慢发展到可以为其他的服务提供高可用，比如对轻量级的调度器haproxy和nginx提供高可用。但是需要自己创建额外的脚本来实现。站在这个角度来讲，keepalived的核心大概是这个样子的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1.vrrp的实现&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2.跟vrrp相关的一些配置virtual server&lt;/strong&gt;   ——针对的是ipvs。&lt;br&gt;比如：基于vrrp所谓通告机制之上的对于其他资源的控制：比如对于虚拟服务器的控制。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;3.vrrp_script：&lt;/strong&gt;vrrp能够调用外部脚本的实现。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;说白了，keepalived就是vrrp协议的实现。&lt;strong&gt;vrrp：虚拟冗余路由协议。&lt;/strong&gt;为什么需要这个协议？比如说，公司有个局域网，有很多很多客户机，这些客户机都需要访问互联网或者其他网络的主机，要想和非本网段的主机通信都需要网关，但是一旦这个网关挂了怎么办？那所有非同网段的都访问不了了。那么如何去实现网关的可用性呢？第一种是让客户端自己发现问题，如果他发现上不了网了，我们在前面提供两个网关，这两个网关之间没有任何心跳信息传递，反正告诉客户端有两网关，其中一个不可用了自己改成另一个网关。第二种：在每一个主机上配置动态路由协议，让主机自动生成路由表。但是我们把pc机上的操作系统都配置为支持动态路由协议，这不是一件小工作。第三种：使用ARP网关。在每个主机上装一个ARP客户端，在前面的路由上装好ARP服务器端，那ARP客户端会自行去判定哪个可以用，哪个不可以用。这三种办法都需要依赖于客户端主机自身去做一些配置，才能保证其可用性。VRRP能够把两个网关虚拟成一个网关来使用，简单来讲，在两个网关前面抹上一层协议，这两个路由器之间可以通过选举决定谁是当前活动节点。一般情况下，只有一个是活动节点。&lt;strong&gt;【注意】:vrrp的ip地址是虚拟的，连mac地址也是虚拟的。vrrp协议专门生成了一段虚拟的mac地址来使用。所以这个活动节点拿到的不仅是是vip，还有vmac地址。&lt;/strong&gt;所以客户端网关地址指向vip就可以了，无论实际上是哪个网关对客户端来讲是透明的。&lt;br&gt;很多路由设备都是支持vrrp协议的，像华为的等。因为vrrp是个开放式协议，几乎所有的厂商生产的设备都能够支持。那keepalived就是在Linux操作系统上实现了vrrp。比如说我们想用keepalived实现对nginx的高可用，不仅需要转移vip，还需要将相应节点上的nginx服务启动起来，同时还要监控本机上的nginx服务。&lt;/p&gt;
&lt;h2 id=&quot;keepalived架构&quot;&gt;&lt;a href=&quot;#keepalived架构&quot; class=&quot;headerlink&quot; title=&quot;keepalived架构&quot;&gt;&lt;/a&gt;keepalived架构&lt;/h2&gt;&lt;p&gt;在一个节点上，会启动一个主进程。一般来讲，在一个主进程下会生成两个子进程。一个是用来实现VRRP，另外一个是实现Checkers，检查服务可用性。【注意】:这里提供的check是对ipvs后端realserver的健康状态监测，而我们去监控服务的健康状况则需要自己写脚本。只不过我们仍然把这些脚本归类于checkers。&lt;br&gt;    还有其他的组件，比如：I/O复用器、内存管理组件。还有最左边的是配置文件分析器，这个就是主进程，读取keepalived核心配置文件，分析主配置文件，生效主配置文件，并指挥这两个子进程工作。&lt;br&gt;    WatchDog：是Linux内核中的一个模块，它也是一个计时器，它可以帮助主进程去盯着这两个子进程。主进程并不负责具体的工作，所有的具体工作都是由子进程完成的。这两个子进程任何一个挂了，keepalived就不完整了。keepalived启动以后，这两个子进程每隔两秒钟定期的向主进程打开的unix套接字文件写数据，就是发心跳信息。万一哪一个子进程不再发了，那么主进程就认为子进程挂了，然后去重启这个子进程。基于watchdog监控子进程。&lt;br&gt;    看图中，官方给的图就说明主要是为ipvs提供高可用的，所以配置文件中的一大部分都是定义跟ipvs相关的配置。如果我们不用ipvs，这些配置大多都用不着。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/23.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;对于想要实现对nginx等服务的高可用，使用keepalived实现vrrp协议还不够，因为我们只转移VIP和VMAC，还需要监控和转移服务。有了chechers，我们就可以自己写一个脚本，这个checkers基于脚本调用每隔1秒钟或者两秒钟就来检查这个服务本身状态是否正常，比如取检查status，一旦得不到running信息，可以先重启这个服务。重启之后还不running就转移。怎么转移啊？vrrp是基于什么机制转移的？此时心跳信息依然正常的，并不是不通告心跳了，这个场景下心跳信息是正常的。此时就不能抢了，这个场景下的转移，依靠每个节点的优先级。优先级是从0-255。一般0和255不用，它们有特殊的用法。数字越大优先级越高。因此我们可以这么来定义，首先上来定义两个物理路由的优先级一大一小，比如100和99。一启动，100那个肯定是主的，99那个是从的。这个选举是通过比较物理路由的优先级的。每个节点上线都是backup，就比如一上来，大家都是村民，等人到齐了，就通过比较优先级选举村长。但是如果某个节点上线等了半天，其他节点不来，于是可以自认为自己是最高优先级的节点。这么个场景：100的那个节点服务已经挂了，脚本里重启服务也不行，但是心跳信息是好的，99那个又抢占不了，怎么办？这就是checkers的作用了，我们可以在检测到服务故障以后，人为的把当前节点的优先级降低，这样99那个就能依靠优先级高抢占VIP资源，然后尝试在99节点上启动服务。如何启动服务需要我们自己去写脚本。&lt;br&gt;    VIP资源转移，我们管理员应该知晓这些转移情况，所以还应该有一个通知机制。万一某个节点发生了故障，应该尽可能早的给管理员发封邮件。你如果配置了有邮件服务器的话，这样节点上资源发生转移的时候会收到邮件通知的。&lt;br&gt;    keepalived的转移速度和监控是非常轻量级的，尤其是对于那些用不着共享存储的、节点非常少的场景等应用的。但是对keepalived来讲，支不支持多节点呢？支持多个节点。但是对于同一组服务来讲，只能有一个节点是活动的，因为VIP和VMAC只能在一个节点上运行。所以是一主多从的模式，但是这种模式下，从越多，浪费越大。其实我们可以这样来做，让两个节点都活动起来。很简单，在两个节点上运行两组服务，一组服务是不可能的。在两个物理路由的基础上做两组虚拟路由。&lt;br&gt;如果说keepalived实现nginx的高可用，弄了两个vip，两台机器A和B都有Nginx服务，如何让用户访问到两个不同的节点呢？现在两个节点都是活动的，两个节点上nginx服务都在运行。而客户端端访问的时候只能访问一个，怎么能让客户端访问两个？&lt;strong&gt;使用DNS的两条A记录。&lt;/strong&gt;不同的用户解析的结果是不同的主机，我们并不要求绝对的均衡，因此这里nginx提供的是轻量级的反向代理，nginx本身不是提供web服务的。如果是web服务的话，最好就不要使用这种方案了。由此，两个nginx都能正常工作，都能分发用户请求到后端的上游服务器上去。&lt;br&gt;    基于DNS的转发，用户请求被解析的结果在一段时间内会缓存下来的，请求所访问的是同一个nginx。这就是分担负载模型的VRRP机制。基于这个机制，比如说你有3个节点，那就定义3组虚拟路由，其中每一组中，一个是组的，其他两个是备的。但是这多组虚拟路由之间不能干扰。如何让同一组物理路由设备上的不同虚拟路由呢？所以VRRP必须提供一套完善的管理机制。简单来讲，每一组虚拟路由得有自己独有的标识，称为虚拟路由VRID，虚拟路由id号。&lt;br&gt;    还有一个问题，如果有人知道你这做了高可用，他拿来一个主机放在这，并且配置好了vrrp协议，请问这个主机是否有机会成为主节点呢？之前讲其他的高可用集群解决方案时提到不可以让别人的节点随意加到集群中来，那么怎么解决这个问题？要通过认证来解决。VRRP的认证支持两种认证机制，明文字符串认证和MD5、SSHA-1散列认证。明文字符串认证是指各节点间配置好共享域密钥。散列认证配置起来麻烦一点。&lt;br&gt;    keepalived核心就是VRRP，能把VRRP玩转，服务可以通过写脚本，明白是怎么调用脚本的就可以了。如果需要对VRRP有个详细的了解，请搜索H3C的VRRP技术白皮书或者华为的。&lt;/p&gt;
&lt;h2 id=&quot;安装配置Keepalived&quot;&gt;&lt;a href=&quot;#安装配置Keepalived&quot; class=&quot;headerlink&quot; title=&quot;安装配置Keepalived&quot;&gt;&lt;/a&gt;安装配置Keepalived&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;服务名称&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;角色&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;vip&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;10.108.72.112&lt;/td&gt;
&lt;td&gt;JDK1.7、elasticsearch-2.2.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Nignx1、Keepalived&lt;/td&gt;
&lt;td&gt;CentOS 6.5&lt;/td&gt;
&lt;td&gt;10.108.72.110&lt;/td&gt;
&lt;td&gt;Master&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Nignx2、Keepalived&lt;/td&gt;
&lt;td&gt;CentOS 6.5&lt;/td&gt;
&lt;td&gt;10.108.72.110&lt;/td&gt;
&lt;td&gt;Backup&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;Nginx安装&quot;&gt;&lt;a href=&quot;#Nginx安装&quot; class=&quot;headerlink&quot; title=&quot;Nginx安装&quot;&gt;&lt;/a&gt;Nginx安装&lt;/h3&gt;&lt;p&gt;关于Nginx的安装，参见前面的博客，这里不再赘述。&lt;/p&gt;
&lt;h3 id=&quot;安装Keepalived&quot;&gt;&lt;a href=&quot;#安装Keepalived&quot; class=&quot;headerlink&quot; title=&quot;安装Keepalived&quot;&gt;&lt;/a&gt;安装Keepalived&lt;/h3&gt;&lt;p&gt;可以rpm安装，也可以源码安装，我这里选择了源码安装。&lt;br&gt;将keepalived-1.2.15.tar.gz上传到/opt/soft目录下。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[nginx@master soft]# tar  -zxvf keepalived-1.2.15.tar.gz
[nginx @master soft]# ./configure --prefix=/opt/keepalived
[nginx @master soft]# make &amp;amp;&amp;amp; make install
[nginx @master soft]# cp /opt/keepalived/etc/rc.d/init.d/keepalived  /etc/rc.d/init.d/
[nginx @master soft]# cp /opt/keepalived/etc/sysconfig/keepalived  /etc/sysconfig/
[nginx @master soft]# mkdir /etc/keepalived
[nginx @master soft]# cp /opt/keepalived/etc/keepalived/keepalived.conf  /etc/keepalived/
[nginx @master soft]# cp /opt/keepalived/sbin/keepalived  /usr/sbin/
[nginx @master soft]#mkdir  /opt/keepalived/log
[nginx @master soft]#mkdir  /opt/keepalived/scripts
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;配置Keepalived&quot;&gt;&lt;a href=&quot;#配置Keepalived&quot; class=&quot;headerlink&quot; title=&quot;配置Keepalived&quot;&gt;&lt;/a&gt;配置Keepalived&lt;/h3&gt;&lt;p&gt;将提供的主、从keepalived.conf配置文件拷贝到/etc/keepalived目录下，参考配置文件中的配置项说明调整配置文件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.Master上的Keeplived配置文件，keepalived.conf&lt;/strong&gt;&lt;br&gt;    ! Configuration File for keepalived&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;global_defs {
        router_id LVS_DEVEL    
        #负载均衡器标识，同一网段内，可以相同
}

vrrp_script chk_nginx {    
        #调用定义的检测模块
        script &amp;quot;/opt/keepalived/scripts/check_nginx.sh&amp;quot;
        interval 2
        weight 2
}

vrrp_instance VI_1 {
    #设置为主
    state MASTER
    #监控网卡 
    interface eth0
    #主备服务器必须一样       
    virtual_router_id 51
    #权重值MASTER 一定要高于备用机器
    priority 101
    # MASTER与BACKUP负载均衡器之间同步检查的时间间隔，单位是秒     
    advert_int 1         

    track_script {
           chk_nginx
    }

    cast_src_ip  10.108.72.110

    unicast_peer {
        10.108.72.111
    }

    authentication {
         #加密
        auth_type PASS
        #加密密码，主备要一致       
        auth_pass fudan123  
    }
    virtual_ipaddress {
       #虚拟IP 
        10.108.72.112      
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.backup上的Keeplived配置文件，keepalived.conf&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;! Configuration File for keepalived

global_defs {
        #负载均衡器标识，同一网段内，可以相同
        router_id LVS_DEVEL
}

#调用定义的检测模块
vrrp_script chk_nginx {
       #检查脚本
        script &amp;quot;/etc/keepalived/scripts/check_nginx.sh&amp;quot;
        #检查时间间隔 
        interval 2
        weight 2
}

vrrp_instance VI_1 {
    #设置为备
    state BACKUP
    #监控网卡        
    interface eth0
    #主备服务器必须一样
    virtual_router_id 51
    #权重值 BACKUP 一定要低于 MASTER
    priority 100
    # MASTER与BACKUP负载均衡器之间同步检查的时间间隔，单位是秒   
    advert_int 1        

    track_script {
        chk_nginx
    }
    #多播的源IP，设置为本机IP
    cast_src_ip  10.108.72.111

    unicast_peer {
        10.108.72.110
    }
    authentication {
        auth_type PASS
        auth_pass fudan123
    }
    virtual_ipaddress {
        #虚拟IP
        10.108.72.112
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;Keepalived监控脚本&quot;&gt;&lt;a href=&quot;#Keepalived监控脚本&quot; class=&quot;headerlink&quot; title=&quot;Keepalived监控脚本&quot;&gt;&lt;/a&gt;Keepalived监控脚本&lt;/h3&gt;&lt;p&gt;将提供的keepalived监控脚本分别拷贝到主、从服务器的/opt/keepalived/scripts目录下，并将脚本设置为可执行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.Master机器的监控脚本&lt;/strong&gt;&lt;br&gt;check_nginx.sh&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#!/bin/bash&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;counter=$(ps -C nginx --no-heading|wc -l)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;if [ &amp;quot;$&amp;#123;counter&amp;#125;&amp;quot; = &amp;quot;0&amp;quot; ]; then&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        service nginx start&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        counter=$(ps -C nginx --no-heading|wc -l)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        if [ &amp;quot;$&amp;#123;counter&amp;#125;&amp;quot; = &amp;quot;0&amp;quot; ]; then&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         /etc/init.d/keepalived stop&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        fi&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;fi&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;2.Backup机器的监控脚本&lt;/strong&gt;&lt;br&gt;check_nginx.sh&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#!/bin/bash&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;counter=$(ps -C nginx --no-heading|wc -l)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;if [ &amp;quot;$&amp;#123;counter&amp;#125;&amp;quot; = &amp;quot;0&amp;quot; ]; then&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         service nginx start&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        counter=$(ps -C nginx --no-heading|wc -l)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        if [ &amp;quot;$&amp;#123;counter&amp;#125;&amp;quot; = &amp;quot;0&amp;quot; ]; then&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                /etc/init.d/keepalived stop&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        fi&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;fi&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;Keepalived启动、关闭&quot;&gt;&lt;a href=&quot;#Keepalived启动、关闭&quot; class=&quot;headerlink&quot; title=&quot;Keepalived启动、关闭&quot;&gt;&lt;/a&gt;Keepalived启动、关闭&lt;/h3&gt;&lt;p&gt;1.将Keepalived加入系统服务&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chkconfig  --add keepalived
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.设置为开机自启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chkconfig keepalived on
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.启动、关闭&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;service keepalived start/stop
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;测试Nginx高可用&quot;&gt;&lt;a href=&quot;#测试Nginx高可用&quot; class=&quot;headerlink&quot; title=&quot;测试Nginx高可用&quot;&gt;&lt;/a&gt;测试Nginx高可用&lt;/h3&gt;&lt;p&gt;1.在主服务器（10.108.72.110）测试与备服务器连接&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tcpdump -vvv  -i ens160 host  10.108.72.111
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.在备服务器（10.108.72.111）测试与主服务器连接&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tcpdump -vvv  -i ens160 host  10.108.72.110
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.先是两台都开启keepalived，然后通过VIP（10.108.72.112）访问；&lt;br&gt;4.再关掉第一台的keepalived，再通过VIP（10.108.72.112）访问，看看能否访问。&lt;/p&gt;
&lt;h3 id=&quot;查看VIP在哪台机器上&quot;&gt;&lt;a href=&quot;#查看VIP在哪台机器上&quot; class=&quot;headerlink&quot; title=&quot;查看VIP在哪台机器上&quot;&gt;&lt;/a&gt;查看VIP在哪台机器上&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;ip addr show
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;高可用集群介绍&quot;&gt;&lt;a href=&quot;#高可用集群介绍&quot; class=&quot;headerlink&quot; title=&quot;高可用集群介绍&quot;&gt;&lt;/a&gt;高可用集群介绍&lt;/h2&gt;&lt;p&gt;前面介绍的Nginx可以实现对后端服务的负载均衡，Nginx就是调度器。但是我们还要考虑一个，调度器本身在工作的时候仍然会有一个风险，因为我们把整个站点的请求的依赖性都建立在了调度器上，调度器坏了怎么办？
    
    </summary>
    
      <category term="Nginx" scheme="http://yoursite.com/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>Nginx配置HTTPS</title>
    <link href="http://yoursite.com/2018/01/30/Nginx%E9%85%8D%E7%BD%AEHTTPS/"/>
    <id>http://yoursite.com/2018/01/30/Nginx配置HTTPS/</id>
    <published>2018-01-30T04:24:12.000Z</published>
    <updated>2018-01-31T11:06:19.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;HTTPS简介&quot;&gt;&lt;a href=&quot;#HTTPS简介&quot; class=&quot;headerlink&quot; title=&quot;HTTPS简介&quot;&gt;&lt;/a&gt;HTTPS简介&lt;/h2&gt;&lt;p&gt;1.https简介&lt;br&gt;HTTPS其实是有两部分组成：HTTP + SSL / TLS，也就是在HTTP上又加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密后的数据。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2.https协议原理&lt;br&gt;首先，客户端与服务器建立连接，各自生成私钥和公钥，是不同的。服务器返给客户端一个公钥，然后客户端拿着这个公钥把要搜索的东西加密，称之为密文，并连并自己的公钥一起返回给服务器，服务器拿着自己的私钥解密密文，然后把响应到的数据用客户端的公钥加密，返回给客户端，客户端拿着自己的私钥解密密文，把数据呈现出来。&lt;/p&gt;
&lt;h3 id=&quot;TLS-SSL&quot;&gt;&lt;a href=&quot;#TLS-SSL&quot; class=&quot;headerlink&quot; title=&quot;TLS/SSL&quot;&gt;&lt;/a&gt;TLS/SSL&lt;/h3&gt;&lt;p&gt;TCP/IP的4层模型：最底层物理层、网络层、传输层、应用层。&lt;br&gt;OSI7层模型：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。&lt;br&gt;以TCP/IP层为例，哪一层可以实现数据的加密和解密？在TCP层和应用层之间引入了半个层，并且称这半个层位为SSL。可以这么理解，把SSL当成一个库，让上层应用层的某种协议如果在传输数据到TCP层之前调用了SSL的功能，那么这个协议就可以实现加密的功能了。比如说，本来http在应用层封装起来，接下来就要交给应用层了，但是加了SSL层，http在传送给TCP层之前经过SSL进行了一次封装，而SSL本身就是实现数据安全通信的，因此，http变成了https。同样，smtp就变成了smtps，ftp就变成了ftps。众多的应用层的协议都可以通过调用SSL库的功能来实现数据的安全传输的。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/13.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;SSL(Secure Socket Layer,，安全的套接字层)，目前比较流行的是SSLv2、SSLv3。它只是一个库，因此要想实现SSL的功能，只需要在我们系统中提供SSL相关的库文件，就能够将http封装成https，也就意味着可以支持https协议了。http和https是两个不同的协议。但是SSL到底是某一家公司的协议，虽然也是开放的，国际标准化组织就不干了，他们决定研发一个更为开放的，通用的协议，TLS就出现了。&lt;br&gt;TLS(Transport Layer Security，传输层安全)：TLSv1，相当于SSLv3。&lt;/p&gt;
&lt;h3 id=&quot;两台主机间TLS-SSL会话的建立：以http为例&quot;&gt;&lt;a href=&quot;#两台主机间TLS-SSL会话的建立：以http为例&quot; class=&quot;headerlink&quot; title=&quot;两台主机间TLS/SSL会话的建立：以http为例&quot;&gt;&lt;/a&gt;两台主机间TLS/SSL会话的建立：以http为例&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;第一步：http是基于TCP的，因此双方在建立会话之前需要3次握手。&lt;br&gt;这是http会话的建立，下面就可以互相通信了。但是有了https后就不是3次握手后直接通信了。&lt;/li&gt;
&lt;li&gt;第二步：双方协商。客户端向服务器端发起请求，双方协商建立SSL会话，比如选择SSL协议的哪个版本、密钥加密算法等等。&lt;/li&gt;
&lt;li&gt;第三步：server端将自己的证书发给客户端。(一般而言客户端都是没有证书的) 。客户端拿到证书后要验证拿到的证书是不是自己信任的机构颁发的，再验证证书完整性。&lt;/li&gt;
&lt;li&gt;第四步：客户端传递加密后的对称密码给服务器端。https的主要作用在于web服务器的数据传递或者称为会话交换通过加密的方式实现的。加密一定要使用对称加密的方式，非对称加密方式速度太慢，既然是对称加密了，就需要对称加密密钥。如何生成这个密码呢？这里不是密钥交换实现的，而是客户端选择生成一个随机的对称密钥。并且将这个密码通过server端的公钥加密后传递给server端。&lt;/li&gt;
&lt;li&gt;第五步：拿着客户端发来的密码给数据加密，并发送给客户端。&lt;br&gt;【注意】:密钥是客户端自己选择的，加密后发送给客户端的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;常用的加解密算法简介&quot;&gt;&lt;a href=&quot;#常用的加解密算法简介&quot; class=&quot;headerlink&quot; title=&quot;常用的加解密算法简介&quot;&gt;&lt;/a&gt;常用的加解密算法简介&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.对称加密：加密和解密使用同样的密码&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DES：数据加密标准，56位的密钥长度。&lt;/li&gt;
&lt;li&gt;3DES：3重DES。&lt;/li&gt;
&lt;li&gt;AES：高级加密标准，Advanced。使用128的密钥。AES192、AES256、AES512。。。&lt;/li&gt;
&lt;li&gt;Blowfish&lt;/li&gt;
&lt;li&gt;IDEA&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.单向加密&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MD4&lt;/li&gt;
&lt;li&gt;MD5:128位。指输出长度，不是密钥长度。&lt;/li&gt;
&lt;li&gt;SHA1:160位。SHA192、SHA256、SHA384&lt;/li&gt;
&lt;li&gt;CRC-32：循环冗余校验码。不是加密算法，只是一种校验码机制，提供校验功能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.公钥加密：&lt;/strong&gt;一对密钥，长度也是可以变化的，512、768、1024、2048、4096。。。越长速度越慢。核心：加密/签名。一般不会使用公钥加密来加密数据的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;身份认证（数字签名）&lt;/li&gt;
&lt;li&gt;数据加密&lt;/li&gt;
&lt;li&gt;密钥交换&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;RSA算法：既能实现加密，也能实现签名。有公开有要钱的。&lt;br&gt;DSA算法：只能实现签名。公开的。&lt;br&gt;ElGamal算法：商业算法，要钱的。&lt;/p&gt;
&lt;p&gt;加密解密需要算法来实现，因此需要一种工具或程序能够在主机上提供算法的实现。在Linux上，不同的加密机制所提供的工具是不同的。比如说，对于能够实现对称加密的工具叫openssl，gpg也可以。&lt;/p&gt;
&lt;h2 id=&quot;OpenSSL&quot;&gt;&lt;a href=&quot;#OpenSSL&quot; class=&quot;headerlink&quot; title=&quot;OpenSSL&quot;&gt;&lt;/a&gt;OpenSSL&lt;/h2&gt;&lt;p&gt;SSL的开源实现。OpenSSL功能非常强大，几乎实现了市面上主流的所有加密算法。OpenSSL是个软件，由3部分组成。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;libcrpto：通用加密库。提供了各种加密函数。&lt;/li&gt;
&lt;li&gt;libssl：TLS/SSL协议的实现。就是那半层。基于会话的、实现了身份认证、数据机密性、会话完整性的TLS/SSL库。&lt;/li&gt;
&lt;li&gt;openssl：多用途命令行工具。能够实现单向加密、对称加密和非对称加密。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OpenSSL还可实现私有证书颁发机构。为什么要实现私有证书颁发机构？我们很多功能都是建立在证书上，假如说我们买不起证书，我们就想在公司内部实现加密解密，而且我们也不跟外人通信。因此就需要个私有的证书颁发机构。&lt;/p&gt;
&lt;p&gt;查看系统上有没有安装openssl：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rpm -q openssl   
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果需要新版本，去 &lt;a href=&quot;http://www.openssl.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.openssl.org/&lt;/a&gt; 下载编译安装。&lt;br&gt;下面开始建立私有CA，颁发证书，配置Nginx实现HTTPS访问网站。&lt;/p&gt;
&lt;h2 id=&quot;OpenSSL实现私有CA&quot;&gt;&lt;a href=&quot;#OpenSSL实现私有CA&quot; class=&quot;headerlink&quot; title=&quot;OpenSSL实现私有CA&quot;&gt;&lt;/a&gt;OpenSSL实现私有CA&lt;/h2&gt;&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;res&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.7.75&lt;/td&gt;
&lt;td&gt;openssl&lt;/td&gt;
&lt;td&gt;私有CA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;res&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.7.180&lt;/td&gt;
&lt;td&gt;openresty&lt;/td&gt;
&lt;td&gt;Nginx服务器&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;比如在公司内部模拟实现https，就得给web服务器发一个证书，不用去买，自己做一个。在给自己颁发证书之前，自己先建立一个证书颁发机构。Openssl可以帮你去实现私有CA。首先私有CA自己要有证书。&lt;/p&gt;
&lt;h3 id=&quot;创建私有CA&quot;&gt;&lt;a href=&quot;#创建私有CA&quot; class=&quot;headerlink&quot; title=&quot;创建私有CA&quot;&gt;&lt;/a&gt;创建私有CA&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.生成一对密钥&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@res ~]# cd /etc/pki/CA/ 
[root@res CA]# openssl genrsa -out private/cakey.pem 2048
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/14.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.生成自签发证书&lt;/strong&gt;&lt;br&gt;CA机构也有自己的证书的&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@res CA]# openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3655
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/15.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.要想把它扮演成私有CA来使用，还要修改openssl.cnf，新建几个需要的文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@res CA]# cd /etc/pki/tls/
[root@res tls]# vim openssl.cnf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/16.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/17.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.生成几个必备的文件和目录&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@res tls]# cd /etc/pki/CA/
[root@res CA]# mkdir certs crl newcerts
[root@res CA]# touch index.txt
[root@res CA]# echo 01 &amp;gt; serial
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上是CA的环境准备和密钥生成以及自签证书的过程。别的主机可以到这个CA申请证书。比如说Nginx服务器过来申请证书。&lt;/p&gt;
&lt;h3 id=&quot;Nginx服务器申请证书&quot;&gt;&lt;a href=&quot;#Nginx服务器申请证书&quot; class=&quot;headerlink&quot; title=&quot;Nginx服务器申请证书&quot;&gt;&lt;/a&gt;Nginx服务器申请证书&lt;/h3&gt;&lt;p&gt;以下操作都是在172.16.7.180机器上操作。&lt;br&gt;任何一个应用要想用到证书，它必须要有私钥，因为必须从私钥中提取出公钥，每一种应用都必须有自己的证书。第一步：生成私钥。【注意】：如果生成的密钥长度不合适，可以重新生成导出到同一个文件中就覆盖了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.生成一对密钥&lt;/strong&gt;&lt;br&gt;这里我在生成时对密钥进行了加密&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@res ~]# mkdir /opt/ssl/
[root@res ~]# cd /opt/ssl/
[root@res ssl]# (umask 077; openssl genrsa 2048 &amp;gt; res.key)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/18.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.生成证书签署请求&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@res ssl]# openssl req -new -key res.key -out res.csr
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/19.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Commone Name一定要是你要授予证书的服务器域名或主机名。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.把证书签署请求送给CA机构，CA生成证书&lt;/strong&gt;&lt;br&gt;【注意】:这个请求要发给CA才可以，要让CA去签名才有效。当然在一台主机上就不用了，直接签了。如果不在一台主机上，要发给服务器的，远程传过去。可以传到CA机器的/tmp目录下。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;登录上CA机器172.16.7.75：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@res CA]# cd /etc/pki/tls/
[root@res tls]# openssl ca -in /tmp/res.csr -out /tmp/res.crt -days 3650
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/20.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.CA机构将证书返回给申请单位，这里即172.16.7.180机器，我将证书放到/opt/ssl目录下&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;配置Nginx&quot;&gt;&lt;a href=&quot;#配置Nginx&quot; class=&quot;headerlink&quot; title=&quot;配置Nginx&quot;&gt;&lt;/a&gt;配置Nginx&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.配置Nginx支持http和https共存&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/21.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.如果只需要https，禁止http，配置如下：&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/22.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.配置http强制转https&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
    listen       80;
    server_name  static.res.com;

    rewrite ^(.*)$  https://$host$1 permanent;

}

server {
    listen       443 ssl;
    server_name  static.res.com;

    ssl on;
    #证书和私钥
    ssl_certificate /opt/ssl/res.crt;
    ssl_certificate_key /opt/ssl/res.key;


    access_log  logs/res.access.log  res;
    ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【注意】：我这里这个域名是假的，所以需要在客户端（你用哪个机器访问网站，哪台机器就是客户端）编辑hosts文件，配置如下的解析：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;172.16.7.180 static.res.com
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;HTTPS简介&quot;&gt;&lt;a href=&quot;#HTTPS简介&quot; class=&quot;headerlink&quot; title=&quot;HTTPS简介&quot;&gt;&lt;/a&gt;HTTPS简介&lt;/h2&gt;&lt;p&gt;1.https简介&lt;br&gt;HTTPS其实是有两部分组成：HTTP + SSL / TLS，也就是在HTTP上又加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密后的数据。
    
    </summary>
    
      <category term="Nginx" scheme="http://yoursite.com/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>Nginx实现TCP负载均衡</title>
    <link href="http://yoursite.com/2018/01/28/Nginx%E5%AE%9E%E7%8E%B0TCP%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>http://yoursite.com/2018/01/28/Nginx实现TCP负载均衡/</id>
    <published>2018-01-28T01:45:57.000Z</published>
    <updated>2018-01-28T02:35:15.000Z</updated>
    
    <content type="html">&lt;blockquote&gt;
&lt;p&gt;nginx在版本1.9.0以后支持tcp的负载均衡，具体可以参照官网关于模块&lt;a href=&quot;https://nginx.org/en/docs/stream/ngx_stream_core_module.html#tcp_nodelay&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ngx_stream_core_module&lt;/a&gt;的说明。一直以来，Nginx 并不支持tcp协议，所以后台的一些基于TCP的业务就只能通过其他高可用负载软件来完成了，比如Haproxy或者LVS。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;编译Nginx启用ngx-stream-core-module模块&quot;&gt;&lt;a href=&quot;#编译Nginx启用ngx-stream-core-module模块&quot; class=&quot;headerlink&quot; title=&quot;编译Nginx启用ngx_stream_core_module模块&quot;&gt;&lt;/a&gt;编译Nginx启用ngx_stream_core_module模块&lt;/h2&gt;&lt;p&gt;ngx_stream_core_module 这个模块在1.90版本后将被启用。但是并不会默认安装，需要在编译时通过指定 –with-stream 参数来激活这个模块。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr/local/
# wget https://nginx.org/download/nginx-1.12.2.tar.gz
# tar zxf nginx-1.12.2.tar.gz
# cd nginx-1.12.2/
# ./configure --prefix=/usr/local/nginx --with-stream
# make &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;配置Nginx负载均衡MySQL&quot;&gt;&lt;a href=&quot;#配置Nginx负载均衡MySQL&quot; class=&quot;headerlink&quot; title=&quot;配置Nginx负载均衡MySQL&quot;&gt;&lt;/a&gt;配置Nginx负载均衡MySQL&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;# cd /usr/local/nginx/conf/
# vim nginx.conf
#user  nobody;
worker_processes  1;

error_log  logs/error.log debug;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

#pid        logs/nginx.pid;

events {
    worker_connections  1024;
}

stream {
    upstream mysql {
        server 172.16.206.30:3306;
    }
    server {
        listen 3306;
        proxy_connect_timeout 8s;
        proxy_timeout 24h;
        proxy_pass mysql;
    }
}

http {
    include       mime.types;
    default_type  application/octet-stream;

    log_format  main  &amp;apos;$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; &amp;apos;
                  &amp;apos;$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; &amp;apos;
                  &amp;apos;&amp;quot;$http_user_agent&amp;quot; &amp;quot;$http_x_forwarded_for&amp;quot;&amp;apos;;

    #access_log  logs/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    gzip  on;

    server {
        listen       80;
        server_name  localhost;

        #charset koi8-r;

        #access_log  logs/access.log  main;

        location / {
            root   html;
            index  index.html index.htm;
        }

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }

    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;stream与http同级别。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;nginx在版本1.9.0以后支持tcp的负载均衡，具体可以参照官网关于模块&lt;a href=&quot;https://nginx.org/en/docs/stream/ngx_stream_core_module.html#tcp_nodelay&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ngx_stream_core_module&lt;/a&gt;的说明。一直以来，Nginx 并不支持tcp协议，所以后台的一些基于TCP的业务就只能通过其他高可用负载软件来完成了，比如Haproxy或者LVS。
    
    </summary>
    
      <category term="Nginx" scheme="http://yoursite.com/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>Nginx配置详解及优化</title>
    <link href="http://yoursite.com/2018/01/23/Nginx%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%E5%8F%8A%E4%BC%98%E5%8C%96/"/>
    <id>http://yoursite.com/2018/01/23/Nginx配置详解及优化/</id>
    <published>2018-01-23T07:06:27.000Z</published>
    <updated>2018-01-27T13:21:04.000Z</updated>
    
    <content type="html">&lt;blockquote&gt;
&lt;p&gt;上篇博文中介绍了安装部署OpenResty，这篇博文主要记录下Nginx的配置及优化。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Nginx&quot;&gt;&lt;a href=&quot;#Nginx&quot; class=&quot;headerlink&quot; title=&quot;Nginx&quot;&gt;&lt;/a&gt;Nginx&lt;/h2&gt;&lt;p&gt;Nginx的代码是由一个核心和一系列的模块组成, 核心主要用于提供Web Server的基本功能，以及Web和Mail反向代理的功能；&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;还用于启用网络协议，创建必要的运行时环境以及确保不同的模块之间平滑地进行交互。不过，大多跟协议相关的功能和某应用特有的功能都是由nginx的模块实现的。这些功能模块大致可以分为事件模块、阶段性处理器、输出过滤器、变量处理器、协议、upstream和负载均衡几个类别，这些共同组成了nginx的http功能。事件模块主要用于提供OS独立的(不同操作系统的事件机制有所不同)事件通知机制如kqueue或epoll等。协议模块则负责实现nginx通过http、tls/ssl、smtp、pop3以及imap与对应的客户端建立会话。&lt;/p&gt;
&lt;p&gt;Nginx的核心模块为Main和Events，此外还包括标准HTTP模块、可选HTTP模块和邮件模块，其还可以支持诸多第三方模块。Main用于配置错误日志、进程及权限等相关的参数，Events用于配置IO模型，如epoll、kqueue、select或poll等，它们是必备模块。&lt;/p&gt;
&lt;p&gt;Nginx的主配置文件由几个段组成，这个段通常也被称为nginx的上下文，每个段的定义格式如下所示。需要注意的是，其每一个指令都必须使用分号(;)结束，否则为语法错误。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;section&amp;gt; {
    &amp;lt;directive&amp;gt; &amp;lt;parameters&amp;gt;;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;配置文件有哪些&quot;&gt;&lt;a href=&quot;#配置文件有哪些&quot; class=&quot;headerlink&quot; title=&quot;配置文件有哪些&quot;&gt;&lt;/a&gt;配置文件有哪些&lt;/h2&gt;&lt;p&gt;1.主配置文件：nginx.conf&lt;br&gt;2.可以使用include指令引入其他地方的配置文件，比如&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;include conf.d/*.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.fastcgi的配置文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fastcgi_params、uwsgi_params
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.配置指令(必须以分号结尾)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Directive  value1 [value2...];

支持使用变量：
    内置变量：由模块引入；
    自定义变量：
        set  variable  value; 

    引用变量：$variable
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;配置文件组织结构&quot;&gt;&lt;a href=&quot;#配置文件组织结构&quot; class=&quot;headerlink&quot; title=&quot;配置文件组织结构&quot;&gt;&lt;/a&gt;配置文件组织结构&lt;/h2&gt;&lt;p&gt;主配置文件结构：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;main block
event {
    ...
}
http {
    ...
    server{
        location{  
            ...          
        }           
    }
}
mail{
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;配置main段&quot;&gt;&lt;a href=&quot;#配置main段&quot; class=&quot;headerlink&quot; title=&quot;配置main段&quot;&gt;&lt;/a&gt;配置main段&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.user USERNAME  [GROUPNAME];&lt;/strong&gt;&lt;br&gt;指定用于运行worker进程的用户和组，如果不设置，默认是nobody。比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;user  nginx  nginx;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.pid  /PATH/TO/PID_FILE;&lt;/strong&gt;&lt;br&gt;指定nginx进程的pid文件路径，也可以使用默认的。比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pid  /var/run/nginx.pid;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3.error_log&lt;/strong&gt;&lt;br&gt;用于配置错误日志，可用于main、http、server及location上下文中；语法格式为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;error_log file | stderr [ debug | info | notice | warn | error | crit | alert | emerg ]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;error_log  logs/error.log debug;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;4.worker_processes&lt;/strong&gt;&lt;br&gt;worker进程是单线程进程。如果Nginx用于CPU密集型的场景中，如SSL或gzip，且主机上的CPU个数至少有2个，那么应该将此参数值设定为与CPU核心数相同；如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。比如：Nginx所在服务器有2颗CPU，每颗两核，那么可以配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;worker_processes  4; #启动的work线程数
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此参数与Events上下文中的work_connections变量一起决定了maxclient的值：&lt;br&gt;maxclients = work_processes * work_connections&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.worker_cpu_affinity&lt;/strong&gt;&lt;br&gt;通过sched_setaffinity()将worker绑定至CPU上，只能用于main上下文。语法格式为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;worker_cpu_affinity cpumask ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;worker_processes     4;
worker_cpu_affinity 0001 0010 0100 1000;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;6.worker_priority&lt;/strong&gt;&lt;br&gt;为worker进程设定优先级(指定nice值)，此参数只能用于main上下文中，默认为0；语法格式为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;worker_priority number
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;7.worker_rlimit_nofile&lt;/strong&gt;&lt;br&gt;设定worker进程所能够打开的文件描述符个数的最大值。语法格式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;worker_rlimit_nofile number
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;配置Events段&quot;&gt;&lt;a href=&quot;#配置Events段&quot; class=&quot;headerlink&quot; title=&quot;配置Events段&quot;&gt;&lt;/a&gt;配置Events段&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.worker_connections&lt;/strong&gt;&lt;br&gt;设定每个worker所处理的最大连接数，它与来自main上下文的worker_processes一起决定了maxclients的值。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;max clients = worker_processes * worker_connections
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.use&lt;/strong&gt;&lt;br&gt;在有着多于一个的事件模型IO的应用场景中，可以使用此指令设定nginx所使用的IO机制，默认为./configure脚本选定的各机制中最适用当前OS的版本。语法格式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;use [ kqueue | rtsig | epoll | /dev/poll | select | poll | eventport ]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;一个配置示例&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;user nginx;
# the load is CPU-bound and we have 16 cores
worker_processes 16;
error_log logs/error.log debug;
pid logs/nginx.pid;

events {
    use epoll;
    worker_connections 2048;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;配置http段&quot;&gt;&lt;a href=&quot;#配置http段&quot; class=&quot;headerlink&quot; title=&quot;配置http段&quot;&gt;&lt;/a&gt;配置http段&lt;/h2&gt;&lt;p&gt;http上下文专用于配置用于http的各模块，此类指令非常的多，每个模块都有其专用指定，具体请参数&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_core_module.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;nginx官方文档关于模块部分的说明&lt;/a&gt;。大体上来讲，这些模块所提供的配置指令还可以分为如下几个类别。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端类指令：如client_body_buffer_size、client_header_buffer_size、client_header_timeout和keepalive_timeout等；&lt;/li&gt;
&lt;li&gt;文件IO类指令：如aio、directio、open_file_cache、open_file_cache_min_uses、open_file_cache_valid和sendfile等；&lt;/li&gt;
&lt;li&gt;hash类指令：用于定义Nginx为某特定的变量分配多大的内存空间，如types_hash_bucket_size、server_names_hash_bucket_size和variables_hash_bucket_size等；&lt;/li&gt;
&lt;li&gt;套接字类指令：用于定义Nginx如何处理tcp套接字相关的功能，如tcp_nodelay(用于keepalive功能启用时)和tcp_nopush(用于sendfile启用时)等；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;套接字或主机相关配置&quot;&gt;&lt;a href=&quot;#套接字或主机相关配置&quot; class=&quot;headerlink&quot; title=&quot;套接字或主机相关配置&quot;&gt;&lt;/a&gt;套接字或主机相关配置&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;server {
    &amp;lt;directive&amp;gt; &amp;lt;parameters&amp;gt;;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;用于定义虚拟主机相关的属性。比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
    listen PORT; #listen指令监听在不同的端口；
    server_name NAME; #server_name指令指向不同的主机名；
    root /PATH/TO/DOCUMENTROOT;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;1.listen&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;listen address[:port] [default_server] [ssl] [http2 | spdy] 
listen port [default_server] [ssl] [http2 | spdy]
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;default_server：设置默认虚拟主机；用于基于IP地址，或使用了任意不能对应于任何一个server的name时所返回站点；&lt;/li&gt;
&lt;li&gt;ssl：用于限制只能通过ssl连接提供服务；&lt;/li&gt;
&lt;li&gt;spdy：SPDY protocol（speedy），在编译了spdy模块的情况下，用于支持SPDY协议；&lt;/li&gt;
&lt;li&gt;http2：http version 2；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.server_name NAME […];&lt;/strong&gt;&lt;br&gt;后可跟一个或多个主机名；名称还可以使用通配符和正则表达式(~)；&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先做精确匹配；例如：www.wisedu.com&lt;/li&gt;
&lt;li&gt;左侧通配符；例如：*.wisedu.com&lt;/li&gt;
&lt;li&gt;右侧通配符，例如：www.wisedu.*&lt;/li&gt;
&lt;li&gt;正则表达式，例如：~^.*.wisedu.com$&lt;/li&gt;
&lt;li&gt;default_server &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.tcp_nodelay on|off;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Syntax:    tcp_nodelay on | off;
Default:    tcp_nodelay on;
Context:    http, server, location
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;对keepalive模式下的连接是否使用TCP_NODELAY选项；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.tcp_nopush on|off;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Syntax:    tcp_nopush on | off;
Default:    tcp_nopush off;
Context:    http, server, location
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;是否启用TCP_NOPUSH(FREEBSE）或TCP_CORK(Linux)选项；仅在sendfile为on时有用；&lt;br&gt;&lt;strong&gt;tcp_nopush和tcp_nodelay选项：&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;先来了解下Nagle算法：&lt;/strong&gt;&lt;br&gt;在网络拥塞控制领域，有一个非常有名的算法叫做&lt;strong&gt;Nagle算法（Nagle algorithm）&lt;/strong&gt;，这是使用它的发明人John Nagle的名字来命名的，John Nagle在1984年首次用这个算法来尝试解决福特汽车公司的网络拥塞问题（RFC 896），该问题的具体描述是：如果我们的应用程序一次产生1个字节的数据，而这个1个字节数据又以网络数据包的形式发送到远端服务器，那么就很容易导致网络由于太多的数据包而过载。比如，当用户使用Telnet连接到远程服务器时，每一次击键操作就会产生1个字节数据，进而发送出去一个数据包，所以，在典型情况下，传送一个只拥有1个字节有效数据的数据包，却要发费40个字节长包头（即ip头20字节+tcp头20字节）的额外开销，这种有效载荷（payload）利用率极其低下的情况被统称之为愚蠢窗口症候群（Silly Window Syndrome）。可以看到，这种情况对于轻负载的网络来说，可能还可以接受，但是对于重负载的网络而言，就极有可能承载不了而轻易的发生拥塞瘫痪。&lt;br&gt;针对上面提到的这个状况，Nagle算法的改进在于：如果发送端欲多次发送包含少量字符的数据包（一般情况下，后面统一称长度小于MSS的数据包为小包，与此相对，称长度等于MSS的数据包为大包，为了某些对比说明，还有中包，即长度比小包长，但又不足一个MSS的包），则发送端会先将第一个小包发送出去，而将后面到达的少量字符数据都缓存起来而不立即发送，直到收到接收端对前一个数据包报文段的ACK确认、或当前字符属于紧急数据，或者积攒到了一定数量的数据（比如缓存的字符数据已经达到数据包报文段的最大长度）等多种情况才将其组成一个较大的数据包发送出去。&lt;br&gt;TCP中的Nagle算法默认是启用的，但是它并不是适合任何情况，对于telnet或rlogin这样的远程登录应用的确比较适合（原本就是为此而设计），但是在某些应用场景下我们却又需要关闭它。&lt;br&gt;Nagle算法是指发送方发送的数据不会立即发出, 而是先放在缓冲区, 等缓存区满了再发出。发送完一批数据后, 会等待接收方对这批数据的回应, 然后再发送下一批数据。Negale 算法适用于发送方需要发送大批量数据, 并且接收方会及时作出回应的场合, 这种算法通过减少传输数据的次数来提高通信效率。如果发送方持续地发送小批量的数据, 并且接收方不一定会立即发送响应数据, 那么Negale算法会使发送方运行很慢. 对于GUI 程序, 如网络游戏程序(服务器需要实时跟踪客户端鼠标的移动), 这个问题尤其突出。客户端鼠标位置改动的信息需要实时发送到服务器上, 由于Negale 算法采用缓冲, 大大减低了实时响应速度, 导致客户程序运行很慢。这个时候就需要使用TCP_NODELAY选项。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;tcp_nopush&lt;/strong&gt;&lt;br&gt;官方:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tcp_nopush
Syntax: tcp_nopush on | off
Default: off
Context: http, server, location
Reference: tcp_nopush

This directive permits or forbids the use of thesocket options TCP_NOPUSH on FreeBSD or TCP_CORK on Linux. This option is onlyavailable when using sendfile.
Setting this option causes nginx to attempt to sendit’s HTTP response headers in one packet on Linux and FreeBSD 4.x
You can read more about the TCP_NOPUSH and TCP_CORKsocket options here.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;linux 下是tcp_cork，上面的意思就是说，当使用sendfile函数时，tcp_nopush才起作用，它和指令tcp_nodelay是互斥的。tcp_cork是linux下tcp/ip传输的一个标准了，这个标准的大概的意思是，一般情况下，在tcp交互的过程中，当应用程序接收到数据包后马上传送出去，不等待，而tcp_cork选项是数据包不会马上传送出去，等到数据包最大时，一次性的传输出去，这样有助于解决网络堵塞。&lt;br&gt;也就是说tcp_nopush = on 会设置调用tcp_cork方法，这个也是默认的，结果就是数据包不会马上传送出去，等到数据包最大时，一次性的传输出去，这样有助于解决网络堵塞。&lt;br&gt;以快递投递举例说明一下（以下是我的理解，也许是不正确的），当快递东西时，快递员收到一个包裹，马上投递，这样保证了即时性，但是会耗费大量的人力物力，在网络上表现就是会引起网络堵塞，而当快递收到一个包裹，把包裹放到集散地，等一定数量后统一投递，这样就是tcp_cork的选项干的事情，这样的话，会最大化的利用网络资源，虽然有一点点延迟。&lt;br&gt;对于nginx配置文件中的tcp_nopush，tcp_nopush on;这个选项对于www，ftp等大文件很有帮助。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;tcp_nodelay&lt;/strong&gt;&lt;br&gt;TCP_NODELAY和TCP_CORK基本上控制了包的“Nagle化”，Nagle化在这里的含义是采用Nagle算法把较小的包组装为更大的帧。 John Nagle是Nagle算法的发明人，后者就是用他的名字来命名的，他在1984年首次用这种方法来尝试解决福特汽车公司的网络拥塞问题（欲了解详情请参看IETF RFC 896）。他解决的问题就是所谓的silly window syndrome，中文称“愚蠢窗口症候群”，具体含义是，因为普遍终端应用程序每产生一次击键操作就会发送一个包，而典型情况下一个包会拥有一个字节的数据载荷以及40个字节长的包头，于是产生4000%的过载，很轻易地就能令网络发生拥塞,。 Nagle化后来成了一种标准并且立即在因特网上得以实现。它现在已经成为缺省配置了，但在我们看来，有些场合下把这一选项关掉也是合乎需要的。&lt;br&gt;现在让我们假设某个应用程序发出了一个请求，希望发送小块数据。我们可以选择立即发送数据或者等待产生更多的数据然后再一次发送两种策略。如果我们马上发送数据，那么交互性的以及客户/服务器型的应用程序将极大地受益。如果请求立即发出那么响应时间也会快一些。以上操作可以通过设置套接字的TCP_NODELAY = on 选项来完成，这样就禁用了Nagle 算法。&lt;br&gt;另外一种情况则需要我们等到数据量达到最大时才通过网络一次发送全部数据，这种数据传输方式有益于大量数据的通信性能，典型的应用就是文件服务器。应用 Nagle算法在这种情况下就会产生问题。但是，如果你正在发送大量数据，你可以设置TCP_CORK选项禁用Nagle化，其方式正好同 TCP_NODELAY相反（TCP_CORK和 TCP_NODELAY是互相排斥的）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.sendfile on|off;&lt;/strong&gt;&lt;br&gt;是否启用sendfile功能；&lt;br&gt;先来看下nginx作为web服务器的工作方式：&lt;br&gt;用户请求进来了，先到达网卡，由内核处理下交给了监听在80套接字上的应用程序，即交给worker进程，这个worker进程通过连接建立、通过接入分析发现用户请求的是一个静态页面，下面就是I/O了。首先进程向内核发出系统调用。内核为它准备一个缓冲，然后内核从磁盘中加载这个文件到缓冲中，然后将这个文件复制给worker进程自己的地址空间，然后进程将这个文件封装成响应报文，这个封装过程是，进程封装http请求首部，然后交给内核封装TCP首部、IP首部，然后交给客户端。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/10.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;然后你会发现这个文件是这么走的：从硬盘到内核空间，从内核到用户空间，从用户空间再到内核空间，白白绕一圈。如果说这个请求直接在内核中就封装好(http请求首部封装其实也是在内核封装的)，这样就避免了两次复制(注意是复制，内核任何时候和进程交互都是复制，除非共享内存)。复制虽然时间短，但是架不住多啊。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/11.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这就是sendfile机制，读过来就响应了。send只支持很小的文件，sendfile64支持更大的文件。&lt;br&gt;现在流行的web 服务器里面都提供 sendfile 选项用来提高服务器性能，那到底 sendfile是什么，怎么影响性能的呢？&lt;br&gt;sendfile实际上是 Linux2.0+以后的推出的一个系统调用，web服务器可以通过调整自身的配置来决定是否利用sendfile这个系统调用。先来看一下不用 sendfile的传统网络传输过程：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;read(file,tmp_buf, len);
write(socket,tmp_buf, len);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;硬盘 &amp;gt;&amp;gt; kernel buffer &amp;gt;&amp;gt; user buffer&amp;gt;&amp;gt; kernel socket buffer &amp;gt;&amp;gt;协议栈&lt;br&gt;一般来说一个网络应用是通过读硬盘数据，然后写数据到socket 来完成网络传输的。上面2行用代码解释了这一点，不过上面2行简单的代码掩盖了底层的很多操作。来看看底层是怎么执行上面2行代码的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;①系统调用 read()产生一个上下文切换：从 user mode 切换到 kernel mode，然后 DMA 执行拷贝，把文件数据从硬盘读到一个 kernel buffer 里。&lt;/li&gt;
&lt;li&gt;②数据从 kernel buffer拷贝到 user buffer，然后系统调用 read() 返回，这时又产生一个上下文切换：从kernel mode 切换到 user mode。&lt;/li&gt;
&lt;li&gt;③系统调用write()产生一个上下文切换：从 user mode切换到 kernel mode，然后把步骤2读到 user buffer的数据拷贝到 kernel buffer（数据第2次拷贝到 kernel buffer），不过这次是个不同的 kernel buffer，这个 buffer和 socket相关联。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;④系统调用 write()返回，产生一个上下文切换：从 kernel mode 切换到 user mode（第4次切换了），然后 DMA 从 kernel buffer拷贝数据到协议栈（第4次拷贝了）。&lt;br&gt;上面4个步骤有4次上下文切换，有4次拷贝，我们发现如果能减少切换次数和拷贝次数将会有效提升性能。在kernel2.0+ 版本中，系统调用 sendfile() 就是用来简化上面步骤提升性能的。sendfile() 不但能减少切换次数而且还能减少拷贝次数。&lt;br&gt;再来看一下用 sendfile() 来进行网络传输的过程：&lt;/p&gt;
&lt;p&gt;  sendfile(socket,file, len);&lt;br&gt;  硬盘 &amp;gt;&amp;gt; kernel buffer (快速拷贝到kernel socket buffer) &amp;gt;&amp;gt;协议栈&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;①系统调用sendfile()通过 DMA把硬盘数据拷贝到 kernel buffer，然后数据被 kernel直接拷贝到另外一个与 socket相关的 kernel buffer。这里没有 user mode和 kernel mode之间的切换，在 kernel中直接完成了从一个 buffer到另一个buffer的拷贝。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;②DMA 把数据从 kernelbuffer 直接拷贝给协议栈，没有切换，也不需要数据从 user mode 拷贝到 kernel mode，因为数据就在 kernel 里。&lt;br&gt;步骤减少了，切换减少了，拷贝减少了，自然性能就提升了。这就是为什么说在 Nginx 配置文件里打开 sendfile on 选项能提高 web server性能的原因。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/12.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;4.gzip  on;&lt;/strong&gt;&lt;br&gt;对于响应用户的内容是不是先压缩再发送，可以节省带宽。如果网络带宽小，用户访问量大的话可以使用这种方式。&lt;/p&gt;
&lt;h3 id=&quot;路径相关的指令&quot;&gt;&lt;a href=&quot;#路径相关的指令&quot; class=&quot;headerlink&quot; title=&quot;路径相关的指令&quot;&gt;&lt;/a&gt;路径相关的指令&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.root&lt;/strong&gt;&lt;br&gt;设置web资源的路径映射；用于指明请求的URL所对应的文档的目录路径；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
    ...
    root  /data/www/vhost1;
}
http://www.wisedu.com/images/logo.jpg --&amp;gt; /data/www/vhosts/images/logo.jpg

server {
    ...
    server_name  www.wisedu.com;

    location /images/ {
         root  /data/imgs/;
         ...
    }
}
http://www.wisedu.com/images/logo.jpg --&amp;gt; /data/imgs/images/logo.jpg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.location [ = | ~ | ~* | ^~ ] uri { … }&lt;br&gt;  location @name { … }&lt;/strong&gt;&lt;br&gt;功能：允许根据用户请求的URI来匹配定义的各location，匹配到时，此请求将被相应的location块中的配置所处理；简言之，即用于为需要用到专用配置的uri提供特定配置。&lt;br&gt;&lt;strong&gt;先来看下location [ = | ~ | ~* | ^~ ] uri { … } &lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;location URI{}：对当前路径及所有对象都生效。&lt;/li&gt;
&lt;li&gt;location = URI{}：只对当前路径生效，不包括子路径。这是精确匹配。&lt;/li&gt;
&lt;li&gt;location ~ URI{}：&lt;/li&gt;
&lt;li&gt;location ~&lt;em&gt; URI{}：模式匹配URI，此处的URI可使用正则表达式，~区分字符大小写。~&lt;/em&gt;不区分字符大小写。&lt;/li&gt;
&lt;li&gt;location ^~ URI{}：明确说明不使用正则表达式。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;【注意】：如果被两个location匹配到，nginx是有优先级的。=优先级最高，^~优先级第二，模式匹配优先级第三，没加任何符号的优先级最低。&lt;br&gt;官方例子：&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_core_module.html#location&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://nginx.org/en/docs/http/ngx_http_core_module.html#location&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location = / {
    [ configuration A ]
}

location / {
    [ configuration B ]
}

location /documents/ {
    [ configuration C ]
}

location ^~ /images/ {
    [ configuration D ]
}

location ~* \.(gif|jpg|jpeg)$ {
    [ configuration E ]
}
The “/” request will match configuration A, the “/index.html” request will match configuration B, the “/documents/document.html” request will match configuration C, the “/images/1.gif” request will match configuration D, and the “/documents/1.jpg” request will match configuration E.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;补充一个，&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location / {
    [ configuration A ]
}
location /abc {
    [ configuration B ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;访问 &lt;a href=&quot;http://ip:port/abc&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ip:port/abc&lt;/a&gt; 将被 location /abc 匹配到。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;再来看下location @name { … }，命名的location&lt;/strong&gt;&lt;br&gt;The “@” prefix defines a named location. Such a location is not used for a regular request processing, but instead used for request redirection. They cannot be nested, and cannot contain nested locations.&lt;br&gt;@：内部服务跳转&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
  location /img/ {
    set $memcached_key $uri;
    memcached_pass     name:11211;
    default_type       text/html;
    error_page         404 @fallback; #以 /img/ 开头的请求，如果连接的状态为 404。则会匹配到 @fallback 这条规则上。
  }

  location @fallback {
    proxy_pass http://backend;
  } 
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3.alias&lt;/strong&gt;&lt;br&gt;定义路径别名。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location  /images/ {
    root /data/imgs/;
}

location  /images/  {
    alias /data/imgs/;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;访问/images/test.jpg，对应的结果如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;root指令：给定的路径对应于location的“/”这个URL；&lt;br&gt;/images/test.jpg –&amp;gt;  /data/imgs/images/test.jpg &lt;/li&gt;
&lt;li&gt;alias指令：给定的路径对应于location的“/uri/“这个URL；&lt;br&gt;/images/test.jpg –&amp;gt;  /data/imgs/test.jpg，注意alias把location后配置的路径images丢弃掉了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;【注意】：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用alias时，目录名后面一定要加”/“。&lt;/li&gt;
&lt;li&gt;alias在使用正则匹配时，必须捕捉要匹配的内容并在指定的内容处使用。&lt;/li&gt;
&lt;li&gt;alias只能位于location块中。（root可以不放在location中）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;4.index&lt;/strong&gt; &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;index file ...;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;设置默认主页面。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.error_page code … [=[response]] uri;&lt;/strong&gt;&lt;br&gt;根据http的状态码重定向错误页面；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;error_page  404  /404.html
error_page  404  =200  /404.html  （以指定的响应状态码进行响应）
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;6.try_files file … uri;&lt;br&gt;  try_files file … =code;&lt;/strong&gt;&lt;br&gt;其作用是按顺序检查文件是否存在，尝试查找第1至第N-1个文件，返回第一个找到的文件或文件夹（结尾加斜线表示为文件夹），如果所有的文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。（必须不能匹配至当前location，而应该匹配至其它location，否则会导致死循环）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location / {
    try_files $uri $uri/ @fallback; # $uri为Nginx内置变量，下面会讲到。
    root   /home/data/FS/desgin_style/;
}

location @fallback {
    proxy_pass_header Server;
    proxy_set_header Host $http_host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Scheme $scheme;

    proxy_pass http://backend;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;客户端请求相关的配置&quot;&gt;&lt;a href=&quot;#客户端请求相关的配置&quot; class=&quot;headerlink&quot; title=&quot;客户端请求相关的配置&quot;&gt;&lt;/a&gt;客户端请求相关的配置&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.keepalive_timeout timeout [header_timeout];&lt;/strong&gt;&lt;br&gt;设定keepalive连接的超时时长；0表示禁止长连接；默认为75s。&lt;br&gt;KeepAlive，意思为是否长连接。如果设置了超时时间，那么在这个时间内，那么当Nginx完成用户的请求后，那么Nginx进程不会断开用户的请求连接，依然保持连接状态。设置成0s则当Nginx完成用户的请求后，那么Nginx进程会立即断开和用户的请求连接。&lt;br&gt;完成用户的请求后，连接依然存在着，这样的好处是：当该用户的请求在过来时，Nginx会用这个已经建立的连接，不需要重新创建连接。这样会节省CPU的资源。但是却耗费了内存。为什么呢？可以假设这样的场景。假如keepalive 超时时间为10s，而每1s中有100个用户请求访问，每个用户3次连接，每个连接耗费2M内存，那么10s内建立的连接次数为1000次（跟用户每s请求次数无关），消耗内存为1000x2=2000M，相反，如果不保持长连接，同样的环境场景下，每1s内有100x3个连接，下一秒还是100x3个连接，也就是说永远都是100x3个连接，那么1s内甚至10s内消耗的内存为100x3x2=600M。 然而，在这10s内创建的连接次数100x3x10=3000次，这样肯定消耗了更多的cpu资源。毕竟每次tcp连接都是需要cpu去处理的。&lt;br&gt;问题来了，既然知道长连接与否的利与弊，那么如何判定什么时候On，什么时候Off？&lt;br&gt;在上面的举例中，涉及到了一个数，那就是每个用户在1s内请求的次数，如果把3改为1，是不是10s内得到的连接次数总和是一样的。那么这样无论是On还是Off，消耗的CPU资源是一样的。所以，我们考虑3种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;①用户浏览一个网页时，除了网页本身外，还引用了多个 javascript 文件，多个 css 文件，多个图片文件，并且这些文件都在同一个 HTTP 服务器上。&lt;/li&gt;
&lt;li&gt;②用户浏览一个网页时，除了网页本身外，还引用一个 javascript 文件，一个图片文件。&lt;/li&gt;
&lt;li&gt;③用户浏览的是一个动态网页，由程序即时生成内容，并且不引用其他内容。&lt;br&gt;对于上面3中情况，我认为：1 最适合打开 KeepAlive ，2 随意，3 最适合关闭 KeepAlive（连接消耗的内存比较大）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总结一下：&lt;br&gt;在内存非常充足的服务器上，不管是否关闭 KeepAlive 功能，服务器性能不会有明显变化；&lt;br&gt;如果服务器内存较少，或者服务器有非常大量的文件系统访问时，或者主要处理动态网页服务，关闭 KeepAlive 后可以节省很多内存，而节省出来的内存用于文件系统Cache，可以提高文件系统访问的性能，并且系统会更加稳定。&lt;br&gt;目前的服务器，CPU很强，所以不用考虑频繁的tcp连接对cpu造成的压力，那还让它长连接干什么，故，建议关闭你的长连接吧！！！&lt;br&gt;PS： 如果，你的服务器上请求量很大，那你最好还是关闭这个参数吧。我试过一次，打开长连接，并且设置超时时间为30s，结果仅仅十几s就把所有的Nginx进程跑满。这样很危险的，直接让用户等待，等30s，这不扯淡嘛？即使是你设置成3s，照样会让用户等待3s，这样很不合理的。所以，归根结蒂还是关闭长连接吧，这样效率会更高。&lt;/p&gt;
&lt;p&gt;举个网上的具体例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1.项目环境：nginx（前段代理，仅作代理用途）+3个tomcat（都在同一个服务器上），做的web项目&lt;/li&gt;
&lt;li&gt;2.涉及到的业务逻辑：文件上传（可能有大文件，比如说android游戏，100m）；客户端接口请求；网站后台管理&lt;/li&gt;
&lt;li&gt;3.问题重现流程：&lt;ul&gt;
&lt;li&gt;3.1 配置好tomcat后，直接加上nginx前段代理（仅配置了http代理）&lt;/li&gt;
&lt;li&gt;3.2 问题一：当管理员后台上传文件时，大文件无法上传成功，出现time-out，经重复测试，发现上传时间超过1分钟以后，就会返回超时信息，小文件没有问题&lt;/li&gt;
&lt;li&gt;3.3 经调研得知nginx默认设置的http连接超时时间为75s，超过75s，会断掉当前的http连接，而大文件上传时经常会超过75s，这就导致大文件无法上传成功，当时的解决方案是，设置nginx http连接超时时间为30分钟，即参数keepalive_timeout=1800；文件上传问题基本解决；&lt;/li&gt;
&lt;li&gt;3.4项目运行2天后，发现服务器突然宕机了，重启nginx可以解决问题，但是2个小时后又再次宕机，重启nginx又解决了问题，调研了一个中午，并且查看nginx的错误日志（socket() failed (24: Too many open files) while connecting to upstream），发现问题来源与nginx的连接数（设置的默认值为1024）达到上限&lt;/li&gt;
&lt;li&gt;3.5发现这个问题后，我就想应该把nginx的连接数调大点，于是设置 worker_connections  10240；重启nginx，短时间没有出现问题，但是运行过程中，我再次查看错误日志，发现（socket() failed (24: Too many open files) while connecting to upstream）时不时的出现&lt;/li&gt;
&lt;li&gt;3.6 此时发现调整nginx的连接数并不能完全解决问题，于是google，百度之，发现问题所在，罪魁祸首是：nginx的keepalive_timeout(参看&lt;a href=&quot;http://fengzheng369.blog.163.com/blog/static/752209792012418103813580/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://fengzheng369.blog.163.com/blog/static/752209792012418103813580/&lt;/a&gt; )设置项时间太长，客户端接口访问其实是一个比较快速的过程，访问完成了已经不需要继续使用http连接了，但是由于对nginx的错误配置，导致接口访问完成后http连接并没有被释放掉，所以导致连接数越来越大，最终nginx崩溃。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;4.那么这个问题应该如何解决呢？&lt;br&gt;将keepalive_timeout时间调小会导致上传操作可能无法完成；调大点的话，许多无效的http连接占据着nginx的连接数。这貌似是一个两难的问题。&lt;br&gt;解决方案一：将接口请求，后台管理，文件上传这三个业务逻辑分开，nginx对这三种业务逻辑分开转发，每个业务逻辑单独设置一个keepalive-timeout(未实验)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.keepalive_requests number;&lt;/strong&gt;&lt;br&gt;在keepalived连接上所允许请求的最大资源数量；默认为100；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.keepalive_disable none | browser …;&lt;/strong&gt;&lt;br&gt;指明禁止为何种浏览器使用keepalive功能；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.send_timeout #;&lt;/strong&gt;&lt;br&gt;发送响应报文的超时时长，默认为60s; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.client_body_buffer_size size;&lt;/strong&gt;&lt;br&gt;接收客户请求报文body的缓冲区大小；默认为16k；超出此指定大小时，其将被移存于磁盘上；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6.client_body_temp_path path [level1 [level2 [level3]]];&lt;/strong&gt;&lt;br&gt;设定用于存储客户端请求body的临时存储路径及子目录结构和数量；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;client_body_temp_path  /var/tmp/client_body  2 2;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;7.client_max_body_size 10m;&lt;/strong&gt;&lt;br&gt;允许客户端请求的最大的单个文件字节数，这个参数可以限制body的大小，默认是1m。如果上传的文件较大，那么需要调大这个参数。&lt;/p&gt;
&lt;h3 id=&quot;对客户端请求的进行限制&quot;&gt;&lt;a href=&quot;#对客户端请求的进行限制&quot; class=&quot;headerlink&quot; title=&quot;对客户端请求的进行限制&quot;&gt;&lt;/a&gt;对客户端请求的进行限制&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1.limit_excpet  METHOD {…}&lt;/strong&gt;&lt;br&gt;对指定范围之外的其它的方法进行访问控制；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;limit_except  GET {
    allow  172.16.0.0/16;
    deny all;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.对客户端限速&lt;/strong&gt;&lt;br&gt;我们经常会遇到这种情况，服务器流量异常，负载过大等等。对于大流量恶意的攻击访问，会带来带宽的浪费，服务器压力，影响业务，往往考虑对同一个ip的连接数，并发数进行限制。下面说说ngx_http_limit_conn_module 模块来实现该需求。该模块可以根据定义的键来限制每个键值的连接数，如同一个IP来源的连接数。并不是所有的连接都会被该模块计数，只有那些正在被处理的请求（这些请求的头信息已被完全读入）所在的连接才会被计数。&lt;br&gt;nginx的限速功能通过limit_zone、limit_conn和limit_rate指令进行配置。首先需要在http上下文配置一个limit_zone，然后在需要的地方使用limit_conn和limit_rate 进行限速设置。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;limit_conn_zone&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;语法: limit_conn_zone $variable zone=name:size;
默认值: none
配置段: http
该指令描述会话状态存储区域。键的状态中保存了当前连接数，键的值可以是特定变量的任何非空值（空值将不会被考虑）。$variable定义键，zone=name定义区域名称，后面的limit_conn指令会用到的。size定义各个键共享内存空间大小。如：

limit_conn_zone $binary_remote_addr zone=addr:10m;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【说明】：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端的IP地址作为键。注意，这里使用的是$binary_remote_addr变量，而不是$remote_addr变量。&lt;/li&gt;
&lt;li&gt;$remote_addr变量的长度为7字节到15字节，而存储状态在32位平台中占用32字节或64字节，在64位平台中占用64字节。&lt;/li&gt;
&lt;li&gt;$binary_remote_addr变量的长度是固定的4字节，存储状态在32位平台中占用32字节或64字节，在64位平台中占用64字节。&lt;/li&gt;
&lt;li&gt;1M共享空间可以保存3.2万个32位的状态，1.6万个64位的状态。如果共享内存空间被耗尽，服务器将会对后续所有的请求返回 503 (Service Temporarily Unavailable) 错误。&lt;/li&gt;
&lt;li&gt;limit_zone 指令和limit_conn_zone指令同等意思，已经被弃用，就不再做说明了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;limit_conn&lt;/strong&gt;&lt;br&gt;语法：limit_conn zone_name number&lt;br&gt;默认值：none&lt;br&gt;配置段：http, server, location&lt;br&gt;指定每个给定键值的最大同时连接数，当超过这个数字时被返回503 (Service Temporarily Unavailable)错误。如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;limit_conn_zone $binary_remote_addr zone=addr:10m;
server {
    location /www.ttlsa.com/ {
        limit_conn addr 1;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同一IP同一时间只允许有一个连接。&lt;br&gt;当多个 limit_conn 指令被配置时，所有的连接数限制都会生效。比如，下面配置不仅会限制单一IP来源的连接数，同时也会限制单一虚拟服务器的总连接数：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;limit_conn_zone $binary_remote_addr zone=perip:10m;
limit_conn_zone $server_name zone=perserver:10m;
server {
    limit_conn perip 10;
    limit_conn perserver 100;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;limit_rate&lt;/strong&gt;&lt;br&gt;语法：limit_rate rate&lt;br&gt;默认值：0&lt;br&gt;配置段：http, server, location, if in location&lt;br&gt;对每个连接的速率限制。参数rate的单位是字节/秒，设置为0将关闭限速。 按连接限速而不是按IP限制，因此如果某个客户端同时开启了两个连接，那么客户端的整体速率是这条指令设置值的2倍。&lt;/p&gt;
&lt;h3 id=&quot;Nginx反向代理配置&quot;&gt;&lt;a href=&quot;#Nginx反向代理配置&quot; class=&quot;headerlink&quot; title=&quot;Nginx反向代理配置&quot;&gt;&lt;/a&gt;Nginx反向代理配置&lt;/h3&gt;&lt;p&gt;Nginx通过proxy模块实现反向代理功能。在作为web反向代理服务器时，nginx负责接收客户请求，并能够根据URI、客户端参数或其它的处理逻辑将用户请求调度至上游服务器上(upstream server)。nginx在实现反向代理功能时的最重要指令为proxy_pass，它能够将location定义的某URI代理至指定的上游服务器(组)上。如下面的示例中，location的/uri将被替换为上游服务器上的/newuri。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location /uri {
    proxy_pass http://www.magedu.com:8080/newuri; # 指定将请求代理至upstream server的URL路径；
} 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;补充：&lt;strong&gt;上游&lt;/strong&gt;，有发源的意思。故上游服务器指的产生内容的服务器。&lt;/p&gt;
&lt;p&gt;不过，这种处理机制中有两个例外。一个是如果location的URI是通过模式匹配定义的，其URI将直接被传递至上游服务器，而不能为其指定转换的另一个URI。例如下面示例中的/forum将被代理为&lt;a href=&quot;http://www.magedu.com/forum。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.magedu.com/forum。&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location ~ ^/bbs {
    proxy_pass http://www.magedu.com;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第二个例外是，如果在loation中使用的URL重定向，那么nginx将使用重定向后的URI处理请求，而不再考虑上游服务器上定义的URI。如下面所示的例子中，传送给上游服务器的URI为/index.php?page=&lt;match&gt;，而不是/index。&lt;/match&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location / {
    rewrite /(.*)$ /index.php?page=$1 break;
    proxy_pass http://localhost:8080/index;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;proxy模块的指令&quot;&gt;&lt;a href=&quot;#proxy模块的指令&quot; class=&quot;headerlink&quot; title=&quot;proxy模块的指令&quot;&gt;&lt;/a&gt;proxy模块的指令&lt;/h4&gt;&lt;p&gt;proxy模块的可用配置指令非常多，它们分别用于定义proxy模块工作时的诸多属性，如连接超时时长、代理时使用http协议版本等。下面对常用的指令做一个简单说明。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;proxy_connect_timeout：nginx将一个请求发送至upstream server之前等待的最大时长；&lt;/li&gt;
&lt;li&gt;proxy_cookie_domain：将upstream server通过Set-Cookie首部设定的domain属性修改为指定的值，其值可以为一个字符串、正则表达式的模式或一个引用的变量；&lt;/li&gt;
&lt;li&gt;proxy_cookie_path: 将upstream server通过Set-Cookie首部设定的path属性修改为指定的值，其值可以为一个字符串、正则表达式的模式或一个引用的变量；&lt;/li&gt;
&lt;li&gt;proxy_hide_header：设定发送给客户端的报文中需要隐藏的首部；&lt;/li&gt;
&lt;li&gt;proxy_pass：指定将请求代理至upstream server的URL路径；&lt;/li&gt;
&lt;li&gt;proxy_set_header：将发送至upsream server的报文的某首部进行重写；&lt;/li&gt;
&lt;li&gt;proxy_redirect：重写location并刷新从upstream server收到的报文的首部；&lt;/li&gt;
&lt;li&gt;proxy_send_timeout：在连接断开之前两次发送至upstream server的写操作的最大间隔时长；&lt;/li&gt;
&lt;li&gt;proxy_read_timeout：在连接断开之前两次从接收upstream server接收读操作的最大间隔时长；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如下面的一个示例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;proxy_redirect off;
proxy_set_header Host $host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
client_max_body_size 10m;
client_body_buffer_size 128k;
proxy_connect_timeout 30;
proxy_send_timeout 15;
proxy_read_timeout 15;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;nginx proxy_pass 后面的url 加与不加/的区别：&lt;/strong&gt;&lt;br&gt;在nginx中配置proxy_pass时，当在后面的url加上了/，相当于是绝对根路径，则nginx不会把location中匹配的路径部分代理走;如果没有/，则会把匹配的路径部分也给代理走。&lt;br&gt;下面四种情况分别用&lt;a href=&quot;http://192.168.1.4/proxy/test.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://192.168.1.4/proxy/test.html&lt;/a&gt; 进行访问。&lt;/p&gt;
&lt;p&gt;第一种：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location  /proxy/ {
    proxy_pass http://127.0.0.1:81/;
}
会被代理到http://127.0.0.1:81/test.html 这个url
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第二种(相对于第一种，最后少一个 /)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location  /proxy/ {
    proxy_pass http://127.0.0.1:81;
}
会被代理到http://127.0.0.1:81/proxy/test.html 这个url
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第三种：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location  /proxy/ {
    proxy_pass http://127.0.0.1:81/ftlynx/;
}
会被代理到http://127.0.0.1:81/ftlynx/test.html 这个url。
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第四种情况(相对于第三种，最后少一个 / )：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location  /proxy/ {
    proxy_pass http://127.0.0.1:81/ftlynx;
}
会被代理到http://127.0.0.1:81/ftlynxtest.html 这个url
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;location后加/和不加/的区别&lt;/strong&gt;&lt;br&gt;首先是location进行的是模糊匹配&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;没有“/”时，location /abc/def可以匹配/abc/defghi请求，也可以匹配/abc/def/ghi等&lt;/li&gt;
&lt;li&gt;而有“/”时，location /abc/def/不能匹配/abc/defghi请求，只能匹配/abc/def/anything这样的请求&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Nginx实现负载均衡-–upstream模块&quot;&gt;&lt;a href=&quot;#Nginx实现负载均衡-–upstream模块&quot; class=&quot;headerlink&quot; title=&quot;Nginx实现负载均衡 –upstream模块&quot;&gt;&lt;/a&gt;Nginx实现负载均衡 –upstream模块&lt;/h4&gt;&lt;p&gt;与proxy模块结合使用的模块中，最常用的当属upstream模块。upstream模块可定义一个新的上下文，它包含了一组服务器，这些服务器可能被赋予了不同的权重、不同的类型甚至可以基于维护等原因被标记为down。直白点就是说如果后端一个服务器是在抗不住了，nginx还可以代理用户请求至多个服务器，也就是一个location里定义多个服务器，即实现负载均衡的效果。还能检查后端server的健康状况。&lt;br&gt;例如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;upstream backend {
    server 172.16.7.151:8080 weight=5;
    server 172.16.7.152:8090 weight=3;
}

server {
    listen 80;
    server_name www.wisedu.com;

    location / {
        proxy_pass http://backend;
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;server也可以使用域名，但是需要内网有DNS服务器，或者在hosts文件做解析。也可以是IP:port。&lt;br&gt;upstream模块定义在http段，可以定义多个upstream，但是每一个都要有自己独立的名称。&lt;/p&gt;
&lt;p&gt;upstream模块常用的指令有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ip_hash：基于客户端IP地址完成请求的分发，它可以保证来自于同一个客户端的请求始终被转发至同一个upstream服务器；&lt;pre&gt;&lt;code&gt;upstream lb {
       ip_hash;
       server 172.16.7.151:8080;
       server 172.16.7.152:8090;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;keepalive：每个worker进程为发送到upstream服务器的连接所缓存的个数；&lt;/li&gt;
&lt;li&gt;least_conn：最少连接调度算法；检查后端的连接状况，挑一个当前连接数最少的来负责响应。&lt;/li&gt;
&lt;li&gt;server：定义一个upstream服务器的地址，还可包括一系列可选参数，如：&lt;ul&gt;
&lt;li&gt;weight：权重；&lt;/li&gt;
&lt;li&gt;max_fails：最大失败连接次数，失败连接的超时时长由fail_timeout指定；&lt;/li&gt;
&lt;li&gt;fail_timeout：等待请求的目标服务器发送响应的时长；&lt;/li&gt;
&lt;li&gt;backup：用于fallback的目的，所有服务均故障时才启动此服务器；&lt;/li&gt;
&lt;li&gt;down：手动标记其不再处理任何请求；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;upstream模块的负载均衡算法主要有三种，轮调(round-robin)、ip哈希(ip_hash)和最少连接(least_conn)三种。默认是轮调算法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;健康状况检查&lt;/strong&gt;&lt;br&gt;如果某台机器挂了怎么办？可以进行健康状况检查。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;upstream webserv {
    server 172.16.7.151:8080 weight=1 max_fails=2 fail_timeout=2;
    server 172.16.7.152:8090 weight=1 max_fails=2 fail_timeout=2;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;健康状况检查还应该有一个功能，万一所有服务器都宕掉怎么办？必须要有个Sorry-Server，下面以本机作为Sorry-Server，可以在定义个虚拟主机:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
    listen 8080;
    server_name localhost;

    root /web/errorpages;
    index index.html
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;upstream添加配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;upstream webserv {
    server 172.16.7.151:8080 weight=1 max_fails=2 fail_timeout=2;
    server 172.16.7.152:8090 weight=1 max_fails=2 fail_timeout=2;
    server 127.0.0.1:8080 backup;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。&lt;/p&gt;
&lt;h3 id=&quot;Nginx的URL重写功能和if指令&quot;&gt;&lt;a href=&quot;#Nginx的URL重写功能和if指令&quot; class=&quot;headerlink&quot; title=&quot;Nginx的URL重写功能和if指令&quot;&gt;&lt;/a&gt;Nginx的URL重写功能和if指令&lt;/h3&gt;&lt;h4 id=&quot;URL重写rewrite&quot;&gt;&lt;a href=&quot;#URL重写rewrite&quot; class=&quot;headerlink&quot; title=&quot;URL重写rewrite&quot;&gt;&lt;/a&gt;URL重写rewrite&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;1.什么叫rewrite&lt;/strong&gt;&lt;br&gt;举个例子：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location /images/ {       ——这是我们当前服务器上的目录
    rewrite http://172.16.2.27/images/;      ——把你转到另外一台服务器上的目录去了。
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.Nginx的rewrite&lt;br&gt;Nginx的rewrite支持正则表达式   ——可以将一类URL转成另一类URL&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Syntax: rewrite regex replacement [flag];
Default:    —
Context:    server, location, if
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;server区块中如果有包含rewrite规则,则会最先执行,而且只会执行一次, 然后再判断命中哪个location的配置。如果location中也配置了rewrite，会再去执行该location中的rewrite，当该location中的rewrite执行完毕时，rewrite并不会停止，而是根据rewrite过的URL再次判断location并执行其中的配置。那么，这里就存在一个问题，如果rewrite写的不正确的话，是会在location区块间造成无限循环的。所以nginx才会加一个最多重试10次的上限。比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location / {
    root html;
    index index.html index.htm;
    rewrite ^/bbs/(.*)$ /forum/$1
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;flag：支持4种标志。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;last：本次重写完成之后重启下一轮检查。一般场景下用的都是last。&lt;/li&gt;
&lt;li&gt;break：本次重写完成之后不启用下一轮检查，直接响应。&lt;/li&gt;
&lt;li&gt;redirect：返回302临时重定向，地址栏会显示跳转后的地址&lt;/li&gt;
&lt;li&gt;permanent： 返回301永久重定向，地址栏会显示跳转后的地址&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;测验一下break与last的区别:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location /test1.txt/ {
    rewrite /test1.txt/ /test2.txt break;
}

location ~ test2.txt {
    return 508;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用break会停止匹配下面的location,直接发起请求www.xxx.com/test2.txt，由于不存在文件test2.txt，则会直接显示404。&lt;br&gt;使用last的话，会继续搜索下面是否有符合条件(符合重写后的/test2.txt请求)的location。此时，/test2.txt刚好与面location的条件对应上了，进入花括号{}里面的代码执行，这里会返回508。&lt;/p&gt;
&lt;h4 id=&quot;if指令&quot;&gt;&lt;a href=&quot;#if指令&quot; class=&quot;headerlink&quot; title=&quot;if指令&quot;&gt;&lt;/a&gt;if指令&lt;/h4&gt;&lt;p&gt;在location中使用if语句可以实现条件判断，其通常有一个return语句，且一般与有着last或break标记的rewrite规则一同使用。但其也可以按需要使用在多种场景下，需要注意的是，不当的使用可能会导致不可预料的后果。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;upstream imageservers {
    server 172.16.100.8:80 weight 2;
    server 172.16.100.9:80 weight 3;
}

location / {
    if ($request_method == “PUT”) {
        proxy_pass http://upload.wisedu.com:8080;
    } 

    if ($request_uri ~ &amp;quot;\.(jpg|gif|jpeg|png)$&amp;quot;) {
        proxy_pass http://imageservers;
        break; #这里的break也是停止rewrite检查
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;if语句中的判断条件&lt;/p&gt;
&lt;p&gt;正则表达式匹配：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;==: 等值比较；
~：与指定正则表达式模式匹配时返回“真”，判断匹配与否时区分字符大小写；
~*：与指定正则表达式模式匹配时返回“真”，判断匹配与否时不区分字符大小写；
!~：与指定正则表达式模式不匹配时返回“真”，判断匹配与否时区分字符大小写；
!~*：与指定正则表达式模式不匹配时返回“真”，判断匹配与否时不区分字符大小写；
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;文件及目录匹配判断：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-f, !-f：判断指定的路径是否为存在且为文件；
-d, !-d：判断指定的路径是否为存在且为目录；
-e, !-e：判断指定的路径是否存在，文件或目录均可；
-x, !-x：判断指定路径的文件是否存在且可执行；
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;http核心模块的内置变量&quot;&gt;&lt;a href=&quot;#http核心模块的内置变量&quot; class=&quot;headerlink&quot; title=&quot;http核心模块的内置变量&quot;&gt;&lt;/a&gt;http核心模块的内置变量&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;$uri: 当前请求的uri，不带参数；
$request_uri: 请求的uri，带完整参数；
$host: http请求报文中host首部；如果请求中没有host首部，则以处理此请求的虚拟主机的主机名代替；
$hostname: nginx服务运行在的主机的主机名；
$remote_addr: 客户端IP
$remote_port: 客户端Port
$remote_user: 使用用户认证时客户端用户输入的用户名；
$request_filename: 用户请求中的URI经过本地root或alias转换后映射的本地的文件路径；
$request_method: 请求方法
$server_addr: 服务器地址
$server_name: 服务器名称
$server_port: 服务器端口
$server_protocol: 服务器向客户端发送响应时的协议，如http/1.1, http/1.0
$scheme: 在请求中使用scheme, 如https://www.magedu.com/中的https；
$http_HEADER: 匹配请求报文中指定的HEADER，$http_host匹配请求报文中的host首部
$sent_http_HEADER: 匹配响应报文中指定的HEADER，例如$http_content_type匹配响应报文中的content-type首部；
$document_root：当前请求映射到的root配置；
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;上篇博文中介绍了安装部署OpenResty，这篇博文主要记录下Nginx的配置及优化。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Nginx&quot;&gt;&lt;a href=&quot;#Nginx&quot; class=&quot;headerlink&quot; title=&quot;Nginx&quot;&gt;&lt;/a&gt;Nginx&lt;/h2&gt;&lt;p&gt;Nginx的代码是由一个核心和一系列的模块组成, 核心主要用于提供Web Server的基本功能，以及Web和Mail反向代理的功能；
    
    </summary>
    
      <category term="Nginx" scheme="http://yoursite.com/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>安装部署Openresty</title>
    <link href="http://yoursite.com/2018/01/21/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Openresty/"/>
    <id>http://yoursite.com/2018/01/21/安装部署Openresty/</id>
    <published>2018-01-21T11:55:10.000Z</published>
    <updated>2018-01-29T01:57:59.000Z</updated>
    
    <content type="html">&lt;blockquote&gt;
&lt;p&gt;由于公司的一个产品用了Nginx Lua写了认证，所以在选型时选了OpenResty。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;什么是OpenResty&quot;&gt;&lt;a href=&quot;#什么是OpenResty&quot; class=&quot;headerlink&quot; title=&quot;什么是OpenResty&quot;&gt;&lt;/a&gt;什么是OpenResty&lt;/h2&gt;&lt;p&gt;Nginx 是俄罗斯人发明的， Lua 是巴西几个教授发明的，中国人章亦春把 LuaJIT VM 嵌入到 Nginx 中，实现了 OpenResty 这个高性能服务端解决方案。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;最先将Nginx，Lua组合到一起的是OpenResty，它有一个ngx_lua模块，将Lua嵌入到了Nginx里面；随后Tengine也包含了ngx_lua模块。至于二者的区别：OpenResty是Nginx的Bundle；而Tengine则是Nginx的Fork。值得一提的是，OpenResty和Tengine均是国人自己创建的项目，前者主要由章亦春和晓哲开发，后者主要由淘宝打理。&lt;/p&gt;
&lt;h2 id=&quot;Nginx特性&quot;&gt;&lt;a href=&quot;#Nginx特性&quot; class=&quot;headerlink&quot; title=&quot;Nginx特性&quot;&gt;&lt;/a&gt;Nginx特性&lt;/h2&gt;&lt;h3 id=&quot;HTTP服务器&quot;&gt;&lt;a href=&quot;#HTTP服务器&quot; class=&quot;headerlink&quot; title=&quot;HTTP服务器&quot;&gt;&lt;/a&gt;HTTP服务器&lt;/h3&gt;&lt;p&gt;即web服务器，具有支持一个基本的web服务器应该具备的绝大多数功能。 (&lt;a href=&quot;http://www.netcraft.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.netcraft.com/&lt;/a&gt; 在这个站点上随时统计更新的有全球web服务器的占有状况)&lt;br&gt;灵活的配置：nginx和apache差不多，也是一个进程生成许多子进程，而这个子进程本身有worker进程，专门负责响应用户请求的。nginx是一个进程响应多个请求，事实上可以称为一个线程响应多个请求。除此之外还有许多其他进程，比如说管理缓存的进程，管理会话的进程。有了这样的架构设计，将来在重新添加配置之后，可以将新的连接都使用新配置，而老的连接即已经建立的连接使用原有的配置，所以在线升级的时候不需要中断正在处理的请求，这称为nginx热部署(无非就是平滑升级)。&lt;br&gt;重写(rewrite)模块：web服务器httpd的重写功能异常强大，但是也比较复杂。nginx比较简单，只需要使用正则表达式重写URL。对于任何一个web服务器来说，URL重写是个非常重要的功能，尤其是反向代理的服务器。&lt;/p&gt;
&lt;h3 id=&quot;模块化设计&quot;&gt;&lt;a href=&quot;#模块化设计&quot; class=&quot;headerlink&quot; title=&quot;模块化设计&quot;&gt;&lt;/a&gt;模块化设计&lt;/h3&gt;&lt;p&gt;nginx是高度模块化的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核心模块：core module&lt;/li&gt;
&lt;li&gt;Standard HTTP modules&lt;/li&gt;
&lt;li&gt;Optional HTTP modules&lt;/li&gt;
&lt;li&gt;Mail modules&lt;/li&gt;
&lt;li&gt;3rd party modules&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;支持热部署&quot;&gt;&lt;a href=&quot;#支持热部署&quot; class=&quot;headerlink&quot; title=&quot;支持热部署&quot;&gt;&lt;/a&gt;支持热部署&lt;/h3&gt;&lt;p&gt;不停机更新配置文件、更换日志、更新服务器程序版本。&lt;/p&gt;
&lt;h3 id=&quot;主要用途&quot;&gt;&lt;a href=&quot;#主要用途&quot; class=&quot;headerlink&quot; title=&quot;主要用途&quot;&gt;&lt;/a&gt;主要用途&lt;/h3&gt;&lt;p&gt;nginx有两个作用。第一，web服务器。具有web服务器要求的所有功能。第二，轻量级的反向代理服务器，能够反向代理两种应用：web和mail，只不过反向代理mail的功能很少被提到。我们的主要着眼点也是它的web服务器和web服务器反向代理。&lt;br&gt;Nginx基于File AIO(异步I/O)，在文件级别上磁盘I/O上基于异步I/O来实现的；同时对于异步通信，nginx基于事件驱动加上边缘触发来完成一个线程处理多个请求，这对于c10k问题是十分有效的解决方案。&lt;/p&gt;
&lt;h2 id=&quot;Nginx工作模式、框架、模型&quot;&gt;&lt;a href=&quot;#Nginx工作模式、框架、模型&quot; class=&quot;headerlink&quot; title=&quot;Nginx工作模式、框架、模型&quot;&gt;&lt;/a&gt;Nginx工作模式、框架、模型&lt;/h2&gt;&lt;p&gt;nginx会按需同时运行多个进程：一个主进程(master)和几个工作进程(worker)，配置了缓存时还会有缓存加载器进程(cache loader)和缓存管理器进程(cache manager)等。所有进程均是仅含有一个线程，并主要通过“共享内存”的机制实现进程间通信。主进程以root用户身份运行，而worker、cache loader和cache manager均应以非特权用户身份运行。 &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;master进程(线程)监控worker进程(线程)，包括运行是否正常等。&lt;/li&gt;
&lt;li&gt;worker进程：master的子进程，响应用户请求。&lt;/li&gt;
&lt;li&gt;cache loader进程：在反向代理的时候用于管理缓存的进程。&lt;/li&gt;
&lt;li&gt;·······&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/8.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;注意：master进程是以管理员启动的，因为nginx要启动为web服务器或反向代理的时候，它应该工作在80端口，只有管理员才有权限启用小于1023的端口，所以启动主进程的时候必须使用管理员身份。然后由master进程启动worker进程，而且master启动worker进程的时候完全以普通用户的身份运行，所以让我们的系统安全性得到提升。&lt;br&gt;nginx是高度模块化的，所以nginx的核心模块，像master进程、worker进程所处理的web应用非常简单，最多就是个web服务器，而额外的更多功能比如SSL、FLV流等都不是worker进程自己提供的，而是由额外的模块提供，所以在每个worker进程内部，它可能调用很多个模块，用到哪个模块再去加载哪个模块，而这些模块以流水线的方式工作，也就是一个模块只负责一个功能。比如说第一个分析头部，第二个帮助去的数据，第三个创建响应等等。每个请求，在内部串联起来的模块还不一样，所以每个请求到来了，worker一分析，到底要使用几个模块，这几个模块组成流水线，随时等待响应。&lt;br&gt;正是由于这种机制的存在，master负责装在主配置文件，如果我们改了nginx配置文件，由master分析一下配置文件中有没有语法错误，就算重新装在配置文件有语法错误，但是并不会影响worker进程，最多master返回错误告诉你配置文件有语法错误，需要重新装载。一装载成功了，并不会让运行中的worker进程都使用这个配置是文件的，让这些已经建立的连接继续使用老的配置文件，当某个worker进程建立的连接都退出了，此时把worker进程挂了，再重新启动个新worker进程，新worker进程响应新请求，而这个新worker进程用的就是新配置。&lt;br&gt;&lt;strong&gt;【nginx进程分工】：&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;主进程master：&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;读取并验正配置信息；&lt;/li&gt;
&lt;li&gt;创建、绑定及关闭套接字；&lt;/li&gt;
&lt;li&gt;启动、终止及维护worker进程的个数；&lt;/li&gt;
&lt;li&gt;无须中止服务而重新配置工作特性；&lt;/li&gt;
&lt;li&gt;控制非中断式程序升级，启用新的二进制程序并在需要时回滚至老版本；   ——nginx自身升级&lt;/li&gt;
&lt;li&gt;重新打开日志文件，实现日志滚动；&lt;/li&gt;
&lt;li&gt;编译嵌入式perl脚本；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;worker进程：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;接收、传入并处理来自客户端的连接；&lt;/li&gt;
&lt;li&gt;提供反向代理及过滤功能；&lt;/li&gt;
&lt;li&gt;nginx任何能完成的其它任务；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;cache loader进程：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;检查缓存存储中的缓存对象；&lt;/li&gt;
&lt;li&gt;使用缓存元数据建立内存数据库；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;cache manager进程：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;缓存的失效及过期检验；&lt;br&gt;【注意】：cache loader和cache manager只是在使用nginx作为反向代理并使用了缓存功能的时候才启动，不是所有时候都运行的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;安装OpenResty&quot;&gt;&lt;a href=&quot;#安装OpenResty&quot; class=&quot;headerlink&quot; title=&quot;安装OpenResty&quot;&gt;&lt;/a&gt;安装OpenResty&lt;/h2&gt;&lt;p&gt;使用的版本是openresty-1.9.7.3.tar.gz&lt;br&gt;&lt;strong&gt;1.安装依赖包&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install readline-devel pcre-devel openssl-devel gcc -y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.安装openresty&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr/local
# wget https://openresty.org/download/openresty-1.9.7.3.tar.gz
# tar zxf openresty-1.9.7.3.tar.gz
# cd openresty-1.9.7.3/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看可配置的选项：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ./configure --help
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/9.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;常用的配置参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;–-prefix=path&lt;br&gt;设置安装目录，默认为/usr/local/openresty&lt;/li&gt;
&lt;li&gt;–user=name&lt;br&gt;设置工作进程使用的非特权用户的用户名，默认为nobody。安装完成后可以在nginx.conf中通过user指令修改。&lt;/li&gt;
&lt;li&gt;–group=name&lt;br&gt;设置工作进程使用的非特权用户组的名称，默认组名和–user的名称一致。安装完成后可以在nginx.conf配置文件中通过user指令指定。&lt;/li&gt;
&lt;li&gt;–-with-http_ssl_module&lt;br&gt;启用添加HTTPS协议支持到HTTP服务器的模块，该模块默认不启用。构建和运行该模块需要OpenSSL库。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ./configure
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;编译和安装：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# gmake &amp;amp;&amp;amp; gmake install
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;安装完成后，在/usr/local/下多了个openresty目录，nginx部署安装在/usr/local/openresty/nginx。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.将nginx加入系统服务&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;【Redhat7之前的版本】：&lt;/strong&gt;&lt;br&gt;(1)    上传脚本nginx启动脚本到/etc/init.d/目录下&lt;br&gt;(2)    授权脚本执行权限&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# chmod a+x nginx
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(3)    加入系统服务&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# chkconfig --add nginx
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(4)    nginx开启自启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# chkconfig nginx on
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(5)    nginx启停重载&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# service nginx start/stop/restart/reload
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;【Redhat7版本】：&lt;/strong&gt;&lt;br&gt;(1)    启动服务单元&lt;br&gt;把写好的nginx.service放到/etc/systemd/system/目录下。&lt;br&gt;(2)    设置开机启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl enable nginx.service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(3)    启动/停止/重载nginx服务&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl start/stop/reload nginx.service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;脚本nginx的内容如下：&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;36&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;37&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;38&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;39&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;40&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;41&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;42&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;43&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;44&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;45&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;46&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;47&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;48&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;49&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;50&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;51&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;52&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;53&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;54&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;55&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;56&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;57&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;58&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;59&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;60&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;61&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;62&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;63&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;64&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;65&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;66&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;67&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;68&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;69&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;70&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;71&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;72&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;73&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;74&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;75&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;76&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;77&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;78&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;79&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;80&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;81&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;82&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;83&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;84&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;85&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;86&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;87&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;88&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;89&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;90&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;91&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;92&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;93&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;94&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;95&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;#!/bin/sh&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;#&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# nginx - this script starts and stops the nginx daemon&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;#&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# chkconfig:   - 85 15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# description: Nginx is an HTTP(S) server, HTTP(S) reverse \&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;#               proxyand IMAP/POP3 proxy server&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# processname: nginx&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# config:      /etc/nginx/nginx.conf&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# config:      /etc/sysconfig/nginx&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# pidfile:     /var/run/nginx.pid&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# Source function library.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;. /etc/rc.d/init.d/functions&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# Source networking configuration.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;. /etc/sysconfig/network&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# Check that networking is up.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[ &amp;quot;$NETWORKING&amp;quot; = &amp;quot;no&amp;quot; ] &amp;amp;&amp;amp; exit 0&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;nginx=&amp;quot;/usr/local/openresty/nginx/sbin/nginx&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;prog=$(basename $nginx)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;NGINX_CONF_FILE=&amp;quot;/usr/local/openresty/nginx/conf/nginx.conf&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[ -f /etc/sysconfig/nginx ] &amp;amp;&amp;amp; . /etc/sysconfig/nginx&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;lockfile=/var/lock/subsys/nginx&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;start() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    [ -x $nginx ] || exit 5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    [ -f $NGINX_CONF_FILE ] || exit 6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    echo -n $&amp;quot;Starting $prog: &amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    daemon $nginx -c $NGINX_CONF_FILE&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    retval=$?&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    echo&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    [ $retval -eq 0 ] &amp;amp;&amp;amp; touch $lockfile&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    return $retval&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;stop() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    echo -n $&amp;quot;Stopping $prog: &amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    killproc $prog -QUIT&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    retval=$?&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    echo&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    [ $retval -eq 0 ] &amp;amp;&amp;amp; rm -f $lockfile&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    return $retval&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;killall -9 nginx&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;restart() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    configtest || return $?&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    stop&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    sleep 1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    start&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;reload() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    configtest || return $?&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    echo -n $&amp;quot;Reloading $prog: &amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    killproc $nginx -HUP&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;RETVAL=$?&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    echo&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;force_reload() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    restart&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;configtest() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;$nginx -t -c $NGINX_CONF_FILE&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;rh_status() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    status $prog&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;rh_status_q() &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    rh_status &amp;gt;/dev/null 2&amp;gt;&amp;amp;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;case &amp;quot;$1&amp;quot; in&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    start)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        rh_status_q &amp;amp;&amp;amp; exit0&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    $1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    stop)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        rh_status_q || exit 0&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        $1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    restart|configtest)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        $1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    reload)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        rh_status_q || exit 7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        $1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    force-reload)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        force_reload&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    status)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        rh_status&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    condrestart|try-restart)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        rh_status_q || exit 0&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            ;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    *)  &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      echo $&amp;quot;Usage: $0 &amp;#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&amp;#125;&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        exit 2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;esac&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;服务单元nginx.service的内容如下：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[Unit]
Description=nginx - high performance web server
Documentation=http://nginx.org/en/docs/
After=network.target remote-fs.target nss-lookup.target

[Service]
Type=forking
PIDFile=/usr/local/openresty/nginx/logs/nginx.pid
ExecStartPre=/usr/local/openresty/nginx/sbin/nginx -t -c /usr/local/openresty/nginx/conf/nginx.conf
ExecStart=/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf
ExecReload=/bin/kill -s HUP $MAINPID
ExecStop=/bin/kill -s QUIT $MAINPID
PrivateTmp=true

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【补充】:&lt;br&gt;RHEL/CentOS 7.0中一个最主要的改变，就是切换到了systemd。它用于替代红帽企业版Linux前任版本中的SysV和Upstart，对系统和服务进行管理。systemd兼容SysV和Linux标准组的启动脚本。&lt;br&gt;Systemd 是 Linux 系统中最新的初始化系统（init），它主要的设计目标是克服 sysvinit 固有的缺点，提高系统的启动速度。systemd 和 ubuntu 的 upstart 是竞争对手，已经取代了UpStart。&lt;br&gt;Systemd也是一个Linux操作系统下的系统和服务管理器。它被设计成向后兼容SysV启动脚本，并提供了大量的特性，如开机时平行启动系统服务，按需启动守护进程，支持系统状态快照，或者基于依赖的服务控制逻辑。&lt;br&gt;先前的使用SysV初始化或Upstart的红帽企业版Linux版本中，使用位于/etc/rc.d/init.d/目录中的bash初始化脚本进行管理。而在RHEL 7/CentOS 7中，这些启动脚本被服务单元取代了。服务单元以.service文件扩展结束，提供了与初始化脚本同样的用途。要查看、启动、停止、重启、启用或者禁用系统服务，你要使用systemctl来代替旧的service命令。&lt;br&gt;注：为了向后兼容，旧的service命令在CentOS 7中仍然可用，它会重定向所有命令到新的systemctl工具。&lt;/p&gt;
&lt;h2 id=&quot;Nginx日志切割&quot;&gt;&lt;a href=&quot;#Nginx日志切割&quot; class=&quot;headerlink&quot; title=&quot;Nginx日志切割&quot;&gt;&lt;/a&gt;Nginx日志切割&lt;/h2&gt;&lt;p&gt;日志对于统计排错来说非常有利的。nginx日志相关的配置如access_log、log_format、error_log等。这部分配置内容将在下一篇博文中讲解，这里先来简单提一下。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;log_format res &amp;apos;$http_host $remote_addr [$time_local] &amp;quot;$request&amp;quot; $status $body_bytes_sent &amp;quot;$http_referer&amp;quot; &amp;quot;$http_user_agent&amp;quot; $request_time $upstream_response_time&amp;apos;; #定义日志格式，并给这个日志格式命名为res
access_log  logs/res.access.log  res; #access_log在虚拟主机段中配置，logs/res.access.log定义了存放该虚拟主机日志文件的名字及存放路径，记录的日志格式为上面定义的res所对应的日志格式
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Nginx每个虚拟主机都应该使用一个单独的日志，这里使用Linux自带的logrotate进行切割。如果不切割，每个日志文件会越来越大。&lt;br&gt;关于logrotate的介绍及配置这里不多介绍，可以自行google。下面开始定义切割Nginx的logrotate的配置文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/logrotate.d/nginx
/usr/local/openresty/nginx/logs/*.log {
    notifempty
    weekly
    rotate 4
    nocompress
    copytruncate
    postrotate
    systemctl reload nginx.service 
    endscript
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面的配置是每周切割一次Nginx日志，保留最近的4个日志文件。&lt;br&gt;对于配置中的 &lt;strong&gt;systemctl reload nginx.service&lt;/strong&gt; 需要换成服务器上重载Nginx的命令，如果是centos6系列，可能命令就是 &lt;strong&gt;service nginx reload&lt;/strong&gt;。&lt;br&gt;&lt;/p&gt;
&lt;p&gt;关于Nginx的具体配置将在下篇博文中分享。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;由于公司的一个产品用了Nginx Lua写了认证，所以在选型时选了OpenResty。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;什么是OpenResty&quot;&gt;&lt;a href=&quot;#什么是OpenResty&quot; class=&quot;headerlink&quot; title=&quot;什么是OpenResty&quot;&gt;&lt;/a&gt;什么是OpenResty&lt;/h2&gt;&lt;p&gt;Nginx 是俄罗斯人发明的， Lua 是巴西几个教授发明的，中国人章亦春把 LuaJIT VM 嵌入到 Nginx 中，实现了 OpenResty 这个高性能服务端解决方案。&lt;br&gt;
    
    </summary>
    
      <category term="Nginx" scheme="http://yoursite.com/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>I/O模型</title>
    <link href="http://yoursite.com/2018/01/18/I-O%E6%A8%A1%E5%9E%8B/"/>
    <id>http://yoursite.com/2018/01/18/I-O模型/</id>
    <published>2018-01-18T09:08:21.000Z</published>
    <updated>2018-01-21T12:12:42.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;I-O类型&quot;&gt;&lt;a href=&quot;#I-O类型&quot; class=&quot;headerlink&quot; title=&quot;I/O类型&quot;&gt;&lt;/a&gt;I/O类型&lt;/h2&gt;&lt;p&gt;从不同的角度来划分，有两种不同的方式：&lt;br&gt;&lt;strong&gt;同步I/O和异步I/O&lt;/strong&gt;    ——synchronous, asynchronous&lt;br&gt;同步和异步关注的是消息通知机制。说白了就是如何通知调用者的。I/O就是一方能够提供服务，一方需要调用别人的服务，&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;所以I/O请求就是调用方向被调用方请求运行一个应用，通常是一个函数，可以理解成是一个库调用、函数调用或者系统调用。假如是一次系统调用，调用方向被调用方发起一次系统调用请求，被调用方本地要把这个系统调用运行完成，所以要在本地处理处理，把处理的结果响应给调用方。问题是调用方什么时候知道自己的请求结束了呢？自己的请求对方响应了呢？所以这就是同步和异步两种模式。&lt;br&gt;所谓同步是调用发出之后不会立即返回，但一旦返回，则返回是最终结果；(被调用者一直在处理处理，处理到最后返回结果给调用者)&lt;br&gt;所谓异步是调用发出之后，被调用方返回消息，但返回的并非最终结果；被调用者通过状态、通知机制(比如打电话通知你)等来通知调用者，或通过回调函数来处理结果。 (当调用者发出请求以后，被调用者立即就告诉调用者了，比如：请求已收到，等着叫号吧。)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;阻塞I/O和非阻塞I/O&lt;/strong&gt;    ——block, nonblock&lt;br&gt;阻塞和非阻塞关注的是调用者等待被调用返回结果时的状态。&lt;br&gt;阻塞是指调用结果返回之前，调用者(一般是进程或者线程)会被挂起；调用者只有在得到返回结果之后才能继续；&lt;br&gt;非阻塞是指调用者在结果返回之前，不会被挂起，即调用不会阻塞调用者。&lt;/p&gt;
&lt;p&gt;【例子】：你去一个饭馆吃饭去了，点了一碗面，师傅在现做。然后你就在那等着，这期间不能做其他的事情，这就是阻塞。还有一种方案是在等面的时候该干嘛干嘛去，比如出去玩了会游戏等，估摸着面差不多的时候回到饭馆，吃面。这就是非阻塞。&lt;/p&gt;
&lt;h2 id=&quot;I-O模型&quot;&gt;&lt;a href=&quot;#I-O模型&quot; class=&quot;headerlink&quot; title=&quot;I/O模型&quot;&gt;&lt;/a&gt;I/O模型&lt;/h2&gt;&lt;p&gt;同步、异步和阻塞、非阻塞看起来很像，但是关注的点不同，一个关注着调用者如何等待结果，一个关注着被调用者如何通知调用者调用完成的。所以压根不是一回事。站在这个角度来划分的话，I/O可以分成5种模型：&lt;br&gt;  ● 阻塞式I/O(blocking I/O)&lt;br&gt;  ● 非阻塞式I/O(nonblocking I/O)&lt;br&gt;  ● 复用式I/O(I/O multiplexing)&lt;br&gt;  ● 事件驱动式I/O(signal driven I/O)&lt;br&gt;  ● 异步I/O(asynchronous I/O)&lt;/p&gt;
&lt;p&gt;下面以磁盘I/O来解释，这些概念非常关键。例如，用户程序发起一个I/O调用，如从磁盘上做一次read操作(用户空间的进程是没有权限直接访问文件的，进程向用户内核发起I/O调用，请求说我要读取某数据)：&lt;br&gt;(1)内核从磁盘将数据加载到内核内存空间；&lt;br&gt;(2)将内核内存中的数据copy一份到进程内存空间。&lt;br&gt;以上两步中真正被称为I/O的那一步其实只是第(2)步，第(1)步只是内核处理数据的过程。&lt;/p&gt;
&lt;h3 id=&quot;阻塞式I-O-blocking-I-O&quot;&gt;&lt;a href=&quot;#阻塞式I-O-blocking-I-O&quot; class=&quot;headerlink&quot; title=&quot;阻塞式I/O(blocking I/O)&quot;&gt;&lt;/a&gt;阻塞式I/O(blocking I/O)&lt;/h3&gt;&lt;p&gt;下图中，左侧竖线代表调用者，右侧竖线代表被调用者。整个I/O调用在右侧内核来看，分为两步。如上。所谓阻塞式I/O指的是调用方发起调用后将会被挂起，这个进程或线程将转为不可中断式睡眠状态。调用者在得到返回结果之前，什么事都不能做，一直处于等待过程当中。想象一下，假如是个web服务器，第一个用户请求来了，由一个进程响应用户请求，这个进程向内核发起I/O调用请求，加载用户请求的页面资源，在加载这个页面资源的过程当中，假设它工作于阻塞式I/O的话，它就会被挂起，它显然不能响应用户的其他请求。Apache的prefork并不是工作在阻塞式I/O之下。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;非阻塞式I-O-nonblocking-I-O&quot;&gt;&lt;a href=&quot;#非阻塞式I-O-nonblocking-I-O&quot; class=&quot;headerlink&quot; title=&quot;非阻塞式I/O(nonblocking I/O)&quot;&gt;&lt;/a&gt;非阻塞式I/O(nonblocking I/O)&lt;/h3&gt;&lt;p&gt;左侧是调用者，右侧是被调用者。对于被调用者，依然是两个阶段，数据从磁盘到内核内存，然后数据从内核内存到进程内存。对于非阻塞式I/O，调用者也把这个过程分成两个阶段(左侧也是两个阶段)，第1阶段，当调用者发出请求之后，被调用者立即告诉你：请求已收到，你等着吧。但问题是等到什么时候呢？就像去面馆点了一碗面一样，然后你出去玩了，但是你怎么知道面好了呢？为了及时得到吃面，所以你不得不每隔几秒钟回去看看面好了没有。这种就叫做盲等，效率并不高。这种不会直接转为睡眠状态，直到好了告诉你。一旦老板告诉你面OK了，是指面已经在柜台上了，其实是指数据从磁盘到内核内存了，你想吃还得自己从柜台上端过去。所以第二阶段你去端面，在这个过程你是什么事情都是做不了的，所以虽然是非阻塞，第2阶段依然是阻塞的。&lt;br&gt;所以对于非阻塞式I/O，第一阶段是盲等，第二阶段依然是阻塞的。很显然第二种模式相对第一种模式，性能并没有提升。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;复用式I-O-I-O-multiplexing&quot;&gt;&lt;a href=&quot;#复用式I-O-I-O-multiplexing&quot; class=&quot;headerlink&quot; title=&quot;复用式I/O(I/O multiplexing)&quot;&gt;&lt;/a&gt;复用式I/O(I/O multiplexing)&lt;/h3&gt;&lt;p&gt;任何一个进程，它只能处理一个I/O，因为它一旦被一个I/O阻塞了，直到被唤醒之前，其他人干的事情它一概不知。但作为web服务器进程，它其实是处理两路I/O的，第一路用户通过网络进来，这是网络I/O，第二路是自己向内核发请求加载数据，这是磁盘I/O。这是两路不同的I/O，因此一旦进程被阻塞在磁盘I/O上，如果这个时候网络I/O发生异动了，这个进程是不会知道的。默认情况下，只能处理完一路I/O，在去处理另一路I/O。&lt;br&gt;再举个例子，比如终端执行一个命令，然后阻塞在磁盘I/O上，你不要了，按了ctrl+c，按道理这个进程处于不可中断睡眠，它应该是不知道的。怎么才能取消。现实中是能取消的，这就是多路I/O(或者说是复用I/O)的工作机制了。&lt;br&gt;默认情况下，调用者向被调用者发起调用请求时，如果阻塞了，调用者就任何事都做不了，任何信号都处理不了。为了避免这种情况，有人就在内核中开发了复用式I/O的程序，当调用者需要发起I/O调用时，而是内核给调用者准备了个代理人，调用者将请求发给这个代理人，代理人在把这个请求转为内核可以理解的请求，这样一来，调用者就被阻塞在代理人上，而不是阻塞在内核中完成任务的那个事情上。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;再举个例子，银行很多人在办业务，都在那排队，假如柜台是单进程模型的，在某个时刻只能处理一个业务。这个银行柜台就相当于内核准备的代理人，比如第一个用户想通过这个银行柜台开一张银行卡。向营业员发调用请求，给我开张银行卡，营业员在把请求结果响应给调用者之前，一般而言，这个调用者要一直在柜台坐在那等着。但是也有第二种情况，比如银行业务是两段式的，营业员不直接面对客户，每个营业员配一个助理，这个助理就站在柜台前，负责处理用户请求。所以当任何一个用户请求来了，用户请求扔给助理，助理帮你负责送到内部去。银行柜台有多个，分别办理不同的业务，比如说某个请求既要开张银行卡，又要存款。假设两个业务能同时进行的话，请求者跟助理说我要开张银行卡，于是助理把这个请求扔给一柜台了，自己就闲出来了。然后请求者又扔给助理一个请求，说我要存钱，于是助理又要第二个请求扔给第二个柜台了。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;内核的那个代理人就相当于助理，帮我们实现多路I/O。如果没有这个助理，想完成复用是不可能的。这个助理在内核中就是一种特殊的系统调用。早期的内核有个select()调用，就是这种模式。另外一个poll()调用，也是这种模式。select()是由BSD研发的，后来BSD内部吵架，又模仿select()写了个poll()。两者功能是一样的，只不过一个是BSD风格的，一个是SysV风格的。&lt;br&gt;此后，任何调用者在发起系统调用时，它把调用请求不是扔给内核，而是扔给内核中的助理了。或者说是向内核助理注册一个I/O。select()在实现多路I/O时有限制，要求最多不能超出1024路，如果你想超出，拿内核源码改一改。改成2048，没问题，但是1024的限制是由道理的，因为超出后性能会下降的。我们在讲到prefork模型时，说最多能接受1024个请求并发，其实prefork就是基于select()多路复用I/O模型来实现的。&lt;br&gt;对于这种复用式I/O，依然是阻塞型的，只不过它不是阻塞在自己真正的那个调用之上，而是阻塞在那个助理上，也是select()或poll()上。&lt;br&gt;因此两个阶段，第一个阶段数据从磁盘到内核空间，这个阶段调用者是被阻塞的，只不过没阻塞在内核的I/O调用上，而是阻塞在select()或poll()上。select()这个时候还可以接受其他请求。阻塞在select()之上的最大好处就是可以继续接受其他请求，因为它能够接受其他信号进来。但是对于第二阶段来讲，调用者依然是阻塞的。第二阶段是真正的I/O过程，这个时候调用者就不是阻塞在select()之上，而是阻塞在自己真正的调用之上。&lt;br&gt;复用式I/O对性能并没有提升，最多只是能处理额外的事情而已，并不是在性能上有什么提升。&lt;/p&gt;
&lt;h3 id=&quot;事件驱动式I-O-signal-driven-I-O&quot;&gt;&lt;a href=&quot;#事件驱动式I-O-signal-driven-I-O&quot; class=&quot;headerlink&quot; title=&quot;事件驱动式I/O(signal driven I/O)&quot;&gt;&lt;/a&gt;事件驱动式I/O(signal driven I/O)&lt;/h3&gt;&lt;p&gt;调用者发起调用之后，在第一阶段，内核立即返回结果给调用者，告诉调用者：你的请求我已经收到了，你该干嘛干嘛去，一旦我这边完成了，我会通知你。就相当于你去吃面了，老板告诉你面做好了我会打电话通知你的。这不是盲等，你该干嘛干嘛，不需要回来看，过一会老板通知你OK了，你就回来了。回来后，面在柜台上，我们去端面。端面的过程才是真正的I/O过程，这个过程是不能干其他事情的。(也像我们去餐馆，没位置，留了个电话号码，然后出去玩了，等服务员电话。)&lt;br&gt;这个过程中，第一段是非阻塞的，第二段是阻塞的。作为web服务器来讲，这有什么用呢？一个进程，第一个用户请求来了，进程向内核发起系统调用，加载文件，内核说你该干嘛干嘛去。于是这个进程就闲下来了，这样它就可以处理其它请求了。这就是为什么一个进程可以处理多个请求的原因。但是这个并不意味着性能一定好。虽然已经比阻塞和盲等有优势了，但是它第二段依然是阻塞的。面已经OK了，你仍然得自己端，所以在内核空间数据复制到进程空间这段，仍然是阻塞的。&lt;br&gt;为什么叫事件驱动呢？因为一旦数据从磁盘到内核空间后，内核会通知调用者。所以调用者本身使用回调函数来处理。&lt;br&gt;假如第二个请求数据已经准备好了，等着调用者进程将数据从内核空间复制到用户空间，但是假如此时调用者阻塞在第一个请求上，正在复制第一个请求的数据到进程空间，怎么办？内核通知完了在特定时间内你没有接收，这个信号就消失了。怎么办？所以通知与否，怎么通知，这就引入了两种通知机制。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一种：水平触发。通知一次，你没响应，没来处理，内核就再通知一次。没来处理留再通知一次，直到你处理为止。多次通知看上去更可靠，但是浪费资源。(类似老板一直打电话给你，直到你接电话)&lt;/li&gt;
&lt;li&gt;第二种：边缘触发。只通知一次，但是如果调用者没响应怎么办呢？把通知事件通过回调函数让调用者自行获取，或者把通知信息放置某处，或者过一会儿调用者自己去要。(老板打了一遍电话，你没接，怕面凉了，就端到厨房。过一会你看到未接电话，知道面好了，就回来了，跟老板要。这叫回调。至于什么是回调函数，可以看：&lt;a href=&quot;https://www.zhihu.com/question/19801131&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.zhihu.com/question/19801131&lt;/a&gt;)&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/5.png&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;异步I-O-asynchronous-I-O&quot;&gt;&lt;a href=&quot;#异步I-O-asynchronous-I-O&quot; class=&quot;headerlink&quot; title=&quot;异步I/O(asynchronous I/O)&quot;&gt;&lt;/a&gt;异步I/O(asynchronous I/O)&lt;/h3&gt;&lt;p&gt;当调用者向内核发调用，内核说请求已收到，该干嘛干嘛去。于是内核在后台默默地完成第一步，默默地完成第二步。然后才告诉调用者，饭已OK了，过来吃吧。饭都不用你端了，直接由营业员端到你事先定义好的座位上。因此第一个阶段不用阻塞，第二个阶段不用阻塞。&lt;br&gt;作为一个web服务器来讲，当第一个用户请求进来时，用户请求资源，这个进程向内核发起系统调用，内核自己把数据从磁盘到内核空间，在复制到进程空间，所有东西都准备好了，告诉进程OK了，进程就立即打包响应报文响应给客户端。&lt;br&gt;httpd的event模型就是事件驱动型I/O，但是据说新版2.4也支持异步I/O。在异步模型下，生产力大大解放。内核从磁盘加载数据到内核内存中，一般都会缓存下来。如果第二个用户请求的资源和前面的用户请求的资源是一样的，直接响应就可以了。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;五种I-O模型对比&quot;&gt;&lt;a href=&quot;#五种I-O模型对比&quot; class=&quot;headerlink&quot; title=&quot;五种I/O模型对比&quot;&gt;&lt;/a&gt;五种I/O模型对比&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Nginx/7.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;有通知机制的我们称为异步I/O，无通知机制的我们称为同步I/O。见上图最下面，前面3个是同步I/O，后面2个是异步I/O。&lt;/p&gt;
&lt;p&gt;Nginx在设计时，用的就是事件驱动型I/O，而且基于边缘触发来实现。Nginx还支持异步I/O。而且还能完成mmap机制，内存映射机制。&lt;/p&gt;
&lt;p&gt;Nginx基于File AIO(异步I/O)，在文件级别上磁盘I/O上基于异步I/O来实现的；同时对于异步通信，nginx基于事件驱动加上边缘触发来完成一个线程处理多个请求，这对于c10k问题是十分有效的解决方案。&lt;/p&gt;
&lt;h2 id=&quot;HTTPD的MPM&quot;&gt;&lt;a href=&quot;#HTTPD的MPM&quot; class=&quot;headerlink&quot; title=&quot;HTTPD的MPM&quot;&gt;&lt;/a&gt;HTTPD的MPM&lt;/h2&gt;&lt;p&gt;httpd的MPM（多道处理模块）&lt;br&gt;  ● prefork：进程模型的。用的是复用型I/O。&lt;br&gt;  ● worker：线程模型的。用的是复用型I/O。并发有限，select()最多1024个。&lt;br&gt;  ● event：线程模型的。用的是事件驱动式I/O。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;prefork工作模型&lt;br&gt;有一个主进程，主进程生成多个子进程，每个子进程处理一个请求。主进程是以管理员的身份启动的，所以它能够监听在80端口上。端口&amp;lt;1024的被称为特权端口，只有管理员才有权限使用的。&lt;/li&gt;
&lt;li&gt;worker工作模型&lt;br&gt;有一个主进程，主进程生成多个子进程，每个子进程在生成多个线程，每个线程响应一个请求。&lt;/li&gt;
&lt;li&gt;event工作模型&lt;br&gt;有一个主进程，生成多个子进程，每个子进程响应多个请求。当然你也可以理解有一个主进程，生成多个子线程，对Linux而言，子进程和线程并没有严格意义上的区分。而event模型中最著名的、最典型的特性是事件驱动机制。&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;I-O类型&quot;&gt;&lt;a href=&quot;#I-O类型&quot; class=&quot;headerlink&quot; title=&quot;I/O类型&quot;&gt;&lt;/a&gt;I/O类型&lt;/h2&gt;&lt;p&gt;从不同的角度来划分，有两种不同的方式：&lt;br&gt;&lt;strong&gt;同步I/O和异步I/O&lt;/strong&gt;    ——synchronous, asynchronous&lt;br&gt;同步和异步关注的是消息通知机制。说白了就是如何通知调用者的。I/O就是一方能够提供服务，一方需要调用别人的服务，
    
    </summary>
    
      <category term="Nginx" scheme="http://yoursite.com/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>Nginx配置HTTP/2.0</title>
    <link href="http://yoursite.com/2018/01/16/Nginx%E9%85%8D%E7%BD%AEHTTP-2-0/"/>
    <id>http://yoursite.com/2018/01/16/Nginx配置HTTP-2-0/</id>
    <published>2018-01-16T05:53:17.000Z</published>
    <updated>2018-01-29T11:57:21.000Z</updated>
    
    <content type="html">&lt;blockquote&gt;
&lt;p&gt;最近将公司前端组件的Nginx配置了http 2.0，特此在此记录一下。突然发现博客里竟然没有什么关于Nginx的文章，毕竟是一直在使用的，后面会写几篇关于自己这几年使用Nginx的一些总结。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;从 2015 年 5 月 14 日 HTTP/2 协议正式版的发布到现在已经快有一年了，越来越多的网站部署了 HTTP2，HTTP2 的广泛应用带来了更好的浏览体验，只要是 Modern 浏览器都支持，所以部署 HTTP2 并不会带来太多困扰。&lt;br&gt;虽然 h2 有 h2c （HTTP/2 Cleartext） 可以通过非加密通道传输，但是支持的浏览器初期还是比较少的，所以目前部署 h2 还是需要走加密的，不过由于 Let’s Encrypt 大力推行免费证书和证书的廉价化，部署 h2 的成本并不高。&lt;/p&gt;
&lt;h2 id=&quot;HTTP-2-0介绍&quot;&gt;&lt;a href=&quot;#HTTP-2-0介绍&quot; class=&quot;headerlink&quot; title=&quot;HTTP 2.0介绍&quot;&gt;&lt;/a&gt;HTTP 2.0介绍&lt;/h2&gt;&lt;p&gt;HTTP 2.0即超文本传输协议 2.0，是下一代HTTP协议。是由互联网工程任务组（IETF）的Hypertext Transfer Protocol Bis (httpbis)工作小组进行开发。是自1999年http1.1发布后的首个更新。&lt;br&gt;HTTP/2 协议是从 SPDY 演变而来，SPDY 已经完成了使命并很快就会退出历史舞台（例如 Chrome 将在「2016 年初结束对 SPDY 的支持」；Nginx、Apache 也已经全面支持 HTTP/2 ，并也不再支持 SPDY）。&lt;br&gt;一般的大家把 HTTP2 简称为 h2，尽管有些朋友可能不怎么愿意，但是这个简称已经默认化了，特别是体现在浏览器对 HTTP2 都是这个简写的。&lt;br&gt;普通的 HTTPS 网站浏览会比 HTTP 网站稍微慢一些，因为需要处理加密任务，而配置了 h2 的 HTTPS，在低延时的情况下速度会比 HTTP 更快更稳定。&lt;br&gt;现在电信劫持事件频发，网站部署了 HTTPS 加密后可以杜绝大部分劫持，但不是完全。像电子商务行业对 HTTPS 加密可是标配啊，因此部署 h2 更是势在必行。&lt;/p&gt;
&lt;h2 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;res&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.7.180&lt;/td&gt;
&lt;td&gt;Res静态资源服务器&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;我这里使用的Nginx是openresty-1.11.2.5。&lt;/p&gt;
&lt;h2 id=&quot;安装Nginx&quot;&gt;&lt;a href=&quot;#安装Nginx&quot; class=&quot;headerlink&quot; title=&quot;安装Nginx&quot;&gt;&lt;/a&gt;安装Nginx&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.安装依赖包&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install readline-devel pcre-devel openssl-devel gcc -y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;首先确认当前openssl版本，最低要求1.0.2，如果不满足，还得手动下载openssl，然后在编译时使用–with-openssl指定openssl目录。我这里是满足条件的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# openssl version
OpenSSL 1.0.2k-fips  26 Jan 2017
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.安装Openresty&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@res local]# cd /usr/local/
[root@res local]# wget https://openresty.org/download/openresty-1.11.2.5.tar.gz
[root@res local]# tar zxf openresty-1.11.2.5.tar.gz 
[root@res local]# cd openresty-1.11.2.5/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;一些较低的版本里是不支持HTTP 2.0的，我这里使用的Openresty-1.11.2.5是支持的。另外，对于官方的Nginx，默认编译的 Nginx 并不包含 h2 模块，我们需要加入参数来编译，截止发文，Nginx 1.9 开发版及以上版本源码需要自己加入编译参数，从软件源仓库下载的则默认编译。 Tengine 可以同时部署 h2 和 SPDY 保证兼容性，Nginx 则是一刀切不再支持 SPDY。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#查看可供编译的参数是否有--with-http_v2_module
[root@res openresty-1.11.2.5]# ./configure --help
[root@res openresty-1.11.2.5]#./configure --with-http_v2_module
[root@res openresty-1.11.2.5]#  gmake &amp;amp;&amp;amp; gmake install
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;配置Nginx&quot;&gt;&lt;a href=&quot;#配置Nginx&quot; class=&quot;headerlink&quot; title=&quot;配置Nginx&quot;&gt;&lt;/a&gt;配置Nginx&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;[root@res conf]# pwd
/usr/local/nginx/nginx/conf
[root@res conf]# cp nginx.conf nginx.conf.bak
[root@res conf]# vim nginx.conf
server {
    listen       80;
    server_name  res.wisedu.com;

    rewrite ^(.*)$  https://$host$1 permanent; #http强制转https

}

server {
    listen       443 ssl http2;
    server_name  res.wisedu.com;

    ssl on;
    #证书和私钥
    ssl_certificate /opt/ssl/214199023800937.pem;
    ssl_certificate_key /opt/ssl/214199023800937.key;
    ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;关于ssl使用的证书，由于是公司对外的服务环境，证书是购买的。当然做实验时也可以建立私有CA，模拟颁发证书。&lt;/p&gt;
&lt;p&gt;启动Nginx：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl start nginx.service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;访问&lt;a href=&quot;https://res.wisedu.com，查看Nginx的access.log，可以看到协议已经是HTTP/2.0了。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://res.wisedu.com，查看Nginx的access.log，可以看到协议已经是HTTP/2.0了。&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;res.wisedu.com 172.16.0.12 [29/Jan/2018:19:54:20 +0800] &amp;quot;GET /static/img/logo.484ce8c.png HTTP/2.0&amp;quot; 200 17354 &amp;quot;https://res.wisedu.com/&amp;quot; &amp;quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36&amp;quot; 0.000 -
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;最近将公司前端组件的Nginx配置了http 2.0，特此在此记录一下。突然发现博客里竟然没有什么关于Nginx的文章，毕竟是一直在使用的，后面会写几篇关于自己这几年使用Nginx的一些总结。&lt;br&gt;
    
    </summary>
    
      <category term="Nginx" scheme="http://yoursite.com/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="http://yoursite.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>Redis安装部署</title>
    <link href="http://yoursite.com/2018/01/10/Redis%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2018/01/10/Redis安装部署/</id>
    <published>2018-01-10T01:12:43.000Z</published>
    <updated>2018-01-10T03:45:22.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;安装Redis&quot;&gt;&lt;a href=&quot;#安装Redis&quot; class=&quot;headerlink&quot; title=&quot;安装Redis&quot;&gt;&lt;/a&gt;安装Redis&lt;/h2&gt;&lt;p&gt;我这里安装的版本是 3.2.2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 ~]# yum install readline-devel pcre-devel openssl-devel -y
[root@log2 local]# tar zxf redis-3.2.2.tar.gz 
[root@log2 local]# cd redis-3.2.2/
[root@log2 redis-3.2.2]# make
[root@log2 redis-3.2.2]# make install
&lt;/code&gt;&lt;/pre&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;配置Redis&quot;&gt;&lt;a href=&quot;#配置Redis&quot; class=&quot;headerlink&quot; title=&quot;配置Redis&quot;&gt;&lt;/a&gt;配置Redis&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;[root@log2 redis-3.2.2]# cp redis.conf /etc/
[root@log2 redis-3.2.2]# vim /etc/redis.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;1.配置redis后台启动&lt;/strong&gt;&lt;br&gt;打开/etc/redis.conf，将daemonize处修改为yes。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;################################# GENERAL #####################################

# By default Redis does not run as a daemon. Use &amp;apos;yes&amp;apos; if you need it.
# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.
daemonize yes
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.配置Redis持久化策略&lt;/strong&gt;&lt;br&gt;使用RDB和AOF双持久化策略：其中默认开启了RDB持久化，我们只需要开启AOF持久化。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# AOF and RDB persistence can be enabled at the same time without problems.
# If the AOF is enabled on startup Redis will load the AOF, that is the file
# with the better durability guarantees.
#
# Please check http://redis.io/topics/persistence for more information.

appendonly yes
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3.配置redis日志文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Specify the log file name. Also the empty string can be used to force
# Redis to log on the standard output. Note that if you use standard
# output for logging but daemonize, logs will be sent to /dev/null
logfile &amp;quot;/var/log/redis.log&amp;quot;   
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;4.配置数据文件存放路径，在/目录下面创建/RedisData目录&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 redis-3.2.2]# mkdir /RedisData

 # The working directory.
#
# The DB will be written inside this directory, with the filename specified
# above using the &amp;apos;dbfilename&amp;apos; configuration directive.
#
# The Append Only File will also be created inside this directory.
#
# Note that you must specify a directory here, not a file name.
dir /RedisData
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;5.修改Redis监听地址&lt;/strong&gt;&lt;br&gt;注释掉 #bind 127.0.0.1&lt;br&gt;否则redis只会监听在127.0.0.1的某个端口上。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6.修改Redis监听端口&lt;/strong&gt;&lt;br&gt;为了安全，强烈建议修改redis的监听端口。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Accept connections on the specified port, default is 6379 (IANA #815344).
# If port 0 is specified Redis will not listen on a TCP socket.
port 6400
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;7.在redis3.2之后，redis增加了protected-mode，在这个模式下，即使注释掉了bind 127.0.0.1，再访问redis的时候还是报错，所以要如下设置：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# By default protected mode is enabled. You should disable it only if
# you are sure you want clients from other hosts to connect to Redis
# even if no authentication is configured, nor a specific set of interfaces
# are explicitly listed using the &amp;quot;bind&amp;quot; directive.
protected-mode no
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;启动-停止&quot;&gt;&lt;a href=&quot;#启动-停止&quot; class=&quot;headerlink&quot; title=&quot;启动/停止&quot;&gt;&lt;/a&gt;启动/停止&lt;/h2&gt;&lt;p&gt;1.启动&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 ~]# /usr/local/bin/redis-server /etc/redis.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.停止&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 ~]# /usr/local/redis-3.2.2/src/redis-cli -p 6400 shutdown
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Redis简单使用&quot;&gt;&lt;a href=&quot;#Redis简单使用&quot; class=&quot;headerlink&quot; title=&quot;Redis简单使用&quot;&gt;&lt;/a&gt;Redis简单使用&lt;/h2&gt;&lt;h3 id=&quot;使用客户端连接redis-server&quot;&gt;&lt;a href=&quot;#使用客户端连接redis-server&quot; class=&quot;headerlink&quot; title=&quot;使用客户端连接redis-server&quot;&gt;&lt;/a&gt;使用客户端连接redis-server&lt;/h3&gt;&lt;p&gt;在Redis的安装目录中有redis客户端，即redis-cli（Redis Command Line Interface），它是Redis自带的基于命令行的Redis的客户端。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /usr/local/bin/
# ./redis-cli -h 172.16.206.30 -p 6400
172.16.206.30:6400&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;向Redis服务器发送命令&quot;&gt;&lt;a href=&quot;#向Redis服务器发送命令&quot; class=&quot;headerlink&quot; title=&quot;向Redis服务器发送命令&quot;&gt;&lt;/a&gt;向Redis服务器发送命令&lt;/h3&gt;&lt;p&gt;redis-cli连上redis服务后，可以在命令行发送命令。&lt;br&gt;&lt;strong&gt;1.ping，测试客户端与redis的连接是否正常，如果正常会收到回复PONG&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ./redis-cli -h 172.16.206.30 -p 6400
172.16.206.30:6400&amp;gt; ping
PONG
172.16.206.30:6400&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.set/get，使用set和get可以向redis设置数据、获取数据&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;172.16.206.30:6400&amp;gt; set name wisedu
OK
172.16.206.30:6400&amp;gt; get name
&amp;quot;wisedu&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3.del，删除指定key的内容&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;172.16.206.30:6400&amp;gt; del name
(integer) 1
172.16.206.30:6400&amp;gt; get name
(nil)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;4.keys *，查看当前库中所有的key&lt;/strong&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;安装Redis&quot;&gt;&lt;a href=&quot;#安装Redis&quot; class=&quot;headerlink&quot; title=&quot;安装Redis&quot;&gt;&lt;/a&gt;安装Redis&lt;/h2&gt;&lt;p&gt;我这里安装的版本是 3.2.2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@log2 ~]# yum install readline-devel pcre-devel openssl-devel -y
[root@log2 local]# tar zxf redis-3.2.2.tar.gz 
[root@log2 local]# cd redis-3.2.2/
[root@log2 redis-3.2.2]# make
[root@log2 redis-3.2.2]# make install
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="NoSQL" scheme="http://yoursite.com/categories/NoSQL/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Python操作InfluxDB</title>
    <link href="http://yoursite.com/2017/12/20/Python%E6%93%8D%E4%BD%9CInfluxDB/"/>
    <id>http://yoursite.com/2017/12/20/Python操作InfluxDB/</id>
    <published>2017-12-20T11:50:06.000Z</published>
    <updated>2017-12-22T13:13:55.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;InfluxDB-API-Client-Libraries&quot;&gt;&lt;a href=&quot;#InfluxDB-API-Client-Libraries&quot; class=&quot;headerlink&quot; title=&quot;InfluxDB API Client Libraries&quot;&gt;&lt;/a&gt;InfluxDB API Client Libraries&lt;/h2&gt;&lt;p&gt;上一篇文章介绍了安装部署InfluxDB和它的一些基本概念，接着就得来处理Nginx access.log，并将处理结果存储在InfluxDB中。&lt;br&gt;InfluxDB支持多种语言使用其客户端库来进行交互，具体参见官方文档：&lt;br&gt;&lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.4/tools/api_client_libraries/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://docs.influxdata.com/influxdb/v1.4/tools/api_client_libraries/&lt;/a&gt;&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;我这里使用Python语言来处理Nginx access.log并将结果存储于InfluxDB中。&lt;/p&gt;
&lt;h2 id=&quot;下载安装模块influxdb&quot;&gt;&lt;a href=&quot;#下载安装模块influxdb&quot; class=&quot;headerlink&quot; title=&quot;下载安装模块influxdb&quot;&gt;&lt;/a&gt;下载安装模块influxdb&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;# pip install influxdb
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;编写代码&quot;&gt;&lt;a href=&quot;#编写代码&quot; class=&quot;headerlink&quot; title=&quot;编写代码&quot;&gt;&lt;/a&gt;编写代码&lt;/h2&gt;&lt;p&gt;Nginx access.log的一行日志如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;line =&amp;apos;res.wisedu.com 172.16.6.4 [20/Dec/2017:09:20:17 +0800] &amp;quot;GET /statistics/res?/bh_apis/1.0/module-bhMenu.html&amp;amp;callback=__jp0 HTTP/1.1&amp;quot; 200 0 &amp;quot;-&amp;quot; &amp;quot;Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)&amp;quot; 0.000 -&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# -*- coding: utf-8 -*-

import re
from influxdb import InfluxDBClient

def read_log(path): # 生成器generator
    &amp;apos;&amp;apos;&amp;apos;一行一行读取日志并返回&amp;apos;&amp;apos;&amp;apos;
    with open(path) as f:
        yield from f

def write_influxDB(lst):
    &amp;apos;&amp;apos;&amp;apos;写入InfluxDB数据库&amp;apos;&amp;apos;&amp;apos;
    client.write_points(lst)

def regular_line(line):
    &amp;apos;&amp;apos;&amp;apos;利用正则分析一行日志，存于字典中&amp;apos;&amp;apos;&amp;apos;
    o = re.compile(pattern)
    m = o.search(line)
    field_dict = m.groupdict()

    return field_dict

def main():
    &amp;apos;&amp;apos;&amp;apos;主函数&amp;apos;&amp;apos;&amp;apos;
    for line in read_log(path):
        field_dict = regular_line(line)
        lst = []
        point_dict = {}
        point_dict[&amp;apos;measurement&amp;apos;] = &amp;apos;res_access_log&amp;apos;
        point_dict[&amp;apos;fields&amp;apos;] = field_dict
        lst.append(point_dict)

        write_influxDB(lst)

if __name__ == &amp;apos;__main__&amp;apos;:
    pattern = &amp;apos;(?P&amp;lt;host&amp;gt;[\w+\.]+\w+) (?P&amp;lt;ip&amp;gt;\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}) \[(?P&amp;lt;time_local&amp;gt;.*)\]&amp;apos;
    pattern += &amp;apos; &amp;quot;(?P&amp;lt;method&amp;gt;\w+) (?P&amp;lt;url&amp;gt;[^\s]*) (?P&amp;lt;version&amp;gt;[\w\/\d\.]*)&amp;quot; (?P&amp;lt;status&amp;gt;\d+) (?P&amp;lt;length&amp;gt;\d+)&amp;apos;
    pattern += &amp;apos; &amp;quot;(?P&amp;lt;http_referer&amp;gt;[^\s]*)&amp;quot; &amp;quot;(?P&amp;lt;ua&amp;gt;.*)&amp;quot; (?P&amp;lt;request_time&amp;gt;[\d\.]*) (?P&amp;lt;upstream_response_time&amp;gt;[\d\.]*)&amp;apos;

    path = &amp;quot;logs/res.statistics.log&amp;quot;
    client = InfluxDBClient(host=&amp;apos;172.16.7.151&amp;apos;, port=8086, username=&amp;apos;root&amp;apos;, password=&amp;apos;wisedu123&amp;apos;, database=&amp;apos;mydb&amp;apos;)

    main()
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Chronograf查看表数据&quot;&gt;&lt;a href=&quot;#Chronograf查看表数据&quot; class=&quot;headerlink&quot; title=&quot;Chronograf查看表数据&quot;&gt;&lt;/a&gt;Chronograf查看表数据&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/TimeSeriesDatabases/7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;InfluxDB-API-Client-Libraries&quot;&gt;&lt;a href=&quot;#InfluxDB-API-Client-Libraries&quot; class=&quot;headerlink&quot; title=&quot;InfluxDB API Client Libraries&quot;&gt;&lt;/a&gt;InfluxDB API Client Libraries&lt;/h2&gt;&lt;p&gt;上一篇文章介绍了安装部署InfluxDB和它的一些基本概念，接着就得来处理Nginx access.log，并将处理结果存储在InfluxDB中。&lt;br&gt;InfluxDB支持多种语言使用其客户端库来进行交互，具体参见官方文档：&lt;br&gt;&lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.4/tools/api_client_libraries/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://docs.influxdata.com/influxdb/v1.4/tools/api_client_libraries/&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="时序数据库" scheme="http://yoursite.com/categories/%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="InfluxDB" scheme="http://yoursite.com/tags/InfluxDB/"/>
    
  </entry>
  
  <entry>
    <title>时序数据库InfluxDB</title>
    <link href="http://yoursite.com/2017/12/15/%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93InfluxDB/"/>
    <id>http://yoursite.com/2017/12/15/时序数据库InfluxDB/</id>
    <published>2017-12-15T14:00:36.000Z</published>
    <updated>2018-01-10T07:55:24.000Z</updated>
    
    <content type="html">&lt;blockquote&gt;
&lt;p&gt;最近帮助公司前端小伙伴处理他们的nginx访问日志，log的数据是半结构化的数据，同时也是典型的时序数据，每一条数据都带有时间戳。于是考虑使用时间序列数据库存储，而不会去使用mysql或是mongodb(zabbix用的是mysql，它在IO上面遇到了瓶颈)。现在时间序列的数据库是有很多的，比如graphite、opentsdb以及新生的influxdb。这次我使用了InfluxDB，在此记录下学习过程，同时也希望能够帮助到其他学习的同学。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;InfluxDB介绍&quot;&gt;&lt;a href=&quot;#InfluxDB介绍&quot; class=&quot;headerlink&quot; title=&quot;InfluxDB介绍&quot;&gt;&lt;/a&gt;InfluxDB介绍&lt;/h2&gt;&lt;p&gt;什么是时间序列数据？最简单的定义就是数据格式里包含timestamp字段的数据。比如股票市场的价格，环境中的温度，主机的CPU使用率等。但是又有什么数据是不包含timestamp的呢？几乎所有的数据都可以打上一个timestamp字段。时间序列数据更重要的一个属性是如何去查询它。在查询的时候，对于时间序列我们总是会带上一个时间范围去过滤数据。同时查询的结果里也总是会包含timestamp字段。&lt;br&gt;InfluxDB 是一个开源分布式时序、事件和指标数据库。使用 Go 语言编写，无需外部依赖。其设计目标是实现分布式和水平伸缩扩展。&lt;br&gt;它有三大特性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Time Series （时间序列）：你可以使用与时间有关的相关函数（如最大，最小，求和等）&lt;/li&gt;
&lt;li&gt;Metrics（度量）：你可以实时对大量数据进行计算&lt;/li&gt;
&lt;li&gt;Eevents（事件）：它支持任意的事件数据&lt;br&gt;特点：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;schemaless(无结构)，可以是任意数量的列&lt;/li&gt;
&lt;li&gt;min, max, sum, count, mean, median 一系列函数，方便统计&lt;/li&gt;
&lt;li&gt;Native HTTP API, 内置http支持，使用http读写&lt;/li&gt;
&lt;li&gt;Powerful Query Language 类似sql&lt;/li&gt;
&lt;li&gt;Built-in Explorer 自带web管理界面。（从1.4版本开始去除了自带的web管理界面）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;安装部署InfluxDB&quot;&gt;&lt;a href=&quot;#安装部署InfluxDB&quot; class=&quot;headerlink&quot; title=&quot;安装部署InfluxDB&quot;&gt;&lt;/a&gt;安装部署InfluxDB&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;influxdb下载地址：&lt;/strong&gt;&lt;br&gt;&lt;a href=&quot;https://portal.influxdata.com/downloads&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://portal.influxdata.com/downloads&lt;/a&gt;&lt;br&gt;&lt;strong&gt;influxdb文档：&lt;/strong&gt;&lt;br&gt;&lt;a href=&quot;http://docs.influxdata.com/influxdb/v1.4/introduction/getting_started/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://docs.influxdata.com/influxdb/v1.4/introduction/getting_started/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.下载安装&lt;/strong&gt;&lt;br&gt;对于在不同操作系统上安装，官网都有说明，我这里使用的是CentOS 7。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/TimeSeriesDatabases/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/TimeSeriesDatabases/2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@docdesginer local]# wget https://dl.influxdata.com/influxdb/releases/influxdb-1.4.2.x86_64.rpm
[root@docdesginer local]# yum localinstall influxdb-1.4.2.x86_64.rpm
[root@docdesginer local]# rpm -ql influxdb
/etc/influxdb/influxdb.conf
/etc/logrotate.d/influxdb
/usr/bin/influx
/usr/bin/influx_inspect
/usr/bin/influx_stress
/usr/bin/influx_tsm
/usr/bin/influxd
/usr/lib/influxdb/scripts/influxdb.service
/usr/lib/influxdb/scripts/init.sh
/usr/share/man/man1/influx.1.gz
/usr/share/man/man1/influx_inspect.1.gz
/usr/share/man/man1/influx_stress.1.gz
/usr/share/man/man1/influx_tsm.1.gz
/usr/share/man/man1/influxd-backup.1.gz
/usr/share/man/man1/influxd-config.1.gz
/usr/share/man/man1/influxd-restore.1.gz
/usr/share/man/man1/influxd-run.1.gz
/usr/share/man/man1/influxd-version.1.gz
/usr/share/man/man1/influxd.1.gz
/var/lib/influxdb
/var/log/influxdb
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.启动&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@docdesginer local]# systemctl start influxdb 
[root@docdesginer local]# systemctl status influxdb
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3.登录&lt;/strong&gt;&lt;br&gt;客户端工具：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@docdesginer local]# /usr/bin/influx
Connected to http://localhost:8086 version 1.4.2
InfluxDB shell version: 1.4.2
&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看数据库：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; SHOW DATABASES
name: databases
name
----
_internal
&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;HTTP API访问：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@docdesginer ~]# curl -G http://localhost:8086/query --data-urlencode &amp;quot;q=SHOW DATABASES&amp;quot;
{&amp;quot;results&amp;quot;:[{&amp;quot;statement_id&amp;quot;:0,&amp;quot;series&amp;quot;:[{&amp;quot;name&amp;quot;:&amp;quot;databases&amp;quot;,&amp;quot;columns&amp;quot;:[&amp;quot;name&amp;quot;],&amp;quot;values&amp;quot;:[[&amp;quot;_internal&amp;quot;]]}]}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此时数据库中还有没有用户，还没开启认证。&lt;/p&gt;
&lt;h2 id=&quot;开启认证&quot;&gt;&lt;a href=&quot;#开启认证&quot; class=&quot;headerlink&quot; title=&quot;开启认证&quot;&gt;&lt;/a&gt;开启认证&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.创建管理员&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@docdesginer local]# /usr/bin/influx
Connected to http://localhost:8086 version 1.4.2
InfluxDB shell version: 1.4.2
&amp;gt; CREATE USER root WITH PASSWORD &amp;apos;wisedu123&amp;apos; WITH ALL PRIVILEGES
&amp;gt; quit
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.修改配置文件，开启认证&lt;/strong&gt;&lt;br&gt;By default, authentication is disabled in the configuration file. Enable authentication by setting the auth-enabled option to true in the [http] section of the configuration file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[http]  
  enabled = true  
  bind-address = &amp;quot;:8086&amp;quot;  
  auth-enabled = true 
  log-enabled = true  
  write-tracing = false  
  pprof-enabled = false  
  https-enabled = false  
  https-certificate = &amp;quot;/etc/ssl/influxdb.pem&amp;quot; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重启InfluxDB：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@docdesginer ~]# systemctl restart influxdb 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3.再次登录&lt;/strong&gt;&lt;br&gt;客户端工具连接数据库：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@docdesginer ~]# influx
Connected to http://localhost:8086 version 1.4.2
InfluxDB shell version: 1.4.2
&amp;gt; show databases;
ERR: unable to parse authentication credentials
Warning: It is possible this error is due to not setting a database.
Please set a database with the command &amp;quot;use &amp;lt;database&amp;gt;&amp;quot;.
&amp;gt;

[root@docdesginer ~]# /usr/bin/influx
Connected to http://localhost:8086 version 1.4.2
InfluxDB shell version: 1.4.2
&amp;gt; auth
username: root
password: 
&amp;gt; show databases;
name: databases
name
----
_internal
&amp;gt; 
或者
[root@docdesginer ~]# /usr/bin/influx -username root -password wisedu123 -precision rfc3339 
Connected to http://localhost:8086 version 1.4.2
InfluxDB shell version: 1.4.2
&amp;gt; show databases;
name: databases
name
----
_internal
&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;HTTP API：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@docdesginer ~]# curl -G http://localhost:8086/query --data-urlencode &amp;quot;q=SHOW DATABASES&amp;quot;                  
{&amp;quot;error&amp;quot;:&amp;quot;unable to parse authentication credentials&amp;quot;}
[root@docdesginer ~]# curl -G http://localhost:8086/query -u root:wisedu123 --data-urlencode &amp;quot;q=SHOW DATABASES&amp;quot;
{&amp;quot;results&amp;quot;:[{&amp;quot;statement_id&amp;quot;:0,&amp;quot;series&amp;quot;:[{&amp;quot;name&amp;quot;:&amp;quot;databases&amp;quot;,&amp;quot;columns&amp;quot;:[&amp;quot;name&amp;quot;],&amp;quot;values&amp;quot;:[[&amp;quot;_internal&amp;quot;]]}]}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;InfluxDB概念&quot;&gt;&lt;a href=&quot;#InfluxDB概念&quot; class=&quot;headerlink&quot; title=&quot;InfluxDB概念&quot;&gt;&lt;/a&gt;InfluxDB概念&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.influxdb相关名词（可类比关系型数据库）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;database：数据库。&lt;/li&gt;
&lt;li&gt;measurement：数据库中的表。它就是tag，field，time的容器；对于influxDB的measurement来说，field是必须的，并且不能根据field来排序；Tag是可选的，tag可以用来做索引，tag是以字符串的形式存放的。&lt;/li&gt;
&lt;li&gt;points：表里面的一行数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.influxDB中独有的概念&lt;/strong&gt;&lt;br&gt;（1）Point由时间戳（time）、数据（field）和标签（tags）组成。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;time：每条数据记录的时间，也是数据库自动生成的主索引；&lt;/li&gt;
&lt;li&gt;fields：各种记录的值；&lt;/li&gt;
&lt;li&gt;tags：各种有索引的属性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;InfluxDb不需要做schema定义，这意味着你可以随意的添加measurements, tags, and fields at any time。&lt;/p&gt;
&lt;p&gt;（2）series&lt;br&gt;a series is the collection of data that share a retention policy, measurement, and tag set&lt;br&gt;所有在数据库中的数据，都需要通过图表来展示，而这个series表示这个表里面的数据，可以在图表上画成几条线：通过tags排列组合算出来。&lt;br&gt;其实一个series就是一个测点，或者说一条曲线，那么retention policy, measurement, tagset就共同组成了一个定位测点序列的唯一标识。&lt;br&gt;point，就是某个series的同一个时刻的多个field的value，就组成了一个point；其实就是一条曲线上的一个点。&lt;/p&gt;
&lt;p&gt;（3）retention policy&lt;br&gt;保留策略，用于决定要保留多久的数据，保存几个备份，以及集群的策略等。&lt;/p&gt;
&lt;h2 id=&quot;InfluxDB基本操作&quot;&gt;&lt;a href=&quot;#InfluxDB基本操作&quot; class=&quot;headerlink&quot; title=&quot;InfluxDB基本操作&quot;&gt;&lt;/a&gt;InfluxDB基本操作&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;连接数据库：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@docdesginer ~]# /usr/bin/influx -username root -password wisedu123 -precision rfc3339   
Connected to http://localhost:8086 version 1.4.2
InfluxDB shell version: 1.4.2
&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里的-precision参数指定了时间戳的格式为rfc3339，也可以不使用该参数。&lt;br&gt;&lt;strong&gt;查看数据库：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; SHOW DATABASES
name: databases
name
----
_internal
&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;创建数据库：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; CREATE DATABASE mydb
&amp;gt; SHOW DATABASES
name: databases
name
----
_internal
mydb
&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;进入数据库：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; USE mydb
Using database mydb
&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;插入数据：&lt;/strong&gt;&lt;br&gt;influxDB存储数据采用的是Line Protocol格式。&lt;br&gt;Line Protocol格式：写入数据库的Point的固定格式。格式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;measurement&amp;gt;[,&amp;lt;tag-key&amp;gt;=&amp;lt;tag-value&amp;gt;...] &amp;lt;field-key&amp;gt;=&amp;lt;field-value&amp;gt;[,&amp;lt;field2-key&amp;gt;=&amp;lt;field2-value&amp;gt;...] [unix-nano-timestamp]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;weather,location=us-midwest temperature=82 1465839830100400200
  |    -------------------- --------------  |
  |             |             |             |
  |             |             |             |
+-----------+--------+-+---------+-+---------+
|measurement|,tag_set| |field_set| |timestamp|
+-----------+--------+-+---------+-+---------+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【注意】：最后的timestamp是 unix时间戳*1000000000 的值，或者使用 %Y-%m-%dT%H:%M:%SZ 这种格式。使用其他格式在插入时会报错。&lt;/p&gt;
&lt;p&gt;示例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; INSERT cpu,host=serverA,region=us_west value=0.64
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cpu是表名&lt;/li&gt;
&lt;li&gt;host=serverA,region=us_west 是tag&lt;/li&gt;
&lt;li&gt;value=0.64是field&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;想对此格式有详细的了解参见&lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.4/write_protocols/line_protocol_tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;查询数据：&lt;/strong&gt;&lt;br&gt;influxDB是支持类sql语句的，具体的查询语法都差不多。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; select * from cpu
name: cpu
time                           host    region  value
----                           ----    ------  -----
2017-12-15T13:17:09.660446488Z serverA us_west 0.64
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【注意】：InfluxDB集群功能已经不再开源。要想使用集群服务需要购买企业版。开源版和企业版的主要区别就是企业版的InfluxDB支持集群，而开源版不支持，此外企业版提供了先进的备份/恢复功能，而开源版本没有。但InfluxDB单机版性能也足够支撑中小公司的业务了。&lt;/p&gt;
&lt;h2 id=&quot;InfluxDB数据保存策略（Retention-Policies）&quot;&gt;&lt;a href=&quot;#InfluxDB数据保存策略（Retention-Policies）&quot; class=&quot;headerlink&quot; title=&quot;InfluxDB数据保存策略（Retention Policies）&quot;&gt;&lt;/a&gt;InfluxDB数据保存策略（Retention Policies）&lt;/h2&gt;&lt;p&gt;InfluxDB每秒可以处理成千上万条数据，要将这些数据全部保存下来会占用大量的存储空间，有时我们可能并不需要将所有历史数据进行存储，因此，InfluxDB推出了数据保留策略（Retention Policies），用来让我们自定义数据的保留时间。&lt;br&gt;InfluxDB的数据保留策略（RP） 用来定义数据在InfluxDB中存放的时间，或者定义保存某个期间的数据。&lt;br&gt;一个数据库可以有多个保留策略，但每个策略必须是独一无二的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.查询策略&lt;/strong&gt;&lt;br&gt;可以通过如下语句查看数据库的现有策略：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; SHOW RETENTION POLICIES ON mydb
name    duration shardGroupDuration replicaN default
----    -------- ------------------ -------- -------
autogen 0s       168h0m0s           1        true
&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【说明】：数据库mydb只有一个策略，各字段的含义如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;name：名称，此示例名称为 autogen。当你创建一个数据库的时候，InfluxDB会自动为数据库创建一个名叫 autogen 的策略，这个策略会永久保存数据。你可以重命名这个策略，并且在InfluxDB的配置文件中禁止掉自动创建策略。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;duration：数据保存时间，0代表无限制&lt;/li&gt;
&lt;li&gt;shardGroupDuration：shardGroup的存储时间，shardGroup是InfluxDB的一个基本储存结构。&lt;/li&gt;
&lt;li&gt;replicaN：全称是REPLICATION，副本个数&lt;/li&gt;
&lt;li&gt;default：是否是默认策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里有两个概念：&lt;br&gt;&lt;strong&gt;shard：&lt;/strong&gt;&lt;br&gt;    shard 在 InfluxDB 中是一个比较重要的概念，它和 retention policy 相关联。每一个存储策略下会存在许多 shard，每一个 shard 存储一个指定时间段内的数据，并且不重复，例如 7点-8点 的数据落入 shard0 中，8点-9点的数据则落入 shard1 中。每一个 shard 都对应一个底层的 tsm 存储引擎，有独立的 cache、wal、tsm file。&lt;br&gt;创建数据库时会自动创建一个默认存储策略，永久保存数据，对应的在此存储策略下的 shard 所保存的数据的时间段为 7 天，也就是上面查询时看到的168h。计算的函数如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func shardGroupDuration(d time.Duration) time.Duration {
    if d &amp;gt;= 180*24*time.Hour || d == 0 { // 6 months or 0
        return 7 * 24 * time.Hour
    } else if d &amp;gt;= 2*24*time.Hour { // 2 days
        return 1 * 24 * time.Hour
    }
    return 1 * time.Hour
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果创建一个新的 retention policy 设置数据的保留时间为 1 天，则单个 shard 所存储数据的时间间隔为 1 小时，超过1个小时的数据会被存放到下一个 shard 中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;shard group：&lt;/strong&gt;&lt;br&gt;    shard group是shards的逻辑容器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.创建策略&lt;/strong&gt;&lt;br&gt;语法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE RETENTION POLICY &amp;lt;retention_policy_name&amp;gt; ON &amp;lt;database_name&amp;gt; DURATION &amp;lt;duration&amp;gt; REPLICATION &amp;lt;n&amp;gt; [SHARD DURATION &amp;lt;duration&amp;gt;] [DEFAULT]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中：SHARD DURATION子句决定了每个shard group存储的时间间隔，在永久存储的策略里这个子句是无效的。这个子句是可选的。shard group duration默认由策略的 duration 决定。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Retention Policy’s DURATION&lt;/th&gt;
&lt;th&gt;Shard Group Duration&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&amp;lt; 2 days&lt;/td&gt;
&lt;td&gt;1 hour&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&amp;gt;= 2 days and &amp;lt;= 6 months&lt;/td&gt;
&lt;td&gt;1 day&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&amp;gt; 6 months&lt;/td&gt;
&lt;td&gt;7 days&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;示例1：为数据库mydb创建一个策略&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE RETENTION POLICY &amp;quot;one_day_only&amp;quot; ON &amp;quot;mydb&amp;quot; DURATION 1d REPLICATION 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;示例2：为数据库mydb创建一个默认策略。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE RETENTION POLICY &amp;quot;one_day_only&amp;quot; ON &amp;quot;mydb&amp;quot; DURATION 23h60m REPLICATION 1 DEFAULT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3.修改策略&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ALTER RETENTION POLICY &amp;lt;retention_policy_name&amp;gt; ON &amp;lt;database_name&amp;gt; DURATION &amp;lt;duration&amp;gt; REPLICATION &amp;lt;n&amp;gt; SHARD DURATION &amp;lt;duration&amp;gt; DEFAULT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;4.删除策略&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DROP RETENTION POLICY &amp;lt;retention_policy_name&amp;gt; ON &amp;lt;database_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【注意】：策略这个关键词“POLICY”在使用是应该大写，小写应该会出错。&lt;br&gt;当一个表使用的策略不是默认策略时，在进行操作时一定要显式的指定策略名称，否则会出现错误。&lt;/p&gt;
&lt;h2 id=&quot;Chronograf介绍&quot;&gt;&lt;a href=&quot;#Chronograf介绍&quot; class=&quot;headerlink&quot; title=&quot;Chronograf介绍&quot;&gt;&lt;/a&gt;Chronograf介绍&lt;/h2&gt;&lt;p&gt;Influxdb在1.3以后版本已经关闭了内置的8086的web管理功能，需要单独的工具来管理。而这个工具就是Chronograf。&lt;br&gt;其实Chronograf是TICK技术栈的一个组成部分。TICK是InfluxdDB公司推出的监控套件，承包指标采集、分析、画图等时序数据库上下游的工作，有点模仿日志分析系统ELK套件的意思。TICK包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;T = Telegraf is a plugin-driven server agent for collecting and reporting metrics.&lt;/li&gt;
&lt;li&gt;I = InfluxDB is a time series database built from the ground up to handle high write and query loads.&lt;/li&gt;
&lt;li&gt;C = Chronograf is a graphing and visualization application for performing ad hoc exploration of data.&lt;/li&gt;
&lt;li&gt;K = Kapacitor is a data processing framework proving alerting, anomaly detection and action frameworks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也就是说：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Telegraf：数据采集&lt;/li&gt;
&lt;li&gt;InfluxDB：数据接收和存储&lt;/li&gt;
&lt;li&gt;Chronograf：数据汇总展示，报警等。&lt;/li&gt;
&lt;li&gt;Kapacitor：数据处理，比如监控策略等&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;安装Chronograf&quot;&gt;&lt;a href=&quot;#安装Chronograf&quot; class=&quot;headerlink&quot; title=&quot;安装Chronograf&quot;&gt;&lt;/a&gt;安装Chronograf&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.安装部署&lt;/strong&gt;&lt;br&gt;下载地址：&lt;a href=&quot;https://portal.influxdata.com/downloads&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://portal.influxdata.com/downloads&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/TimeSeriesDatabases/3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@docdesginer local]# wget https://dl.influxdata.com/chronograf/releases/chronograf-1.3.10.0.x86_64.rpm
[root@docdesginer local]# yum localinstall chronograf-1.3.10.0.x86_64.rpm
[root@docdesginer local]# rpm -ql chronograf
/etc/logrotate.d/chronograf
/usr/bin/chronograf
/usr/lib/chronograf/scripts/chronograf.service
/usr/lib/chronograf/scripts/init.sh
/usr/share/chronograf/canned/apache.json
/usr/share/chronograf/canned/consul.json
/usr/share/chronograf/canned/consul_agent.json
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2.启动&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@docdesginer local]# systemctl start chronograf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3.访问Chronograf&lt;/strong&gt;&lt;br&gt;浏览器输入&lt;a href=&quot;http://IP:8888&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://IP:8888&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/TimeSeriesDatabases/4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;查询：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/TimeSeriesDatabases/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/TimeSeriesDatabases/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在查询时，最好数据库名和表名都加上引号。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;最近帮助公司前端小伙伴处理他们的nginx访问日志，log的数据是半结构化的数据，同时也是典型的时序数据，每一条数据都带有时间戳。于是考虑使用时间序列数据库存储，而不会去使用mysql或是mongodb(zabbix用的是mysql，它在IO上面遇到了瓶颈)。现在时间序列的数据库是有很多的，比如graphite、opentsdb以及新生的influxdb。这次我使用了InfluxDB，在此记录下学习过程，同时也希望能够帮助到其他学习的同学。&lt;br&gt;
    
    </summary>
    
      <category term="时序数据库" scheme="http://yoursite.com/categories/%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="InfluxDB" scheme="http://yoursite.com/tags/InfluxDB/"/>
    
  </entry>
  
  <entry>
    <title>nexus搭建maven私服</title>
    <link href="http://yoursite.com/2017/11/19/nexus%E6%90%AD%E5%BB%BAmaven%E7%A7%81%E6%9C%8D/"/>
    <id>http://yoursite.com/2017/11/19/nexus搭建maven私服/</id>
    <published>2017-11-19T06:49:41.000Z</published>
    <updated>2017-11-19T08:06:13.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;为什么要搭建私服&quot;&gt;&lt;a href=&quot;#为什么要搭建私服&quot; class=&quot;headerlink&quot; title=&quot;为什么要搭建私服&quot;&gt;&lt;/a&gt;为什么要搭建私服&lt;/h2&gt;&lt;p&gt;私服不是Maven的核心概念，它仅仅是一种衍生出来的特殊的Maven仓库。通过建立自己的私服，就可以降低中央仓库负荷、节省外网带宽、加速Maven构建、自己部署构建等，从而高效地使用Maven。Nexus也是当前最流行的Maven仓库管理软件。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;下载Nexus&quot;&gt;&lt;a href=&quot;#下载Nexus&quot; class=&quot;headerlink&quot; title=&quot;下载Nexus&quot;&gt;&lt;/a&gt;下载Nexus&lt;/h2&gt;&lt;p&gt;最新nexus下载地址：&lt;a href=&quot;http://www.sonatype.org/nexus/go&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.sonatype.org/nexus/go&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Maven/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Nexus是典型的Java Web应用，它有两种安装包，一种是包含Jetty容器的Bundle包，另一种是不包含Web容器的war包。&lt;/p&gt;
&lt;h2 id=&quot;安装Nexus&quot;&gt;&lt;a href=&quot;#安装Nexus&quot; class=&quot;headerlink&quot; title=&quot;安装Nexus&quot;&gt;&lt;/a&gt;安装Nexus&lt;/h2&gt;&lt;h3 id=&quot;安装JDK1-8&quot;&gt;&lt;a href=&quot;#安装JDK1-8&quot; class=&quot;headerlink&quot; title=&quot;安装JDK1.8&quot;&gt;&lt;/a&gt;安装JDK1.8&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;# mkdir /usr/java
# tar zxf /usr/local/jdk-8u73-linux-x64.gz -C /usr/java/
# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.8.0_73
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装Nexus-1&quot;&gt;&lt;a href=&quot;#安装Nexus-1&quot; class=&quot;headerlink&quot; title=&quot;安装Nexus&quot;&gt;&lt;/a&gt;安装Nexus&lt;/h3&gt;&lt;p&gt;上传Nexus安装包到/opt目录下。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@hadoop33 opt]# mkdir nexus
[root@hadoop33 opt]# tar zxf nexus-2.14.0-01-bundle.tar.gz -C /opt/nexus
[root@hadoop33 opt]# cd nexus/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Maven/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;nexus-2.6.2-01: 该目录包含了Nexus运行所需要的文件，如启动脚本、依赖jar包等。&lt;br&gt;sonatype-work：该目录包含Nenus生成的配置文件、日志文件、仓库文件等。&lt;br&gt;其中第一个目录是运行Nexus必须的，而第二个不是必须的，Nexus会在运行的时候动态创建该目录。&lt;/p&gt;
&lt;h3 id=&quot;启动Nexus&quot;&gt;&lt;a href=&quot;#启动Nexus&quot; class=&quot;headerlink&quot; title=&quot;启动Nexus&quot;&gt;&lt;/a&gt;启动Nexus&lt;/h3&gt;&lt;p&gt;默认端口为8081，如需修改请查看配置文件 conf/nexus.properties&lt;br&gt;它本身不建议在root用户下使用，如果我们需要在root用户下启动服务，要先配置 bin/nexus 文件中的 RUN_AS_USER=root&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Maven/3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@hadoop33 nexus]# cd nexus-2.14.0-01/bin/
[root@hadoop33 bin]# ./nexus start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Maven/4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;停止-Nexus&quot;&gt;&lt;a href=&quot;#停止-Nexus&quot; class=&quot;headerlink&quot; title=&quot;停止 Nexus&quot;&gt;&lt;/a&gt;停止 Nexus&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@hadoop33 bin]# ./nexus stop
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;访问&quot;&gt;&lt;a href=&quot;#访问&quot; class=&quot;headerlink&quot; title=&quot;访问&quot;&gt;&lt;/a&gt;访问&lt;/h2&gt;&lt;p&gt;启动后访问首页： &lt;a href=&quot;http://172.16.206.33:8081/nexus/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.206.33:8081/nexus/index.html&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Maven/5.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击右上角的Login in&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Maven/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;登录默认账号/密码 admin/admin123。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如何修改 nexus 账号密码：&lt;/strong&gt;先停止 nexus，打开 %NEXUS_HOME%/sonatype-work/nexus/conf/security.xml，修改即可。&lt;br&gt;nexus 的密码采用 SHA1 加密算法 ( 在线加密工具 )，将加密后的 SHA1 串（小写）拷贝覆盖原来的。重启 nexus：./nexus restart。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Maven/7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;配置Nexus&quot;&gt;&lt;a href=&quot;#配置Nexus&quot; class=&quot;headerlink&quot; title=&quot;配置Nexus&quot;&gt;&lt;/a&gt;配置Nexus&lt;/h2&gt;&lt;p&gt;Nexus常用功能就是：指定私服的中央地址、将自己的Maven项目指定到私服地址、从私服下载中央库的项目索引、从私服仓库下载依赖组件、将第三方项目jar上传到私服供其他项目组使用。&lt;br&gt;登录&lt;a href=&quot;http://172.16.206.33:8081/nexus/index.html，点击左侧菜单栏的“Repositories”。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.206.33:8081/nexus/index.html，点击左侧菜单栏的“Repositories”。&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Maven/8.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;一般用到的仓库种类是hosted、proxy。Hosted代表宿主仓库，用来发布一些第三方不允许的组件，比如oracle驱动、比如商业软件jar包。Proxy代表代理远程的仓库，最典型的就是Maven官方中央仓库、JBoss仓库等等。如果构建的Maven项目本地仓库没有依赖包，那么就会去这个代理站点去下载，那么如果代理站点也没有此依赖包，就回去远程中央仓库下载依赖，这些中央仓库就是proxy。代理站点下载成功后再下载至本机。一般情况下Maven这个自带的默认仓库一般情况下已经够大多数项目使用了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hosted   类型的仓库，内部项目的发布仓库&lt;/li&gt;
&lt;li&gt;releases 内部的模块中release模块的发布仓库&lt;/li&gt;
&lt;li&gt;snapshots 发布内部的SNAPSHOT模块的仓库&lt;/li&gt;
&lt;li&gt;3rd party 第三方依赖的仓库，这个数据通常是由内部人员自行下载之后发布上去&lt;/li&gt;
&lt;li&gt;proxy   类型的仓库，从远程中央仓库中寻找数据的仓库&lt;/li&gt;
&lt;li&gt;group   类型的仓库，组仓库用来方便我们开发人员进行设置的仓库&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;maven项目索引&quot;&gt;&lt;a href=&quot;#maven项目索引&quot; class=&quot;headerlink&quot; title=&quot;maven项目索引&quot;&gt;&lt;/a&gt;maven项目索引&lt;/h3&gt;&lt;p&gt;下载Maven项目索引，项目索引是为了使用者能够在私服站点查找依赖使用的功能。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Maven/9.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;保存后后台会运行一个任务，点击菜单栏的Scheduled Tasks选项即可看到有个任务在RUNNING。 下载完成后，Maven索引就可以使用了，在搜索栏输入要搜索的项，就可以查到相关的信息。例如spring-core&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Maven/10.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;就可以检索出它的相关信息，包括怎么配置依赖信息。我们要想使用这个私服仓库，先在项目pom中配置相关私服信息。&lt;/p&gt;
&lt;h2 id=&quot;Maven项目配置&quot;&gt;&lt;a href=&quot;#Maven项目配置&quot; class=&quot;headerlink&quot; title=&quot;Maven项目配置&quot;&gt;&lt;/a&gt;Maven项目配置&lt;/h2&gt;&lt;p&gt;在pom.xml文件中指定仓库：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;repositories&amp;gt;
    &amp;lt;repository&amp;gt;
        &amp;lt;id&amp;gt;nexus&amp;lt;/id&amp;gt;
        &amp;lt;url&amp;gt;http://172.16.206.33:8081/nexus/content/groups/public/&amp;lt;/url&amp;gt;
        &amp;lt;snapshots&amp;gt;&amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt;&amp;lt;/snapshots&amp;gt;
        &amp;lt;releases&amp;gt;&amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt;&amp;lt;/releases&amp;gt;
    &amp;lt;/repository&amp;gt;
&amp;lt;/repositories&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在pom.xml文件中指定插件仓库：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;pluginRepositories&amp;gt;
    &amp;lt;pluginRepository&amp;gt;
        &amp;lt;id&amp;gt;nexus&amp;lt;/id&amp;gt;
        &amp;lt;url&amp;gt;http://172.16.206.33:8081/nexus/content/groups/public/&amp;lt;/url&amp;gt;
        &amp;lt;snapshots&amp;gt;&amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt;&amp;lt;/snapshots&amp;gt;
        &amp;lt;releases&amp;gt;&amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt;&amp;lt;/releases&amp;gt;
    &amp;lt;/pluginRepository&amp;gt;
&amp;lt;/pluginRepositories&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上的配置使得只有本项目才在私服下载组件。这个Maven项目构建的时候会从私服下载相关依赖。&lt;br&gt;上面的配置仅仅是在此项目中生效，对于其他项目还是不起作用。如果相对Maven的其他项目也生效的话。需要修改全局的settings.xml文件。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Maven/11.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;追加激活profile：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;activeProfiles&amp;gt;  
     &amp;lt;activeProfile&amp;gt;central&amp;lt;/activeProfile&amp;gt;  
&amp;lt;/activeProfiles
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;之后所有本机的Maven项目就在私服下载组件。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;为什么要搭建私服&quot;&gt;&lt;a href=&quot;#为什么要搭建私服&quot; class=&quot;headerlink&quot; title=&quot;为什么要搭建私服&quot;&gt;&lt;/a&gt;为什么要搭建私服&lt;/h2&gt;&lt;p&gt;私服不是Maven的核心概念，它仅仅是一种衍生出来的特殊的Maven仓库。通过建立自己的私服，就可以降低中央仓库负荷、节省外网带宽、加速Maven构建、自己部署构建等，从而高效地使用Maven。Nexus也是当前最流行的Maven仓库管理软件。&lt;br&gt;
    
    </summary>
    
      <category term="maven" scheme="http://yoursite.com/categories/maven/"/>
    
    
      <category term="nexus" scheme="http://yoursite.com/tags/nexus/"/>
    
  </entry>
  
  <entry>
    <title>Filebeat日志收集器</title>
    <link href="http://yoursite.com/2017/10/24/Filebeat%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E5%99%A8/"/>
    <id>http://yoursite.com/2017/10/24/Filebeat日志收集器/</id>
    <published>2017-10-24T02:26:16.000Z</published>
    <updated>2017-11-13T07:38:39.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Beats工具&quot;&gt;&lt;a href=&quot;#Beats工具&quot; class=&quot;headerlink&quot; title=&quot;Beats工具&quot;&gt;&lt;/a&gt;Beats工具&lt;/h2&gt;&lt;p&gt;Beats是elastic公司的一款轻量级数据采集产品，它是从packetbeat发展出来的数据收集器系统，它包含了几个子产品：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Packetbeat(用于监控网络流量)&lt;/li&gt;
&lt;li&gt;Filebeat(用于监听日志数据)&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Metricbeat(用于搜集CPU、内存、磁盘的信息以及Nginx、Redis等服务的数据)&lt;/li&gt;
&lt;li&gt;Winlogbeat(用于搜集windows事件日志)&lt;/li&gt;
&lt;li&gt;Heartbeat(用于监控服务的可用性)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Beats可以直接把数据发送给Elasticsearch或者发送给Logstash，然后Logstash发送给Elasticsearch，然后进行后续的数据分析活动。&lt;br&gt;由于他们都是基于libbeat写出来的，提供了统一的数据发送方法，输入配置解析，日志记录框架等功能。所有的beat工具，在配置上基本相同，只是input输入的地方各有差异。&lt;br&gt;如果有其他特殊需求，可以使用Go语言借助libbeat库方便地开发自己的Beat工具，社区中有很多工具可以参考。&lt;/p&gt;
&lt;h2 id=&quot;Logstash和Filebeat&quot;&gt;&lt;a href=&quot;#Logstash和Filebeat&quot; class=&quot;headerlink&quot; title=&quot;Logstash和Filebeat&quot;&gt;&lt;/a&gt;Logstash和Filebeat&lt;/h2&gt;&lt;p&gt;上一篇文章中介绍过，Logstash是跑在JVM上的，需要消耗较多的系统资源，而Filebeat则是一个轻量级的日志采集工具，占用资源更少。我们完全可以在每台机器上安装启动个Filebeat，由Filebeat来采集日志，将数据传输给Redis或者Kafka，然后logstash去获取，利用filter功能过滤分析，然后存储到elasticsearch中。架构图如下：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;hadoop16&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.206.16&lt;/td&gt;
&lt;td&gt;elasticsearch-5.6.3.zip、kibana-5.6.3-linux-x86_64.tar.gz&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;spark32&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.206.32&lt;/td&gt;
&lt;td&gt;logstash-5.6.3.tar.gz、filebeat-5.6.3-linux-x86_64.tar.gz、Nginx&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;osb30&lt;/td&gt;
&lt;td&gt;Redhat 6.5&lt;/td&gt;
&lt;td&gt;172.16.206.30&lt;/td&gt;
&lt;td&gt;redis-3.2.2.tar.gz&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;安装配置Redis&quot;&gt;&lt;a href=&quot;#安装配置Redis&quot; class=&quot;headerlink&quot; title=&quot;安装配置Redis&quot;&gt;&lt;/a&gt;安装配置Redis&lt;/h2&gt;&lt;h3 id=&quot;安装Redis&quot;&gt;&lt;a href=&quot;#安装Redis&quot; class=&quot;headerlink&quot; title=&quot;安装Redis&quot;&gt;&lt;/a&gt;安装Redis&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;# yum install readline-devel pcre-devel openssl-devel -y
# cd /usr/local/
# tar zxf redis-3.2.2.tar.gz 
# cd redis-3.2.2/
# make
# make install
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;配置Redis&quot;&gt;&lt;a href=&quot;#配置Redis&quot; class=&quot;headerlink&quot; title=&quot;配置Redis&quot;&gt;&lt;/a&gt;配置Redis&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;# cd /usr/local/redis-3.2.2/
# cp redis.conf /etc/
# vim /etc/redis.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;1.打开/etc/redis.conf，将daemonize处修改为yes。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;2.配置Redis持久化策略&lt;br&gt;使用RDB和AOF双持久化策略：其中默认开启了RDB持久化，我们只需要开启AOF持久化。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/10.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;3.配置redis日志文件&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/11.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4.配置数据文件存放路径，在/目录下面创建/RedisData目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mkdir /RedisData
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/12.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;5.修改Redis监听地址&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/13.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;6.修改Redis监听端口&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/14.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;7.在redis3.2之后，redis增加了protected-mode，在这个模式下，即使注释掉了bind 127.0.0.1，再访问redis的时候还是报错，所以要如下设置&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/15.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;启动-停止Redis&quot;&gt;&lt;a href=&quot;#启动-停止Redis&quot; class=&quot;headerlink&quot; title=&quot;启动/停止Redis&quot;&gt;&lt;/a&gt;启动/停止Redis&lt;/h3&gt;&lt;p&gt;启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# /usr/local/bin/redis-server /etc/redis.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;停止：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# /usr/local/redis-3.2.2/src/redis-cli -p 6400 shutdown
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;安装配置Filebeat&quot;&gt;&lt;a href=&quot;#安装配置Filebeat&quot; class=&quot;headerlink&quot; title=&quot;安装配置Filebeat&quot;&gt;&lt;/a&gt;安装配置Filebeat&lt;/h2&gt;&lt;p&gt;filebeat的工作流程：当开启filebeat程序的时候，它会启动一个或多个探测器（prospectors）去检测指定的日志目录或文件，对于探测器找出的每一个日志文件，filebeat启动收割进程（harvester），每一个收割进程读取一个日志文件的新内容，并发送这些新的日志数据到处理程序（spooler），处理程序会集合这些事件，最后filebeat会发送集合的数据到你指定的地点（Elasticsearch、Logstash、Kafka或者Redis）。&lt;/p&gt;
&lt;h3 id=&quot;安装Filebeat&quot;&gt;&lt;a href=&quot;#安装Filebeat&quot; class=&quot;headerlink&quot; title=&quot;安装Filebeat&quot;&gt;&lt;/a&gt;安装Filebeat&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@spark32 opt]# wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.6.3-linux-x86_64.tar.gz
[root@spark32 opt]# ln -sv filebeat-5.6.3-linux-x86_64 filebeat
‘filebeat’ -&amp;gt; ‘filebeat-5.6.3-linux-x86_64’
[root@spark32 opt]# cd filebeat
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;配置Filebeat&quot;&gt;&lt;a href=&quot;#配置Filebeat&quot; class=&quot;headerlink&quot; title=&quot;配置Filebeat&quot;&gt;&lt;/a&gt;配置Filebeat&lt;/h3&gt;&lt;p&gt;1.定义你的日志文件的路径（一个或多个）&lt;br&gt;对于大多数的基本filebeat配置，可以定义一个单一探测器针对一个单一的路径，例如：&lt;br&gt;filebeat.prospectors:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- input_type: log
  paths:
    - /usr/local/openresty/nginx/logs/host.access.log
  #json.keys_under_root: true 若收取日志格式为json的log，请开启此配置
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.定义输出日志，我这里输出到redis中&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;output.redis:
  hosts: [&amp;quot;172.16.206.30:6400&amp;quot;]
  #password: &amp;quot;my_password&amp;quot;
  key: &amp;quot;filebeat&amp;quot;
  db: 0
  timeout: 5
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;启动Filebeat&quot;&gt;&lt;a href=&quot;#启动Filebeat&quot; class=&quot;headerlink&quot; title=&quot;启动Filebeat&quot;&gt;&lt;/a&gt;启动Filebeat&lt;/h3&gt;&lt;p&gt;测试配置文件语法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cd /opt/filebeat/
# ./filebeat -configtest -e
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ./filebeat &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看数据是否进入redis：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@osb30 src]# ./redis-cli -p 6400 
127.0.0.1:6400&amp;gt; help @LIST
127.0.0.1:6400&amp;gt; LLEN filebeat
(integer) 15
127.0.0.1:6400&amp;gt; LINDEX filebeat 1
&amp;quot;{\&amp;quot;@timestamp\&amp;quot;:\&amp;quot;2017-10-23T07:13:37.551Z\&amp;quot;,\&amp;quot;beat\&amp;quot;:{\&amp;quot;hostname\&amp;quot;:\&amp;quot;spark32\&amp;quot;,\&amp;quot;name\&amp;quot;:\&amp;quot;spark32\&amp;quot;,\&amp;quot;version\&amp;quot;:\&amp;quot;5.6.3\&amp;quot;},\&amp;quot;input_type\&amp;quot;:\&amp;quot;log\&amp;quot;,\&amp;quot;message\&amp;quot;:\&amp;quot;172.16.4.81 - - [19/Oct/2017:09:47:17 +0800] \\\&amp;quot;GET /favicon.ico HTTP/1.1\\\&amp;quot; 404 576 \\\&amp;quot;http://172.16.206.32:808/\\\&amp;quot; \\\&amp;quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\\\&amp;quot; \\\&amp;quot;-\\\&amp;quot;\&amp;quot;,\&amp;quot;offset\&amp;quot;:439,\&amp;quot;source\&amp;quot;:\&amp;quot;/usr/local/openresty/nginx/logs/host.access.log\&amp;quot;,\&amp;quot;type\&amp;quot;:\&amp;quot;log\&amp;quot;}&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;浏览器访问下nginx，再次查看redis数据：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;127.0.0.1:6400&amp;gt; LLEN filebeat
(integer) 16
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;安装配置Elasticsearch&quot;&gt;&lt;a href=&quot;#安装配置Elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;安装配置Elasticsearch&quot;&gt;&lt;/a&gt;安装配置Elasticsearch&lt;/h2&gt;&lt;p&gt;关于Elasticsearch的安装部署详见上一篇博客&lt;a href=&quot;http://jkzhao.github.io/2017/10/20/ELK%E5%AE%9E%E6%88%98/#more&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《ELK实战》&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;安装配置Logstash&quot;&gt;&lt;a href=&quot;#安装配置Logstash&quot; class=&quot;headerlink&quot; title=&quot;安装配置Logstash&quot;&gt;&lt;/a&gt;安装配置Logstash&lt;/h2&gt;&lt;p&gt;Logstash从redis中取数据，输出结果到Elasticsearch中。关于Logstash的安装部署详见上一篇博客&lt;a href=&quot;http://jkzhao.github.io/2017/10/20/ELK%E5%AE%9E%E6%88%98/#more&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《ELK实战》&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&quot;配置Logstash&quot;&gt;&lt;a href=&quot;#配置Logstash&quot; class=&quot;headerlink&quot; title=&quot;配置Logstash&quot;&gt;&lt;/a&gt;配置Logstash&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;# cd /opt/logstash-5.6.3/conf
# vim logstash_redis.conf
input {
  redis {
    host  =&amp;gt;  &amp;quot;172.16.206.30&amp;quot;
    port  =&amp;gt;  &amp;quot;6400&amp;quot;
    data_type  =&amp;gt;  &amp;quot;list&amp;quot;
    key  =&amp;gt;  &amp;quot;filebeat&amp;quot;
  }
}

filter {
  grok {
    match =&amp;gt; { &amp;quot;message&amp;quot; =&amp;gt; &amp;quot;%{NGINXACCESS}&amp;quot; }
  }
}

output {
  elasticsearch {
    hosts    =&amp;gt;  [&amp;quot;172.16.206.16:9200&amp;quot;]
    action   =&amp;gt;  &amp;quot;index&amp;quot;
    index    =&amp;gt;  &amp;quot;filebeat-%{+YYYY.MM.dd}&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;启动Logstash&quot;&gt;&lt;a href=&quot;#启动Logstash&quot; class=&quot;headerlink&quot; title=&quot;启动Logstash&quot;&gt;&lt;/a&gt;启动Logstash&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@spark32 logstash-5.6.3]# bin/logstash -f /opt/logstash-5.6.3/conf/logstash_redis.conf &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看redis中的数据，发现已经全部被消费了：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;127.0.0.1:6400&amp;gt; LLEN filebeat
(integer) 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看Elasticsearch中的索引：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# curl -XGET &amp;apos;172.16.206.16:9200/_cat/indices&amp;apos;
yellow open filebeat-2017.10.23 PQe6qyVfSSG7GHQJUOPWtA 5 1 18 0 92.8kb 92.8kb
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;安装配置Kibana&quot;&gt;&lt;a href=&quot;#安装配置Kibana&quot; class=&quot;headerlink&quot; title=&quot;安装配置Kibana&quot;&gt;&lt;/a&gt;安装配置Kibana&lt;/h2&gt;&lt;p&gt;关于Kibana的安装部署详见上一篇博客&lt;a href=&quot;http://jkzhao.github.io/2017/10/20/ELK%E5%AE%9E%E6%88%98/#more&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《ELK实战》&lt;/a&gt;。&lt;br&gt;浏览器访问：&lt;a href=&quot;http://172.16.206.16:5601/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.206.16:5601/&lt;/a&gt;&lt;br&gt;1.左侧菜单点击“Management”，点击“Index Patterns”。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/16.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;2.点击“Create Index Pattern”。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/17.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;3.输入索引名字，点击“Create”&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/18.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;4.点击Discover，选择上一步创建的索引。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/19.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Beats工具&quot;&gt;&lt;a href=&quot;#Beats工具&quot; class=&quot;headerlink&quot; title=&quot;Beats工具&quot;&gt;&lt;/a&gt;Beats工具&lt;/h2&gt;&lt;p&gt;Beats是elastic公司的一款轻量级数据采集产品，它是从packetbeat发展出来的数据收集器系统，它包含了几个子产品：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Packetbeat(用于监控网络流量)&lt;/li&gt;
&lt;li&gt;Filebeat(用于监听日志数据)
    
    </summary>
    
      <category term="日志" scheme="http://yoursite.com/categories/%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="ELK" scheme="http://yoursite.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>ELK实战</title>
    <link href="http://yoursite.com/2017/10/20/ELK%E5%AE%9E%E6%88%98/"/>
    <id>http://yoursite.com/2017/10/20/ELK实战/</id>
    <published>2017-10-20T01:33:57.000Z</published>
    <updated>2017-11-13T07:38:32.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;ELK介绍&quot;&gt;&lt;a href=&quot;#ELK介绍&quot; class=&quot;headerlink&quot; title=&quot;ELK介绍&quot;&gt;&lt;/a&gt;ELK介绍&lt;/h2&gt;&lt;p&gt;ELK由Elasticsearch、Logstash和Kibana三部分组件组成。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Elasticsearch是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。&lt;/li&gt;
&lt;li&gt;Logstash是一个完全开源的工具，它可以对你的日志进行收集、分析，并将其存储供以后使用。&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;kibana 是一个开源和免费的工具，它可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Elasticsearch&quot;&gt;&lt;a href=&quot;#Elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch&quot;&gt;&lt;/a&gt;Elasticsearch&lt;/h3&gt;&lt;p&gt;Elasticsearch是一个基于Lucene实现的开源、分布式、Restful的全文本搜索引擎。（仅支持文本搜索）此外，它还是一个分布式实时文档存储，其中每个文档的每个field均是被索引的数据，且可被搜索；也是一个带实时分析功能的分布式搜索引擎，能够扩展至数以百计的节点实时处理PB级的数据。&lt;br&gt;Elasticsearch借助于Lucene的API，在Lucene之外又重新封装了一层实现构建搜索引擎中的搜索组件。除此之外，Elasticsearch还新增了更强大的功能。比如把自己构建为分布式，分布式地将Lucene所提供的索引组建成shard形式，分布于多个节点之上，从而构建成分布式实时查询的组件。&lt;/p&gt;
&lt;h3 id=&quot;Logstash&quot;&gt;&lt;a href=&quot;#Logstash&quot; class=&quot;headerlink&quot; title=&quot;Logstash&quot;&gt;&lt;/a&gt;Logstash&lt;/h3&gt;&lt;p&gt;支持多数据获取机制，通过TCP/UDP协议、文件、syslog、windows EventLogs及STDIN等。获取到数据后，它支持对数据执行过滤、修改等操作。&lt;/p&gt;
&lt;p&gt;logstash配置框架：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;input {
  ...
}

filter {
  ...
}

output {
  ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Logstash是高度插件化的，支持4种类型的插件(每一类都有数10种具体的实现)：&lt;br&gt;input、filter、codec、output  &lt;/p&gt;
&lt;h4 id=&quot;input插件&quot;&gt;&lt;a href=&quot;#input插件&quot; class=&quot;headerlink&quot; title=&quot;input插件&quot;&gt;&lt;/a&gt;input插件&lt;/h4&gt;&lt;p&gt;下面介绍input插件几种常见的实现。&lt;br&gt;&lt;strong&gt;1.File：&lt;/strong&gt;&lt;br&gt;从指定的文件中读取事件流；其工作特性类似于tail -1，不断将文件的最后一行读出来；不过第一次读取文件时是从第1行开始的；文件中的每一行都被识别为一个事件。对于Logstash而言，每一个独立的信息就是一个事件，而对于文本文件来讲，每一个事件是用一行来表示的，如果期望将多行识别为一个事件的话，就需要codec插件。logstash使用FileWatch(Ruby Gem库)机制来监听文件的变化，FileWatch是Linux内核中提供的一个功能。可以一下子监听多个文件。文件状态记录在.sincedb数据库中。另外，FIle插件还能够自动识别你的日志滚动操作，日志一般达到某个体积、或者满足多少天后会滚动，File也能识别。它会按照上一次那个日志文件所在的位置读取，自动进行滚动，读到最新的文件。&lt;br&gt;&lt;strong&gt;2.udp插件:&lt;/strong&gt;&lt;br&gt;如果我们安装的某个程序，它能够通过udp的某个端口输出自己相关日志信息或者事件。Logstash通过udp协议从网络连接来读取Message。其必备参数为port，用于指明自己监听的端口，别的主机向这个端口发事件，host则用来指明自己监听的地址。&lt;br&gt;&lt;strong&gt;3.redis插件：&lt;/strong&gt;&lt;br&gt;允许Logstash从redis读数据。支持redis channel和lists两种方式来获取数据。&lt;/p&gt;
&lt;h4 id=&quot;filter插件&quot;&gt;&lt;a href=&quot;#filter插件&quot; class=&quot;headerlink&quot; title=&quot;filter插件&quot;&gt;&lt;/a&gt;filter插件&lt;/h4&gt;&lt;p&gt;filter插件主要用于将event通过output发出之前，对其实现某些处理功能。&lt;br&gt;&lt;strong&gt;1.grok：&lt;/strong&gt;用于分析并结构化文本数据。把每一个事件字段切好，做成结构化的形式。使得我们后续可以分析。目前能处理syslog、apache、nginx的日志等。目前Logstash提供120种grok模式，因为我们要分析文本，必须提供模式。&lt;br&gt;简单举个例子说明下什么是模式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;55.3.244.1 GET /index.html 15824 0.043
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;比如对于上面一条日志，我们定义如下的模式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;那么经过grok过滤后，这个事件后将会加有分析后的字段：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;client =&amp;gt; 55.3.244.1
method =&amp;gt; GET
request =&amp;gt; /index.html
bytes =&amp;gt; 15824
duration =&amp;gt; 0.043
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Logstash中默认自带了很多pattern，但是如果没有你需要的，就需要自己在文件中定义你需要的模式。&lt;br&gt;&lt;strong&gt;grok语法格式：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;%{SYNTAX:SEMANTIC}
    SYNTAX表示预定义模式名称。就是Logstash解压后pattern相关文件里已经定义好的模式，如果没有的，可以自己写在上面那个文件里，名字得全大写。具体的文件在下面的实战中会讲到。
    SEMANTIC表示匹配到的文本的自定义的标识符。比如识别处理的ip可能是clientip也可能是server端的ip，我们可以自定义名字。
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;output插件&quot;&gt;&lt;a href=&quot;#output插件&quot; class=&quot;headerlink&quot; title=&quot;output插件&quot;&gt;&lt;/a&gt;output插件&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;1.stdout：&lt;/strong&gt;标准输出插件。&lt;br&gt;&lt;strong&gt;2.elasticsearch：&lt;/strong&gt;将结果输出到Elasticsearch中。&lt;br&gt;elasticsearch插件常见配置参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;index：数据存储在ES中的哪个索引中。默认“logstash-%{+YYYY.MM.dd}”，每天使用一个单独的索引。&lt;/li&gt;
&lt;li&gt;workers：执行output的线程数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.redis插件：&lt;/strong&gt;将结果输出到redis中。&lt;br&gt;Logstash使用redis作为输入或输出插件时，尤其是输出插件时，它有两种数据类型可以用来保存Logstash输出的数据。一种是list，一种是channel。一般使用list，list比较简单。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【注意】：Logstash版本不同，每种插件支持的参数也不同，具体看&lt;a href=&quot;https://www.elastic.co/guide/en/logstash/current/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官方文档&lt;/a&gt;。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;hadoop16&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.206.16&lt;/td&gt;
&lt;td&gt;elasticsearch-5.6.3.zip、kibana-5.6.3-linux-x86_64.tar.gz&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;spark32&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.206.32&lt;/td&gt;
&lt;td&gt;logstash-5.6.3.tar.gz&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;Elasticsearch-1&quot;&gt;&lt;a href=&quot;#Elasticsearch-1&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch&quot;&gt;&lt;/a&gt;Elasticsearch&lt;/h2&gt;&lt;h3 id=&quot;安装JDK8&quot;&gt;&lt;a href=&quot;#安装JDK8&quot; class=&quot;headerlink&quot; title=&quot;安装JDK8&quot;&gt;&lt;/a&gt;安装JDK8&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;# tar zxf jdk-8u73-linux-x64.gz -C /usr/java/
# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.8.0_73
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;新建用户&quot;&gt;&lt;a href=&quot;#新建用户&quot; class=&quot;headerlink&quot; title=&quot;新建用户&quot;&gt;&lt;/a&gt;新建用户&lt;/h3&gt;&lt;p&gt;【注意】:elasticsearch不能使用root用户去启动。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# groupadd -g 510 es
# useradd -g 510 -u 510 es
# echo &amp;quot;wisedu123&amp;quot; | passwd --stdin es &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装配置Elasticsearch&quot;&gt;&lt;a href=&quot;#安装配置Elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;安装配置Elasticsearch&quot;&gt;&lt;/a&gt;安装配置Elasticsearch&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@hadoop16 opt]# unzip -oq elasticsearch-5.6.3.zip
[root@hadoop16 opt]# vim elasticsearch-5.6.3/config/elasticsearch.yml 
cluster.name: loges
node.name: hadoop16
network.host: 172.16.206.16
bootstrap.memory_lock: true
[root@hadoop16 opt]# vim /etc/security/limits.conf
es - memlock -1
[root@hadoop16 opt]# chown -R es.es elasticsearch-5.6.3
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置说明：&lt;br&gt;bootstrap.memory_lock: true&lt;br&gt;这个配置的作用是保护Elasticsearch使用的内存防止其被swapped。&lt;/p&gt;
&lt;h3 id=&quot;优化Elasticsearch&quot;&gt;&lt;a href=&quot;#优化Elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;优化Elasticsearch&quot;&gt;&lt;/a&gt;优化Elasticsearch&lt;/h3&gt;&lt;p&gt;1.配置操作系统文件描述符数&lt;br&gt;输入下面的命令进行查看：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ulimit -a
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;找到open files那行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;open files                      (-n) 1024
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;设置需要修改：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/security/limits.conf
es               -       nofile          65536
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.增大虚拟内存mmap count配置&lt;br&gt;备注：如果你以.deb或.rpm包安装，则默认不需要设置此项，因为已经被自动设置，查看方式为：&lt;br&gt;sysctl vm.max_map_count&lt;br&gt;如果是手动安装，以root身份执行如下命令：&lt;br&gt;sysctl vm.max_map_count=262144&lt;br&gt;并修改文件使设置永久生效：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/sysctl.conf    
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;加一行：vm.max_map_count = 262144&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# sysctl -p
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;改完后，重启elasticsearch。&lt;br&gt;如果需要需改JVM大小，请修改 jvm.options 配置文件。&lt;/p&gt;
&lt;h3 id=&quot;启动Elasticsearch&quot;&gt;&lt;a href=&quot;#启动Elasticsearch&quot; class=&quot;headerlink&quot; title=&quot;启动Elasticsearch&quot;&gt;&lt;/a&gt;启动Elasticsearch&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@hadoop16 opt]# su - es
[es@hadoop16 ~]$ /opt/elasticsearch-5.6.3/bin/elasticsearch -d
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检验bootstrap.mlockall: true是否生效：&lt;br&gt;curl &lt;a href=&quot;http://172.16.206.16:9200/_nodes/process?pretty&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.206.16:9200/_nodes/process?pretty&lt;/a&gt;&lt;br&gt;关注这个这个请求返回数据中的mlockall的值，如果为false，则说明锁定内存失败，这可能由于运行elasticsearch的用户不具备这样的权限。解决该问题的方法是：&lt;br&gt;在运行elasticsearch之前，以root身份执行&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ulimit -l unlimited
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后再次重启elasticsearch。并查看上面的请求中的mlockall的值是否为true。&lt;br&gt;【注意】:这时候需要在root执行ulimit -l unlimited的shell终端上su - es，然后重启elasticsearch。因为这是命令行设置的ulimit -l unlimited，只对当前会话生效。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ulimit -l unlimited
# su - es
$ ps -ef|grep elasticsearch
$ kill -9 27189
$ /usr/local/elasticsearch/bin/elasticsearch -d
$ curl http://172.16.206.16:9200/_nodes/process?pretty
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;要想永久修改锁定内存大小无限制，需修改/etc/security/limits.conf，添加下面的内容，改完不需要重启系统，但是需要重新打开一个shell建立会话。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;es - memlock -1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，es代表运行elasticsearch的用户，-表示同时设置了soft和hard，memlock代表设置的是”锁定内存”这个类型，-1(unlimited或者infinity)代表没限制。&lt;br&gt;【补充】: 要使 /etc/security/limits.conf 文件配置生效，必须要确保 pam_limits.so 文件被加入到相关的启动文件中，启动文件位于/etc/pam.d路径下，如该路径下sshd、login、system-auth等，一般是system-auth文件负责加载该so文件。只要加载了pam_limits.so，则配置就会生效，无需重启系统。&lt;/p&gt;
&lt;h3 id=&quot;安装配置head插件&quot;&gt;&lt;a href=&quot;#安装配置head插件&quot; class=&quot;headerlink&quot; title=&quot;安装配置head插件&quot;&gt;&lt;/a&gt;安装配置head插件&lt;/h3&gt;&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/mobz/elasticsearch-head&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/mobz/elasticsearch-head&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;安装head插件&quot;&gt;&lt;a href=&quot;#安装head插件&quot; class=&quot;headerlink&quot; title=&quot;安装head插件&quot;&gt;&lt;/a&gt;安装head插件&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@hadoop16 opt]# git clone git://github.com/mobz/elasticsearch-head.git
[root@hadoop16 opt]# yum -y install epel-release
[root@hadoop16 opt]# yum install nodejs -y
[root@hadoop16 opt]# cd elasticsearch-head/
[root@hadoop16 elasticsearch-head]# npm install
npm: relocation error: npm: symbol SSL_set_cert_cb, version libssl.so.10 not defined in file libssl.so.10 with link time reference
[root@hadoop16 elasticsearch-head]# yum update openssl -y
[root@hadoop16 elasticsearch-head]# npm install 
# 如果下载速度太慢，可以如下方式安装
[root@hadoop16 elasticsearch-head]# npm install -gd express --registry=http://registry.npm.taobao.org
# 为了避免每次安装都需要--registry参数，可以使用如下命令进行永久设置：
[root@hadoop16 elasticsearch-head]# npm config set registry http://registry.npm.taobao.org 
[root@hadoop16 elasticsearch-head]# npm install grunt --save-dev
[root@hadoop16 elasticsearch-head]# npm install grunt-contrib-clean 
[root@hadoop16 elasticsearch-head]# npm install grunt-contrib-concat 
[root@hadoop16 elasticsearch-head]# npm install grunt-contrib-watch 
[root@hadoop16 elasticsearch-head]# npm install grunt-contrib-connect 
[root@hadoop16 elasticsearch-head]# npm install grunt-contrib-copy 
[root@hadoop16 elasticsearch-head]# npm install grunt-contrib-jasmine 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;奇怪的是最后一个没有安装成功，是因为该模块依赖了phantomjs。但是配置之后，依然无法安装。直接启动就可以了：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@hadoop16 elasticsearch-head]# grunt server 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上安装head插件的步骤太过复杂，我们可以将下载下来的elasticsearch-head包放入tomcat中，直接启动tomcat就可以访问head插件了。本实验环境下是采用将head插件放入tomcat中运行。&lt;/p&gt;
&lt;h4 id=&quot;配置&quot;&gt;&lt;a href=&quot;#配置&quot; class=&quot;headerlink&quot; title=&quot;配置&quot;&gt;&lt;/a&gt;配置&lt;/h4&gt;&lt;p&gt;1.修改Elasticsearch的配置文件elasticsearch.yml，增加跨域的配置(需要重启es才能生效)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http.cors.enabled: true
http.cors.allow-origin: &amp;quot;*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.编辑head/Gruntfile.js，修改服务器监听地址，增加hostname属性，将其值设置为*。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@hadoop16 elasticsearch-head]# pwd
/opt/apache-tomcat-8.5.23/webapps/elasticsearch-head
[root@hadoop16 elasticsearch-head]# vim Gruntfile.js
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以下两种配置都是可以的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Type1
connect: {
        hostname: &amp;apos;*&amp;apos;,
        server: {
                options: {
                        port: 9100,
                        base: &amp;apos;.&amp;apos;,
                        keepalive: true
                }
        }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;　　&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Type 2
connect: {
        server: {
                options: {
                        hostname: &amp;apos;*&amp;apos;,
                        port: 9100,
                        base: &amp;apos;.&amp;apos;,
                        keepalive: true
                }
        }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.编辑head/_site/app.js，修改head连接es的地址，将localhost修改为es的IP地址&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@hadoop16 elasticsearch-head]# pwd
/opt/apache-tomcat-8.5.23/webapps/elasticsearch-head
[root@hadoop16 elasticsearch-head]# vim _site/app.js
# 原配置
this.base_uri = this.config.base_uri || this.prefs.get(&amp;quot;app-base_uri&amp;quot;) || &amp;quot;http://localhost:9200&amp;quot;;
# 将localhost修改为ES的IP地址
this.base_uri = this.config.base_uri || this.prefs.get(&amp;quot;app-base_uri&amp;quot;) || &amp;quot;http://YOUR-ES-IP:9200&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;启动&quot;&gt;&lt;a href=&quot;#启动&quot; class=&quot;headerlink&quot; title=&quot;启动&quot;&gt;&lt;/a&gt;启动&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@hadoop16 elasticsearch-head]# cd /opt/apache-tomcat-8.5.23/
[root@hadoop16 apache-tomcat-8.5.23]# bin/startup.sh 
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Logstash-1&quot;&gt;&lt;a href=&quot;#Logstash-1&quot; class=&quot;headerlink&quot; title=&quot;Logstash&quot;&gt;&lt;/a&gt;Logstash&lt;/h2&gt;&lt;h3 id=&quot;安装JDK8-1&quot;&gt;&lt;a href=&quot;#安装JDK8-1&quot; class=&quot;headerlink&quot; title=&quot;安装JDK8&quot;&gt;&lt;/a&gt;安装JDK8&lt;/h3&gt;&lt;p&gt;Logstash是jruby研发的，需要跑在JVM上，所以需要安装JDK。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# tar zxf jdk-8u73-linux-x64.gz -C /usr/java/
# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.8.0_73
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
# source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装配置Logstash&quot;&gt;&lt;a href=&quot;#安装配置Logstash&quot; class=&quot;headerlink&quot; title=&quot;安装配置Logstash&quot;&gt;&lt;/a&gt;安装配置Logstash&lt;/h3&gt;&lt;p&gt;我这里选择二进制包安装。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@spark32 opt]# tar zxf logstash-5.6.3.tar.gz 
[root@spark32 opt]# cd logstash-5.6.3/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由于我这里选择是二进制安装，pattern文件位置在：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@spark32 logstash-5.6.3]# ls /opt/logstash-5.6.3/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-4.1.2/patterns/grok-patterns
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;收集Nginx-access日志&quot;&gt;&lt;a href=&quot;#收集Nginx-access日志&quot; class=&quot;headerlink&quot; title=&quot;收集Nginx access日志&quot;&gt;&lt;/a&gt;收集Nginx access日志&lt;/h3&gt;&lt;p&gt;Logstash收集Nginx日志，输出到Elasticsearch中。&lt;/p&gt;
&lt;h4 id=&quot;创建Nginx-pattern&quot;&gt;&lt;a href=&quot;#创建Nginx-pattern&quot; class=&quot;headerlink&quot; title=&quot;创建Nginx pattern&quot;&gt;&lt;/a&gt;创建Nginx pattern&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@spark32 ~]# vim /opt/logstash-5.6.3/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-4.1.2/patterns/grok-patterns
# Nginx log
NGUSERNAME [a-zA-Z\.\@\-\+_%]+
NGUSER %{NGUSERNAME}
NGINXACCESS %{IPORHOST:clientip} - %{NOTSPACE:remote_user} \[%{HTTPDATE:timestamp}\] \&amp;quot;(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\&amp;quot; %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} %{NOTSPACE:http_x_forwarded_for}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;创建Logstash配置文件&quot;&gt;&lt;a href=&quot;#创建Logstash配置文件&quot; class=&quot;headerlink&quot; title=&quot;创建Logstash配置文件&quot;&gt;&lt;/a&gt;创建Logstash配置文件&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@spark32 logstash-5.6.3]# cd /opt/logstash-5.6.3
[root@spark32 logstash-5.6.3]# mkdir conf
[root@spark32 logstash-5.6.3]# cd conf
[root@spark32 conf]# vim logstash_nginx.conf
input {
  file {
    path  =&amp;gt;  [&amp;quot;/usr/local/openresty/nginx/logs/host.access.log&amp;quot;]
    type  =&amp;gt;  &amp;quot;nginxlog&amp;quot;
    start_position  =&amp;gt;  &amp;quot;beginning&amp;quot;
  }
}

filter {
  grok {
    match =&amp;gt; { &amp;quot;message&amp;quot; =&amp;gt; &amp;quot;%{NGINXACCESS}&amp;quot; }
  }
}

output {
  elasticsearch {
    hosts    =&amp;gt;  [&amp;quot;172.16.206.16:9200&amp;quot;]
    action   =&amp;gt;  &amp;quot;index&amp;quot;
    index    =&amp;gt;  &amp;quot;logstash-%{+YYYY.MM.dd}&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;启动Logstash&quot;&gt;&lt;a href=&quot;#启动Logstash&quot; class=&quot;headerlink&quot; title=&quot;启动Logstash&quot;&gt;&lt;/a&gt;启动Logstash&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;[root@spark32 logstash-5.6.3]# bin/logstash -f /opt/logstash-5.6.3/conf/logstash_nginx.conf -t
Sending Logstash&amp;apos;s logs to /opt/logstash-5.6.3/logs which is now configured via log4j2.properties
[2017-10-20T17:07:14,793][INFO ][logstash.modules.scaffold] Initializing module {:module_name=&amp;gt;&amp;quot;fb_apache&amp;quot;, :directory=&amp;gt;&amp;quot;/opt/logstash-5.6.3/modules/fb_apache/configuration&amp;quot;}
[2017-10-20T17:07:14,797][INFO ][logstash.modules.scaffold] Initializing module {:module_name=&amp;gt;&amp;quot;netflow&amp;quot;, :directory=&amp;gt;&amp;quot;/opt/logstash-5.6.3/modules/netflow/configuration&amp;quot;}
[2017-10-20T17:07:14,803][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=&amp;gt;&amp;quot;path.queue&amp;quot;, :path=&amp;gt;&amp;quot;/opt/logstash-5.6.3/data/queue&amp;quot;}
[2017-10-20T17:07:14,804][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=&amp;gt;&amp;quot;path.dead_letter_queue&amp;quot;, :path=&amp;gt;&amp;quot;/opt/logstash-5.6.3/data/dead_letter_queue&amp;quot;}
Configuration OK
[2017-10-20T17:07:14,999][INFO ][logstash.runner          ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash
[root@spark32 logstash-5.6.3]# bin/logstash -f /opt/logstash-5.6.3/conf/logstash_nginx.conf &amp;amp; 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;记录收集到日志的文件位置在:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@spark32 file]# ls -a
.  ..  .sincedb_650663ba19529187a32a8b9dc99049f8
[root@spark32 file]# pwd
/opt/logstash-5.6.3/data/plugins/inputs/file
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看Elasticsearch索引：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[es@hadoop16 elasticsearch-5.6.3]$ curl -XGET &amp;apos;172.16.206.16:9200/_cat/indices&amp;apos;
yellow open logstash-2017.10.20 DVARGYZ2R9CfT-xyLrhyAQ 5 1 7 0 49.9kb 49.9kb
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Kibana&quot;&gt;&lt;a href=&quot;#Kibana&quot; class=&quot;headerlink&quot; title=&quot;Kibana&quot;&gt;&lt;/a&gt;Kibana&lt;/h2&gt;&lt;h3 id=&quot;安装配置kibana&quot;&gt;&lt;a href=&quot;#安装配置kibana&quot; class=&quot;headerlink&quot; title=&quot;安装配置kibana&quot;&gt;&lt;/a&gt;安装配置kibana&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@hadoop16 opt]# tar zxf kibana-5.6.3-linux-x86_64.tar.gz 
[root@hadoop16 opt]# ln -sv kibana-5.6.3-linux-x86_64 kibana
‘kibana’ -&amp;gt; ‘kibana-5.6.3-linux-x86_64’
[root@hadoop16 opt]# cd kibana
[root@hadoop16 kibana]# cd config/
[root@hadoop16 config]# vim kibana.yml 
server.host: &amp;quot;172.16.206.16&amp;quot;
elasticsearch.url: &amp;quot;http://172.16.206.16:9200&amp;quot;
[root@hadoop16 config]# cd ..
[root@hadoop16 kibana]# bin/kibana &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;访问&quot;&gt;&lt;a href=&quot;#访问&quot; class=&quot;headerlink&quot; title=&quot;访问&quot;&gt;&lt;/a&gt;访问&lt;/h3&gt;&lt;p&gt;浏览器输入：&lt;a href=&quot;http://172.16.206.16:5601/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.206.16:5601/&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击左侧菜单的Discover：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;比如我用curl访问下nginx，然后去kibana中搜索。要稍微等一下，等日志进到Elasticsearch中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@hadoop16 kibana]# curl http://172.16.206.32:808
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/4.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结：&lt;/strong&gt;&lt;br&gt;1.Logstash 主要的特点就是它的灵活性，因为它有很多插件。然后它清楚的文档已经直白的配置格式让它可以再多种场景下应用。这样的良性循环让我们可以在网上找到很多资源，几乎可以处理任何问题。&lt;br&gt;2.Logstash不支持缓存，当然我们可以使用redis或者kafka作为中心缓冲池，架构如下：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;3.Logstash是在jvm跑的，资源消耗比较大，太重量级了。后来作者又用golang写了一个功能较少但是资源消耗也小的轻量级的logstash-forwarder。后来这个人加入了elastic公司。因为elastic公司本身还收购了另一个开源项目packetbeat，而这个项目专门就是用golang写的，有整个团队，所以elastic公司干脆把logstash-forwarder的开发工作也合并到同一个golang团队来搞，于是新的项目就叫filebeat了。当然也可以自己写agent，用go、python都可以写。这样我们就可以使用轻量的日志传输工具，将数据从服务器端经由一个或多个 Logstash 中心服务器传输到 Elasticsearch。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/ELK/7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;ELK介绍&quot;&gt;&lt;a href=&quot;#ELK介绍&quot; class=&quot;headerlink&quot; title=&quot;ELK介绍&quot;&gt;&lt;/a&gt;ELK介绍&lt;/h2&gt;&lt;p&gt;ELK由Elasticsearch、Logstash和Kibana三部分组件组成。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Elasticsearch是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。&lt;/li&gt;
&lt;li&gt;Logstash是一个完全开源的工具，它可以对你的日志进行收集、分析，并将其存储供以后使用。
    
    </summary>
    
      <category term="日志" scheme="http://yoursite.com/categories/%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="ELK" scheme="http://yoursite.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>EFK收集Kubernetes应用日志</title>
    <link href="http://yoursite.com/2017/10/12/EFK%E6%94%B6%E9%9B%86Kubernetes%E5%BA%94%E7%94%A8%E6%97%A5%E5%BF%97/"/>
    <id>http://yoursite.com/2017/10/12/EFK收集Kubernetes应用日志/</id>
    <published>2017-10-12T06:53:08.000Z</published>
    <updated>2017-12-04T02:36:46.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;EFK介绍&quot;&gt;&lt;a href=&quot;#EFK介绍&quot; class=&quot;headerlink&quot; title=&quot;EFK介绍&quot;&gt;&lt;/a&gt;EFK介绍&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Logstash(或者Fluentd)负责收集日志 &lt;/li&gt;
&lt;li&gt;Elasticsearch存储日志并提供搜索 &lt;/li&gt;
&lt;li&gt;Kibana负责日志查询和展示&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;官方地址：&lt;a href=&quot;https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/fluentd-elasticsearch&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/fluentd-elasticsearch&lt;/a&gt;&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;通过在每台node上部署一个以DaemonSet方式运行的fluentd来收集每台node上的日志。Fluentd将docker日志目录/var/lib/docker/containers和/var/log目录挂载到Pod中，然后Pod会在node节点的/var/log/pods目录中创建新的目录，可以区别不同的容器日志输出，该目录下有一个日志文件链接到/var/lib/docker/contianers目录下的容器日志输出。&lt;/p&gt;
&lt;h2 id=&quot;配置efk-rbac-yaml文件&quot;&gt;&lt;a href=&quot;#配置efk-rbac-yaml文件&quot; class=&quot;headerlink&quot; title=&quot;配置efk-rbac.yaml文件&quot;&gt;&lt;/a&gt;配置efk-rbac.yaml文件&lt;/h2&gt;&lt;p&gt;EFK服务也需要一个efk-rbac.yaml文件，配置serviceaccount为efk。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 opt]# mkdir efk
[root@node1 opt]# cd efk
[root@node1 efk]# vim efk-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: efk
  namespace: kube-system

---

kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: efk
subjects:
  - kind: ServiceAccount
    name: efk
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;配置-es-controller-yaml&quot;&gt;&lt;a href=&quot;#配置-es-controller-yaml&quot; class=&quot;headerlink&quot; title=&quot;配置 es-controller.yaml&quot;&gt;&lt;/a&gt;配置 es-controller.yaml&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;36&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;37&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;38&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;39&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;40&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;41&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;42&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;43&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;44&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;45&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;46&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;47&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;48&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;49&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;50&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;51&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@node1 efk]# vim es-controller.yaml&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;apiVersion: v1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;kind: ReplicationController&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;metadata:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  name: elasticsearch-logging-v1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  namespace: kube-system&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  labels:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    k8s-app: elasticsearch-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    version: v1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    kubernetes.io/cluster-service: &amp;quot;true&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    addonmanager.kubernetes.io/mode: Reconcile&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;spec:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  replicas: 2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  selector:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    k8s-app: elasticsearch-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    version: v1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  template:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    metadata:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      labels:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        k8s-app: elasticsearch-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        version: v1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        kubernetes.io/cluster-service: &amp;quot;true&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    spec:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      serviceAccountName: efk&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      containers:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      - image: index.tenxcloud.com/jimmy/elasticsearch:v2.4.1-2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        name: elasticsearch-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        resources:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          # need more cpu upon initialization, therefore burstable class&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          limits:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            cpu: 1000m&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          requests:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            cpu: 100m&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ports:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        - containerPort: 9200&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          name: db&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          protocol: TCP&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        - containerPort: 9300&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          name: transport&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          protocol: TCP&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        volumeMounts:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        - name: es-persistent-storage&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          mountPath: /data&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        env:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        - name: &amp;quot;NAMESPACE&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          valueFrom:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            fieldRef:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;              fieldPath: metadata.namespace&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      volumes:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      - name: es-persistent-storage&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        emptyDir: &amp;#123;&amp;#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;配置-es-service-yaml&quot;&gt;&lt;a href=&quot;#配置-es-service-yaml&quot; class=&quot;headerlink&quot; title=&quot;配置 es-service.yaml&quot;&gt;&lt;/a&gt;配置 es-service.yaml&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@node1 efk]# vim es-service.yaml&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;apiVersion: v1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;kind: Service&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;metadata:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  name: elasticsearch-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  namespace: kube-system&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  labels:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    k8s-app: elasticsearch-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    kubernetes.io/cluster-service: &amp;quot;true&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    addonmanager.kubernetes.io/mode: Reconcile&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    kubernetes.io/name: &amp;quot;Elasticsearch&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;spec:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  ports:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  - port: 9200&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    protocol: TCP&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    targetPort: db&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  selector:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    k8s-app: elasticsearch-logging&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;配置-fluentd-es-ds-yaml&quot;&gt;&lt;a href=&quot;#配置-fluentd-es-ds-yaml&quot; class=&quot;headerlink&quot; title=&quot;配置 fluentd-es-ds.yaml&quot;&gt;&lt;/a&gt;配置 fluentd-es-ds.yaml&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;36&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;37&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;38&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;39&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;40&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;41&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;42&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;43&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;44&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;45&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;46&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;47&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;48&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;49&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;50&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;51&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;52&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;53&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;54&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;55&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;56&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;apiVersion: extensions/v1beta1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;kind: DaemonSet&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;metadata:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  name: fluentd-es-v1.22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  namespace: kube-system&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  labels:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    k8s-app: fluentd-es&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    kubernetes.io/cluster-service: &amp;quot;true&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    addonmanager.kubernetes.io/mode: Reconcile&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    version: v1.22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;spec:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  template:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    metadata:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      labels:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        k8s-app: fluentd-es&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        kubernetes.io/cluster-service: &amp;quot;true&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        version: v1.22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      # This annotation ensures that fluentd does not get evicted if the node&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      # supports critical pod annotation based priority scheme.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      # Note that this does not guarantee admission on the nodes (#40573).&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      annotations:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        scheduler.alpha.kubernetes.io/critical-pod: &amp;apos;&amp;apos;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    spec:  &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      serviceAccountName: efk&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      containers:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      - name: fluentd-es&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        image: index.tenxcloud.com/jimmy/fluentd-elasticsearch:1.22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        command:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          - &amp;apos;/bin/sh&amp;apos;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          - &amp;apos;-c&amp;apos;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          - &amp;apos;/usr/sbin/td-agent 2&amp;gt;&amp;amp;1 &amp;gt;&amp;gt; /var/log/fluentd.log&amp;apos;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        resources:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          limits:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            memory: 200Mi&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          requests:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            cpu: 100m&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            memory: 200Mi&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        volumeMounts:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        - name: varlog&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          mountPath: /var/log&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        - name: varlibdockercontainers&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          mountPath: /var/lib/docker/containers&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          readOnly: true&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      nodeSelector:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        beta.kubernetes.io/fluentd-ds-ready: &amp;quot;true&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      tolerations:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      - key : &amp;quot;node.alpha.kubernetes.io/ismaster&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        effect: &amp;quot;NoSchedule&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      terminationGracePeriodSeconds: 30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      volumes:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      - name: varlog&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        hostPath:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          path: /var/log&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      - name: varlibdockercontainers&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        hostPath:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          path: /var/lib/docker/containers&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;配置-kibana-controller-yaml&quot;&gt;&lt;a href=&quot;#配置-kibana-controller-yaml&quot; class=&quot;headerlink&quot; title=&quot;配置 kibana-controller.yaml&quot;&gt;&lt;/a&gt;配置 kibana-controller.yaml&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;36&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;37&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;38&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;apiVersion: extensions/v1beta1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;kind: Deployment&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;metadata:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  name: kibana-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  namespace: kube-system&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  labels:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    k8s-app: kibana-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    kubernetes.io/cluster-service: &amp;quot;true&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    addonmanager.kubernetes.io/mode: Reconcile&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;spec:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  replicas: 1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  selector:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    matchLabels:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      k8s-app: kibana-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  template:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    metadata:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      labels:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        k8s-app: kibana-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    spec:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      serviceAccountName: efk&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      containers:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      - name: kibana-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        image: index.tenxcloud.com/jimmy/kibana:v4.6.1-1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        resources:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          # keep request = limit to keep this container in guaranteed class&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          limits:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            cpu: 100m&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          requests:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            cpu: 100m&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        env:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          - name: &amp;quot;ELASTICSEARCH_URL&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            value: &amp;quot;http://elasticsearch-logging:9200&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          - name: &amp;quot;KIBANA_BASE_URL&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            value: &amp;quot;/api/v1/proxy/namespaces/kube-system/services/kibana-logging&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        ports:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        - containerPort: 5601&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          name: ui&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;          protocol: TCP&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;配置-kibana-service-yaml&quot;&gt;&lt;a href=&quot;#配置-kibana-service-yaml&quot; class=&quot;headerlink&quot; title=&quot;配置 kibana-service.yaml&quot;&gt;&lt;/a&gt;配置 kibana-service.yaml&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;apiVersion: v1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;kind: Service&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;metadata:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  name: kibana-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  namespace: kube-system&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  labels:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    k8s-app: kibana-logging&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    kubernetes.io/cluster-service: &amp;quot;true&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    addonmanager.kubernetes.io/mode: Reconcile&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    kubernetes.io/name: &amp;quot;Kibana&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;spec:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  ports:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  - port: 5601&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    protocol: TCP&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    targetPort: ui&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  selector:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    k8s-app: kibana-logging&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 efk]# ls
efk-rbac.yaml  es-controller.yaml  es-service.yaml  fluentd-es-ds.yaml  kibana-controller.yaml  kibana-service.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;给-Node-设置标签&quot;&gt;&lt;a href=&quot;#给-Node-设置标签&quot; class=&quot;headerlink&quot; title=&quot;给 Node 设置标签&quot;&gt;&lt;/a&gt;给 Node 设置标签&lt;/h2&gt;&lt;p&gt;定义 DaemonSet fluentd-es-v1.22 时设置了 nodeSelector beta.kubernetes.io/fluentd-ds-ready=true ，所以需要在期望运行 fluentd 的 Node 上设置该标签；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 efk]# kubectl label nodes 172.16.7.151 beta.kubernetes.io/fluentd-ds-ready=true
node &amp;quot;172.16.7.151&amp;quot; labeled
[root@node1 efk]# kubectl label nodes 172.16.7.152 beta.kubernetes.io/fluentd-ds-ready=true
node &amp;quot;172.16.7.152&amp;quot; labeled
[root@node1 efk]# kubectl label nodes 172.16.7.153 beta.kubernetes.io/fluentd-ds-ready=true
node &amp;quot;172.16.7.153&amp;quot; labeled
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;执行定义文件&quot;&gt;&lt;a href=&quot;#执行定义文件&quot; class=&quot;headerlink&quot; title=&quot;执行定义文件&quot;&gt;&lt;/a&gt;执行定义文件&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;[root@node1 efk]# kubectl create -f .
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;检查执行结果&quot;&gt;&lt;a href=&quot;#检查执行结果&quot; class=&quot;headerlink&quot; title=&quot;检查执行结果&quot;&gt;&lt;/a&gt;检查执行结果&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;[root@node1 efk]# kubectl get deployment -n kube-system|grep kibana
kibana-logging         1         1         1            1           1h

[root@node1 efk]# kubectl get pods -n kube-system|grep -E &amp;apos;elasticsearch|fluentd|kibana&amp;apos;
elasticsearch-logging-v1-nw3p3          1/1       Running   0          43m
elasticsearch-logging-v1-pp89h          1/1       Running   0          43m
fluentd-es-v1.22-cqd1s                  1/1       Running   0          15m
fluentd-es-v1.22-f5ljr                  0/1       Error     6          15m
fluentd-es-v1.22-x24jx                  1/1       Running   0          15m
kibana-logging-4293390753-kg8kx         1/1       Running   0          1h

[root@node1 efk]# kubectl get service  -n kube-system|grep -E &amp;apos;elasticsearch|kibana&amp;apos;
elasticsearch-logging   10.254.50.63     &amp;lt;none&amp;gt;        9200/TCP                        1h
kibana-logging          10.254.169.159   &amp;lt;none&amp;gt;        5601/TCP                        1h
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;kibana Pod 第一次启动时会用&lt;strong&gt;较长时间(10-20分钟)&lt;/strong&gt;来优化和 Cache 状态页面，可以 tailf 该 Pod 的日志观察进度。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 efk]# kubectl logs kibana-logging-4293390753-86h5d -n kube-system -f
ELASTICSEARCH_URL=http://elasticsearch-logging:9200
server.basePath: /api/v1/proxy/namespaces/kube-system/services/kibana-logging
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T00:51:31Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;info&amp;quot;,&amp;quot;optimize&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;message&amp;quot;:&amp;quot;Optimizing and caching bundles for kibana and statusPage. This may take a few minutes&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:36Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;info&amp;quot;,&amp;quot;optimize&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;message&amp;quot;:&amp;quot;Optimization of bundles for kibana and statusPage complete in 1324.64 seconds&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:37Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;status&amp;quot;,&amp;quot;plugin:kibana@1.0.0&amp;quot;,&amp;quot;info&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;state&amp;quot;:&amp;quot;green&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;Status changed from uninitialized to green - Ready&amp;quot;,&amp;quot;prevState&amp;quot;:&amp;quot;uninitialized&amp;quot;,&amp;quot;prevMsg&amp;quot;:&amp;quot;uninitialized&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:38Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;status&amp;quot;,&amp;quot;plugin:elasticsearch@1.0.0&amp;quot;,&amp;quot;info&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;state&amp;quot;:&amp;quot;yellow&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;Status changed from uninitialized to yellow - Waiting for Elasticsearch&amp;quot;,&amp;quot;prevState&amp;quot;:&amp;quot;uninitialized&amp;quot;,&amp;quot;prevMsg&amp;quot;:&amp;quot;uninitialized&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:39Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;status&amp;quot;,&amp;quot;plugin:kbn_vislib_vis_types@1.0.0&amp;quot;,&amp;quot;info&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;state&amp;quot;:&amp;quot;green&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;Status changed from uninitialized to green - Ready&amp;quot;,&amp;quot;prevState&amp;quot;:&amp;quot;uninitialized&amp;quot;,&amp;quot;prevMsg&amp;quot;:&amp;quot;uninitialized&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:39Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;status&amp;quot;,&amp;quot;plugin:markdown_vis@1.0.0&amp;quot;,&amp;quot;info&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;state&amp;quot;:&amp;quot;green&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;Status changed from uninitialized to green - Ready&amp;quot;,&amp;quot;prevState&amp;quot;:&amp;quot;uninitialized&amp;quot;,&amp;quot;prevMsg&amp;quot;:&amp;quot;uninitialized&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:39Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;status&amp;quot;,&amp;quot;plugin:metric_vis@1.0.0&amp;quot;,&amp;quot;info&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;state&amp;quot;:&amp;quot;green&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;Status changed from uninitialized to green - Ready&amp;quot;,&amp;quot;prevState&amp;quot;:&amp;quot;uninitialized&amp;quot;,&amp;quot;prevMsg&amp;quot;:&amp;quot;uninitialized&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:39Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;status&amp;quot;,&amp;quot;plugin:spyModes@1.0.0&amp;quot;,&amp;quot;info&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;state&amp;quot;:&amp;quot;green&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;Status changed from uninitialized to green - Ready&amp;quot;,&amp;quot;prevState&amp;quot;:&amp;quot;uninitialized&amp;quot;,&amp;quot;prevMsg&amp;quot;:&amp;quot;uninitialized&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:40Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;status&amp;quot;,&amp;quot;plugin:statusPage@1.0.0&amp;quot;,&amp;quot;info&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;state&amp;quot;:&amp;quot;green&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;Status changed from uninitialized to green - Ready&amp;quot;,&amp;quot;prevState&amp;quot;:&amp;quot;uninitialized&amp;quot;,&amp;quot;prevMsg&amp;quot;:&amp;quot;uninitialized&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:40Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;status&amp;quot;,&amp;quot;plugin:table_vis@1.0.0&amp;quot;,&amp;quot;info&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;state&amp;quot;:&amp;quot;green&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;Status changed from uninitialized to green - Ready&amp;quot;,&amp;quot;prevState&amp;quot;:&amp;quot;uninitialized&amp;quot;,&amp;quot;prevMsg&amp;quot;:&amp;quot;uninitialized&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:40Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;listening&amp;quot;,&amp;quot;info&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;message&amp;quot;:&amp;quot;Server running at http://0.0.0.0:5601&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:45Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;status&amp;quot;,&amp;quot;plugin:elasticsearch@1.0.0&amp;quot;,&amp;quot;info&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;state&amp;quot;:&amp;quot;yellow&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;Status changed from yellow to yellow - No existing Kibana index found&amp;quot;,&amp;quot;prevState&amp;quot;:&amp;quot;yellow&amp;quot;,&amp;quot;prevMsg&amp;quot;:&amp;quot;Waiting for Elasticsearch&amp;quot;}
{&amp;quot;type&amp;quot;:&amp;quot;log&amp;quot;,&amp;quot;@timestamp&amp;quot;:&amp;quot;2017-10-13T01:13:49Z&amp;quot;,&amp;quot;tags&amp;quot;:[&amp;quot;status&amp;quot;,&amp;quot;plugin:elasticsearch@1.0.0&amp;quot;,&amp;quot;info&amp;quot;],&amp;quot;pid&amp;quot;:5,&amp;quot;state&amp;quot;:&amp;quot;green&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;Status changed from yellow to green - Kibana index ready&amp;quot;,&amp;quot;prevState&amp;quot;:&amp;quot;yellow&amp;quot;,&amp;quot;prevMsg&amp;quot;:&amp;quot;No existing Kibana index found&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;访问-kibana&quot;&gt;&lt;a href=&quot;#访问-kibana&quot; class=&quot;headerlink&quot; title=&quot;访问 kibana&quot;&gt;&lt;/a&gt;访问 kibana&lt;/h2&gt;&lt;h3 id=&quot;通过-kube-apiserver-访问：获取-kibana-服务-URL&quot;&gt;&lt;a href=&quot;#通过-kube-apiserver-访问：获取-kibana-服务-URL&quot; class=&quot;headerlink&quot; title=&quot;通过 kube-apiserver 访问：获取 kibana 服务 URL&quot;&gt;&lt;/a&gt;通过 kube-apiserver 访问：获取 kibana 服务 URL&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@node1 efk]# kubectl cluster-info
Kubernetes master is running at https://172.16.7.151:6443
Elasticsearch is running at https://172.16.7.151:6443/api/v1/proxy/namespaces/kube-system/services/elasticsearch-logging
Heapster is running at https://172.16.7.151:6443/api/v1/proxy/namespaces/kube-system/services/heapster
Kibana is running at https://172.16.7.151:6443/api/v1/proxy/namespaces/kube-system/services/kibana-logging
KubeDNS is running at https://172.16.7.151:6443/api/v1/proxy/namespaces/kube-system/services/kube-dns
kubernetes-dashboard is running at https://172.16.7.151:6443/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard
monitoring-grafana is running at https://172.16.7.151:6443/api/v1/proxy/namespaces/kube-system/services/monitoring-grafana
monitoring-influxdb is running at https://172.16.7.151:6443/api/v1/proxy/namespaces/kube-system/services/monitoring-influxdb

To further debug and diagnose cluster problems, use &amp;apos;kubectl cluster-info dump&amp;apos;.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;浏览器访问 URL： &lt;a href=&quot;https://172.16.7.151:6443/api/v1/proxy/namespaces/kube-system/services/kibana-logging/app/kibana&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://172.16.7.151:6443/api/v1/proxy/namespaces/kube-system/services/kibana-logging/app/kibana&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;通过-kubectl-proxy-访问：创建代理&quot;&gt;&lt;a href=&quot;#通过-kubectl-proxy-访问：创建代理&quot; class=&quot;headerlink&quot; title=&quot;通过 kubectl proxy 访问：创建代理&quot;&gt;&lt;/a&gt;通过 kubectl proxy 访问：创建代理&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@node1 efk]# kubectl proxy --address=&amp;apos;172.16.7.151&amp;apos; --port=8086 --accept-hosts=&amp;apos;^*$&amp;apos; &amp;amp;        
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;浏览器访问 URL：&lt;a href=&quot;http://172.16.7.151:8086/api/v1/proxy/namespaces/kube-system/services/kibana-logging&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.7.151:8086/api/v1/proxy/namespaces/kube-system/services/kibana-logging&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kubernetes/16.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果你在这里发现Create按钮是灰色的无法点击，且Time-filed name中没有选项，fluentd要读取/var/log/containers/目录下的log日志，这些日志是从/var/lib/docker/containers/${CONTAINER_ID}/${CONTAINER_ID}-json.log链接过来的，查看你的docker配置，—-log-driver需要设置为json-file格式，默认的可能是journald。&lt;/p&gt;
&lt;p&gt;查看当前的–log-driver:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# docker version
Client:
 Version:         1.12.6
 API version:     1.24
 Package version: docker-1.12.6-32.git88a4867.el7.centos.x86_64
 Go version:      go1.7.4
 Git commit:      88a4867/1.12.6
 Built:           Mon Jul  3 16:02:02 2017
 OS/Arch:         linux/amd64

Server:
 Version:         1.12.6
 API version:     1.24
 Package version: docker-1.12.6-32.git88a4867.el7.centos.x86_64
 Go version:      go1.7.4
 Git commit:      88a4867/1.12.6
 Built:           Mon Jul  3 16:02:02 2017
 OS/Arch:         linux/amd64   
[root@node1 efk]# docker info |grep &amp;apos;Logging Driver&amp;apos;
 WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.
WARNING: bridge-nf-call-ip6tables is disabled
Logging Driver: journald
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;修改当前版本docker的–log-driver:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# vim /etc/sysconfig/docker
OPTIONS=&amp;apos;--selinux-enabled --log-driver=json-file --signature-verification=false&amp;apos;
[root@node1 efk]# systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;【注意】：本来修改这个参数应该在在/etc/docker/daemon.json文件中添加&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;log-driver&amp;quot;: &amp;quot;json-file&amp;quot;,
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但是在该版本中，–log-driver是在文件/etc/sysconfig/docker中定义的。&lt;br&gt;在docker-ce版本中，默认的–log-driver是json-file。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;遇到的问题：&lt;/strong&gt;&lt;br&gt;由于之前在/etc/docker/daemon.json中配置–log-driver，重启导致docker程序启动失败，等到后来在/etc/sysconfig/docker配置文件中配置好后，启动docker却发现当前node变成NotReady状态，所有的Pod也变为Unknown状态。查看kubelet状态，发现kubelet程序已经挂掉了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# kubectl get nodes
NAME           STATUS     AGE       VERSION
172.16.7.151   NotReady   28d       v1.6.0
172.16.7.152   Ready      28d       v1.6.0
172.16.7.153   Ready      28d       v1.6.0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动kubelet：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 ~]# systemctl start kubelet
[root@node1 ~]# kubectl get nodes
NAME           STATUS    AGE       VERSION
172.16.7.151   Ready     28d       v1.6.0
172.16.7.152   Ready     28d       v1.6.0
172.16.7.153   Ready     28d       v1.6.0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;浏览器再次访问 kibana URL：&lt;a href=&quot;http://172.16.7.151:8086/api/v1/proxy/namespaces/kube-system/services/kibana-logging&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.7.151:8086/api/v1/proxy/namespaces/kube-system/services/kibana-logging&lt;/a&gt;&lt;br&gt;此时就会发现有Create按钮了。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kubernetes/17.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在 Settings -&amp;gt; Indices 页面创建一个 index（相当于 mysql 中的一个 database），去掉已经勾选的 &lt;strong&gt;Index contains time-based events&lt;/strong&gt;，使用默认的 &lt;strong&gt;logstash-*&lt;/strong&gt; pattern，点击 Create ;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kubernetes/18.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;创建Index后，可以在 Discover 下看到 ElasticSearch logging 中汇聚的日志。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kubernetes/19.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;EFK介绍&quot;&gt;&lt;a href=&quot;#EFK介绍&quot; class=&quot;headerlink&quot; title=&quot;EFK介绍&quot;&gt;&lt;/a&gt;EFK介绍&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Logstash(或者Fluentd)负责收集日志 &lt;/li&gt;
&lt;li&gt;Elasticsearch存储日志并提供搜索 &lt;/li&gt;
&lt;li&gt;Kibana负责日志查询和展示&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;官方地址：&lt;a href=&quot;https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/fluentd-elasticsearch&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/fluentd-elasticsearch&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="容器编排" scheme="http://yoursite.com/categories/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/"/>
    
    
      <category term="Kubernetes" scheme="http://yoursite.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes架构</title>
    <link href="http://yoursite.com/2017/10/09/Kubernetes%E6%9E%B6%E6%9E%84/"/>
    <id>http://yoursite.com/2017/10/09/Kubernetes架构/</id>
    <published>2017-10-09T06:49:31.000Z</published>
    <updated>2017-11-13T07:39:34.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Kubernetes整体架构&quot;&gt;&lt;a href=&quot;#Kubernetes整体架构&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes整体架构&quot;&gt;&lt;/a&gt;Kubernetes整体架构&lt;/h2&gt;&lt;p&gt;Kubernetes的整体架构如下图：&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kubernetes/14.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Kubernetes主要由以下几个核心组件组成:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;etcd保存了整个集群的状态; &lt;/li&gt;
&lt;li&gt;apiserver提供了资源操作的唯一入口,并提供认证、授权、访问控制、API注册和 发现等机制;&lt;/li&gt;
&lt;li&gt;controller manager负责维护集群的状态,比如故障检测、自动扩展、滚动更新等; - scheduler负责资源的调度,按照预定的调度策略将Pod调度到相应的机器上;&lt;/li&gt;
&lt;li&gt;kubelet负责维护容器的生命周期,同时也负责Volume(CVI)和网络(CNI)的管 理;&lt;/li&gt;
&lt;li&gt;Container runtime负责镜像管理以及Pod和容器的真正运行(CRI); &lt;/li&gt;
&lt;li&gt;kube-proxy负责为Service提供cluster内部的服务发现和负载均衡;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了核心组件,还有一些推荐的Add-ons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kube-dns负责为整个集群提供DNS服务 &lt;/li&gt;
&lt;li&gt;Ingress Controller为服务提供外网入口 &lt;/li&gt;
&lt;li&gt;Heapster提供资源监控 &lt;/li&gt;
&lt;li&gt;Dashboard提供GUI&lt;/li&gt;
&lt;li&gt;Federation提供跨可用区的集群 &lt;/li&gt;
&lt;li&gt;Fluentd-elasticsearch提供集群日志采集、存储与查询&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes总体包含两种角色，一个是Master节点，负责集群调度、对外接口、访问控制、对象的生命周期维护等工作；另一个是Node节点，负责维护容器的生命周期，例如创建、删除、停止Docker容器，负责容器的服务抽象和负载均衡等工作。其中Master节点上，运行着三个核心组件：API Server, Scheduler, Controller Mananger。Node节点上运行两个核心组件：Kubelet， Kube-Proxy。API Server提供Kubernetes集群访问的统一接口，Scheduler, Controller Manager, Kubelet, Kube-Proxy等组件都通过API Server进行通信，API Server将Pod, Service, Replication Controller, Daemonset等对象存储在ETCD集群中。ETCD是CoreOS开发的高效、稳定的强一致性Key-Value数据库，ETCD本身可以搭建成集群对外服务，它负责存储Kubernetes所有对象的生命周期，是Kubernetes的最核心的组件。&lt;/p&gt;
&lt;h2 id=&quot;核心组件介绍&quot;&gt;&lt;a href=&quot;#核心组件介绍&quot; class=&quot;headerlink&quot; title=&quot;核心组件介绍&quot;&gt;&lt;/a&gt;核心组件介绍&lt;/h2&gt;&lt;p&gt;下面先大概介绍一下Kubernetes的核心组件的功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;API Server: 提供了资源对象的唯一操作入口，其他所有的组件都必须通过它提供的API来操作资源对象。它以RESTful风格的API对外提供接口。所有Kubernetes资源对象的生命周期维护都是通过调用API Server的接口来完成，例如，用户通过kubectl创建一个Pod，即是通过调用API Server的接口创建一个Pod对象，并储存在ETCD集群中。&lt;/li&gt;
&lt;li&gt;Controller Manager: 集群内部的管理控制中心，主要目的是实现Kubernetes集群的故障检测和自动恢复等工作。它包含两个核心组件：Node Controller和Replication Controller。其中Node Controller负责计算节点的加入和退出，可以通过Node Controller实现计算节点的扩容和缩容。Replication Controller用于Kubernetes资源对象RC的管理，应用的扩容、缩容以及滚动升级都是有Replication Controller来实现。&lt;/li&gt;
&lt;li&gt;Scheduler: 集群中的调度器，负责Pod在集群的中的调度和分配。&lt;/li&gt;
&lt;li&gt;Kubelet: 负责本Node节点上的Pod的创建、修改、监控、删除等Pod的全生命周期管理，Kubelet实时向API Server发送所在计算节点（Node）的信息。&lt;/li&gt;
&lt;li&gt;Kube-Proxy: 实现Service的抽象，为一组Pod抽象的服务（Service）提供统一接口并提供负载均衡功能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;核心原理介绍&quot;&gt;&lt;a href=&quot;#核心原理介绍&quot; class=&quot;headerlink&quot; title=&quot;核心原理介绍&quot;&gt;&lt;/a&gt;核心原理介绍&lt;/h2&gt;&lt;h3 id=&quot;API-Server&quot;&gt;&lt;a href=&quot;#API-Server&quot; class=&quot;headerlink&quot; title=&quot;API Server&quot;&gt;&lt;/a&gt;API Server&lt;/h3&gt;&lt;p&gt;1.如何访问Kubernetes API，Kubernetes API通过一个kube-apiserver的进程提供服务，该进程运行在Kubernetes Master节点上，默认的情况下，监听两个端口：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;本地端口: 默认值为8080，用于接收HTTP请求，非认证授权的HTTP请求通过该端口访问API Server。&lt;/li&gt;
&lt;li&gt;安全端口：默认值为6443，用于接收HTTPS请求，用于基于Token文件或者客户端证书及HTTP Base的认证，用于基于策略的授权，Kubernetes默认情况下不启动HTTPS安全访问机制。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用户可以通过编程方式访问API接口，也可以通过curl命令来直接访问它，例如，我们在Master节点上访问API Server：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;36&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;37&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;38&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;39&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;40&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;41&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;42&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;43&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;44&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;45&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;46&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;47&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;48&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;[root@node1 ~]# curl http://172.16.7.151:8080/ap/&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  &amp;quot;paths&amp;quot;: [&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/api&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/api/v1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/apps&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/apps/v1beta1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/authentication.k8s.io&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/authentication.k8s.io/v1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/authentication.k8s.io/v1beta1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/authorization.k8s.io&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/authorization.k8s.io/v1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/authorization.k8s.io/v1beta1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/autoscaling&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/autoscaling/v1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/autoscaling/v2alpha1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/batch&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/batch/v1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/batch/v2alpha1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/certificates.k8s.io&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/certificates.k8s.io/v1beta1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/extensions&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/extensions/v1beta1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/policy&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/policy/v1beta1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/rbac.authorization.k8s.io&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/rbac.authorization.k8s.io/v1alpha1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/rbac.authorization.k8s.io/v1beta1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/settings.k8s.io&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/settings.k8s.io/v1alpha1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/storage.k8s.io&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/storage.k8s.io/v1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/apis/storage.k8s.io/v1beta1&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/healthz&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/healthz/ping&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/healthz/poststarthook/bootstrap-controller&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/healthz/poststarthook/ca-registration&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/healthz/poststarthook/extensions/third-party-resources&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/healthz/poststarthook/rbac/bootstrap-roles&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/logs&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/metrics&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/swagger-ui/&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/swaggerapi/&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/ui/&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;/version&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  ]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Kubernetes还提供了一个代理程序——Kubectl Proxy，它既能作为API Server的反向代理，也能作为普通客户端访问API Server，使用方法如下：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;# kubectl proxy --port=9090 &amp;amp;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;# curl http://172.16.7.151:9090/api&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  &amp;quot;kind&amp;quot;: &amp;quot;APIVersions&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  &amp;quot;versions&amp;quot;: [&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;quot;v1&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  ],&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  &amp;quot;serverAddressByClientCIDRs&amp;quot;: [&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      &amp;quot;clientCIDR&amp;quot;: &amp;quot;0.0.0.0/0&amp;quot;,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      &amp;quot;serverAddress&amp;quot;: &amp;quot;172.16.7.151:6443&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  ]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;2.集群功能模块之间的通信&lt;br&gt;API Server是整个集群的核心，负责集群各个模块之间的通信。集群内部的功能模块通过API Server将信息存入ETCD，其他模块通过API Server读取这些信息，从而实现各模块之间的信息交互。比如，Node节点上的Kubelet每个一个时间周期，通过API Server报告自身状态，API Server接收这些信息后，将节点状态信息保存到ETCd中。Controller Manager中的Node Controller通过API Server定期读取这些节点状态信息，并做相应处理。Scheduler监听到某个Pod创建的信息后，检索所有符合该Pod要求的节点列表，并将Pod绑定到节点李彪中最符合要求的节点上：如果Scheduler监听到某个Pod被删除，则删除本节点上的相应Pod实例。&lt;br&gt;从上面的通信过程可以看出，API Server的访问压力很大，这也是限制（制约）Kubernetes集群规模的关键，缓解API Server的压力可以通过缓存来实现，通过watch/list操作，将资源对象的信息缓存到本地，这种方法在一定程度上缓解了API Server的压力，但是不是最好的解决办法。&lt;/p&gt;
&lt;h3 id=&quot;Controller-Manager&quot;&gt;&lt;a href=&quot;#Controller-Manager&quot; class=&quot;headerlink&quot; title=&quot;Controller Manager&quot;&gt;&lt;/a&gt;Controller Manager&lt;/h3&gt;&lt;p&gt;Controller Manager作为集群的内部管理控制中心，负责集群内的Node，Pod，RC，服务端点（Endpoint），命名空间（Namespace），服务账号（ServiceAccount）、资源配额（ResourceQuota）等的管理并执行自动化修复流程，确保集群出处于预期的工作状态，比如，RC实现自动控制Pod活跃副本数，如果Pod出错退出，RC自动创建一个新的Pod，来保持活跃的Pod的个数。&lt;br&gt;Controller Manager包含Replication Controller、Node Controller、ResourceQuota Controller、Namespace Controller、ServiceAccount Controller、Token Controller、Server Controller以及Endpoint Controller等多个控制器，Controller Manager是这些Controller的管理者。&lt;/p&gt;
&lt;h3 id=&quot;Scheduler&quot;&gt;&lt;a href=&quot;#Scheduler&quot; class=&quot;headerlink&quot; title=&quot;Scheduler&quot;&gt;&lt;/a&gt;Scheduler&lt;/h3&gt;&lt;p&gt;Kubernetes Scheduler负责Pod的调度管理，它负责将要创建的Pod按照一定的规则分配在某个适合的Node上。&lt;br&gt;Scheduler的默认调度流程分为以下两步：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;预选调度过程，即遍历所有目标Node，筛选出符合要求的候选节点。为此，Kubernetes内置了多种预选策略供用户选择。&lt;/li&gt;
&lt;li&gt;确定最优节点，在第一步的基础上，采用优选策略为每个候选节点打分，分值最高的胜出。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Scheduler的调度流程是通过插件方式加载“调度算法提供者”具体实现的，一个调度算法提供者其实就是包括了一组预选策略与一组有限选择策略的结构体，注册算法插件的函数如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func RegisterAlgorithmProvider(name string, predicateKeys, priorityKeys util.StringSet)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;它包含3个参数：“name string”参数为算法名，“predicateKeys”为为算法用到的预选策略集合，”priorityKeys”为算法用到的优选策略集合。&lt;br&gt;Scheduler中可用的预算策略包含：NoDiskConflict,  PodFitResources, PodSelectorMatches,  PodFitHost,  CheckNodeLabelPresence,  CheckServiceAffinity和PodFitsPorts策略等。其默认的AlgorithmProvider加载的预选策略Predicates包括：PodFitsPorts,  PodFitsResources,  NoDiskConflict,  MatchNodeSelector和HostName，即每个节点只有通过前面的五个默认预选策略后，才能初步被选中，进入下一个流程。&lt;/p&gt;
&lt;h3 id=&quot;kubelet&quot;&gt;&lt;a href=&quot;#kubelet&quot; class=&quot;headerlink&quot; title=&quot;kubelet&quot;&gt;&lt;/a&gt;kubelet&lt;/h3&gt;&lt;p&gt;在Kubernetes集群中，每个计算节点（Node）上会运行一个守护进程：Kubelet。它用于处理Master节点下发到本节点的任务，管理Pod以及Pod中的容器。每个Kubelet进程会在API Server上注册自身节点的信息，定期向API Server汇报节点资源的使用情况，并通过cAdvise监控容器和节点资源。&lt;br&gt;Kubelet主要功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点管理：kubelet可以自动向API Server注册自己，它可以采集所在计算节点的资源信息和使用情况并提交给API Server，通过启动/停止kubelet进程来实现计算节点的扩容、缩容。&lt;/li&gt;
&lt;li&gt;Pod管理：kubelet通过API Server监听ETCD目录，同步Pod清单，当发现有新的Pod绑定到所在的节点，则按照Pod清单的要求创建改清单。如果发现本地的Pod被删除，则kubelet通过docker client删除该容器。&lt;/li&gt;
&lt;li&gt;健康检查：Pod通过两类探针来检查容器的健康状态。一个是LivenessProbe探针，用于判断容器是否健康，如果LivenessProbe探针探测到容器不健康，则kubelet将删除该容器，并根据容器的重启策略做相应的处理。另一类是ReadnessProbe探针，用于判断容器是否启动完成，且准备接受请求，如果ReadnessProbe探针检测到失败，则Pod的状态被修改。Enpoint Controller将从Service的Endpoint中删除包含该容器的IP地址的Endpoint条目。kubelet定期调用LivenessProbe探针来诊断容器的健康状况，它目前支持三种探测：HTTP的方式发送GET请求; TCP方式执行Connect目的端口; Exec的方式，执行一个脚本。&lt;/li&gt;
&lt;li&gt;cAdvisor资源监控: 在Kubernetes集群中，应用程序的执行情况可以在不同的级别上检测到，这些级别包含Container，Pod，Service和整个集群。作为Kubernetes集群的一部分，Kubernetes希望提供给用户各个级别的资源使用信息，这将使用户能够更加深入地了解应用的执行情况，并找到可能的瓶颈。Heapster项目为Kubernetes提供了一个基本的监控平台，他是集群级别的监控和事件数据集成器。Heapster通过收集所有节点的资源使用情况，将监控信息实时推送至一个可配置的后端，用于存储和可视化展示。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;kube-proxy&quot;&gt;&lt;a href=&quot;#kube-proxy&quot; class=&quot;headerlink&quot; title=&quot;kube-proxy&quot;&gt;&lt;/a&gt;kube-proxy&lt;/h3&gt;&lt;p&gt;每台机器上都运行一个kube-proxy服务,它监听API server中service和endpoint的变化 情况,并通过iptables等来为服务配置负载均衡(仅支持TCP和UDP)。&lt;br&gt;kube-proxy可以直接运行在物理机上,也可以以static pod或者daemonset的方式运行。 kube-proxy当前支持以下几种实现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;userspace:最早的负载均衡方案,它在用户空间监听一个端口,所有服务通过 iptables转发到这个端口,然后在其内部负载均衡到实际的Pod。该方式最主要的问 题是效率低,有明显的性能瓶颈。 &lt;/li&gt;
&lt;li&gt;iptables:目前推荐的方案,完全以iptables规则的方式来实现service负载均衡。该 方式最主要的问题是在服务多的时候产生太多的iptables规则(社区有人提到过几万 条),大规模下也有性能问题 &lt;/li&gt;
&lt;li&gt;winuserspace:同userspace,但仅工作在windows上&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外,基于ipvs的方案正在讨论中,大规模情况下可以大幅提升性 能,比如slide里面提供的示例将服务延迟从小时缩短到毫秒级。&lt;br&gt;kube-proxy目前仅支持TCP和UDP,不支持HTTP路由,并且也没有健康检查机制。这 些可以通过自定义Ingress Controller的方法来解决。&lt;/p&gt;
&lt;h3 id=&quot;kube-dns&quot;&gt;&lt;a href=&quot;#kube-dns&quot; class=&quot;headerlink&quot; title=&quot;kube-dns&quot;&gt;&lt;/a&gt;kube-dns&lt;/h3&gt;&lt;p&gt;kube-dns为Kubernetes集群提供命名服务,一般通过addon的方式部署,从v1.3版本开 始,成为了一个内建的自启动服务。&lt;/p&gt;
&lt;h2 id=&quot;Kubernetes应用部署模型&quot;&gt;&lt;a href=&quot;#Kubernetes应用部署模型&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes应用部署模型&quot;&gt;&lt;/a&gt;Kubernetes应用部署模型&lt;/h2&gt;&lt;p&gt;主要包括Pod、Replication controller、Label和Service。&lt;/p&gt;
&lt;h3 id=&quot;Pod&quot;&gt;&lt;a href=&quot;#Pod&quot; class=&quot;headerlink&quot; title=&quot;Pod&quot;&gt;&lt;/a&gt;Pod&lt;/h3&gt;&lt;p&gt;Kubernetes的最小部署单元是Pod而不是容器。作为First class API公民，Pods能被创建，调度和管理。简单地来说，像一个豌豆荚中的豌豆一样，一个Pod中的应用容器同享同一个上下文：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;PID 名字空间。但是在docker中不支持&lt;/li&gt;
&lt;li&gt;网络名字空间，在同一Pod中的多个容器访问同一个IP和端口空间。&lt;/li&gt;
&lt;li&gt;IPC名字空间，同一个Pod中的应用能够使用SystemV IPC和POSIX消息队列进行通信。&lt;/li&gt;
&lt;li&gt;UTS名字空间，同一个Pod中的应用共享一个主机名。&lt;/li&gt;
&lt;li&gt;Pod中的各个容器应用还可以访问Pod级别定义的共享卷。&lt;br&gt;从生命周期来说，Pod应该是短暂的而不是长久的应用。 Pods被调度到节点，保持在这个节点上直到被销毁。当节点死亡时，分配到这个节点的Pods将会被删掉。将来可能会实现Pod的迁移特性。在实际使用时，我们一般不直接创建Pods, 我们通过replication controller来负责Pods的创建，复制，监控和销毁。一个Pod可以包括多个容器，他们直接往往相互协作完成一个应用功能。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;Replication-controller和ReplicaSet&quot;&gt;&lt;a href=&quot;#Replication-controller和ReplicaSet&quot; class=&quot;headerlink&quot; title=&quot;Replication controller和ReplicaSet&quot;&gt;&lt;/a&gt;Replication controller和ReplicaSet&lt;/h3&gt;&lt;p&gt;复制控制器确保Pod的一定数量的份数(replica)在运行。如果超过这个数量，控制器会杀死一些，如果少了，控制器会启动一些。控制器也会在节点失效、维护的时候来保证这个数量。所以强烈建议即使我们的份数是1，也要使用复制控制器，而不是直接创建Pod。&lt;br&gt;在生命周期上讲，复制控制器自己不会终止，但是跨度不会比Service强。Service能够横跨多个复制控制器管理的Pods。而且在一个Service的生命周期内，复制控制器能被删除和创建。Service和客户端程序是不知道复制控制器的存在的。&lt;br&gt;复制控制器创建的Pods应该是可以互相替换的和语义上相同的，这个对无状态服务特别合适。&lt;br&gt;在新版本的Kubernetes中建议使用ReplicaSet(也简称为rs)来取代 ReplicationController。ReplicaSet跟ReplicationController没有本质的不同,只是名字不 一样,并且ReplicaSet支持集合式的selector(ReplicationController仅支持等式)。&lt;br&gt;虽然也ReplicaSet可以独立使用,但建议使用 Deployment 来自动管理ReplicaSet,这 样就无需担心跟其他机制的不兼容问题(比如ReplicaSet不支持rolling-update但 Deployment支持),并且还支持版本记录、回滚、暂停升级等高级特性。&lt;br&gt;Pod是临时性的对象，被创建和销毁，而且不会恢复。复制器动态地创建和销毁Pod。虽然Pod会分配到IP地址，但是这个IP地址都不是持久的。这样就产生了一个疑问：外部如何消费Pod提供的服务呢？&lt;/p&gt;
&lt;h3 id=&quot;Service&quot;&gt;&lt;a href=&quot;#Service&quot; class=&quot;headerlink&quot; title=&quot;Service&quot;&gt;&lt;/a&gt;Service&lt;/h3&gt;&lt;p&gt;Service定义了一个Pod的逻辑集合和访问这个集合的策略。集合是通过定义Service时提供的Label选择器完成的。举个例子，我们假定有3个Pod的备份来完成一个图像处理的后端。这些后端备份逻辑上是相同的，前端不关心哪个后端在给它提供服务。虽然组成这个后端的实际Pod可能变化，前端客户端不会意识到这个变化，也不会跟踪后端。Service就是用来实现这种分离的抽象。&lt;br&gt;对于Service，我们还可以定义Endpoint，Endpoint把Service和Pod动态地连接起来。&lt;/p&gt;
&lt;h4 id=&quot;Service-Cluster-IP和-kuber-proxy&quot;&gt;&lt;a href=&quot;#Service-Cluster-IP和-kuber-proxy&quot; class=&quot;headerlink&quot; title=&quot;Service Cluster IP和 kuber proxy&quot;&gt;&lt;/a&gt;Service Cluster IP和 kuber proxy&lt;/h4&gt;&lt;p&gt;每个代理节点都运行了一个kube-proxy进程。这个进程从服务进程那边拿到Service和Endpoint对象的变化。 对每一个Service, 它在本地打开一个端口。 到这个端口的任意连接都会代理到后端Pod集合中的一个Pod IP和端口。在创建了服务后，服务Endpoint模型会体现后端Pod的 IP和端口列表，kube-proxy就是从这个endpoint维护的列表中选择服务后端的。另外Service对象的sessionAffinity属性也会帮助kube-proxy来选择哪个具体的后端。缺省情况下，后端Pod的选择是随机的。可以设置service.spec.sessionAffinity 成”ClientIP”来指定同一个ClientIP的流量代理到同一个后端。在实现上，kube-proxy会用IPtables规则把访问Service的Cluster IP和端口的流量重定向到这个本地端口。下面的部分会讲什么是service的Cluster IP。&lt;br&gt;注意：在0.18以前的版本中Cluster IP叫PortalNet IP。&lt;/p&gt;
&lt;h4 id=&quot;Pod-IP-and-Service-Cluster-IP&quot;&gt;&lt;a href=&quot;#Pod-IP-and-Service-Cluster-IP&quot; class=&quot;headerlink&quot; title=&quot;Pod IP and Service Cluster IP&quot;&gt;&lt;/a&gt;Pod IP and Service Cluster IP&lt;/h4&gt;&lt;p&gt;Pod IP 地址是实际存在于某个网卡(可以是虚拟设备)上的，但Service Cluster IP就不一样了，没有网络设备为这个地址负责。它是由kube-proxy使用Iptables规则重新定向到其本地端口，再均衡到后端Pod的。我们前面说的Service环境变量和DNS都使用Service的Cluster IP和端口。&lt;br&gt;就拿上面我们提到的图像处理程序为例。当我们的Service被创建时，Kubernetes给它分配一个地址10.0.0.1。这个地址从我们启动API的service-cluster-ip-range参数(旧版本为portal_net参数)指定的地址池中分配，比如–service-cluster-ip-range=10.0.0.0/16。假设这个Service的端口是1234。集群内的所有kube-proxy都会注意到这个Service。当proxy发现一个新的service后，它会在本地节点打开一个任意端口，建相应的iptables规则，重定向服务的IP和port到这个新建的端口，开始接受到达这个服务的连接。&lt;br&gt;当一个客户端访问这个service时，这些iptable规则就开始起作用，客户端的流量被重定向到kube-proxy为这个service打开的端口上，kube-proxy随机选择一个后端pod来服务客户。这个流程如下图所示：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kubernetes/15.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;根据Kubernetes的网络模型，使用Service Cluster IP和Port访问Service的客户端可以坐落在任意代理节点上。外部要访问Service，我们就需要给Service外部访问IP。&lt;/p&gt;
&lt;h4 id=&quot;外部访问Service&quot;&gt;&lt;a href=&quot;#外部访问Service&quot; class=&quot;headerlink&quot; title=&quot;外部访问Service&quot;&gt;&lt;/a&gt;外部访问Service&lt;/h4&gt;&lt;p&gt;Service对象在Cluster IP range池中分配到的IP只能在内部访问，如果服务作为一个应用程序内部的层次，还是很合适的。如果这个Service作为前端服务，准备为集群外的客户提供业务，我们就需要给这个服务提供公共IP了。&lt;br&gt;外部访问者是访问集群代理节点的访问者。为这些访问者提供服务，我们可以在定义Service时指定其spec.publicIPs，一般情况下publicIP 是代理节点的物理IP地址。和先前的Cluster IP range上分配到的虚拟的IP一样，kube-proxy同样会为这些publicIP提供Iptables 重定向规则，把流量转发到后端的Pod上。有了publicIP，我们就可以使用load balancer等常用的互联网技术来组织外部对服务的访问了。&lt;br&gt;spec.publicIPs在新的版本中标记为过时了，代替它的是spec.type=NodePort，这个类型的service，系统会给它在集群的各个代理节点上分配一个节点级别的端口，能访问到代理节点的客户端都能访问这个端口，从而访问到服务。&lt;/p&gt;
&lt;h3 id=&quot;Label和Label-selector&quot;&gt;&lt;a href=&quot;#Label和Label-selector&quot; class=&quot;headerlink&quot; title=&quot;Label和Label selector&quot;&gt;&lt;/a&gt;Label和Label selector&lt;/h3&gt;&lt;p&gt;Label标签在Kubernetes模型中占着非常重要的作用。Label表现为key/value对，附加到Kubernetes管理的对象上，典型的就是Pods。它们定义了这些对象的识别属性，用来组织和选择这些对象。Label可以在对象创建时附加在对象上，也可以对象存在时通过API管理对象的Label。&lt;br&gt;在定义了对象的Label后，其它模型可以用Label 选择器（selector)来定义其作用的对象。&lt;br&gt;Label选择器有两种，分别是Equality-based和Set-based。&lt;br&gt;比如如下Equality-based选择器样例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;environment = production
tier != frontend
environment = production，tier != frontend
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;对于上面的选择器，第一条匹配Label具有environment key且等于production的对象，第二条匹配具有tier key，但是值不等于frontend的对象。由于kubernetes使用AND逻辑，第三条匹配production但不是frontend的对象。&lt;br&gt;Set-based选择器样例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;environment in (production, qa)
tier notin (frontend, backend)
partition
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第一条选择具有environment key，而且值是production或者qa的label附加的对象。第二条选择具有tier key，但是其值不是frontend和backend。第三条选则具有partition key的对象，不对value进行校验。&lt;br&gt;replication controller复制控制器和Service都用label和label selctor来动态地配备作用对象。复制控制器在定义的时候就指定了其要创建Pod的Label和自己要匹配这个Pod的selector， API服务器应该校验这个定义。我们可以动态地修改replication controller创建的Pod的Label用于调式，数据恢复等。一旦某个Pod由于Label改变从replication controller移出来后，replication controller会马上启动一个新的Pod来确保复制池子中的份数。对于Service，Label selector可以用来选择一个Service的后端Pods。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Kubernetes整体架构&quot;&gt;&lt;a href=&quot;#Kubernetes整体架构&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes整体架构&quot;&gt;&lt;/a&gt;Kubernetes整体架构&lt;/h2&gt;&lt;p&gt;Kubernetes的整体架构如下图：&lt;br&gt;
    
    </summary>
    
      <category term="容器编排" scheme="http://yoursite.com/categories/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/"/>
    
    
      <category term="Kubernetes" scheme="http://yoursite.com/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins + Docker 持续集成</title>
    <link href="http://yoursite.com/2017/09/30/Jenkins-Docker-%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"/>
    <id>http://yoursite.com/2017/09/30/Jenkins-Docker-持续集成/</id>
    <published>2017-09-30T08:56:51.000Z</published>
    <updated>2017-11-14T02:17:53.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Jenkins介绍&quot;&gt;&lt;a href=&quot;#Jenkins介绍&quot; class=&quot;headerlink&quot; title=&quot;Jenkins介绍&quot;&gt;&lt;/a&gt;Jenkins介绍&lt;/h2&gt;&lt;p&gt;Jenkins是一个开源软件项目，是基于Java开发的一种持续集成工具，用于监控持续重复的工作，旨在提供一个开放易用的软件平台，使软件的持续集成变成可能。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装部署Jenkins&quot;&gt;&lt;a href=&quot;#安装部署Jenkins&quot; class=&quot;headerlink&quot; title=&quot;安装部署Jenkins&quot;&gt;&lt;/a&gt;安装部署Jenkins&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://jenkins.io/download/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://jenkins.io/download/&lt;/a&gt;&lt;br&gt;我这里下载war包安装，版本：1.642.3 LTS .war&lt;/p&gt;
&lt;h3 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;osb30&lt;/td&gt;
&lt;td&gt;Redhat 6.5&lt;/td&gt;
&lt;td&gt;172.16.206.30&lt;/td&gt;
&lt;td&gt;jenkins&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;新建Jenkins用户&quot;&gt;&lt;a href=&quot;#新建Jenkins用户&quot; class=&quot;headerlink&quot; title=&quot;新建Jenkins用户&quot;&gt;&lt;/a&gt;新建Jenkins用户&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@osb30 ~]# groupadd jenkins
[root@osb30 ~]# useradd -g jenkins jenkins
[root@osb30 ~]# id jenkins
uid=501(jenkins) gid=501(jenkins) groups=501(jenkins)
[root@osb30 ~]# echo &amp;quot;wisedu&amp;quot; | passwd --stdin jenkins &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;Jenkins安装方式&quot;&gt;&lt;a href=&quot;#Jenkins安装方式&quot; class=&quot;headerlink&quot; title=&quot;Jenkins安装方式&quot;&gt;&lt;/a&gt;Jenkins安装方式&lt;/h3&gt;&lt;p&gt;安装jenkins有两种方式，tomcat方式部署和java部署启动。本次实验我以tomcat下部署启动为例。&lt;/p&gt;
&lt;h4 id=&quot;tomcat方式部署&quot;&gt;&lt;a href=&quot;#tomcat方式部署&quot; class=&quot;headerlink&quot; title=&quot;tomcat方式部署&quot;&gt;&lt;/a&gt;tomcat方式部署&lt;/h4&gt;&lt;p&gt;1.首先安装tomcat和JAVA，配置环境变量（此步骤不再讲述，java配置不可缺少）&lt;br&gt;我这里安装的是jdk 1.8.0_65。&lt;/p&gt;
&lt;p&gt;2.将从官网下载下来的jenkins.war文件放入tomcat下的webapps目录下，进入tomcat的/bin目录下，启动tomcat即启动jenkins。&lt;br&gt;我这里用的是tomcat8。&lt;/p&gt;
&lt;p&gt;3.启动jenkins时，会自动在webapps目录下建立jenkins目录，访问地址为：&lt;a href=&quot;http://localhost:8080/jenkins&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://localhost:8080/jenkins&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[jenkins@osb30 ~]$ tar zxf apache-tomcat-8.0.30.tar.gz
[jenkins@osb30 ~]$ mv jenkins.war apache-tomcat-8.0.30/webapps/
[jenkins@osb30 ~]$ cd apache-tomcat-8.0.30
[jenkins@osb30 apache-tomcat-8.0.30]$ bin/startup.sh
Jenkins home directory: /home/jenkins/.jenkins found at: $user.home/.jenkins
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果启动时报错：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Caused by:java.awt.AWTError: Can&amp;apos;t connect to X11 window server using &amp;apos;:0&amp;apos; as the value of the DISPLAY varible...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;解决：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[jenkins@osb30 ~]$ cd apache-tomcat-8.0.30/bin/
[jenkins@osb30 bin]$ vim catalina.sh 
JAVA_OPTS=&amp;quot;-Xms1024m -Xmx1024m -Djava.awt.headless=true&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.访问jenkins&lt;br&gt;&lt;a href=&quot;http://172.16.206.30:8080/jenkins&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.206.30:8080/jenkins&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;java部署启动jenkins&quot;&gt;&lt;a href=&quot;#java部署启动jenkins&quot; class=&quot;headerlink&quot; title=&quot;java部署启动jenkins&quot;&gt;&lt;/a&gt;java部署启动jenkins&lt;/h4&gt;&lt;p&gt;切换到jenkins.war存放的目录，输入如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ java -jar jenkins.war   
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以修改启动端口&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ java -jar jenkins.war --httpPort=8000
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后在浏览器中（推荐用火狐、chrome）输入&lt;a href=&quot;http://localhost:8080，localhost可以是本机的ip，也可以是计算机名。就可以打开jenkins；修改端口后，访问地址的端口需同步变更。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://localhost:8080，localhost可以是本机的ip，也可以是计算机名。就可以打开jenkins；修改端口后，访问地址的端口需同步变更。&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Jenkins授权和访问控制&quot;&gt;&lt;a href=&quot;#Jenkins授权和访问控制&quot; class=&quot;headerlink&quot; title=&quot;Jenkins授权和访问控制&quot;&gt;&lt;/a&gt;Jenkins授权和访问控制&lt;/h3&gt;&lt;p&gt;默认地Jenkins不包含任何的安全检查，任何人可以修改Jenkins设置，job和启动build等。显然地在大规模的公司需要多个部门一起协调工作的时候，没有任何安全检查会带来很多的问题。 我们可以通过下面的方式来增强Jenkins的安全：&lt;br&gt;访问jenkins：&lt;a href=&quot;http://172.16.206.30:8080/jenkins，&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.206.30:8080/jenkins，&lt;/a&gt;&lt;br&gt;点击系统管理—&amp;gt; Configure Global Security，点击”启用安全”，可以看到可以使用多种方式来增强Jenkins的授权和访问控制：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/44.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/45.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;如上图所示，默认是”任何用户可以做任何事情(没有任何限制)”。&lt;br&gt;我们在”安全域”选择”Jenkins专有用户数据库”，”允许用户注册”；并先在“授权策略”点击“任何用户可以做任何事情(没有任何限制)”， 防止注册之后无法再管理jenkins。此时就可以刷新一下jenkins的页面看到右上角有登录、注册的按钮。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/46.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;注册管理员账号&quot;&gt;&lt;a href=&quot;#注册管理员账号&quot; class=&quot;headerlink&quot; title=&quot;注册管理员账号&quot;&gt;&lt;/a&gt;注册管理员账号&lt;/h4&gt;&lt;p&gt;1.点击注册，首先注册一个管理员账号。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/47.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;2.点击系统管理—&amp;gt; Configure Global Security，在“授权策略”选择”安全矩阵”，添加用户/组——添加admin账户——为admin账户添加所有权限，为匿名用户勾选你希望对方了解的功能。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/48.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;【注意】：匿名用户一定要开启此处的可读权限，若不开启，后面github或者bitbucket的webhook自动构建会没有权限。&lt;br&gt;并且勾选上该项，点击保存。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/49.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;做完此部操作之后，即可用admin帐号登录，取消登录用户可以做任何事的权限。&lt;br&gt;以上操作，即可完成jenkins的授权和访问控制。&lt;/p&gt;
&lt;h3 id=&quot;Jenkins系统配置&quot;&gt;&lt;a href=&quot;#Jenkins系统配置&quot; class=&quot;headerlink&quot; title=&quot;Jenkins系统配置&quot;&gt;&lt;/a&gt;Jenkins系统配置&lt;/h3&gt;&lt;p&gt;登录jenkins——系统管理——系统设置，为jenkins添加上需要的功能配置，有如下几个方面：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/50.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;jdk版本&quot;&gt;&lt;a href=&quot;#jdk版本&quot; class=&quot;headerlink&quot; title=&quot;jdk版本&quot;&gt;&lt;/a&gt;jdk版本&lt;/h4&gt;&lt;p&gt;在jdk的选项，点击”新增JDK”，取消自动安装，输入jdk别名（名称随意），JAVA_HOME大家应该都很了解，在此处填写jenkins所在服务器安装的java程序的HOME位置即可，根据不同操作系统填写不同路径，如win7 D:\Java\jdk1.8   linux /usr/lib/jvm/jdk1.7.0_51。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/51.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;设置完了请记得保存。&lt;/p&gt;
&lt;h4 id=&quot;git-svn版本控制添加&quot;&gt;&lt;a href=&quot;#git-svn版本控制添加&quot; class=&quot;headerlink&quot; title=&quot;git/svn版本控制添加&quot;&gt;&lt;/a&gt;git/svn版本控制添加&lt;/h4&gt;&lt;p&gt;根据使用的版本选择控制版本的应用程序的路径，如jdk配置即可。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/52.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;【注意】:如果使用Git作为版本控制库，Jenkins默认情况下是没有安装Git的。我们需要到插件管理界面中选中Git，然后点击直接安装。&lt;br&gt;点击系统管理—&amp;gt;管理插件—&amp;gt;可选插件，在右上角”过滤”处输入git进行搜索：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/53.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;找到Git client plugin和Git plugin，在前面打上√，点击直接安装。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/54.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/55.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;安装成功后，重启jenkins。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[jenkins@osb30 ~]$ cd apache-tomcat-8.0.30
[jenkins@osb30 apache-tomcat-8.0.30]$ bin/shutdown.sh
[jenkins@osb30 apache-tomcat-8.0.30]$ bin/startup.sh ;tail -f logs/catalina.out
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;Jenkins添加maven配置&quot;&gt;&lt;a href=&quot;#Jenkins添加maven配置&quot; class=&quot;headerlink&quot; title=&quot;Jenkins添加maven配置&quot;&gt;&lt;/a&gt;Jenkins添加maven配置&lt;/h4&gt;&lt;p&gt;先判断jenkins所在主机是否安装了maven：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mvn –version
-bash: mvn: command not found
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果没有安装，请先安装maven。&lt;/p&gt;
&lt;h5 id=&quot;CentOS-安装maven&quot;&gt;&lt;a href=&quot;#CentOS-安装maven&quot; class=&quot;headerlink&quot; title=&quot;CentOS 安装maven&quot;&gt;&lt;/a&gt;CentOS 安装maven&lt;/h5&gt;&lt;pre&gt;&lt;code&gt;[root@osb30 ~]# cd /usr/local/
[root@osb30 local]# wget http://apache.opencas.org/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz

[root@osb30 local]# tar zxf apache-maven-3.3.9-bin.tar.gz
[root@osb30 local]# ln -s apache-maven-3.3.9 maven
[root@osb30 local]# vim /etc/profile
# 添加如下配置：
# Maven configuration.
MAVEN_HOME=/usr/local/maven
export PATH=$MAVEN_HOME/bin:$PATH
[root@osb30 local]# source /etc/profile

[root@osb30 local]# mvn -version
Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)
Maven home: /usr/local/maven
Java version: 1.8.0_65, vendor: Oracle Corporation
Java home: /usr/java/jdk1.8.0_65/jre
Default locale: en_US, platform encoding: UTF-8
OS name: &amp;quot;linux&amp;quot;, version: &amp;quot;2.6.32-431.el6.x86_64&amp;quot;, arch: &amp;quot;amd64&amp;quot;, family: &amp;quot;unix&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;h5 id=&quot;Jenkins配置maven&quot;&gt;&lt;a href=&quot;#Jenkins配置maven&quot; class=&quot;headerlink&quot; title=&quot;Jenkins配置maven&quot;&gt;&lt;/a&gt;Jenkins配置maven&lt;/h5&gt;&lt;p&gt;安装完成后，登录jenkins。点击系统管理—&amp;gt;系统设置。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/56.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Jenkins构建maven风格的job&quot;&gt;&lt;a href=&quot;#Jenkins构建maven风格的job&quot; class=&quot;headerlink&quot; title=&quot;Jenkins构建maven风格的job&quot;&gt;&lt;/a&gt;Jenkins构建maven风格的job&lt;/h2&gt;&lt;h3 id=&quot;新建maven任务&quot;&gt;&lt;a href=&quot;#新建maven任务&quot; class=&quot;headerlink&quot; title=&quot;新建maven任务&quot;&gt;&lt;/a&gt;新建maven任务&lt;/h3&gt;&lt;p&gt;登录jenkins，点击新建。输入Item名称，选择“构建一个maven项目”，点击OK。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/57.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;构建任务配置&quot;&gt;&lt;a href=&quot;#构建任务配置&quot; class=&quot;headerlink&quot; title=&quot;构建任务配置&quot;&gt;&lt;/a&gt;构建任务配置&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/58.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;源码管理配置&quot;&gt;&lt;a href=&quot;#源码管理配置&quot; class=&quot;headerlink&quot; title=&quot;源码管理配置&quot;&gt;&lt;/a&gt;源码管理配置&lt;/h3&gt;&lt;p&gt;进入配置页面，找到”源码管理”。我这里是svn，输入项目所在版本库的地址。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/59.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;构建触发器配置&quot;&gt;&lt;a href=&quot;#构建触发器配置&quot; class=&quot;headerlink&quot; title=&quot;构建触发器配置&quot;&gt;&lt;/a&gt;构建触发器配置&lt;/h3&gt;&lt;p&gt;在”源码管理”下面是”构建触发器”。&lt;br&gt;”构建触发器”是一个持续集成的触发器插件，可以根据已经完成构建的结果，触发新Job或者传递参数。默认的选项是Build whenever a SNAPSHOT dependency is built，意思是依赖于快照的构建，意思是依赖于快照的构建，当代码有更新时就构建项目。&lt;br&gt;Build periodically和Poll SCM可以设置定时自动构建。两者区别如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Poll SCM：定时检查源码变更（根据SCM软件的版本号），如果有更新就checkout最新code下来，然后执行构建动作。&lt;/li&gt;
&lt;li&gt;Build periodically：定时进行项目构建（它不care源码是否发生变化）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我这里设置为每12小时构建一次。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/60.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Maven构建设置&quot;&gt;&lt;a href=&quot;#Maven构建设置&quot; class=&quot;headerlink&quot; title=&quot;Maven构建设置&quot;&gt;&lt;/a&gt;Maven构建设置&lt;/h3&gt;&lt;h4 id=&quot;Pre-Step&quot;&gt;&lt;a href=&quot;#Pre-Step&quot; class=&quot;headerlink&quot; title=&quot;Pre Step&quot;&gt;&lt;/a&gt;Pre Step&lt;/h4&gt;&lt;p&gt;Pre Steps选项用来配置构建前的工作，这里不作更改。&lt;/p&gt;
&lt;h4 id=&quot;配置Root-POM和Goals-and-options&quot;&gt;&lt;a href=&quot;#配置Root-POM和Goals-and-options&quot; class=&quot;headerlink&quot; title=&quot;配置Root POM和Goals and options&quot;&gt;&lt;/a&gt;配置Root POM和Goals and options&lt;/h4&gt;&lt;p&gt;因为是Maven项目，所以Build选项有Root POM和Goals and options的设置。Root POM:填写你项目的pom.xml文件的位置，注意：是相对位置，如果该文件不存在，会有红色字提示。&lt;br&gt;比如我这里是：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/61.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;Post-Steps&quot;&gt;&lt;a href=&quot;#Post-Steps&quot; class=&quot;headerlink&quot; title=&quot;Post Steps&quot;&gt;&lt;/a&gt;Post Steps&lt;/h4&gt;&lt;p&gt;在maven项目创建完成后，我们还需要实现每次构建完成，将war发布到阿里云主机上，以实现自动发布。我们通过添加shell实现自动发布。&lt;/p&gt;
&lt;p&gt;找到Post steps下有个Execute shell：&lt;br&gt;【注意】:Jenkins在执行该shell脚本的时候是以jenkins这个用户身份去执行。某些场景下请注意环境变量PATH。&lt;br&gt;将构建完成后，所要采取的动作，shell脚本脚本内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash

# Stop tomcat.
ssh root@114.55.29.246 &amp;apos;/usr/local/apache-tomcat-7.0.65/bin/shutdown.sh&amp;apos; &amp;amp;&amp;gt;/dev/null
sleep 10

# Check the stop is successful or not.
if ssh root@114.55.29.246 &amp;apos;ps -ef|grep tomcat |grep -v &amp;quot;grep&amp;quot;&amp;apos; &amp;amp;&amp;gt;/dev/null; then
  echo &amp;quot;Tomcat stop failed.Please check the problem.&amp;quot;
  exit 5
fi

# Backup previous version and delete the war in the path /usr/local/apache-tomcat-7.0.65/webapps/.
ssh root@114.55.29.246 &amp;apos;/usr/bin/cp -f /usr/local/apache-tomcat-7.0.65/webapps/*.war /backups/*war&amp;apos;
ssh root@114.55.29.246 &amp;apos;rm -rf /usr/local/apache-tomcat-7.0.65/webapps/*&amp;apos;

# Copy the newest war to aliyun ECS.
scp /home/jenkins/.jenkins/workspace/godseye/godseye-parent/godseye-container/target/godseye-container-aliyun.war root@114.55.29.246:/usr/local/apache-tomcat-7.0.65/webapps/godseye.war &amp;amp;&amp;gt;/dev/null

# Start the tomcat.
ssh root@114.55.29.246 &amp;apos;/usr/local/apache-tomcat-7.0.65/bin/startup.sh&amp;apos; &amp;amp;&amp;gt;/dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置阿里云主机信任内网的这台jenkins主机：&lt;br&gt;由于是war包在内网服务器上，发布的环境是在阿里云主机上，所以要配置主机互信，防止scp war包时还需要输入密码。我这里内网服务器ip是172.16.206.30，外网是114.55.29.246。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[jenkins@osb30 ~]$ ssh-keygen -t rsa -f .ssh/id_rsa
[jenkins@osb30 ~]$ ssh-copy-id -i .ssh/id_rsa.pub root@114.55.29.246
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Jenkins邮件通知设置&quot;&gt;&lt;a href=&quot;#Jenkins邮件通知设置&quot; class=&quot;headerlink&quot; title=&quot;Jenkins邮件通知设置&quot;&gt;&lt;/a&gt;Jenkins邮件通知设置&lt;/h2&gt;&lt;h3 id=&quot;配置jenkins自带的邮件功能&quot;&gt;&lt;a href=&quot;#配置jenkins自带的邮件功能&quot; class=&quot;headerlink&quot; title=&quot;配置jenkins自带的邮件功能&quot;&gt;&lt;/a&gt;配置jenkins自带的邮件功能&lt;/h3&gt;&lt;p&gt;1.找到系统设置&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/62.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;2.填写系统管理员邮箱&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/63.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;3.找到邮件通知，输入SMTP服务器地址，点击高级，输入发件人帐号和密码&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/64.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;4.勾选上”通过发送测试邮件测试配置”，然后输入收件人帐号&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/65.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;此时我们已经可以发送邮件了。在具体job配置处，找到”构建设置”，输入收件人信箱，但是你会发现只能在构建失败时发邮件。可以安装插件Email Extension Plugin来自定义。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/66.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装使用插件Email-Extension-Plugin&quot;&gt;&lt;a href=&quot;#安装使用插件Email-Extension-Plugin&quot; class=&quot;headerlink&quot; title=&quot;安装使用插件Email Extension Plugin&quot;&gt;&lt;/a&gt;安装使用插件Email Extension Plugin&lt;/h3&gt;&lt;p&gt;1.安装插件Email Extension Plugin&lt;br&gt;该插件支持jenkins 1.5以上的版本。&lt;br&gt;在系统管理-插件管理-安装Email Extension Plugin。它可根据构建的结果，发送构建报告。该插件支持jenkins 1.5以上的版本。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/67.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;【注意】:安装完如果使用Email Extension Plugin，就可以弃用自带的那个邮件功能了。&lt;/p&gt;
&lt;p&gt;2.配置使用插件Email Extension Plugin&lt;br&gt;点击”系统配置”—&amp;gt;”系统设置”。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/68.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;找到Extended E-mail Notification处，输入如下的配置：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/69.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/70.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;构建通知：$PROJECT_NAME - Build # $BUILD_NUMBER - $BUILD_STATUS!

&amp;lt;hr/&amp;gt;
(本邮件是程序自动下发的，请勿回复！)&amp;lt;br/&amp;gt;&amp;lt;hr/&amp;gt;
项目名称：$PROJECT_NAME&amp;lt;br/&amp;gt;&amp;lt;hr/&amp;gt;
构建编号：$BUILD_NUMBER&amp;lt;br/&amp;gt;&amp;lt;hr/&amp;gt;
svn版本号：${SVN_REVISION}&amp;lt;br/&amp;gt;&amp;lt;hr/&amp;gt;
构建状态：$BUILD_STATUS&amp;lt;br/&amp;gt;&amp;lt;hr/&amp;gt;
触发原因：${CAUSE}&amp;lt;br/&amp;gt;&amp;lt;hr/&amp;gt;
构建日志地址：&amp;lt;a href=&amp;quot;${BUILD_URL}console&amp;quot;&amp;gt;${BUILD_URL}console&amp;lt;/a&amp;gt;&amp;lt;br/&amp;gt;&amp;lt;hr/&amp;gt;
构建地址：&amp;lt;a href=&amp;quot;$BUILD_URL&amp;quot;&amp;gt;$BUILD_URL&amp;lt;/a&amp;gt;&amp;lt;br/&amp;gt;&amp;lt;hr/&amp;gt;
变更集:${JELLY_SCRIPT,template=&amp;quot;html&amp;quot;}&amp;lt;br/&amp;gt;&amp;lt;hr/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;点击下面的保存。&lt;br&gt;然后去job配置页面激活这个插件。找到需要发邮件的项目，点击进去。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/71.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击配置，点击”增加构建后操作步骤”，选择Editable Email Notification。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/72.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;附上构建日志，点击高级设置。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/73.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;配置Triggers：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/74.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;更详细的介绍：&lt;a href=&quot;http://www.cnblogs.com/zz0412/p/jenkins_jj_01.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/zz0412/p/jenkins_jj_01.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;sonar&quot;&gt;&lt;a href=&quot;#sonar&quot; class=&quot;headerlink&quot; title=&quot;sonar&quot;&gt;&lt;/a&gt;sonar&lt;/h2&gt;&lt;p&gt;官方文档：&lt;a href=&quot;http://docs.sonarqube.org/display/SONARQUBE45/Documentation&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://docs.sonarqube.org/display/SONARQUBE45/Documentation&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;sonar简介&quot;&gt;&lt;a href=&quot;#sonar简介&quot; class=&quot;headerlink&quot; title=&quot;sonar简介&quot;&gt;&lt;/a&gt;sonar简介&lt;/h3&gt;&lt;p&gt;Sonar是一个用于代码质量管理的开源平台，用于管理Java源代码的质量。通过插件机制，Sonar 可以集成不同的测试工具，代码分析工具，以及持续集成工具，比如pmd-cpd、checkstyle、findbugs、Jenkins。通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。&lt;br&gt;与持续集成工具（例如 Hudson/Jenkins 等）不同，Sonar 并不是简单地把不同的代码检查工具结果（例如 FindBugs，PMD 等）直接显示在 Web 页面上，而是通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。&lt;br&gt;在对其他工具的支持方面，Sonar 不仅提供了对 IDE 的支持，可以在 Eclipse 和 IntelliJ IDEA 这些工具里联机查看结果；同时 Sonar 还对大量的持续集成工具提供了接口支持，可以很方便地在持续集成中使用 Sonar。&lt;br&gt;此外，Sonar 的插件还可以对 Java 以外的其他编程语言提供支持，对国际化以及报告文档化也有良好的支持。&lt;/p&gt;
&lt;h3 id=&quot;环境要求&quot;&gt;&lt;a href=&quot;#环境要求&quot; class=&quot;headerlink&quot; title=&quot;环境要求&quot;&gt;&lt;/a&gt;环境要求&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://docs.sonarqube.org/display/SONAR/Requirements&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://docs.sonarqube.org/display/SONAR/Requirements&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;新建用户&quot;&gt;&lt;a href=&quot;#新建用户&quot; class=&quot;headerlink&quot; title=&quot;新建用户&quot;&gt;&lt;/a&gt;新建用户&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@osb30 ~]# groupadd sonar
[root@osb30 ~]# useradd -g sonar sonar
[root@osb30 ~]# id sonar
uid=502(sonar) gid=502(sonar) groups=502(sonar)
[root@osb30 ~]# echo &amp;quot;wisedu&amp;quot; | passwd --stdin sonar &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装jdk&quot;&gt;&lt;a href=&quot;#安装jdk&quot; class=&quot;headerlink&quot; title=&quot;安装jdk&quot;&gt;&lt;/a&gt;安装jdk&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[sonar@osb30 ~]$ java -version
java version &amp;quot;1.8.0_65&amp;quot;
Java(TM) SE Runtime Environment (build 1.8.0_65-b17)
Java HotSpot(TM) 64-Bit Server VM (build 25.65-b01, mixed mode)
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装配置数据库&quot;&gt;&lt;a href=&quot;#安装配置数据库&quot; class=&quot;headerlink&quot; title=&quot;安装配置数据库&quot;&gt;&lt;/a&gt;安装配置数据库&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[root@osb30 ~]# mysql -uroot –p
mysql&amp;gt; CREATE DATABASE sonar CHARACTER SET utf8 COLLATE utf8_general_ci;
mysql&amp;gt; CREATE USER &amp;apos;sonar&amp;apos; IDENTIFIED BY &amp;apos;sonar&amp;apos;;
mysql&amp;gt; GRANT ALL ON sonar.* TO &amp;apos;sonar&amp;apos;@&amp;apos;%&amp;apos; IDENTIFIED BY &amp;apos;wisedu&amp;apos;;
mysql&amp;gt; GRANT ALL ON sonar.* TO &amp;apos;sonar&amp;apos;@&amp;apos;localhost&amp;apos; IDENTIFIED BY &amp;apos;wisedu&amp;apos;;
mysql&amp;gt; FLUSH PRIVILEGES;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装sonar&quot;&gt;&lt;a href=&quot;#安装sonar&quot; class=&quot;headerlink&quot; title=&quot;安装sonar&quot;&gt;&lt;/a&gt;安装sonar&lt;/h3&gt;&lt;p&gt;我这里用的版本是SonarQube 4.5.7 (LTS *)，上传该软件到sonar用户的家目录下。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[sonar@osb30 ~]$ unzip -oq sonarqube-4.5.7.zip
[sonar@osb30 ~]$ vim sonarqube-4.5.7/conf/sonar.properties
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;修改如下字段(就是配置数据库信息，其他不用动)：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sonar.jdbc.username:                       sonar
sonar.jdbc.password:                       wisedu
sonar.jdbc.url:                            jdbc:mysql://localhost:3306/sonar?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;rewriteBatchedStatements=true

# Optional properties
sonar.jdbc.driverClassName:                com.mysql.jdbc.Driver
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;启动sonar&quot;&gt;&lt;a href=&quot;#启动sonar&quot; class=&quot;headerlink&quot; title=&quot;启动sonar&quot;&gt;&lt;/a&gt;启动sonar&lt;/h3&gt;&lt;p&gt;Sonar默认集成了jetty容器，可以直接启动提供服务，也可以通过脚本构建为war包，部署在tomcat容器中。&lt;br&gt;Sonar默认的端口是”9000”、默认的上下文路径是”/”、默认的网络接口是”0.0.0.0”，默认的管理员帐号和密码为:admin/admin，这些参数都可以在配置文件sonar.properties中修改。我这里修改下port，因为本机的9000端口被其他程序占用了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[sonar@osb30 ~]$ vim sonarqube-4.5.7/conf/sonar.properties
sonar.web.port=9003
[sonar@osb30 ~]$ sonarqube-4.5.7/bin/linux-x86-64/sonar.sh start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看日志：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[sonar@osb30 ~]$ tail -f sonarqube-4.5.7/logs/sonar.log
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到第一次启动时，初始化语句：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/75.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;关闭sonar&quot;&gt;&lt;a href=&quot;#关闭sonar&quot; class=&quot;headerlink&quot; title=&quot;关闭sonar&quot;&gt;&lt;/a&gt;关闭sonar&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;[sonar@osb30 ~]$ sonarqube-4.5.7/bin/linux-x86-64/sonar.sh stop
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;访问sonar&quot;&gt;&lt;a href=&quot;#访问sonar&quot; class=&quot;headerlink&quot; title=&quot;访问sonar&quot;&gt;&lt;/a&gt;访问sonar&lt;/h3&gt;&lt;p&gt;浏览器输入&lt;a href=&quot;http://172.16.206.30:9003/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.206.30:9003/&lt;/a&gt;&lt;br&gt;默认的管理员帐号和密码为:admin/admin。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/76.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/77.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/78.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;sonar插件&quot;&gt;&lt;a href=&quot;#sonar插件&quot; class=&quot;headerlink&quot; title=&quot;sonar插件&quot;&gt;&lt;/a&gt;sonar插件&lt;/h3&gt;&lt;p&gt;Sonar支持多种插件，插件的下载地址为：&lt;a href=&quot;http://docs.codehaus.org/display/SONAR/Plugin+Library&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://docs.codehaus.org/display/SONAR/Plugin+Library&lt;/a&gt;&lt;br&gt;将下载后的插件上传到${SONAR_HOME}extensions\plugins目录下，重新启动sonar。&lt;/p&gt;
&lt;p&gt;sonar默认集成了Java Ecosystem插件，该插件是一组插件的合集:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Java [sonar-java-plugin]：java源代码解析，计算指标等&lt;/li&gt;
&lt;li&gt;Squid [sonar-squid-java-plugin]：检查违反Sonar定义规则的代码&lt;/li&gt;
&lt;li&gt;Checkstyle [sonar-checkstyle-plugin]：使用CheckStyle检查违反统一代码编写风格的代码&lt;/li&gt;
&lt;li&gt;FindBugs [sonar-findbugs-plugin]：使用FindBugs检查违反规则的缺陷代码&lt;/li&gt;
&lt;li&gt;PMD [sonar-pmd-plugin]：使用pmd检查违反规则的代码&lt;/li&gt;
&lt;li&gt;Surefire [sonar-surefire-plugin]：使用Surefire执行单元测试&lt;/li&gt;
&lt;li&gt;Cobertura [sonar-cobertura-plugin]：使用Cobertura获取代码覆盖率&lt;/li&gt;
&lt;li&gt;JaCoCo [sonar-jacoco-plugin]：使用JaCOCO获取代码覆盖率&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;与jenkins集成&quot;&gt;&lt;a href=&quot;#与jenkins集成&quot; class=&quot;headerlink&quot; title=&quot;与jenkins集成&quot;&gt;&lt;/a&gt;与jenkins集成&lt;/h3&gt;&lt;p&gt;可以通过maven集成，也可以直接与jenkins集成。我这里选择直接与jenkins集成。&lt;/p&gt;
&lt;h4 id=&quot;通过maven集成&quot;&gt;&lt;a href=&quot;#通过maven集成&quot; class=&quot;headerlink&quot; title=&quot;通过maven集成&quot;&gt;&lt;/a&gt;通过maven集成&lt;/h4&gt;&lt;p&gt;修改maven的主配置文件（${MAVEN_HOME}/conf/settings.xml文件或者 ~/.m2/settings.xml文件），在其中增加访问Sonar数据库及Sonar服务地址，添加如下配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;profile&amp;gt;
&amp;lt;id&amp;gt;sonar&amp;lt;/id&amp;gt;
&amp;lt;properties&amp;gt;
    &amp;lt;sonar.jdbc.url&amp;gt;jdbc:mysql://localhost:3306/sonar&amp;lt;/sonar.jdbc.url&amp;gt;
    &amp;lt;sonar.jdbc.driver&amp;gt;com.mysql.jdbc.Driver&amp;lt;/sonar.jdbc.driver&amp;gt;
    &amp;lt;sonar.jdbc.username&amp;gt;sonar&amp;lt;/sonar.jdbc.username&amp;gt;
    &amp;lt;sonar.jdbc.password&amp;gt;sonar&amp;lt;/sonar.jdbc.password&amp;gt;
    &amp;lt;sonar.host.url&amp;gt;http://localhost:9003&amp;lt;/sonar.host.url&amp;gt; &amp;lt;!-- Sonar服务器访问地址 --&amp;gt;
&amp;lt;/properties&amp;gt;
&amp;lt;/profile&amp;gt;

&amp;lt;activeProfiles&amp;gt;
  &amp;lt;activeProfile&amp;gt;sonar&amp;lt;/activeProfile&amp;gt;
&amp;lt;/activeProfiles&amp;gt;

...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这部分内容具体可参照网上&lt;a href=&quot;http://www.cnblogs.com/gao241/p/3190701.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/gao241/p/3190701.html&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;直接与Jenkins集成&quot;&gt;&lt;a href=&quot;#直接与Jenkins集成&quot; class=&quot;headerlink&quot; title=&quot;直接与Jenkins集成&quot;&gt;&lt;/a&gt;直接与Jenkins集成&lt;/h4&gt;&lt;p&gt;在jenkins的插件管理中选择安装sonar jenkins plugin，该插件可以使项目每次构建都调用sonar进行代码度量。&lt;/p&gt;
&lt;p&gt;1.安装插件&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/79.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;2.系统配置添加sonar的配置&lt;br&gt;进入系统配置页面对sonar插件进行配置，如下图：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/80.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/81.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;然后点击下面的保存。&lt;/p&gt;
&lt;p&gt;3.配置构建项目，增加Post Build Action&lt;br&gt;点击要构建的项目，在点击左侧的配置。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/82.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;在页面的最下面找到”构建后操作”，选择SonarQube。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/83.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/84.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;It is no longer recommended to use SonarQube maven builder. It is preferable to set up SonarQube in the build environment and use a standard Jenkins maven target.&lt;br&gt;【解决】：&lt;br&gt;&lt;a href=&quot;http://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Jenkins&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Jenkins&lt;/a&gt;&lt;br&gt;修改Build处：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/85.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;最后去jenkins构建项目，构建完查看sonar控制台：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/86.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;常见问题&quot;&gt;&lt;a href=&quot;#常见问题&quot; class=&quot;headerlink&quot; title=&quot;常见问题&quot;&gt;&lt;/a&gt;常见问题&lt;/h3&gt;&lt;p&gt;Jenkins构建完成后，sonar扫描代码报错：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/87.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;解决：&lt;br&gt;卸载sonar的JavaScript插件。&lt;/p&gt;
&lt;h2 id=&quot;Jenkins与Docker结合&quot;&gt;&lt;a href=&quot;#Jenkins与Docker结合&quot; class=&quot;headerlink&quot; title=&quot;Jenkins与Docker结合&quot;&gt;&lt;/a&gt;Jenkins与Docker结合&lt;/h2&gt;&lt;p&gt;我这里没有使用Docker Pipeline，直接在构建完成后，执行shell脚本，这样更灵活。&lt;/p&gt;
&lt;h3 id=&quot;部署流程&quot;&gt;&lt;a href=&quot;#部署流程&quot; class=&quot;headerlink&quot; title=&quot;部署流程&quot;&gt;&lt;/a&gt;部署流程&lt;/h3&gt;&lt;p&gt;1.研发push到svn代码库&lt;br&gt;2.Jenkins 构建，pull svn代码 使用maven进行编译打包&lt;br&gt;3.打包生成的代码，生成一个新版本的镜像，push到本地docker仓库harbor&lt;br&gt;4.发布，测试机器 pull 新版本的镜像，并删除原来的容器，重新运行新版本镜像。&lt;/p&gt;
&lt;h3 id=&quot;环境说明&quot;&gt;&lt;a href=&quot;#环境说明&quot; class=&quot;headerlink&quot; title=&quot;环境说明&quot;&gt;&lt;/a&gt;环境说明&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;操作系统版本&lt;/th&gt;
&lt;th&gt;IP地址&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;th&gt;安装软件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;osb30&lt;/td&gt;
&lt;td&gt;Redhat 6.5&lt;/td&gt;
&lt;td&gt;172.16.206.30&lt;/td&gt;
&lt;td&gt;svn代码库、Jenkins、Docker&lt;/td&gt;
&lt;td&gt;jenkins、svn、Docker 1.7.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;spark32&lt;/td&gt;
&lt;td&gt;CentOS 7.0&lt;/td&gt;
&lt;td&gt;172.16.206.32&lt;/td&gt;
&lt;td&gt;本地docker仓库、业务部署测试环境&lt;/td&gt;
&lt;td&gt;harbor、Docker 17.06.1-ce&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;配置&quot;&gt;&lt;a href=&quot;#配置&quot; class=&quot;headerlink&quot; title=&quot;配置&quot;&gt;&lt;/a&gt;配置&lt;/h3&gt;&lt;p&gt;由于在Jenkins机器上docker是使用root用户运行的，而Jenkins是使用普通用户jenkins运行的，所以要先配置下jenkins用户可以使用docker命令。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@osb30 ~]# visudo
jenkins ALL=(root)      NOPASSWD: /usr/bin/docker
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;另外在Jenkins机器上配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Disable &amp;quot;ssh hostname sudo &amp;lt;cmd&amp;gt;&amp;quot;, because it will show the password in clear.
#         You have to run &amp;quot;ssh -t hostname sudo &amp;lt;cmd&amp;gt;&amp;quot;.
#
#Defaults    requiretty
Defaults:jenkins !requiretty
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果不配置这个，在执行下面脚本时，会报错误：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+ cp -f /home/jenkins/.jenkins/workspace/godseyeBranchForNov/godseye-container/target/godseye-container-wisedu.war /home/jenkins/docker-file/godseye_war/godseye.war
+ sudo docker login -u jkzhao -p Wisedu123 -e 01115004@wisedu.com 172.16.206.32
sudo: sorry, you must have a tty to run sudo
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在172.16.206.32机器上配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# visudo
#
#Defaults    requiretty
Defaults:root !requiretty
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;否则在机器172.16.206.32机器上执行脚本时会报错：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[SSH] executing...
sudo: sorry, you must have a tty to run sudo
docker: invalid reference format.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;安装插件&quot;&gt;&lt;a href=&quot;#安装插件&quot; class=&quot;headerlink&quot; title=&quot;安装插件&quot;&gt;&lt;/a&gt;安装插件&lt;/h3&gt;&lt;p&gt;登录Jenkins，点击“系统管理”，点击“管理插件”，搜索插件“SSH plugin”，进行安装。&lt;br&gt;登录Jenkins，点击“Credentials”，点击“Add domain”。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/88.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/89.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/90.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;点击“系统管理”，“系统配置”，找到“SSH remote hosts”。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/91.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;配置Post-Steps&quot;&gt;&lt;a href=&quot;#配置Post-Steps&quot; class=&quot;headerlink&quot; title=&quot;配置Post Steps&quot;&gt;&lt;/a&gt;配置Post Steps&lt;/h3&gt;&lt;p&gt;项目其他的配置不变，见上面的章节。&lt;br&gt;【注意】：脚本中用到的仓库和认证的账号需要先在harbor新建好。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/92.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Jenkins机器：编译完成后，build生成一个新版本的镜像，push到远程docker仓库

# Variables
JENKINS_WAR_HOME=&amp;apos;/home/jenkins/.jenkins/workspace/godseyeBranchForNov/godseye-container/target&amp;apos;
DOCKERFILE_HOME=&amp;apos;/home/jenkins/docker-file/godseye_war&amp;apos;
HARBOR_IP=&amp;apos;172.16.206.32&amp;apos;
REPOSITORIES=&amp;apos;godseye_war/godseye&amp;apos;
HARBOR_USER=&amp;apos;jkzhao&amp;apos;
HARBOR_USER_PASSWD=&amp;apos;Wisedu123&amp;apos;
HARBOR_USER_EMAIL=&amp;apos;01115004@wisedu.com&amp;apos;

# Copy the newest war to docker-file directory.
\cp -f ${JENKINS_WAR_HOME}/godseye-container-wisedu.war ${DOCKERFILE_HOME}/godseye.war 

# Delete image early version.
sudo docker login -u ${HARBOR_USER} -p ${HARBOR_USER_PASSWD} -e ${HARBOR_USER_EMAIL} ${HARBOR_IP}  
IMAGE_ID=`sudo docker images | grep ${REPOSITORIES} | awk &amp;apos;{print $3}&amp;apos;`
if [ -n &amp;quot;${IMAGE_ID}&amp;quot; ];then
    sudo docker rmi ${IMAGE_ID}
fi

# Build image.
cd ${DOCKERFILE_HOME}
TAG=`date +%Y%m%d-%H%M%S`
sudo docker build -t ${HARBOR_IP}/${REPOSITORIES}:${TAG} . &amp;amp;&amp;gt;/dev/null

# Push to the harbor registry.
sudo docker push ${HARBOR_IP}/${REPOSITORIES}:${TAG} &amp;amp;&amp;gt;/dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Docker/93.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 拉取镜像，发布
HARBOR_IP=&amp;apos;172.16.206.32&amp;apos;
REPOSITORIES=&amp;apos;godseye_war/godseye&amp;apos;
HARBOR_USER=&amp;apos;jkzhao&amp;apos;
HARBOR_USER_PASSWD=&amp;apos;Wisedu123&amp;apos;

# 登录harbor
#docker login -u ${HARBOR_USER} -p ${HARBOR_USER_PASSWD} ${HARBOR_IP}

# Stop container, and delete the container.
CONTAINER_ID=`docker ps | grep &amp;quot;godseye_web&amp;quot; | awk &amp;apos;{print $1}&amp;apos;`
if [ -n &amp;quot;$CONTAINER_ID&amp;quot; ]; then
    docker stop $CONTAINER_ID
    docker rm $CONTAINER_ID
else #如果容器启动时失败了，就需要docker ps -a才能找到那个容器
    CONTAINER_ID=`docker ps -a | grep &amp;quot;godseye_web&amp;quot; | awk &amp;apos;{print $1}&amp;apos;`
    if [ -n &amp;quot;$CONTAINER_ID&amp;quot; ]; then  # 如果是第一次在这台机器上拉取运行容器，那么docker ps -a也是找不到这个容器的
        docker rm $CONTAINER_ID
    fi
fi

# Delete godseye_web image early version.
IMAGE_ID=`sudo docker images | grep ${REPOSITORIES} | awk &amp;apos;{print $3}&amp;apos;`
if [ -n &amp;quot;${IMAGE_ID}&amp;quot; ];then
    docker rmi ${IMAGE_ID}
fi

# Pull image.
TAG=`curl -s http://${HARBOR_IP}/api/repositories/${REPOSITORIES}/tags | jq &amp;apos;.[-1]&amp;apos; | sed &amp;apos;s/\&amp;quot;//g&amp;apos;` #最后的sed是为了去掉tag前后的双引号
docker pull ${HARBOR_IP}/${REPOSITORIES}:${TAG} &amp;amp;&amp;gt;/dev/null

# Run.
docker run -d --name godseye_web -p 8080:8080 ${HARBOR_IP}/${REPOSITORIES}:${TAG}
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Jenkins介绍&quot;&gt;&lt;a href=&quot;#Jenkins介绍&quot; class=&quot;headerlink&quot; title=&quot;Jenkins介绍&quot;&gt;&lt;/a&gt;Jenkins介绍&lt;/h2&gt;&lt;p&gt;Jenkins是一个开源软件项目，是基于Java开发的一种持续集成工具，用于监控持续重复的工作，旨在提供一个开放易用的软件平台，使软件的持续集成变成可能。&lt;br&gt;
    
    </summary>
    
      <category term="持续集成" scheme="http://yoursite.com/categories/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>在Kubernetes上使用Traefik</title>
    <link href="http://yoursite.com/2017/09/25/%E5%9C%A8Kubernetes%E4%B8%8A%E4%BD%BF%E7%94%A8Traefik/"/>
    <id>http://yoursite.com/2017/09/25/在Kubernetes上使用Traefik/</id>
    <published>2017-09-25T03:30:01.000Z</published>
    <updated>2017-12-01T13:22:25.000Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Traefik介绍&quot;&gt;&lt;a href=&quot;#Traefik介绍&quot; class=&quot;headerlink&quot; title=&quot;Traefik介绍&quot;&gt;&lt;/a&gt;Traefik介绍&lt;/h2&gt;&lt;p&gt;traefik 是一个前端负载均衡器，对于微服务架构尤其是 kubernetes 等编排工具具有良好的支持；同 nginx 等相比，traefik 能够自动感知后端容器变化，从而实现自动服务发现。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;由于微服务架构以及 Docker 技术和 kubernetes 编排工具最近几年才开始逐渐流行，所以一开始的反向代理服务器比如 nginx、apache 并未提供其支持，毕竟他们也不是先知；所以才会出现 Ingress Controller 这种东西来做 kubernetes 和前端负载均衡器如 nginx 之间做衔接；即 Ingress Controller 的存在就是为了能跟 kubernetes 交互，又能写 nginx 配置，还能 reload 它，这是一种折中方案；而 traefik 天生就是提供了对 kubernetes 的支持，也就是说 traefik 本身就能跟 kubernetes API 交互，感知后端变化，因此可以得知: 在使用 traefik 时，Ingress Controller 已经没什么用了，整体架构如下：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kubernetes/12.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;部署测试用的两个服务&quot;&gt;&lt;a href=&quot;#部署测试用的两个服务&quot; class=&quot;headerlink&quot; title=&quot;部署测试用的两个服务&quot;&gt;&lt;/a&gt;部署测试用的两个服务&lt;/h2&gt;&lt;p&gt;部署两个服务nginx1-7和nginx1-8，后面用Traefik去负载这两个服务：&lt;br&gt;nginx1-7.yaml：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: frontend
spec:
  ports:
    - port: 80
      targetPort: 80
  selector:
    app: nginx1-7
---
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: nginx1-7-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx1-7
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;nginx1-8.yaml：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: my-nginx
spec:
  ports:
    - port: 80
      targetPort: 80
  selector:
    app: nginx1-8
---
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: nginx1-8-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx1-8
    spec:
      containers:
      - name: nginx
        image: nginx:1.8
        ports:
        - containerPort: 80
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行两个服务：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 nginx_ingress]# kubectl create -f nginx1-7.yaml
service &amp;quot;frontend&amp;quot; created
deployment &amp;quot;nginx1-7-deployment&amp;quot; created
[root@node1 nginx_ingress]# kubectl create -f nginx1-8.yaml
service &amp;quot;my-nginx&amp;quot; created
deployment &amp;quot;nginx1-8-deployment&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Role-Based-Access-Control-configuration-Kubernetes-1-6-only&quot;&gt;&lt;a href=&quot;#Role-Based-Access-Control-configuration-Kubernetes-1-6-only&quot; class=&quot;headerlink&quot; title=&quot;Role Based Access Control configuration (Kubernetes 1.6+ only)&quot;&gt;&lt;/a&gt;Role Based Access Control configuration (Kubernetes 1.6+ only)&lt;/h2&gt;&lt;p&gt;我这里部署的是1.6.0集群，开启了RBAC，授权需要使用角色和绑定角色。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 traefik]# pwd
/opt/traefik
[root@node1 traefik]# vim ingress-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ingress
  namespace: kube-system

---

kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: ingress
subjects:
  - kind: ServiceAccount
    name: ingress
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;部署Traefik&quot;&gt;&lt;a href=&quot;#部署Traefik&quot; class=&quot;headerlink&quot; title=&quot;部署Traefik&quot;&gt;&lt;/a&gt;部署Traefik&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;[root@node1 traefik]# pwd
/opt/traefik
[root@node1 traefik]# vim traefik-deploy.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: traefik-ingress-lb
  namespace: kube-system
  labels:
    k8s-app: traefik-ingress-lb
spec:
  template:
    metadata:
      labels:
        k8s-app: traefik-ingress-lb
        name: traefik-ingress-lb
    spec:
      terminationGracePeriodSeconds: 60
      hostNetwork: true
      restartPolicy: Always
      serviceAccountName: ingress
      containers:
      - image: traefik
        name: traefik-ingress-lb
        resources:
          limits:
            cpu: 200m
            memory: 30Mi
          requests:
            cpu: 100m
            memory: 20Mi
        ports:
        - name: http
          containerPort: 80
          hostPort: 80
        - name: admin
          containerPort: 8580
          hostPort: 8580
        args:
        - --web
        - --web.address=:8580
        - --kubernetes  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中 traefik 监听 node 的 80 和 8580 端口，80 提供正常服务，8580 是其自带的 UI 界面，原本默认是 8080，因为环境里端口冲突了，所以这里临时改一下。&lt;br&gt;【注意】：这里用的是Deploy类型，没有限定该pod运行在哪个主机上。&lt;/p&gt;
&lt;h2 id=&quot;部署-Ingress&quot;&gt;&lt;a href=&quot;#部署-Ingress&quot; class=&quot;headerlink&quot; title=&quot;部署 Ingress&quot;&gt;&lt;/a&gt;部署 Ingress&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;[root@node1 traefik]# cat traefik.yaml 
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: traefik-ingress
  namespace: default
spec:
  rules:
  - host: traefik.nginx.io
    http:
      paths:
      - path: /
        backend:
          serviceName: my-nginx
          servicePort: 80
  - host: traefik.frontend.io
    http:
      paths:
      - path: /
        backend:
          serviceName: frontend
          servicePort: 80
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中的backend中要配置default namespace中启动的service名字，如果你没有配置namespace名字，默认使用default namespace，如果你在其他namespace中创建服务想要暴露到kubernetes集群外部，可以创建新的ingress.yaml文件，同时在文件中指定该namespace，其他配置与上面的文件格式相同。path就是URL地址后的路径，如traefik.frontend.io/path，service将会接受path这个路径，host最好使用service-name.filed1.filed2.domain-name这种类似主机名称的命名方式，方便区分服务。&lt;br&gt;根据实际环境中部署的service的名字和端口自行修改，有新service增加时，修改该文件后可以使用kubectl replace -f traefik.yaml来更新。&lt;/p&gt;
&lt;h2 id=&quot;部署Traefik-UI&quot;&gt;&lt;a href=&quot;#部署Traefik-UI&quot; class=&quot;headerlink&quot; title=&quot;部署Traefik UI&quot;&gt;&lt;/a&gt;部署Traefik UI&lt;/h2&gt;&lt;p&gt;traefik 本身还提供了一套 UI 供我们使用，其同样以 Ingress 方式暴露，只需要创建一下即可。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 traefik]# cat traefik-ui-service.yaml 
apiVersion: v1
kind: Service
metadata:
  name: traefik-web-ui
  namespace: kube-system
spec:
  selector:
    k8s-app: traefik-ingress-lb
  ports:
  - name: web
    port: 80
    targetPort: 8580
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: traefik-web-ui
  namespace: kube-system
spec:
  rules:
  - host: traefik-ui.local
    http:
      paths:
      - path: /
        backend:
          serviceName: traefik-web-ui
          servicePort: web
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后一起创建：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 traefik]# kubectl create -f .
serviceaccount &amp;quot;ingress&amp;quot; created
clusterrolebinding &amp;quot;ingress&amp;quot; created
deployment &amp;quot;traefik-ingress-lb&amp;quot; created
service &amp;quot;traefik-web-ui&amp;quot; created
ingress &amp;quot;traefik-web-ui&amp;quot; created
ingress &amp;quot;traefik-ingress&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;访问测试&quot;&gt;&lt;a href=&quot;#访问测试&quot; class=&quot;headerlink&quot; title=&quot;访问测试&quot;&gt;&lt;/a&gt;访问测试&lt;/h2&gt;&lt;p&gt;查看traefik pod被分配到了哪台主机上：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 traefik]# kubectl get pods -n kube-system -l k8s-app=traefik-ingress-lb -o wide                       
NAME                                  READY     STATUS    RESTARTS   AGE       IP             NODE
traefik-ingress-lb-4237248072-1dg9n   1/1       Running   0          2m        172.16.7.152   172.16.7.152
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;浏览器输入&lt;a href=&quot;http://172.16.7.152:8580/，将可以看到dashboard。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://172.16.7.152:8580/，将可以看到dashboard。&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Kubernetes/13.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;左侧黄色部分部分列出的是所有的rule，右侧绿色部分是所有的backend。&lt;/p&gt;
&lt;p&gt;在Kubernetes集群的任意一个节点上执行。假如现在我要访问nginx的”/“路径。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -H Host:traefik.nginx.io http://172.16.7.152/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果需要在kubernetes集群以外访问就需要设置DNS，或者修改本机的hosts文件。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;172.16.7.152 traefik.nginx.io
172.16.7.152 traefik.frontend.io
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;所有访问这些地址的流量都会发送给172.16.7.152这台主机，就是我们启动traefik的主机。&lt;br&gt;Traefik会解析http请求header里的Host参数将流量转发给Ingress配置里的相应service。&lt;br&gt;修改hosts后就就可以在kubernetes集群外访问以上两个service。&lt;/p&gt;
&lt;h2 id=&quot;健康检查&quot;&gt;&lt;a href=&quot;#健康检查&quot; class=&quot;headerlink&quot; title=&quot;健康检查&quot;&gt;&lt;/a&gt;健康检查&lt;/h2&gt;&lt;p&gt;关于健康检查，测试可以使用 kubernetes 的 Liveness Probe 实现，如果 Liveness Probe检查失败，则 traefik 会自动移除该 pod。&lt;br&gt;【示例】：我们定义一个 test-health 的 deployment，健康检查方式是 cat /tmp/health，容器启动 2 分钟后会删掉这个文件，模拟健康检查失败。&lt;br&gt;test-health的deployment：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 traefik]# vim test-health-deploy.yaml
apiVersion: v1
kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: test
  namespace: default
  labels:
    test: alpine
spec:
  replicas: 1
  selector:
    matchLabels:
      test: alpine
  template:
    metadata:
      labels:
        test: alpine
        name: test
    spec:
      containers:
      - image: mritd/alpine:3.4
        name: alpine
        resources:
          limits:
            cpu: 200m
            memory: 30Mi
          requests:
            cpu: 100m
            memory: 20Mi
        ports:
        - name: http
          containerPort: 80
        args:
        command:
        - &amp;quot;bash&amp;quot;
        - &amp;quot;-c&amp;quot;
        - &amp;quot;echo ok &amp;gt; /tmp/health;sleep 120;rm -f /tmp/health&amp;quot;
        livenessProbe:
          exec:
            command:
            - cat
            - /tmp/health
          initialDelaySeconds: 20
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;test-health 的 service：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 traefik]# vim test-health-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: test 
  labels:
    name: test
spec:
  ports:
  - port: 8123
    targetPort: 80
  selector:
    name: test
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;test-health的 Ingress：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@node1 traefik]# vim test-health-ingress.yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: test
spec:
  rules:
  - host: test.com
    http:
      paths:
      - path: /
        backend:
          serviceName: test
          servicePort: 8123
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;全部创建好以后，进入 traefik ui 界面，可以观察到每隔 2 分钟健康检查失败后，kubernetes 重建 pod，同时 traefik 会从后端列表中移除这个 pod。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Traefik介绍&quot;&gt;&lt;a href=&quot;#Traefik介绍&quot; class=&quot;headerlink&quot; title=&quot;Traefik介绍&quot;&gt;&lt;/a&gt;Traefik介绍&lt;/h2&gt;&lt;p&gt;traefik 是一个前端负载均衡器，对于微服务架构尤其是 kubernetes 等编排工具具有良好的支持；同 nginx 等相比，traefik 能够自动感知后端容器变化，从而实现自动服务发现。&lt;br&gt;
    
    </summary>
    
      <category term="容器编排" scheme="http://yoursite.com/categories/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/"/>
    
    
      <category term="Kubernetes" scheme="http://yoursite.com/tags/Kubernetes/"/>
    
  </entry>
  
</feed>
