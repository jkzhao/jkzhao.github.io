<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|consolas:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Spark," />





  <link rel="alternate" href="/atom.xml" title="jkzhao's blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico?v=5.0.1" />






<meta name="description" content="Spark介绍Apache SparkApache Spark是一个围绕速度、易用性和复杂分析构建的大数据处理框架(没有数据存储)。最初在2009年由加州大学伯克利分校的AMPLab开发，并于2010年成为Apache的开源项目之一。">
<meta name="keywords" content="Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark介绍及安装部署">
<meta property="og:url" content="http://yoursite.com/2017/08/11/Spark介绍及安装部署/index.html">
<meta property="og:site_name" content="jkzhao&#39;s blog">
<meta property="og:description" content="Spark介绍Apache SparkApache Spark是一个围绕速度、易用性和复杂分析构建的大数据处理框架(没有数据存储)。最初在2009年由加州大学伯克利分校的AMPLab开发，并于2010年成为Apache的开源项目之一。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/1.png">
<meta property="og:image" content="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/2.png">
<meta property="og:image" content="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/2.png">
<meta property="og:image" content="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/3.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/4.png">
<meta property="og:image" content="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/5.png">
<meta property="og:image" content="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/6.png">
<meta property="og:image" content="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/7.png">
<meta property="og:updated_time" content="2017-11-07T07:49:20.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark介绍及安装部署">
<meta name="twitter:description" content="Spark介绍Apache SparkApache Spark是一个围绕速度、易用性和复杂分析构建的大数据处理框架(没有数据存储)。最初在2009年由加州大学伯克利分校的AMPLab开发，并于2010年成为Apache的开源项目之一。">
<meta name="twitter:image" content="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/1.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 6287775856811050000,
      author: 'Author'
    }
  };
</script>

  <title> Spark介绍及安装部署 | jkzhao's blog </title>
</head>
<a href="https://github.com/you"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/38ef81f8aca64bb9a64448d0d70f1308ef5341ab/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6461726b626c75655f3132313632312e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png"></a>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?c179eb46ac47d3b4b1b9203b82ee5821";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <a href="https://github.com/jkzhao"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/38ef81f8aca64bb9a64448d0d70f1308ef5341ab/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6461726b626c75655f3132313632312e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png"></a>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">jkzhao's blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">学习 总结 思考</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-guestbook">
          <a href="/guestbook" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            留言
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="#" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'CziK4aDdRyzFJrfygnHH','2.0.0');
</script>



    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Spark介绍及安装部署
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-08-11T08:11:26+08:00" content="2017-08-11">
              2017-08-11
            </time>
            
              <span class="post-updated">
              &nbsp; | &nbsp; 更新于
              <time itemprop="dateUpdated" datetime="2017-11-07T15:49:20+08:00" content="2017-11-07">
              2017-11-07
              </time>
              </span>
            
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/实时处理/" itemprop="url" rel="index">
                    <span itemprop="name">实时处理</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/08/11/Spark介绍及安装部署/" class="leancloud_visitors" data-flag-title="Spark介绍及安装部署">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Spark介绍"><a href="#Spark介绍" class="headerlink" title="Spark介绍"></a>Spark介绍</h2><h3 id="Apache-Spark"><a href="#Apache-Spark" class="headerlink" title="Apache Spark"></a>Apache Spark</h3><p>Apache Spark是一个围绕速度、易用性和复杂分析构建的大数据处理框架(没有数据存储)。最初在2009年由加州大学伯克利分校的AMPLab开发，并于2010年成为Apache的开源项目之一。<br><a id="more"></a></p>
<h3 id="Hadoop和Spark"><a href="#Hadoop和Spark" class="headerlink" title="Hadoop和Spark"></a>Hadoop和Spark</h3><p>Hadoop常用于解决高吞吐、批量处理的业务场景，例如离线计算结果用于浏览量统计。如果需要实时查看浏览量统计信息，Hadoop显然不符合这样的要求。Spark通过内存计算能力极大地提高了大数据处理速度，满足了以上场景的需要。<br>与Hadoop和Storm等其他大数据和MapReduce技术相比，Spark有以下特点：<br><strong>1.快速处理能力</strong><br>随着实时大数据应用越来越多，Hadoop作为离线的高吞吐、低响应框架已不能满足这类需求。Hadoop MapReduce的Job将中间输出和结果存储在HDFS中，读写HDFS造成磁盘I/O称为瓶颈。Spark允许将中间输出和结果存储在内存中，避免了大量的磁盘I/O。同时Spark自身的DAG执行引擎也支持数据在内存中的计算。Spark官网声称性能比Hadoop快100倍，如图所示。即便是内存不足，需要磁盘I/O，其速度也是Hadoop的10倍以上。<br><img src="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/1.png" alt=""></p>
<p><strong>2.易于使用</strong><br>Spark现在支持Java、Scala、Python和R等语言编写应用程序，大大降低了使用者的门槛。自带了80多个高等级操作符，允许在Scala、Python、R的shell中进行交互式查询。</p>
<p><strong>3.通用性</strong><br>Spark支持SQL及Hive SQL对数据查询，支持流式计算、支持机器学习和图计算。而且除了Spark core以外，建立在其上的这些功能都是一些库，安装好Spark后，这些库就可以使用了。<br><img src="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/2.png" alt=""></p>
<p><strong>4.可用性高</strong><br>Spark自身实现了Standalone部署模式，还可以跑在Hadoop、Mesos、或者云上。此外，Spark还有丰富的数据源支持。Spark除了可以访问操作系统自身的文件系统和HDFS，还可以访问Cassandra、HBase、Hive、Tachyon以及任何Hadoop的数据源。</p>
<h3 id="Spark中的概念"><a href="#Spark中的概念" class="headerlink" title="Spark中的概念"></a>Spark中的概念</h3><ul>
<li><strong>RDD：</strong>弹性分布式数据集。</li>
<li><strong>Task：</strong>具体执行任务。Task分为ShuffleMapTask和ResultTask两种。ShuffleMapTask和ResultTask分别类似于Hadoop中的Map和Reduce。</li>
<li><strong>Job：</strong>用户提交的作业。一个Job可能由一到多个Task组成。</li>
<li><strong>Stage：</strong>Job分成的阶段。一个Job可能被划分为一到多个Stage。</li>
<li><strong>Partition：</strong>数据分区。即一个RDD的数据可以划分为多少个分区。</li>
<li><strong>NarrowDependency：</strong>窄依赖，即子RDD依赖于父RDD中固定的Partition。NarrowDependency分为OneToOneDependency和RangeDependency两种。</li>
<li><strong>ShuffleDependency：</strong>shuffle依赖，也称为宽依赖，即子RDD对父RDD中的所有Partition都有依赖。</li>
<li><strong>DAG：</strong>有向无环图。用于反映各RDD之间的依赖关系。</li>
</ul>
<h3 id="Spark生态系统"><a href="#Spark生态系统" class="headerlink" title="Spark生态系统"></a>Spark生态系统</h3><p>整个Spark主要由以下模块组成：</p>
<ul>
<li><strong>Spark Core：</strong>Spark的核心功能实现，包括：SparkContext的初始化(Driver Application通过SparkContext提交)、部署模式、存储体系、任务提交与执行、计算引擎等。</li>
<li><strong>Spark SQL：</strong>提供SQL处理能力，便于熟悉关系型数据库操作的工程师进行交互查询。此外，还为熟悉Hadoop的用户提供Hive SQL处理能力。</li>
<li><strong>Spark Streaming：</strong>提供流式计算处理能力，目前支持Kafka、Flume、Twitter、MQTT、ZeroMQ、Kinesis和简单的TCP套接字等数据源。此外，还提供窗口操作。</li>
<li><strong>GraphX：</strong>提供图计算处理能力，支持分布式。</li>
<li><strong>MLlib：</strong>提供机器学习相关的统计、分类、回归等领域的多种算法实现。其一致的API接口大大降低了用户的学习成本。<br>Spark SQL、Spark Streaming、GraphX、MLlib的能力都是建立在核心引擎之上。如下图所示。<br><img src="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/2.png" alt=""></li>
</ul>
<h4 id="Spark核心功能"><a href="#Spark核心功能" class="headerlink" title="Spark核心功能"></a>Spark核心功能</h4><p>Spark Core提供Spark最基础与最核心的功能，主要包括以下功能：</p>
<ul>
<li><strong>SparkContext：</strong>通常而言，Driver Application的执行和输出都是通过SparkContent来完成的，在正式提交Application之前，首先需要初始化SparkContent。SparkContent隐藏了网络通信、分布式部署、消息通信、存储能力、计算能力、缓存、测量系统、文件服务、Web服务等内容，应用程序开发者只需要使用SparkContent提供的API完成功能开发。SparkContent内置的DAGScheduler负责创建Job，将DAG中的RDD划分到不同的Stage，提交Stage等功能。内置的TaskScheduler负责资源的申请、任务的提交及请求集群对任务的调度等工作。</li>
<li><strong>存储体系：</strong>Spark优先考虑使用各节点的内存作为存储，当内存不足时才会考虑使用磁盘，这极大地减少了磁盘I/O，提升了任务执行效率，使得Spark适用于实时计算、流式计算等场景。此外，Spark还提供了以内存为中心的高容错的分布式文件系统Tachyon供用户进行选择。Tachyon能够为Spark提供可靠的内存级的文件共享服务。</li>
<li><strong>计算引擎：</strong>计算引擎由SparkContent中的DAGScheduler、RDD以及具体节点上的Executor负责执行的Map和Reduce任务组成。</li>
<li><strong>部署模式：</strong>由于单节点不足以提供足够的存储和计算能力，所以作为大数据处理的Spark在SparkContext的TaskScheduler组件中提供了对Standalone部署模式的实现和Yarn、Mesos等分布式资源管理系统的支持。通过使用Standallone、Yarn、Mesos等部署模式为Task分配计算资源，提高任务的并发执行效率。除了可用于实际生产环境的Standalone、Yarn、Mesos等部署模式外，Spark还提供了Local模式和local-cluster模式便于开发和调试。</li>
</ul>
<h4 id="Spark扩展功能"><a href="#Spark扩展功能" class="headerlink" title="Spark扩展功能"></a>Spark扩展功能</h4><ul>
<li>Spark SQL</li>
<li>Spark Streaming</li>
<li>GraphX</li>
<li>MLlib</li>
</ul>
<h3 id="Spark部署架构"><a href="#Spark部署架构" class="headerlink" title="Spark部署架构"></a>Spark部署架构</h3><h4 id="集群架构"><a href="#集群架构" class="headerlink" title="集群架构"></a>集群架构</h4><p>从集群部署的角度看，Spark集群由以下部分组成：</p>
<ul>
<li><strong>Cluster Manager：</strong>Spark的集群管理器，主要负责资源的分配与管理。集群管理器分配的资源属于一级分配，它将各个Worker上内存、CPU等资源分配给应用程序，但是并不负责对Executor的资源分配。目前Standalone、YARN、Mesos、EC2等都可以作为Spark的集群管理器。</li>
<li><strong>Worker：</strong>Spark的工作节点。对Spark应用程序来说，由集群管理器分配得到资源的Worker节点主要负责以下工作：创建Executor，将资源和任务进一步分配给Executor，同步资源信息给Cluster Manager。</li>
<li><strong>Executor：</strong>执行计算任务的一线进程。主要负责任务的执行以及与Worker、Driver App的信息同步。</li>
<li><strong>Driver App：</strong>客户端驱动程序，也可以理解问客户端应用程序，用于将任务程序转换为RDD和DAG，并与Cluster Manager进行通信与调度。<br><img src="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/3.jpg" alt=""></li>
</ul>
<h4 id="Spark部署模式"><a href="#Spark部署模式" class="headerlink" title="Spark部署模式"></a>Spark部署模式</h4><p><strong>1.一些概念</strong></p>
<ul>
<li><strong>Driver：</strong>应用驱动程序，可以理解为是老板的客户。</li>
<li><strong>Master：</strong>Spark的主控节点，可以理解为集群的老板。</li>
<li><strong>Worker：</strong>Spark的工作节点，可以理解为集群的各个主管。</li>
<li><strong>Executor：</strong>Spark的工作进程，由Worker监管，负责具体任务的执行。</li>
</ul>
<p><strong>2.Spark目前支持的部署方式</strong></p>
<ul>
<li><strong>本地部署模式：</strong>local、local[N]或者local[N, maxRetries]。主要用于代码调试和跟踪。不具备容错能力，所以不适用于生产环境。local部署模式只有Driver，没有Master和Worker，执行任务的Executor与Driver在同一个JVM进程内。</li>
<li><strong>本地集群部署模式：</strong>local-cluster[N, cores, memory]。也主要用于代码调试，是源码学习常用的模式。不具备容错能力，不能用于生产环境。local-cluster模式是一种伪分布式集群部署模式，Driver、Master和Worker在同一个JVM内，可以存在多个Worker，每个Worker会有多个Executor，但这些Executor都独自存在于一个JVM进程内。</li>
<li><strong>Standalone部署模式：</strong>spark://。具备容错能力并且支持分布式部署，所以可用于实际的生产。Driver在集群之外，可以是任意的客户端应用程序。Master部署于单独的进程，甚至应该在单独的机器节点上。Master有多个，但同时最多有只有一个处于激活状态。Worker部署于单独的进程，也推荐在单独的节点上部署。</li>
<li><strong>第三方部署模式：</strong>yarn-standalone、yarn-cluster、mesos://、zk://、simr://等。</li>
</ul>
<h2 id="安装部署spark"><a href="#安装部署spark" class="headerlink" title="安装部署spark"></a>安装部署spark</h2><p>Spark runs on Java 7+, Python 2.6+ and R 3.1+. For the Scala API, Spark 1.6.2 uses Scala 2.10. You will need to use a compatible Scala version (2.10.x).</p>
<h3 id="本地部署模式"><a href="#本地部署模式" class="headerlink" title="本地部署模式"></a>本地部署模式</h3><h4 id="下载安装JDK8"><a href="#下载安装JDK8" class="headerlink" title="下载安装JDK8"></a>下载安装JDK8</h4><pre><code># mkdir /usr/java
# tar zxf /usr/local/jdk-8u73-linux-x64.gz -C /usr/java/
# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.8.0_73
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
# source /etc/profile
</code></pre><h4 id="下载安装scala-2-10-6"><a href="#下载安装scala-2-10-6" class="headerlink" title="下载安装scala-2.10.6"></a>下载安装scala-2.10.6</h4><pre><code>[root@care ~]# cd /usr/local/
[root@care local]# tar zxf scala-2.10.6.tgz
[root@care local]# vim /etc/profile
# Scala environment
export SCALA_HOME=/usr/local/scala-2.10.6
export PATH=$SCALA_HOME/bin:$PATH
[root@care local]# source /etc/profile
</code></pre><p>查看是否成功：</p>
<pre><code>[root@care local]# scala -version
</code></pre><h4 id="配置登录自己不需要输入密码"><a href="#配置登录自己不需要输入密码" class="headerlink" title="配置登录自己不需要输入密码"></a>配置登录自己不需要输入密码</h4><pre><code>[root@care ~]# ssh-keygen -t rsa -P &apos;&apos;
[root@care ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@localhost
</code></pre><h4 id="下载安装spark"><a href="#下载安装spark" class="headerlink" title="下载安装spark"></a>下载安装spark</h4><p><a href="http://spark.apache.org/downloads.html，我这里选择编译好的二进制版本1.6.1" target="_blank" rel="external">http://spark.apache.org/downloads.html，我这里选择编译好的二进制版本1.6.1</a><br><img src="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/4.png" alt=""></p>
<pre><code>[root@care local]# tar zxf spark-1.6.1-bin-hadoop2.6.tgz
[root@care local]# mv spark-1.6.1-bin-hadoop2.6 spark-1.6.1
[root@care local]# vim /etc/profile
# Spark environment
export SPARK_HOME=/usr/local/spark-1.6.1
export PATH=$SPARK_HOME/bin:$PATH
[root@care local]# source /etc/profile

[root@care local]# cd spark-1.6.1/conf/
[root@care conf]# cp spark-env.sh.template spark-env.sh
[root@care conf]# vim spark-env.sh
export JAVA_HOME=/usr/java/jdk1.8.0_73
export SCALA_HOME=/usr/local/scala-2.10.6
export SPARK_MASTER_IP=172.16.7.119
export SPARK_WORKER_MEMORY=4G
</code></pre><p>如果要选择源码编译安装，Build方法网址：<br><a href="http://spark.apache.org/docs/latest/building-spark.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/building-spark.html</a></p>
<h4 id="启动spark"><a href="#启动spark" class="headerlink" title="启动spark"></a>启动spark</h4><pre><code>[root@care ~]# /usr/local/spark-1.6.1/sbin/start-all.sh
</code></pre><p>查看启动的进程：</p>
<pre><code>[root@care ~]# jps
</code></pre><h4 id="查看Web-UI"><a href="#查看Web-UI" class="headerlink" title="查看Web UI"></a>查看Web UI</h4><p><strong>Master UI：</strong><a href="http://172.16.7.119:8080/" target="_blank" rel="external">http://172.16.7.119:8080/</a><br><img src="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/5.png" alt=""><br><strong>Worker UI：</strong><a href="http://172.16.7.119:8081/" target="_blank" rel="external">http://172.16.7.119:8081/</a><br><img src="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/6.png" alt=""></p>
<h4 id="停止spark"><a href="#停止spark" class="headerlink" title="停止spark"></a>停止spark</h4><pre><code>[root@care ~]# /usr/local/spark-1.6.1/sbin/stop-all.sh
</code></pre><h3 id="Standalone模式部署spark-无HA"><a href="#Standalone模式部署spark-无HA" class="headerlink" title="Standalone模式部署spark (无HA)"></a>Standalone模式部署spark (无HA)</h3><p>Spark Standalone采用了Master/Slaves架构的集群模式，因此，存在着Master单点故障。<br>Spark提供了两种单点故障的解决方案：</p>
<ul>
<li>基于文件系统的单点恢复</li>
<li>基于ZooKeeper的Standby Masters<br>此模式主要用来做开发，因为开发时应用运行频率高，而且对Master故障的影响不大，最主要的是出现故障重新运行便可，不需要恢复。</li>
</ul>
<h4 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h4><table>
<thead>
<tr>
<th>主机名</th>
<th>IP地址</th>
<th>操作系统版本</th>
<th>安装软件</th>
</tr>
</thead>
<tbody>
<tr>
<td>spark17</td>
<td>172.16.206.17</td>
<td>CentOS 7.1</td>
<td>JDK8、scala-2.10.6、spark-1.6.1</td>
</tr>
<tr>
<td>spark31</td>
<td>172.16.206.31</td>
<td>CentOS 7.1</td>
<td>JDK8、scala-2.10.6、spark-1.6.1</td>
</tr>
<tr>
<td>spark132</td>
<td>172.16.206.32</td>
<td>CentOS 7.1</td>
<td>JDK8、scala-2.10.6、spark-1.6.1</td>
</tr>
</tbody>
</table>
<p>spark17作为Mater节点，其他两台作为Worker节点。</p>
<h4 id="节点时间同步"><a href="#节点时间同步" class="headerlink" title="节点时间同步"></a>节点时间同步</h4><p>采用NTP(Network Time Protocol)方式来实现, 选择一台机器, 作为集群的时间同步服务器, 然后分别配置服务端和集群其他机器。我这里以spark17机器(Hadoop集群机器)时间为准，其他机器同这台机器时间做同步。</p>
<h5 id="NTP服务端"><a href="#NTP服务端" class="headerlink" title="NTP服务端"></a>NTP服务端</h5><p>1.安装ntp服务</p>
<pre><code># yum install ntp -y
</code></pre><p>2.配置/etc/ntp.conf，这边采用本地机器作为时间的原点<br>注释server列表：</p>
<pre><code>server 0.centos.pool.ntp.org iburst
server 1.centos.pool.ntp.org iburst
server 2.centos.pool.ntp.org iburst
server 3.centos.pool.ntp.org iburst
</code></pre><p>添加如下内容：</p>
<pre><code>server 127.127.1.0 prefer
fudge 127.127.1.0 stratum 8
logfile /var/log/ntp.log
</code></pre><p>3.启动ntpd服务</p>
<pre><code># systemctl start ntpd
</code></pre><p>4.查看ntp服务状态</p>
<pre><code># systemctl status ntpd
</code></pre><p>5.加入开机启动</p>
<pre><code># systemctl enable ntpd
</code></pre><h5 id="NTP客户端"><a href="#NTP客户端" class="headerlink" title="NTP客户端"></a>NTP客户端</h5><p>1.安装ntp</p>
<pre><code># yum install ntpdate -y
</code></pre><p>2.配置crontab任务主动同步</p>
<pre><code># crontab -e
*/10 * * * * /usr/sbin/ntpdate 172.16.206.17;hwclock -w
</code></pre><h4 id="各节点配置hosts文件"><a href="#各节点配置hosts文件" class="headerlink" title="各节点配置hosts文件"></a>各节点配置hosts文件</h4><p>集群各主机都要配置：</p>
<pre><code># vim /etc/hosts
172.16.206.17 spark17
172.16.206.31 spark31
172.16.206.32 spark32
</code></pre><h4 id="下载安装JDK8-1"><a href="#下载安装JDK8-1" class="headerlink" title="下载安装JDK8"></a>下载安装JDK8</h4><p>集群每台机器都要安装JDK8。</p>
<pre><code># mkdir /usr/java
# tar zxf /usr/local/jdk-8u73-linux-x64.gz -C /usr/java/
# vim /etc/profile
export JAVA_HOME=/usr/java/jdk1.8.0_73
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
# source /etc/profile
</code></pre><h4 id="下载安装scala-2-10-6-1"><a href="#下载安装scala-2-10-6-1" class="headerlink" title="下载安装scala-2.10.6"></a>下载安装scala-2.10.6</h4><p>集群每个节点都需要安装scala。</p>
<pre><code># cd /usr/local/
# tar zxf scala-2.10.6.tgz
# vim /etc/profile
# Scala environment
export SCALA_HOME=/usr/local/scala-2.10.6
export PATH=$SCALA_HOME/bin:$PATH
# source /etc/profile
</code></pre><p>查看是否成功：</p>
<pre><code># scala -version
</code></pre><h4 id="配置主节点登录自己和其他节点不需要输入密码"><a href="#配置主节点登录自己和其他节点不需要输入密码" class="headerlink" title="配置主节点登录自己和其他节点不需要输入密码"></a>配置主节点登录自己和其他节点不需要输入密码</h4><p>生成一对密钥：</p>
<pre><code>[root@spark17 ~]# ssh-keygen -t rsa -P &apos;&apos;
</code></pre><p>拷贝公钥到自己和其他节点：</p>
<pre><code>[root@spark17 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@spark17
[root@spark17 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@spark31
[root@spark17 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@spark32
</code></pre><h4 id="安装配置spark"><a href="#安装配置spark" class="headerlink" title="安装配置spark"></a>安装配置spark</h4><p>我这里下载的是Spark的编译版本spark-1.6.1-bin-hadoop2.6.tgz，否则需要自己事先自行编译。<br><strong>先在master机器上(172.16.206.17)安装spark：</strong></p>
<pre><code>[root@spark17 ~]# cd /usr/local/
[root@spark17 local]# tar zxf spark-1.6.1-bin-hadoop2.6.tgz
[root@spark17 local]# mv spark-1.6.1-bin-hadoop2.6 spark-1.6.1
[root@spark17 local]# vim /etc/profile
# Spark environment
export SPARK_HOME=/usr/local/spark-1.6.1
export PATH=$SPARK_HOME/bin:$PATH
[root@spark17 local]# source /etc/profile
</code></pre><p><strong>配置spark：</strong><br><strong>修改spark-env.sh文件：</strong></p>
<pre><code>[root@spark17 local]# cd spark-1.6.1/conf/
[root@ spark17 conf]# cp spark-env.sh.template spark-env.sh
[root@ spark17 conf]# vim spark-env.sh
export JAVA_HOME=/usr/java/jdk1.8.0_73
export SCALA_HOME=/usr/local/scala-2.10.6
export SPARK_MASTER_IP=spark17
export SPARK_MASTER_PORT=7077
export SPARK_WORKER_CORES=1
export SPARK_WORDER_INSTANCES=1
export SPARK_WORKER_MEMORY=4G
</code></pre><p><strong>修改slave文件：</strong>只需要在slave文件中写入各节点的主机名即可，包括master的主机名。</p>
<pre><code>[root@spark17 conf]# cp slaves.template slaves
[root@spark17 conf]# vim slaves
</code></pre><p><img src="https://raw.githubusercontent.com/jkzhao/MarkdownPictures/master/Spark/7.png" alt=""></p>
<p>一旦创建好文件， 你就可以使用下面的shell脚本启动或者停止你的集群了。 这些脚本基于Hadoop的发布脚本， 可以在SPARK_HOME/bin找到:</p>
<ul>
<li>sbin/start-master.sh：在脚本执行的机器上启动master.</li>
<li>sbin/start-slaves.sh：启动conf/slaves 文件中配置的所有的slave.</li>
<li>sbin/start-all.sh：启动上面描述的master和salve.</li>
<li>sbin/stop-master.sh：停止bin/start-master.sh 脚本启动的master.</li>
<li>sbin/stop-slaves.sh：停止conf/slaves 文件中配置的slave.</li>
<li>sbin/stop-all.sh：停止上面描述的master和slave.</li>
</ul>
<p><strong>【注意】:这些脚本必须在你想运行的master机器上执行，而不是你的本地机。</strong></p>
<p>将master上配置好的spark通过scp复制到其他各个节点上（注意其他节点上的profile文件也要一致）</p>
<pre><code>[root@spark17 ~]# scp -r /usr/local/spark-1.6.1 root@spark31:/usr/local/
[root@spark17 ~]# scp -r /usr/local/spark-1.6.1 root@spark32:/usr/local/
[root@spark31 local]# vim /etc/profile
# Spark environment
export SPARK_HOME=/usr/local/spark-1.6.1
export PATH=$SPARK_HOME/bin:$PATH
[root@spark31 local]# source /etc/profile
</code></pre><h4 id="启动spark-1"><a href="#启动spark-1" class="headerlink" title="启动spark"></a>启动spark</h4><p>在master上一次性启动集群：</p>
<pre><code>[root@spark17 ~]# cd /usr/local/spark-1.6.1/sbin/
[root@spark17 sbin]# ./start-all.sh
</code></pre><h4 id="停止spark-1"><a href="#停止spark-1" class="headerlink" title="停止spark"></a>停止spark</h4><pre><code>[root@spark17 ~]# cd /usr/local/spark-1.6.1/sbin/
[root@spark17 sbin]# ./stop-all.sh
</code></pre>
      
    </div>

    <div>
      
        
      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Spark/" rel="tag"><i class="fa fa-tag"></i>Spark</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/07/27/Ansible实战：部署分布式日志系统/" rel="next" title="Ansible实战：部署分布式日志系统">
                <i class="fa fa-chevron-left"></i> Ansible实战：部署分布式日志系统
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/08/14/Docker介绍/" rel="prev" title="Docker介绍">
                Docker介绍 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


      <div id="lv-container" data-id="city" data-uid="MTAyMC8yODkyNi81NDk1"></div>

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="Zhao Jiankai" />
          <p class="site-author-name" itemprop="name">Zhao Jiankai</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">64</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">23</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/jkzhao" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/3566507667/profile?rightmod=1&wvr=6&mod=personinfo&is_all=1" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  微博
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.importnew.com/" title="ImportNew" target="_blank">ImportNew</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark介绍"><span class="nav-number">1.</span> <span class="nav-text">Spark介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Apache-Spark"><span class="nav-number">1.1.</span> <span class="nav-text">Apache Spark</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop和Spark"><span class="nav-number">1.2.</span> <span class="nav-text">Hadoop和Spark</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark中的概念"><span class="nav-number">1.3.</span> <span class="nav-text">Spark中的概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark生态系统"><span class="nav-number">1.4.</span> <span class="nav-text">Spark生态系统</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Spark核心功能"><span class="nav-number">1.4.1.</span> <span class="nav-text">Spark核心功能</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Spark扩展功能"><span class="nav-number">1.4.2.</span> <span class="nav-text">Spark扩展功能</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark部署架构"><span class="nav-number">1.5.</span> <span class="nav-text">Spark部署架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#集群架构"><span class="nav-number">1.5.1.</span> <span class="nav-text">集群架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Spark部署模式"><span class="nav-number">1.5.2.</span> <span class="nav-text">Spark部署模式</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装部署spark"><span class="nav-number">2.</span> <span class="nav-text">安装部署spark</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#本地部署模式"><span class="nav-number">2.1.</span> <span class="nav-text">本地部署模式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#下载安装JDK8"><span class="nav-number">2.1.1.</span> <span class="nav-text">下载安装JDK8</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#下载安装scala-2-10-6"><span class="nav-number">2.1.2.</span> <span class="nav-text">下载安装scala-2.10.6</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#配置登录自己不需要输入密码"><span class="nav-number">2.1.3.</span> <span class="nav-text">配置登录自己不需要输入密码</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#下载安装spark"><span class="nav-number">2.1.4.</span> <span class="nav-text">下载安装spark</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#启动spark"><span class="nav-number">2.1.5.</span> <span class="nav-text">启动spark</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#查看Web-UI"><span class="nav-number">2.1.6.</span> <span class="nav-text">查看Web UI</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#停止spark"><span class="nav-number">2.1.7.</span> <span class="nav-text">停止spark</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Standalone模式部署spark-无HA"><span class="nav-number">2.2.</span> <span class="nav-text">Standalone模式部署spark (无HA)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#环境信息"><span class="nav-number">2.2.1.</span> <span class="nav-text">环境信息</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#节点时间同步"><span class="nav-number">2.2.2.</span> <span class="nav-text">节点时间同步</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#NTP服务端"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">NTP服务端</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#NTP客户端"><span class="nav-number">2.2.2.2.</span> <span class="nav-text">NTP客户端</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#各节点配置hosts文件"><span class="nav-number">2.2.3.</span> <span class="nav-text">各节点配置hosts文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#下载安装JDK8-1"><span class="nav-number">2.2.4.</span> <span class="nav-text">下载安装JDK8</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#下载安装scala-2-10-6-1"><span class="nav-number">2.2.5.</span> <span class="nav-text">下载安装scala-2.10.6</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#配置主节点登录自己和其他节点不需要输入密码"><span class="nav-number">2.2.6.</span> <span class="nav-text">配置主节点登录自己和其他节点不需要输入密码</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#安装配置spark"><span class="nav-number">2.2.7.</span> <span class="nav-text">安装配置spark</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#启动spark-1"><span class="nav-number">2.2.8.</span> <span class="nav-text">启动spark</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#停止spark-1"><span class="nav-number">2.2.9.</span> <span class="nav-text">停止spark</span></a></li></ol></li></ol></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhao Jiankai</span>
</div>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共169.6k字</span>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  



  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  


  
  
  

  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("r9OTvh5qdm5WfVnhJBm4XoP9-gzGzoHsz", "VAES8qziiwbdUq0IzdQVj5xD");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
    <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  
</body>
</html>
